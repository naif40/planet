{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "from tempfile import TemporaryFile\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(x):\n",
    "    if random.random() < 0.5:\n",
    "        x=np.fliplr(x)\n",
    "    else:\n",
    "        x=x\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_train_data(batch_size,img_dir,labels_file):\n",
    "\n",
    "  filenames = os.listdir(img_dir) #list of images in folder\n",
    "  labels_df=pd.read_csv(open(labels_file,'rU'), encoding='utf-8', engine='c') #reads the csv file which contains labels/reggression values\n",
    "\n",
    "\n",
    "  train_set=filenames[2000:] #all except first 2000 will be used for training\n",
    "\n",
    "  batch_img=[]\n",
    "  batch_labels=[]\n",
    "  while True:\n",
    "      random.shuffle(train_set) #shuffles the dataset\n",
    "\n",
    "      for filename in train_set:\n",
    "\n",
    "          if not filename.__contains__(\"png\"):        #MaxOSX adds a .DS_STORE metadata file in every folder, this is for skipping that\n",
    "              continue\n",
    "\n",
    "          img=rotate(cv2.imread(os.path.join(img_dir,filename),0))\n",
    "\n",
    "          label = np.around(labels_df[labels_df['images'] == filename]['sa1000'].values[0],decimals=3)\n",
    "\n",
    "          batch_img.append(img)\n",
    "          batch_labels.append(label)\n",
    "\n",
    "          if len(batch_img) == batch_size:\n",
    "\n",
    "              yield np.expand_dims(np.array(batch_img),axis=-1), np.expand_dims(np.array(batch_labels),axis=-1)\n",
    "\n",
    "              batch_img = []\n",
    "              batch_labels=[]\n",
    "              \n",
    "def get_test_data(batch_size,img_dir,labels_file):\n",
    "  filenames = os.listdir(img_dir) \n",
    "  labels_df=pd.read_csv(open(labels_file,'rU'), encoding='utf-8', engine='c')\n",
    "  test_set=filenames[:2000]\n",
    "\n",
    "  batch_img=[]\n",
    "  batch_labels=[]\n",
    "  while True:\n",
    "\n",
    "      random.shuffle(test_set)\n",
    "\n",
    "      for filename in test_set:\n",
    "\n",
    "          if not filename.__contains__(\"png\"):        #MaxOSX adds a .DS_STORE metadata file in every folder, this is for skipping that\n",
    "              continue\n",
    "\n",
    "          img=rotate(cv2.imread(os.path.join(img_dir,filename),0))\n",
    "          label = np.around(labels_df[labels_df['images'] == filename]['sa1000'].values[0],decimals=3)\n",
    "\n",
    "          batch_img.append(img)\n",
    "          batch_labels.append(label)\n",
    "\n",
    "          if len(batch_img) == batch_size:\n",
    "\n",
    "              yield np.expand_dims(np.array(batch_img),axis=-1), np.expand_dims(np.array(batch_labels),axis=-1)\n",
    "              batch_img = []\n",
    "              batch_labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    # size of window   movement of window\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def averagepool(x):\n",
    "    # size of window   movement of window\n",
    "    return tf.nn.averagepool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "def l2_loss(gt, logits, thresh=1):\n",
    "    print(gt.get_shape() ,logits.get_shape())\n",
    "    square_loss = (tf.squeeze(gt) - tf.squeeze(logits)) ** 2\n",
    "\n",
    "    return tf.reduce_mean(square_loss, axis=-1)\n",
    " \n",
    "    \n",
    "def l1_loss(gt, logits, thresh=1):\n",
    "    print(gt.get_shape() ,logits.get_shape())\n",
    "    loss = tf.abs(tf.squeeze(gt) - tf.squeeze(logits))\n",
    "\n",
    "    return tf.reduce_mean(loss, axis=-1)\n",
    "  \n",
    "  #Commonly Used Loss Function https://en.wikipedia.org/wiki/Huber_loss\n",
    "def smooth_l1_loss(gt, logits,sigma=0.5):\n",
    "    gt=tf.squeeze(gt)\n",
    "    logits=tf.squeeze(logits)\n",
    "    with tf.variable_scope(\"L1_Loss\"):\n",
    "        absolute_loss = tf.abs(gt - logits)\n",
    "        square_loss = 0.5 * (gt - logits) ** 2\n",
    "        l1_loss = tf.where(tf.less(absolute_loss, sigma), square_loss, absolute_loss - sigma/2)\n",
    "\n",
    "    return tf.reduce_mean(l1_loss, axis=-1)\n",
    "  \n",
    "def cnn1(x, TR_BIT = True):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,1,32],dtype=tf.float32, stddev=0.1)),\n",
    "               'W_fc':tf.Variable(tf.random_normal([4096*32,1024],dtype=tf.float32, stddev=0.1)),\n",
    "               'out':tf.Variable(tf.random_normal([1024, 1],dtype=tf.float32, stddev=0.1))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1]))}\n",
    "\n",
    "    #x = tf.reshape(x, shape=[None, 200, 200, 1])\n",
    "    print(x.get_shape())\n",
    "\n",
    "    bn1 = tf.layers.batch_normalization(conv2d(x, weights['W_conv1']) + biases['b_conv1'],training= TR_BIT)\n",
    "    conv1 = tf.nn.sigmoid(bn1)\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    print(conv1.get_shape())\n",
    "\n",
    "    fc = tf.reshape(conv1,[-1,4096*32])\n",
    "    fc = tf.nn.sigmoid(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, 0.8)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "    print(output.get_shape())\n",
    "    return output\n",
    "\n",
    "\n",
    "def convolutional_neural_network1(x, TR_BIT = True):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,1,32],dtype=tf.float32, stddev=0.1)),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3,3,32,32],dtype=tf.float32, stddev=0.1)),\n",
    "               'W_conv3':tf.Variable(tf.random_normal([3,3,32,64],dtype=tf.float32, stddev=0.1)),\n",
    "               'W_conv4':tf.Variable(tf.random_normal([3,3,64,128],dtype=tf.float32, stddev=0.1)),\n",
    "               'W_conv5':tf.Variable(tf.random_normal([3,3,128,256],dtype=tf.float32, stddev=0.1)),\n",
    "               'W_fc':tf.Variable(tf.random_normal([16*256,1024],dtype=tf.float32, stddev=0.1)),\n",
    "               'out':tf.Variable(tf.random_normal([1024, 1],dtype=tf.float32, stddev=0.1))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv3':tf.Variable(tf.random_normal([64])),\n",
    "               'b_conv4':tf.Variable(tf.random_normal([128])),\n",
    "               'b_conv5':tf.Variable(tf.random_normal([256])),\n",
    "\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1]))}\n",
    "\n",
    "    #x = tf.reshape(x, shape=[None, 200, 200, 1])\n",
    "    print(x.get_shape())\n",
    "\n",
    "    bn1 = tf.layers.batch_normalization(conv2d(x, weights['W_conv1']) + biases['b_conv1'],training= TR_BIT)\n",
    "    conv1 = tf.nn.relu(bn1)\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    print(conv1.get_shape())\n",
    "\n",
    "    bn2  = tf.layers.batch_normalization(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'],training= TR_BIT)\n",
    "    conv2 = tf.nn.relu(bn2)\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    print(conv2.get_shape())\n",
    "    \n",
    "    bn3  = tf.layers.batch_normalization(conv2d(conv2, weights['W_conv3']) + biases['b_conv3'],training= TR_BIT)\n",
    "    conv3 = tf.nn.relu(bn3)\n",
    "    conv3 = maxpool2d(conv3)\n",
    "    print(conv3.get_shape())\n",
    "    \n",
    "    bn4 = tf.layers.batch_normalization(conv2d(conv3, weights['W_conv4']) + biases['b_conv4'],training= TR_BIT)\n",
    "    conv4 = tf.nn.relu(bn4)\n",
    "    conv4 = maxpool2d(conv4)\n",
    "    print(conv4.get_shape())\n",
    "\n",
    "    bn5 = tf.layers.batch_normalization(conv2d(conv4, weights['W_conv5']) + biases['b_conv5'],training= TR_BIT)\n",
    "    conv5 = tf.nn.relu(bn5)\n",
    "    conv5 = maxpool2d(conv5)\n",
    "    print(conv5.get_shape())\n",
    "\n",
    "\n",
    "    fc = tf.reshape(conv5,[-1,16*256])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, 0.8)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "#     output= tf.nn.sigmoid(output)\n",
    "    print(output.get_shape())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir= r'C:\\Users\\Peyman\\Desktop\\Naif\\Journal\\images'\n",
    "labels_file= r'C:\\Users\\Peyman\\Desktop\\Naif\\Journal\\lgg.csv'\n",
    "ckpt_dir= r'C:\\Users\\Peyman\\Desktop\\Naif\\Journal\\checkpoint'\n",
    "load=0\n",
    "batch_size = 256\n",
    "number_files=len(os.listdir(r'C:\\Users\\Peyman\\Desktop\\Naif\\Journal\\images'))\n",
    "next_train_batch=get_train_data(batch_size,img_dir,labels_file)\n",
    "next_test_batch=get_test_data(batch_size,img_dir,labels_file)\n",
    "name='_jgsa1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(): \n",
    "#   outfile = TemporaryFile()\n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allow_growth = True\n",
    "#   config = tf.ConfigProto(\n",
    "#         device_count = {'GPU': 0}\n",
    "#     )\n",
    "  \n",
    "  images = tf.placeholder(dtype=tf.float32, shape=[None, 128,128, 1], name=\"inp_batch\")\n",
    "  y = tf.placeholder(dtype=tf.float32, shape=[None,1], name=\"inp_batch\")\n",
    "\n",
    "  logits=convolutional_neural_network1(images)\n",
    "  #logits=vgg(images)\n",
    "  timing=[]\n",
    "  \n",
    "\n",
    "  loss = smooth_l1_loss(y,logits)\n",
    "  #loss = l2_loss(y, logits)\n",
    "  optimizer = tf.train.AdamOptimizer(1e-5).minimize(loss)\n",
    "\n",
    "  #for saving a checkpoint after 50 epochs\n",
    "  saver = tf.train.Saver(max_to_keep = 100)\n",
    "\n",
    "  hm_epochs = 300\n",
    "  with tf.Session(config=config) as sess:\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      starting_epoch=1\n",
    "      if load > 0:\n",
    "          print(\"Restoring\", load, \".ckpt.....\")\n",
    "          saver.restore(sess, os.path.join(ckpt_dir,\"backup\"+ str(name)+ str(load)))\n",
    "          starting_epoch=load+1\n",
    "\n",
    "      for epoch in range(starting_epoch,hm_epochs):\n",
    "  \n",
    "          epoch_loss = 0\n",
    "\n",
    "          for i in range(int((number_files-2000)/batch_size)):\n",
    "\n",
    "            start=time.time()\n",
    "            batch_x, batch_y = next(next_train_batch)\n",
    "            _, step_loss = sess.run([optimizer, loss], feed_dict={images: batch_x, y: batch_y})\n",
    "            epoch_loss += step_loss\n",
    "            end= time.time()\n",
    "            timing.append(end-start)\n",
    "\n",
    "            print('#Epoch {} with total epochs {} at step {} loss: {} running average of batch loss {}, time {}'.format(epoch,hm_epochs,i, step_loss, epoch_loss/(i+1), time.time()-start))    \n",
    "            with open('losses'+str(name)+'.txt','a') as loss_file:\n",
    "            \tloss_file.write('#Epoch {} with total epochs {} at step {} loss: {} running average of batch loss {}\\n'.format(epoch,hm_epochs,i, step_loss, epoch_loss/(i+1)))\n",
    "          \n",
    "    \n",
    "          if epoch%20==0:\n",
    "        \n",
    "\n",
    "              error = []\n",
    "              gt=[]\n",
    "              predic=[]\n",
    "\n",
    "              for i in range(int(2000/batch_size)):\n",
    "                    batch_x, batch_y = next(next_test_batch)\n",
    "                    pred = sess.run([logits], feed_dict={images: batch_x})\n",
    "                    error.append(np.mean(abs(pred-batch_y)))\n",
    "                    predic.append(pred)\n",
    "                    gt.append(batch_y)\n",
    "\n",
    "              print( \"avg difference between predicted and ground truth batch wise {}\".format(np.mean(np.array(error))))\n",
    "              with open('losses'+str(name)+'.txt','a') as loss_file:\n",
    "                loss_file.write(\"avg difference between predicted and ground truth batch wise {}\\n\".format(np.mean(np.array(error))))\n",
    "               \n",
    "          if epoch% (hm_epochs-1)==0:\n",
    "              error = []\n",
    "              gt=[]\n",
    "              predic=[]\n",
    "\n",
    "              for i in range(int(2000/batch_size)):\n",
    "                    batch_x, batch_y = next(next_test_batch)\n",
    "                    pred = sess.run([logits], feed_dict={images: batch_x})\n",
    "                    error.append(np.mean(abs(pred-batch_y)))\n",
    "                    predic.append(pred)\n",
    "                    gt.append(batch_y)\n",
    "\n",
    "              print( \"avg difference between predicted and ground truth batch wise {}\".format(np.mean(np.array(error))))\n",
    "              with open('losses'+str(name)+'.txt','a') as loss_file:\n",
    "                loss_file.write(\"avg difference between predicted and ground truth batch wise {}\\n\".format(np.mean(np.array(error))))\n",
    "               \n",
    "            \n",
    "              np.save(str(epoch)+'gt'+str(name)+'.npy',gt)\n",
    "              np.save(str(epoch)+'predic'+str(name)+'.npy', predic)  \n",
    "\n",
    "                \n",
    "                \n",
    "        \n",
    "                \n",
    "#           if epoch%999==0:\n",
    "        \n",
    "\n",
    "#           for i in range(10):\n",
    "\n",
    "#                     batch_x, batch_y = next(next_test_batch)\n",
    "#                     error=[]  \n",
    "#                     pred = sess.run([logits], feed_dict={images: batch_x})\n",
    "#                     error.append(np.mean(abs(pred-batch_y)))\n",
    "#                     errors.append(error)\n",
    "#                     predic.append(pred)\n",
    "#                     gt.append(batch_y)\n",
    "                    \n",
    "\n",
    "                \n",
    "          \n",
    "\n",
    "#           np.savez(outfile,timing=timing,errors=errors,predic=predic,gt=gt)\n",
    "\n",
    "        \n",
    "          if epoch%10==0:\n",
    "                save_path = saver.save(sess, os.path.join(ckpt_dir, \"backup\"+str(name)+str(epoch)))\n",
    "          \n",
    "      print('D')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 128, 1)\n",
      "(?, 64, 64, 32)\n",
      "(?, 32, 32, 32)\n",
      "(?, 16, 16, 64)\n",
      "(?, 8, 8, 128)\n",
      "(?, 4, 4, 256)\n",
      "(?, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peyman\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: 'U' mode is deprecated\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 1 with total epochs 300 at step 0 loss: 65.18657684326172 running average of batch loss 65.18657684326172, time 8.856288433074951\n",
      "#Epoch 1 with total epochs 300 at step 1 loss: 62.643409729003906 running average of batch loss 63.91499328613281, time 0.9326634407043457\n",
      "#Epoch 1 with total epochs 300 at step 2 loss: 60.74011993408203 running average of batch loss 62.856702168782554, time 0.9526760578155518\n",
      "#Epoch 1 with total epochs 300 at step 3 loss: 58.621009826660156 running average of batch loss 61.79777908325195, time 0.9556779861450195\n",
      "#Epoch 1 with total epochs 300 at step 4 loss: 57.589412689208984 running average of batch loss 60.95610580444336, time 0.9676854610443115\n",
      "#Epoch 1 with total epochs 300 at step 5 loss: 56.68901824951172 running average of batch loss 60.244924545288086, time 0.9576807022094727\n",
      "#Epoch 1 with total epochs 300 at step 6 loss: 55.17842102050781 running average of batch loss 59.52113832746233, time 0.9397149085998535\n",
      "#Epoch 1 with total epochs 300 at step 7 loss: 52.40445327758789 running average of batch loss 58.63155269622803, time 0.9606833457946777\n",
      "#Epoch 1 with total epochs 300 at step 8 loss: 49.25258255004883 running average of batch loss 57.589444902208115, time 0.9441721439361572\n",
      "#Epoch 1 with total epochs 300 at step 9 loss: 46.459529876708984 running average of batch loss 56.476453399658205, time 0.9656851291656494\n",
      "#Epoch 1 with total epochs 300 at step 10 loss: 46.473758697509766 running average of batch loss 55.56711751764471, time 0.9382178783416748\n",
      "#Epoch 1 with total epochs 300 at step 11 loss: 45.660221099853516 running average of batch loss 54.74154281616211, time 0.9616811275482178\n",
      "#Epoch 1 with total epochs 300 at step 12 loss: 40.832942962646484 running average of batch loss 53.67165051973783, time 0.9485435485839844\n",
      "#Epoch 1 with total epochs 300 at step 13 loss: 42.442466735839844 running average of batch loss 52.86956596374512, time 0.9339263439178467\n",
      "#Epoch 1 with total epochs 300 at step 14 loss: 38.694602966308594 running average of batch loss 51.92456843058268, time 0.9331879615783691\n",
      "#Epoch 1 with total epochs 300 at step 15 loss: 36.68099594116211 running average of batch loss 50.9718451499939, time 0.9342288970947266\n",
      "#Epoch 1 with total epochs 300 at step 16 loss: 37.07080078125 running average of batch loss 50.154136657714844, time 0.9476714134216309\n",
      "#Epoch 1 with total epochs 300 at step 17 loss: 35.018394470214844 running average of batch loss 49.31326209174262, time 0.9496760368347168\n",
      "#Epoch 1 with total epochs 300 at step 18 loss: 33.078521728515625 running average of batch loss 48.45880207262541, time 0.9406659603118896\n",
      "#Epoch 1 with total epochs 300 at step 19 loss: 31.13074493408203 running average of batch loss 47.592399215698244, time 0.9282128810882568\n",
      "#Epoch 1 with total epochs 300 at step 20 loss: 27.81927490234375 running average of batch loss 46.65082186744327, time 0.949676513671875\n",
      "#Epoch 2 with total epochs 300 at step 0 loss: 26.748998641967773 running average of batch loss 26.748998641967773, time 0.941669225692749\n",
      "#Epoch 2 with total epochs 300 at step 1 loss: 27.736591339111328 running average of batch loss 27.24279499053955, time 0.9466714859008789\n",
      "#Epoch 2 with total epochs 300 at step 2 loss: 26.50368881225586 running average of batch loss 26.996426264444988, time 0.9476718902587891\n",
      "#Epoch 2 with total epochs 300 at step 3 loss: 24.10511016845703 running average of batch loss 26.273597240447998, time 0.9396672248840332\n",
      "#Epoch 2 with total epochs 300 at step 4 loss: 25.867870330810547 running average of batch loss 26.192451858520506, time 0.9236574172973633\n",
      "#Epoch 2 with total epochs 300 at step 5 loss: 22.30099868774414 running average of batch loss 25.54387633005778, time 0.9436686038970947\n",
      "#Epoch 2 with total epochs 300 at step 6 loss: 23.34596061706543 running average of batch loss 25.229888371058873, time 0.9552278518676758\n",
      "#Epoch 2 with total epochs 300 at step 7 loss: 23.17963981628418 running average of batch loss 24.973607301712036, time 0.9385898113250732\n",
      "#Epoch 2 with total epochs 300 at step 8 loss: 23.620912551879883 running average of batch loss 24.82330788506402, time 0.9248647689819336\n",
      "#Epoch 2 with total epochs 300 at step 9 loss: 20.79557991027832 running average of batch loss 24.42053508758545, time 0.96368408203125\n",
      "#Epoch 2 with total epochs 300 at step 10 loss: 20.987083435058594 running average of batch loss 24.108403119173918, time 0.9572539329528809\n",
      "#Epoch 2 with total epochs 300 at step 11 loss: 21.184045791625977 running average of batch loss 23.86470667521159, time 0.9456720352172852\n",
      "#Epoch 2 with total epochs 300 at step 12 loss: 21.041790008544922 running average of batch loss 23.647559239314152, time 0.9406676292419434\n",
      "#Epoch 2 with total epochs 300 at step 13 loss: 18.63186264038086 running average of batch loss 23.289295196533203, time 0.9350180625915527\n",
      "#Epoch 2 with total epochs 300 at step 14 loss: 19.773496627807617 running average of batch loss 23.05490862528483, time 0.933661937713623\n",
      "#Epoch 2 with total epochs 300 at step 15 loss: 20.900468826293945 running average of batch loss 22.9202561378479, time 0.9346656799316406\n",
      "#Epoch 2 with total epochs 300 at step 16 loss: 20.460128784179688 running average of batch loss 22.77554276410271, time 0.9677224159240723\n",
      "#Epoch 2 with total epochs 300 at step 17 loss: 19.835079193115234 running average of batch loss 22.61218367682563, time 0.969688892364502\n",
      "#Epoch 2 with total epochs 300 at step 18 loss: 20.16370964050293 running average of batch loss 22.48331662228233, time 0.9666860103607178\n",
      "#Epoch 2 with total epochs 300 at step 19 loss: 17.857341766357422 running average of batch loss 22.252017879486083, time 0.937664270401001\n",
      "#Epoch 2 with total epochs 300 at step 20 loss: 18.674083709716797 running average of batch loss 22.081640061878023, time 0.9416701793670654\n",
      "#Epoch 3 with total epochs 300 at step 0 loss: 19.672807693481445 running average of batch loss 19.672807693481445, time 0.9366641044616699\n",
      "#Epoch 3 with total epochs 300 at step 1 loss: 17.08138084411621 running average of batch loss 18.377094268798828, time 0.9266581535339355\n",
      "#Epoch 3 with total epochs 300 at step 2 loss: 19.857908248901367 running average of batch loss 18.870698928833008, time 0.9396674633026123\n",
      "#Epoch 3 with total epochs 300 at step 3 loss: 16.562711715698242 running average of batch loss 18.293702125549316, time 0.937664270401001\n",
      "#Epoch 3 with total epochs 300 at step 4 loss: 16.807376861572266 running average of batch loss 17.996437072753906, time 0.9406466484069824\n",
      "#Epoch 3 with total epochs 300 at step 5 loss: 16.938758850097656 running average of batch loss 17.820157368977863, time 0.9356746673583984\n",
      "#Epoch 3 with total epochs 300 at step 6 loss: 16.496885299682617 running average of batch loss 17.631118501935685, time 0.9391677379608154\n",
      "#Epoch 3 with total epochs 300 at step 7 loss: 15.291078567504883 running average of batch loss 17.338613510131836, time 0.9391801357269287\n",
      "#Epoch 3 with total epochs 300 at step 8 loss: 16.832788467407227 running average of batch loss 17.28241072760688, time 0.9396944046020508\n",
      "#Epoch 3 with total epochs 300 at step 9 loss: 16.200288772583008 running average of batch loss 17.17419853210449, time 0.9342188835144043\n",
      "#Epoch 3 with total epochs 300 at step 10 loss: 17.201717376708984 running average of batch loss 17.176700245250355, time 0.9406676292419434\n",
      "#Epoch 3 with total epochs 300 at step 11 loss: 13.983604431152344 running average of batch loss 16.910608927408855, time 0.9501891136169434\n",
      "#Epoch 3 with total epochs 300 at step 12 loss: 15.16774845123291 running average of batch loss 16.77654273693378, time 0.9397616386413574\n",
      "#Epoch 3 with total epochs 300 at step 13 loss: 13.596153259277344 running average of batch loss 16.549372059958323, time 0.9211537837982178\n",
      "#Epoch 3 with total epochs 300 at step 14 loss: 14.561356544494629 running average of batch loss 16.416837692260742, time 0.9391682147979736\n",
      "#Epoch 3 with total epochs 300 at step 15 loss: 13.129690170288086 running average of batch loss 16.21139097213745, time 0.9556782245635986\n",
      "#Epoch 3 with total epochs 300 at step 16 loss: 13.097014427185059 running average of batch loss 16.028192351846133, time 0.9386661052703857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 3 with total epochs 300 at step 17 loss: 12.777122497558594 running average of batch loss 15.84757735994127, time 0.9776937961578369\n",
      "#Epoch 3 with total epochs 300 at step 18 loss: 14.993975639343262 running average of batch loss 15.802650953594007, time 0.9506747722625732\n",
      "#Epoch 3 with total epochs 300 at step 19 loss: 13.453082084655762 running average of batch loss 15.685172510147094, time 0.9606828689575195\n",
      "#Epoch 3 with total epochs 300 at step 20 loss: 13.926064491271973 running average of batch loss 15.601405461629232, time 0.941666841506958\n",
      "#Epoch 4 with total epochs 300 at step 0 loss: 13.30561637878418 running average of batch loss 13.30561637878418, time 0.9336633682250977\n",
      "#Epoch 4 with total epochs 300 at step 1 loss: 13.096708297729492 running average of batch loss 13.201162338256836, time 0.9382033348083496\n",
      "#Epoch 4 with total epochs 300 at step 2 loss: 12.690814018249512 running average of batch loss 13.031046231587728, time 0.9336621761322021\n",
      "#Epoch 4 with total epochs 300 at step 3 loss: 13.961540222167969 running average of batch loss 13.263669729232788, time 0.9476714134216309\n",
      "#Epoch 4 with total epochs 300 at step 4 loss: 12.635284423828125 running average of batch loss 13.137992668151856, time 0.9286589622497559\n",
      "#Epoch 4 with total epochs 300 at step 5 loss: 11.99412727355957 running average of batch loss 12.947348435719809, time 0.9356622695922852\n",
      "#Epoch 4 with total epochs 300 at step 6 loss: 11.656373977661133 running average of batch loss 12.762923513139997, time 0.9386672973632812\n",
      "#Epoch 4 with total epochs 300 at step 7 loss: 12.745002746582031 running average of batch loss 12.760683417320251, time 0.9306371212005615\n",
      "#Epoch 4 with total epochs 300 at step 8 loss: 11.697405815124512 running average of batch loss 12.642541461520725, time 0.9346654415130615\n",
      "#Epoch 4 with total epochs 300 at step 9 loss: 12.856281280517578 running average of batch loss 12.66391544342041, time 0.9416680335998535\n",
      "#Epoch 4 with total epochs 300 at step 10 loss: 12.113079071044922 running average of batch loss 12.613839409568094, time 0.9406452178955078\n",
      "#Epoch 4 with total epochs 300 at step 11 loss: 11.525833129882812 running average of batch loss 12.52317221959432, time 0.9416677951812744\n",
      "#Epoch 4 with total epochs 300 at step 12 loss: 11.720376968383789 running average of batch loss 12.461418738731972, time 0.9336624145507812\n",
      "#Epoch 4 with total epochs 300 at step 13 loss: 11.651756286621094 running average of batch loss 12.403585706438337, time 0.9426679611206055\n",
      "#Epoch 4 with total epochs 300 at step 14 loss: 12.313167572021484 running average of batch loss 12.397557830810547, time 0.9356410503387451\n",
      "#Epoch 4 with total epochs 300 at step 15 loss: 12.71930980682373 running average of batch loss 12.41766732931137, time 0.9416682720184326\n",
      "#Epoch 4 with total epochs 300 at step 16 loss: 11.108047485351562 running average of batch loss 12.34063086790197, time 0.9466700553894043\n",
      "#Epoch 4 with total epochs 300 at step 17 loss: 12.49349594116211 running average of batch loss 12.349123371971977, time 0.9266312122344971\n",
      "#Epoch 4 with total epochs 300 at step 18 loss: 11.682494163513184 running average of batch loss 12.314037624158358, time 0.9286608695983887\n",
      "#Epoch 4 with total epochs 300 at step 19 loss: 11.141467094421387 running average of batch loss 12.255409097671508, time 0.9406664371490479\n",
      "#Epoch 4 with total epochs 300 at step 20 loss: 11.73155689239502 running average of batch loss 12.230463754563104, time 0.9326608180999756\n",
      "#Epoch 5 with total epochs 300 at step 0 loss: 12.13167953491211 running average of batch loss 12.13167953491211, time 0.9356656074523926\n",
      "#Epoch 5 with total epochs 300 at step 1 loss: 11.760326385498047 running average of batch loss 11.946002960205078, time 0.9396665096282959\n",
      "#Epoch 5 with total epochs 300 at step 2 loss: 11.988334655761719 running average of batch loss 11.960113525390625, time 0.9696869850158691\n",
      "#Epoch 5 with total epochs 300 at step 3 loss: 12.114241600036621 running average of batch loss 11.998645544052124, time 0.9516761302947998\n",
      "#Epoch 5 with total epochs 300 at step 4 loss: 11.444416046142578 running average of batch loss 11.887799644470215, time 0.9596819877624512\n",
      "#Epoch 5 with total epochs 300 at step 5 loss: 10.899388313293457 running average of batch loss 11.723064422607422, time 0.9466452598571777\n",
      "#Epoch 5 with total epochs 300 at step 6 loss: 11.743529319763184 running average of batch loss 11.725987979343959, time 0.9316596984863281\n",
      "#Epoch 5 with total epochs 300 at step 7 loss: 11.695751190185547 running average of batch loss 11.722208380699158, time 0.9486746788024902\n",
      "#Epoch 5 with total epochs 300 at step 8 loss: 10.98660945892334 running average of batch loss 11.64047516716851, time 0.9736926555633545\n",
      "#Epoch 5 with total epochs 300 at step 9 loss: 11.12767505645752 running average of batch loss 11.589195156097412, time 0.9526774883270264\n",
      "#Epoch 5 with total epochs 300 at step 10 loss: 11.068595886230469 running average of batch loss 11.541867949745871, time 0.9382376670837402\n",
      "#Epoch 5 with total epochs 300 at step 11 loss: 11.108535766601562 running average of batch loss 11.505756934483847, time 0.9416685104370117\n",
      "#Epoch 5 with total epochs 300 at step 12 loss: 11.94503402709961 running average of batch loss 11.539547480069674, time 0.9386451244354248\n",
      "#Epoch 5 with total epochs 300 at step 13 loss: 11.759105682373047 running average of batch loss 11.555230208805629, time 0.9436695575714111\n",
      "#Epoch 5 with total epochs 300 at step 14 loss: 12.244552612304688 running average of batch loss 11.601185035705566, time 0.9416685104370117\n",
      "#Epoch 5 with total epochs 300 at step 15 loss: 11.865713119506836 running average of batch loss 11.617718040943146, time 0.9356625080108643\n",
      "#Epoch 5 with total epochs 300 at step 16 loss: 11.267387390136719 running average of batch loss 11.597110355601592, time 0.9376657009124756\n",
      "#Epoch 5 with total epochs 300 at step 17 loss: 10.981627464294434 running average of batch loss 11.562916861640083, time 0.9406683444976807\n",
      "#Epoch 5 with total epochs 300 at step 18 loss: 11.540227890014648 running average of batch loss 11.561722705238743, time 0.9246566295623779\n",
      "#Epoch 5 with total epochs 300 at step 19 loss: 12.18307876586914 running average of batch loss 11.592790508270264, time 0.9386663436889648\n",
      "#Epoch 5 with total epochs 300 at step 20 loss: 11.939188003540039 running average of batch loss 11.609285627092634, time 0.9326598644256592\n",
      "#Epoch 6 with total epochs 300 at step 0 loss: 12.38622760772705 running average of batch loss 12.38622760772705, time 0.9326400756835938\n",
      "#Epoch 6 with total epochs 300 at step 1 loss: 11.513184547424316 running average of batch loss 11.949706077575684, time 0.9396653175354004\n",
      "#Epoch 6 with total epochs 300 at step 2 loss: 11.891473770141602 running average of batch loss 11.93029530843099, time 0.9326629638671875\n",
      "#Epoch 6 with total epochs 300 at step 3 loss: 11.357780456542969 running average of batch loss 11.787166595458984, time 0.9546792507171631\n",
      "#Epoch 6 with total epochs 300 at step 4 loss: 11.940937042236328 running average of batch loss 11.817920684814453, time 0.9436678886413574\n",
      "#Epoch 6 with total epochs 300 at step 5 loss: 11.294337272644043 running average of batch loss 11.73065678278605, time 0.9346656799316406\n",
      "#Epoch 6 with total epochs 300 at step 6 loss: 11.494014739990234 running average of batch loss 11.696850776672363, time 0.9666626453399658\n",
      "#Epoch 6 with total epochs 300 at step 7 loss: 11.633527755737305 running average of batch loss 11.688935399055481, time 0.9576795101165771\n",
      "#Epoch 6 with total epochs 300 at step 8 loss: 11.469511985778809 running average of batch loss 11.664555019802517, time 0.935664176940918\n",
      "#Epoch 6 with total epochs 300 at step 9 loss: 10.859817504882812 running average of batch loss 11.584081268310547, time 0.9546778202056885\n",
      "#Epoch 6 with total epochs 300 at step 10 loss: 11.031774520874023 running average of batch loss 11.533871563998135, time 0.9496760368347168\n",
      "#Epoch 6 with total epochs 300 at step 11 loss: 11.281770706176758 running average of batch loss 11.512863159179688, time 0.9636836051940918\n",
      "#Epoch 6 with total epochs 300 at step 12 loss: 11.470218658447266 running average of batch loss 11.509582812969501, time 0.9546775817871094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 6 with total epochs 300 at step 13 loss: 11.131133079528809 running average of batch loss 11.482550689152308, time 0.9546761512756348\n",
      "#Epoch 6 with total epochs 300 at step 14 loss: 12.366578102111816 running average of batch loss 11.541485850016276, time 0.9556798934936523\n",
      "#Epoch 6 with total epochs 300 at step 15 loss: 12.435315132141113 running average of batch loss 11.597350180149078, time 0.9496500492095947\n",
      "#Epoch 6 with total epochs 300 at step 16 loss: 11.136955261230469 running average of batch loss 11.570268126095042, time 0.9426701068878174\n",
      "#Epoch 6 with total epochs 300 at step 17 loss: 11.522345542907715 running average of batch loss 11.567605760362413, time 0.9433948993682861\n",
      "#Epoch 6 with total epochs 300 at step 18 loss: 12.544143676757812 running average of batch loss 11.619002492804276, time 0.9486727714538574\n",
      "#Epoch 6 with total epochs 300 at step 19 loss: 11.301239013671875 running average of batch loss 11.603114318847656, time 0.9636836051940918\n",
      "#Epoch 6 with total epochs 300 at step 20 loss: 11.146233558654785 running average of batch loss 11.581358092171806, time 0.9426686763763428\n",
      "#Epoch 7 with total epochs 300 at step 0 loss: 11.725549697875977 running average of batch loss 11.725549697875977, time 0.9321990013122559\n",
      "#Epoch 7 with total epochs 300 at step 1 loss: 10.448565483093262 running average of batch loss 11.08705759048462, time 0.9476728439331055\n",
      "#Epoch 7 with total epochs 300 at step 2 loss: 11.890729904174805 running average of batch loss 11.354948361714682, time 0.9406676292419434\n",
      "#Epoch 7 with total epochs 300 at step 3 loss: 11.810929298400879 running average of batch loss 11.46894359588623, time 0.9426684379577637\n",
      "#Epoch 7 with total epochs 300 at step 4 loss: 10.80765151977539 running average of batch loss 11.336685180664062, time 0.9336609840393066\n",
      "#Epoch 7 with total epochs 300 at step 5 loss: 10.573784828186035 running average of batch loss 11.209535121917725, time 0.9376673698425293\n",
      "#Epoch 7 with total epochs 300 at step 6 loss: 11.031591415405273 running average of batch loss 11.184114592415947, time 0.9416701793670654\n",
      "#Epoch 7 with total epochs 300 at step 7 loss: 11.132665634155273 running average of batch loss 11.177683472633362, time 0.9456713199615479\n",
      "#Epoch 7 with total epochs 300 at step 8 loss: 10.522273063659668 running average of batch loss 11.104860093858507, time 0.933661699295044\n",
      "#Epoch 7 with total epochs 300 at step 9 loss: 11.199012756347656 running average of batch loss 11.114275360107422, time 0.9462051391601562\n",
      "#Epoch 7 with total epochs 300 at step 10 loss: 11.838465690612793 running average of batch loss 11.180110844698818, time 0.93666672706604\n",
      "#Epoch 7 with total epochs 300 at step 11 loss: 11.558883666992188 running average of batch loss 11.2116752465566, time 0.9316384792327881\n",
      "#Epoch 7 with total epochs 300 at step 12 loss: 10.96798038482666 running average of batch loss 11.192929487961988, time 0.9477076530456543\n",
      "#Epoch 7 with total epochs 300 at step 13 loss: 11.077726364135742 running average of batch loss 11.184700693402972, time 0.9601829051971436\n",
      "#Epoch 7 with total epochs 300 at step 14 loss: 11.04345703125 running average of batch loss 11.17528444925944, time 0.936192512512207\n",
      "#Epoch 7 with total epochs 300 at step 15 loss: 11.455465316772461 running average of batch loss 11.192795753479004, time 0.973691463470459\n",
      "#Epoch 7 with total epochs 300 at step 16 loss: 11.433572769165039 running average of batch loss 11.206959107342888, time 0.9576807022094727\n",
      "#Epoch 7 with total epochs 300 at step 17 loss: 12.472208023071289 running average of batch loss 11.277250713772244, time 0.9546787738800049\n",
      "#Epoch 7 with total epochs 300 at step 18 loss: 11.172171592712402 running average of batch loss 11.271720233716463, time 0.9276580810546875\n",
      "#Epoch 7 with total epochs 300 at step 19 loss: 11.699427604675293 running average of batch loss 11.293105602264404, time 0.9406659603118896\n",
      "#Epoch 7 with total epochs 300 at step 20 loss: 11.55514144897461 running average of batch loss 11.305583499726795, time 0.9566807746887207\n",
      "#Epoch 8 with total epochs 300 at step 0 loss: 11.35423755645752 running average of batch loss 11.35423755645752, time 0.9506731033325195\n",
      "#Epoch 8 with total epochs 300 at step 1 loss: 10.633336067199707 running average of batch loss 10.993786811828613, time 0.947674036026001\n",
      "#Epoch 8 with total epochs 300 at step 2 loss: 10.904590606689453 running average of batch loss 10.964054743448893, time 0.9556779861450195\n",
      "#Epoch 8 with total epochs 300 at step 3 loss: 11.239402770996094 running average of batch loss 11.032891750335693, time 0.9556779861450195\n",
      "#Epoch 8 with total epochs 300 at step 4 loss: 11.494720458984375 running average of batch loss 11.12525749206543, time 0.9356627464294434\n",
      "#Epoch 8 with total epochs 300 at step 5 loss: 11.282878875732422 running average of batch loss 11.151527722676596, time 0.9326620101928711\n",
      "#Epoch 8 with total epochs 300 at step 6 loss: 11.742374420166016 running average of batch loss 11.235934393746513, time 0.9586796760559082\n",
      "#Epoch 8 with total epochs 300 at step 7 loss: 10.655696868896484 running average of batch loss 11.163404703140259, time 0.9426679611206055\n",
      "#Epoch 8 with total epochs 300 at step 8 loss: 11.330381393432617 running average of batch loss 11.181957668728298, time 0.9306600093841553\n",
      "#Epoch 8 with total epochs 300 at step 9 loss: 12.087043762207031 running average of batch loss 11.272466278076172, time 0.943244218826294\n",
      "#Epoch 8 with total epochs 300 at step 10 loss: 10.763731002807617 running average of batch loss 11.226217616688121, time 0.9366641044616699\n",
      "#Epoch 8 with total epochs 300 at step 11 loss: 11.995497703552246 running average of batch loss 11.290324290593466, time 0.9436709880828857\n",
      "#Epoch 8 with total epochs 300 at step 12 loss: 11.660634994506836 running average of batch loss 11.318809729356031, time 0.9516873359680176\n",
      "#Epoch 8 with total epochs 300 at step 13 loss: 10.664761543273926 running average of batch loss 11.27209200177874, time 0.9316632747650146\n",
      "#Epoch 8 with total epochs 300 at step 14 loss: 10.984156608581543 running average of batch loss 11.252896308898926, time 0.9336655139923096\n",
      "#Epoch 8 with total epochs 300 at step 15 loss: 10.555841445922852 running average of batch loss 11.209330379962921, time 0.9426674842834473\n",
      "#Epoch 8 with total epochs 300 at step 16 loss: 11.302986145019531 running average of batch loss 11.21483954261331, time 0.9336621761322021\n",
      "#Epoch 8 with total epochs 300 at step 17 loss: 10.60226058959961 running average of batch loss 11.180807378556993, time 0.9346628189086914\n",
      "#Epoch 8 with total epochs 300 at step 18 loss: 10.787534713745117 running average of batch loss 11.160108817251105, time 0.9356410503387451\n",
      "#Epoch 8 with total epochs 300 at step 19 loss: 12.03843879699707 running average of batch loss 11.204025316238404, time 0.9566786289215088\n",
      "#Epoch 8 with total epochs 300 at step 20 loss: 11.356719017028809 running average of batch loss 11.21129644484747, time 0.9466710090637207\n",
      "#Epoch 9 with total epochs 300 at step 0 loss: 11.346465110778809 running average of batch loss 11.346465110778809, time 0.9586813449859619\n",
      "#Epoch 9 with total epochs 300 at step 1 loss: 10.98491096496582 running average of batch loss 11.165688037872314, time 0.9486749172210693\n",
      "#Epoch 9 with total epochs 300 at step 2 loss: 11.6429443359375 running average of batch loss 11.324773470560709, time 0.9516739845275879\n",
      "#Epoch 9 with total epochs 300 at step 3 loss: 10.85782527923584 running average of batch loss 11.208036422729492, time 0.9406688213348389\n",
      "#Epoch 9 with total epochs 300 at step 4 loss: 10.16177749633789 running average of batch loss 10.998784637451172, time 0.9296598434448242\n",
      "#Epoch 9 with total epochs 300 at step 5 loss: 11.393640518188477 running average of batch loss 11.064593950907389, time 0.9386661052703857\n",
      "#Epoch 9 with total epochs 300 at step 6 loss: 11.004453659057617 running average of batch loss 11.056002480643135, time 0.9586801528930664\n",
      "#Epoch 9 with total epochs 300 at step 7 loss: 10.297574043273926 running average of batch loss 10.961198925971985, time 0.9456713199615479\n",
      "#Epoch 9 with total epochs 300 at step 8 loss: 10.822290420532227 running average of batch loss 10.94576464758979, time 0.9516754150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 9 with total epochs 300 at step 9 loss: 11.308369636535645 running average of batch loss 10.982025146484375, time 0.947176456451416\n",
      "#Epoch 9 with total epochs 300 at step 10 loss: 10.772844314575195 running average of batch loss 10.963008707219904, time 0.9556796550750732\n",
      "#Epoch 9 with total epochs 300 at step 11 loss: 10.975235939025879 running average of batch loss 10.964027643203735, time 0.9366638660430908\n",
      "#Epoch 9 with total epochs 300 at step 12 loss: 10.681158065795898 running average of batch loss 10.942268444941593, time 0.9406683444976807\n",
      "#Epoch 9 with total epochs 300 at step 13 loss: 11.856911659240723 running average of batch loss 11.007600103105817, time 0.9426677227020264\n",
      "#Epoch 9 with total epochs 300 at step 14 loss: 11.007740020751953 running average of batch loss 11.007609430948893, time 0.9346649646759033\n",
      "#Epoch 9 with total epochs 300 at step 15 loss: 10.503604888916016 running average of batch loss 10.976109147071838, time 0.9356637001037598\n",
      "#Epoch 9 with total epochs 300 at step 16 loss: 9.473851203918457 running average of batch loss 10.887741032768698, time 0.9406661987304688\n",
      "#Epoch 9 with total epochs 300 at step 17 loss: 12.419463157653809 running average of batch loss 10.972836706373426, time 0.9306623935699463\n",
      "#Epoch 9 with total epochs 300 at step 18 loss: 10.728534698486328 running average of batch loss 10.959978705958315, time 0.94767165184021\n",
      "#Epoch 9 with total epochs 300 at step 19 loss: 11.317875862121582 running average of batch loss 10.97787356376648, time 0.9366655349731445\n",
      "#Epoch 9 with total epochs 300 at step 20 loss: 11.134806632995605 running average of batch loss 10.985346567063104, time 0.9376654624938965\n",
      "#Epoch 10 with total epochs 300 at step 0 loss: 11.47780704498291 running average of batch loss 11.47780704498291, time 0.947230339050293\n",
      "#Epoch 10 with total epochs 300 at step 1 loss: 10.675386428833008 running average of batch loss 11.076596736907959, time 0.9466710090637207\n",
      "#Epoch 10 with total epochs 300 at step 2 loss: 10.420775413513184 running average of batch loss 10.857989629109701, time 0.9286599159240723\n",
      "#Epoch 10 with total epochs 300 at step 3 loss: 11.09329605102539 running average of batch loss 10.916816234588623, time 0.9356658458709717\n",
      "#Epoch 10 with total epochs 300 at step 4 loss: 11.359925270080566 running average of batch loss 11.005438041687011, time 0.9456708431243896\n",
      "#Epoch 10 with total epochs 300 at step 5 loss: 10.970964431762695 running average of batch loss 10.999692440032959, time 0.9356629848480225\n",
      "#Epoch 10 with total epochs 300 at step 6 loss: 10.745404243469238 running average of batch loss 10.96336555480957, time 0.9666872024536133\n",
      "#Epoch 10 with total epochs 300 at step 7 loss: 10.03541374206543 running average of batch loss 10.847371578216553, time 0.9436700344085693\n",
      "#Epoch 10 with total epochs 300 at step 8 loss: 11.277181625366211 running average of batch loss 10.89512825012207, time 0.9386663436889648\n",
      "#Epoch 10 with total epochs 300 at step 9 loss: 10.504555702209473 running average of batch loss 10.85607099533081, time 0.939354419708252\n",
      "#Epoch 10 with total epochs 300 at step 10 loss: 11.06466007232666 running average of batch loss 10.87503363869407, time 0.940669059753418\n",
      "#Epoch 10 with total epochs 300 at step 11 loss: 10.229629516601562 running average of batch loss 10.821249961853027, time 0.9576797485351562\n",
      "#Epoch 10 with total epochs 300 at step 12 loss: 10.68795394897461 running average of batch loss 10.81099642240084, time 0.9576799869537354\n",
      "#Epoch 10 with total epochs 300 at step 13 loss: 10.159035682678223 running average of batch loss 10.76442779813494, time 0.9526755809783936\n",
      "#Epoch 10 with total epochs 300 at step 14 loss: 10.815361976623535 running average of batch loss 10.767823410034179, time 0.9576783180236816\n",
      "#Epoch 10 with total epochs 300 at step 15 loss: 11.232710838317871 running average of batch loss 10.79687887430191, time 0.9266605377197266\n",
      "#Epoch 10 with total epochs 300 at step 16 loss: 11.094901084899902 running average of batch loss 10.81440959257238, time 0.9576795101165771\n",
      "#Epoch 10 with total epochs 300 at step 17 loss: 10.576066970825195 running average of batch loss 10.801168335808647, time 0.9316611289978027\n",
      "#Epoch 10 with total epochs 300 at step 18 loss: 11.255513191223145 running average of batch loss 10.825081222935728, time 0.932661771774292\n",
      "#Epoch 10 with total epochs 300 at step 19 loss: 10.321466445922852 running average of batch loss 10.799900484085082, time 0.9396660327911377\n",
      "#Epoch 10 with total epochs 300 at step 20 loss: 11.454591751098633 running average of batch loss 10.831076258704776, time 0.9426684379577637\n",
      "#Epoch 11 with total epochs 300 at step 0 loss: 11.611299514770508 running average of batch loss 11.611299514770508, time 0.6164374351501465\n",
      "#Epoch 11 with total epochs 300 at step 1 loss: 11.152565002441406 running average of batch loss 11.381932258605957, time 0.6799931526184082\n",
      "#Epoch 11 with total epochs 300 at step 2 loss: 10.826027870178223 running average of batch loss 11.196630795796713, time 0.9461727142333984\n",
      "#Epoch 11 with total epochs 300 at step 3 loss: 11.000102043151855 running average of batch loss 11.147498607635498, time 0.9456708431243896\n",
      "#Epoch 11 with total epochs 300 at step 4 loss: 10.673904418945312 running average of batch loss 11.05277976989746, time 0.9356637001037598\n",
      "#Epoch 11 with total epochs 300 at step 5 loss: 10.973054885864258 running average of batch loss 11.03949228922526, time 0.9446718692779541\n",
      "#Epoch 11 with total epochs 300 at step 6 loss: 10.268391609191895 running average of batch loss 10.929335049220494, time 0.9366660118103027\n",
      "#Epoch 11 with total epochs 300 at step 7 loss: 11.646002769470215 running average of batch loss 11.018918514251709, time 0.9366650581359863\n",
      "#Epoch 11 with total epochs 300 at step 8 loss: 10.655906677246094 running average of batch loss 10.97858386569553, time 0.9376652240753174\n",
      "#Epoch 11 with total epochs 300 at step 9 loss: 11.665079116821289 running average of batch loss 11.047233390808106, time 0.9376652240753174\n",
      "#Epoch 11 with total epochs 300 at step 10 loss: 9.85195255279541 running average of batch loss 10.938571496443315, time 0.9233536720275879\n",
      "#Epoch 11 with total epochs 300 at step 11 loss: 10.28004264831543 running average of batch loss 10.883694092432657, time 0.932161808013916\n",
      "#Epoch 11 with total epochs 300 at step 12 loss: 10.744269371032715 running average of batch loss 10.872969113863432, time 0.9460480213165283\n",
      "#Epoch 11 with total epochs 300 at step 13 loss: 11.141420364379883 running average of batch loss 10.892144203186035, time 0.9428269863128662\n",
      "#Epoch 11 with total epochs 300 at step 14 loss: 11.413002967834473 running average of batch loss 10.926868120829264, time 0.972771406173706\n",
      "#Epoch 11 with total epochs 300 at step 15 loss: 10.082046508789062 running average of batch loss 10.874066770076752, time 0.9620811939239502\n",
      "#Epoch 11 with total epochs 300 at step 16 loss: 10.454169273376465 running average of batch loss 10.849366917329675, time 0.9649429321289062\n",
      "#Epoch 11 with total epochs 300 at step 17 loss: 11.256202697753906 running average of batch loss 10.871968905131022, time 0.9547178745269775\n",
      "#Epoch 11 with total epochs 300 at step 18 loss: 11.813549041748047 running average of batch loss 10.921525754426655, time 0.948706865310669\n",
      "#Epoch 11 with total epochs 300 at step 19 loss: 10.475950241088867 running average of batch loss 10.899246978759766, time 0.9431719779968262\n",
      "#Epoch 11 with total epochs 300 at step 20 loss: 10.999801635742188 running average of batch loss 10.904035295758929, time 0.9306602478027344\n",
      "#Epoch 12 with total epochs 300 at step 0 loss: 10.842426300048828 running average of batch loss 10.842426300048828, time 0.9356606006622314\n",
      "#Epoch 12 with total epochs 300 at step 1 loss: 10.194897651672363 running average of batch loss 10.518661975860596, time 0.9516773223876953\n",
      "#Epoch 12 with total epochs 300 at step 2 loss: 10.308865547180176 running average of batch loss 10.448729832967123, time 0.9466719627380371\n",
      "#Epoch 12 with total epochs 300 at step 3 loss: 10.76885986328125 running average of batch loss 10.528762340545654, time 0.9446694850921631\n",
      "#Epoch 12 with total epochs 300 at step 4 loss: 10.963308334350586 running average of batch loss 10.615671539306641, time 0.9356367588043213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 12 with total epochs 300 at step 5 loss: 10.79608154296875 running average of batch loss 10.645739873250326, time 0.9406697750091553\n",
      "#Epoch 12 with total epochs 300 at step 6 loss: 9.66850757598877 running average of batch loss 10.506135259355817, time 0.9438650608062744\n",
      "#Epoch 12 with total epochs 300 at step 7 loss: 11.483898162841797 running average of batch loss 10.628355622291565, time 0.942669153213501\n",
      "#Epoch 12 with total epochs 300 at step 8 loss: 10.492070198059082 running average of batch loss 10.613212797376844, time 0.9326605796813965\n",
      "#Epoch 12 with total epochs 300 at step 9 loss: 10.792912483215332 running average of batch loss 10.631182765960693, time 0.9366641044616699\n",
      "#Epoch 12 with total epochs 300 at step 10 loss: 11.274803161621094 running average of batch loss 10.68969371102073, time 0.9286572933197021\n",
      "#Epoch 12 with total epochs 300 at step 11 loss: 10.731461524963379 running average of batch loss 10.693174362182617, time 0.9456729888916016\n",
      "#Epoch 12 with total epochs 300 at step 12 loss: 10.995723724365234 running average of batch loss 10.716447390042818, time 0.948662519454956\n",
      "#Epoch 12 with total epochs 300 at step 13 loss: 10.113662719726562 running average of batch loss 10.673391342163086, time 0.95867919921875\n",
      "#Epoch 12 with total epochs 300 at step 14 loss: 10.831960678100586 running average of batch loss 10.683962631225587, time 0.9416663646697998\n",
      "#Epoch 12 with total epochs 300 at step 15 loss: 10.441469192504883 running average of batch loss 10.668806791305542, time 0.9626853466033936\n",
      "#Epoch 12 with total epochs 300 at step 16 loss: 10.35580825805664 running average of batch loss 10.650395112879137, time 0.9386646747589111\n",
      "#Epoch 12 with total epochs 300 at step 17 loss: 10.666868209838867 running average of batch loss 10.651310284932455, time 0.958681583404541\n",
      "#Epoch 12 with total epochs 300 at step 18 loss: 11.253425598144531 running average of batch loss 10.683000564575195, time 0.9596810340881348\n",
      "#Epoch 12 with total epochs 300 at step 19 loss: 9.836238861083984 running average of batch loss 10.640662479400635, time 0.9406664371490479\n",
      "#Epoch 12 with total epochs 300 at step 20 loss: 11.223794937133789 running average of batch loss 10.668430691673642, time 0.9286608695983887\n",
      "#Epoch 13 with total epochs 300 at step 0 loss: 10.18105697631836 running average of batch loss 10.18105697631836, time 0.9416682720184326\n",
      "#Epoch 13 with total epochs 300 at step 1 loss: 11.200965881347656 running average of batch loss 10.691011428833008, time 0.9456710815429688\n",
      "#Epoch 13 with total epochs 300 at step 2 loss: 11.092595100402832 running average of batch loss 10.824872652689615, time 0.9356622695922852\n",
      "#Epoch 13 with total epochs 300 at step 3 loss: 10.989816665649414 running average of batch loss 10.866108655929565, time 0.9356648921966553\n",
      "#Epoch 13 with total epochs 300 at step 4 loss: 11.183504104614258 running average of batch loss 10.929587745666504, time 0.9416697025299072\n",
      "#Epoch 13 with total epochs 300 at step 5 loss: 11.211148262023926 running average of batch loss 10.97651449839274, time 0.9326393604278564\n",
      "#Epoch 13 with total epochs 300 at step 6 loss: 11.375226020812988 running average of batch loss 11.033473287309919, time 0.9416689872741699\n",
      "#Epoch 13 with total epochs 300 at step 7 loss: 10.847002983093262 running average of batch loss 11.010164499282837, time 0.9426708221435547\n",
      "#Epoch 13 with total epochs 300 at step 8 loss: 10.713506698608398 running average of batch loss 10.977202521430122, time 0.933661937713623\n",
      "#Epoch 13 with total epochs 300 at step 9 loss: 10.59584903717041 running average of batch loss 10.939067173004151, time 0.9326605796813965\n",
      "#Epoch 13 with total epochs 300 at step 10 loss: 10.464056015014648 running average of batch loss 10.89588434045965, time 0.9216876029968262\n",
      "#Epoch 13 with total epochs 300 at step 11 loss: 10.420618057250977 running average of batch loss 10.856278816858927, time 0.9421701431274414\n",
      "#Epoch 13 with total epochs 300 at step 12 loss: 10.985639572143555 running average of batch loss 10.866229644188515, time 0.9356656074523926\n",
      "#Epoch 13 with total epochs 300 at step 13 loss: 9.256118774414062 running average of batch loss 10.75122172491891, time 0.9456727504730225\n",
      "#Epoch 13 with total epochs 300 at step 14 loss: 10.386555671691895 running average of batch loss 10.726910654703776, time 0.9466722011566162\n",
      "#Epoch 13 with total epochs 300 at step 15 loss: 10.544563293457031 running average of batch loss 10.715513944625854, time 0.9366629123687744\n",
      "#Epoch 13 with total epochs 300 at step 16 loss: 11.278817176818848 running average of batch loss 10.7486494288725, time 0.9456727504730225\n",
      "#Epoch 13 with total epochs 300 at step 17 loss: 9.808761596679688 running average of batch loss 10.696433438195122, time 0.9506750106811523\n",
      "#Epoch 13 with total epochs 300 at step 18 loss: 9.797189712524414 running average of batch loss 10.649104821054559, time 0.9626827239990234\n",
      "#Epoch 13 with total epochs 300 at step 19 loss: 9.902568817138672 running average of batch loss 10.611778020858765, time 0.936664342880249\n",
      "#Epoch 13 with total epochs 300 at step 20 loss: 10.181137084960938 running average of batch loss 10.591271309625535, time 0.9482121467590332\n",
      "#Epoch 14 with total epochs 300 at step 0 loss: 10.386552810668945 running average of batch loss 10.386552810668945, time 0.9446709156036377\n",
      "#Epoch 14 with total epochs 300 at step 1 loss: 10.116968154907227 running average of batch loss 10.251760482788086, time 0.9396655559539795\n",
      "#Epoch 14 with total epochs 300 at step 2 loss: 10.814901351928711 running average of batch loss 10.439474105834961, time 0.9416697025299072\n",
      "#Epoch 14 with total epochs 300 at step 3 loss: 10.781964302062988 running average of batch loss 10.525096654891968, time 0.9346630573272705\n",
      "#Epoch 14 with total epochs 300 at step 4 loss: 10.902667045593262 running average of batch loss 10.600610733032227, time 0.9336614608764648\n",
      "#Epoch 14 with total epochs 300 at step 5 loss: 11.94413948059082 running average of batch loss 10.824532190958658, time 0.9346632957458496\n",
      "#Epoch 14 with total epochs 300 at step 6 loss: 10.480208396911621 running average of batch loss 10.775343077523369, time 0.9276580810546875\n",
      "#Epoch 14 with total epochs 300 at step 7 loss: 11.054609298706055 running average of batch loss 10.810251355171204, time 0.9316616058349609\n",
      "#Epoch 14 with total epochs 300 at step 8 loss: 10.20547103881836 running average of batch loss 10.74305354224311, time 0.943669319152832\n",
      "#Epoch 14 with total epochs 300 at step 9 loss: 9.670567512512207 running average of batch loss 10.63580493927002, time 0.9416675567626953\n",
      "#Epoch 14 with total epochs 300 at step 10 loss: 10.972195625305176 running average of batch loss 10.666385910727762, time 0.9356427192687988\n",
      "#Epoch 14 with total epochs 300 at step 11 loss: 10.323602676391602 running average of batch loss 10.637820641199747, time 0.9406671524047852\n",
      "#Epoch 14 with total epochs 300 at step 12 loss: 10.504134178161621 running average of batch loss 10.627537067119892, time 0.9476499557495117\n",
      "#Epoch 14 with total epochs 300 at step 13 loss: 11.197590827941895 running average of batch loss 10.668255192892891, time 0.9286589622497559\n",
      "#Epoch 14 with total epochs 300 at step 14 loss: 11.26040267944336 running average of batch loss 10.707731691996257, time 0.9346637725830078\n",
      "#Epoch 14 with total epochs 300 at step 15 loss: 10.571221351623535 running average of batch loss 10.699199795722961, time 0.9586794376373291\n",
      "#Epoch 14 with total epochs 300 at step 16 loss: 9.67901611328125 running average of batch loss 10.63918899087345, time 0.9486730098724365\n",
      "#Epoch 14 with total epochs 300 at step 17 loss: 11.358253479003906 running average of batch loss 10.679137017991808, time 0.9616820812225342\n",
      "#Epoch 14 with total epochs 300 at step 18 loss: 10.486466407775879 running average of batch loss 10.66899645955939, time 0.9546771049499512\n",
      "#Epoch 14 with total epochs 300 at step 19 loss: 10.177840232849121 running average of batch loss 10.644438648223877, time 0.9536778926849365\n",
      "#Epoch 14 with total epochs 300 at step 20 loss: 10.621949195861816 running average of batch loss 10.64336772192092, time 0.936664342880249\n",
      "#Epoch 15 with total epochs 300 at step 0 loss: 11.359000205993652 running average of batch loss 11.359000205993652, time 0.9466705322265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 15 with total epochs 300 at step 1 loss: 10.031847953796387 running average of batch loss 10.69542407989502, time 0.9436712265014648\n",
      "#Epoch 15 with total epochs 300 at step 2 loss: 9.73210620880127 running average of batch loss 10.37431812286377, time 0.9326605796813965\n",
      "#Epoch 15 with total epochs 300 at step 3 loss: 11.090702056884766 running average of batch loss 10.553414106369019, time 0.9456706047058105\n",
      "#Epoch 15 with total epochs 300 at step 4 loss: 11.152376174926758 running average of batch loss 10.673206520080566, time 0.9346635341644287\n",
      "#Epoch 15 with total epochs 300 at step 5 loss: 9.975654602050781 running average of batch loss 10.556947867075602, time 0.9356634616851807\n",
      "#Epoch 15 with total epochs 300 at step 6 loss: 10.452103614807129 running average of batch loss 10.541970116751534, time 0.9386663436889648\n",
      "#Epoch 15 with total epochs 300 at step 7 loss: 10.327333450317383 running average of batch loss 10.515140533447266, time 0.9296612739562988\n",
      "#Epoch 15 with total epochs 300 at step 8 loss: 10.218852043151855 running average of batch loss 10.482219590081108, time 0.9376654624938965\n",
      "#Epoch 15 with total epochs 300 at step 9 loss: 10.581731796264648 running average of batch loss 10.492170810699463, time 0.9536762237548828\n",
      "#Epoch 15 with total epochs 300 at step 10 loss: 10.454992294311523 running average of batch loss 10.488790945573287, time 0.9426443576812744\n",
      "#Epoch 15 with total epochs 300 at step 11 loss: 10.492694854736328 running average of batch loss 10.489116271336874, time 0.9346396923065186\n",
      "#Epoch 15 with total epochs 300 at step 12 loss: 10.346839904785156 running average of batch loss 10.47817193544828, time 0.9356637001037598\n",
      "#Epoch 15 with total epochs 300 at step 13 loss: 10.026944160461426 running average of batch loss 10.445941380092076, time 0.9426450729370117\n",
      "#Epoch 15 with total epochs 300 at step 14 loss: 11.316798210144043 running average of batch loss 10.50399850209554, time 0.9386677742004395\n",
      "#Epoch 15 with total epochs 300 at step 15 loss: 10.666385650634766 running average of batch loss 10.514147698879242, time 0.9706904888153076\n",
      "#Epoch 15 with total epochs 300 at step 16 loss: 10.823525428771973 running average of batch loss 10.532346388872933, time 0.9526758193969727\n",
      "#Epoch 15 with total epochs 300 at step 17 loss: 11.215658187866211 running average of batch loss 10.57030815548367, time 0.9406673908233643\n",
      "#Epoch 15 with total epochs 300 at step 18 loss: 9.796905517578125 running average of batch loss 10.529602753488641, time 0.9606814384460449\n",
      "#Epoch 15 with total epochs 300 at step 19 loss: 10.566290855407715 running average of batch loss 10.531437158584595, time 0.9616811275482178\n",
      "#Epoch 15 with total epochs 300 at step 20 loss: 10.001423835754395 running average of batch loss 10.506198428926014, time 0.9556801319122314\n",
      "#Epoch 16 with total epochs 300 at step 0 loss: 9.895172119140625 running average of batch loss 9.895172119140625, time 0.9376637935638428\n",
      "#Epoch 16 with total epochs 300 at step 1 loss: 10.60746955871582 running average of batch loss 10.251320838928223, time 0.9376676082611084\n",
      "#Epoch 16 with total epochs 300 at step 2 loss: 9.758441925048828 running average of batch loss 10.087027867635092, time 0.940666913986206\n",
      "#Epoch 16 with total epochs 300 at step 3 loss: 10.576807022094727 running average of batch loss 10.20947265625, time 0.9366648197174072\n",
      "#Epoch 16 with total epochs 300 at step 4 loss: 10.577674865722656 running average of batch loss 10.283113098144531, time 0.9406676292419434\n",
      "#Epoch 16 with total epochs 300 at step 5 loss: 10.250556945800781 running average of batch loss 10.277687072753906, time 0.929659366607666\n",
      "#Epoch 16 with total epochs 300 at step 6 loss: 11.020577430725098 running average of batch loss 10.383814266749791, time 0.9416673183441162\n",
      "#Epoch 16 with total epochs 300 at step 7 loss: 10.143548965454102 running average of batch loss 10.35378110408783, time 0.9356381893157959\n",
      "#Epoch 16 with total epochs 300 at step 8 loss: 10.398551940917969 running average of batch loss 10.358755641513401, time 0.9386656284332275\n",
      "#Epoch 16 with total epochs 300 at step 9 loss: 10.115694046020508 running average of batch loss 10.33444948196411, time 0.9556801319122314\n",
      "#Epoch 16 with total epochs 300 at step 10 loss: 10.560508728027344 running average of batch loss 10.355000322515314, time 0.944669246673584\n",
      "#Epoch 16 with total epochs 300 at step 11 loss: 9.967606544494629 running average of batch loss 10.322717507680258, time 0.934661865234375\n",
      "#Epoch 16 with total epochs 300 at step 12 loss: 10.684423446655273 running average of batch loss 10.350541041447567, time 0.9476749897003174\n",
      "#Epoch 16 with total epochs 300 at step 13 loss: 9.21640682220459 running average of batch loss 10.269531454358782, time 0.9426689147949219\n",
      "#Epoch 16 with total epochs 300 at step 14 loss: 10.075342178344727 running average of batch loss 10.256585502624512, time 0.9336409568786621\n",
      "#Epoch 16 with total epochs 300 at step 15 loss: 9.915753364562988 running average of batch loss 10.235283493995667, time 0.9426472187042236\n",
      "#Epoch 16 with total epochs 300 at step 16 loss: 9.656830787658691 running average of batch loss 10.201256864211139, time 0.9576795101165771\n",
      "#Epoch 16 with total epochs 300 at step 17 loss: 10.875248908996582 running average of batch loss 10.238700866699219, time 0.9576797485351562\n",
      "#Epoch 16 with total epochs 300 at step 18 loss: 10.630247116088867 running average of batch loss 10.259308564035516, time 0.9416682720184326\n",
      "#Epoch 16 with total epochs 300 at step 19 loss: 10.467172622680664 running average of batch loss 10.269701766967774, time 0.9512207508087158\n",
      "#Epoch 16 with total epochs 300 at step 20 loss: 9.852518081665039 running average of batch loss 10.249835877191453, time 0.9396684169769287\n",
      "#Epoch 17 with total epochs 300 at step 0 loss: 10.290539741516113 running average of batch loss 10.290539741516113, time 0.9486730098724365\n",
      "#Epoch 17 with total epochs 300 at step 1 loss: 10.776811599731445 running average of batch loss 10.53367567062378, time 0.9291996955871582\n",
      "#Epoch 17 with total epochs 300 at step 2 loss: 10.202157974243164 running average of batch loss 10.42316977183024, time 0.9458940029144287\n",
      "#Epoch 17 with total epochs 300 at step 3 loss: 9.779041290283203 running average of batch loss 10.262137651443481, time 0.9356632232666016\n",
      "#Epoch 17 with total epochs 300 at step 4 loss: 11.040250778198242 running average of batch loss 10.417760276794434, time 0.944000244140625\n",
      "#Epoch 17 with total epochs 300 at step 5 loss: 9.727418899536133 running average of batch loss 10.302703380584717, time 0.9361653327941895\n",
      "#Epoch 17 with total epochs 300 at step 6 loss: 10.172518730163574 running average of batch loss 10.284105573381696, time 0.935664176940918\n",
      "#Epoch 17 with total epochs 300 at step 7 loss: 9.847272872924805 running average of batch loss 10.229501485824585, time 0.9586801528930664\n",
      "#Epoch 17 with total epochs 300 at step 8 loss: 10.944037437438965 running average of batch loss 10.308894369337294, time 0.940643310546875\n",
      "#Epoch 17 with total epochs 300 at step 9 loss: 10.439375877380371 running average of batch loss 10.3219425201416, time 0.9336624145507812\n",
      "#Epoch 17 with total epochs 300 at step 10 loss: 10.355439186096191 running average of batch loss 10.32498767159202, time 0.9456708431243896\n",
      "#Epoch 17 with total epochs 300 at step 11 loss: 9.252391815185547 running average of batch loss 10.235604683558146, time 0.9446711540222168\n",
      "#Epoch 17 with total epochs 300 at step 12 loss: 10.75267219543457 running average of batch loss 10.275379107548641, time 0.9376657009124756\n",
      "#Epoch 17 with total epochs 300 at step 13 loss: 9.789533615112305 running average of batch loss 10.240675858088903, time 0.9456725120544434\n",
      "#Epoch 17 with total epochs 300 at step 14 loss: 10.481093406677246 running average of batch loss 10.256703694661459, time 0.939666748046875\n",
      "#Epoch 17 with total epochs 300 at step 15 loss: 10.238617897033691 running average of batch loss 10.255573332309723, time 0.9396660327911377\n",
      "#Epoch 17 with total epochs 300 at step 16 loss: 10.098445892333984 running average of batch loss 10.246330541722914, time 0.9546771049499512\n",
      "#Epoch 17 with total epochs 300 at step 17 loss: 11.256614685058594 running average of batch loss 10.302457438574898, time 0.957679271697998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 17 with total epochs 300 at step 18 loss: 10.650382041931152 running average of batch loss 10.320769259804173, time 0.9476733207702637\n",
      "#Epoch 17 with total epochs 300 at step 19 loss: 10.686031341552734 running average of batch loss 10.3390323638916, time 0.9516749382019043\n",
      "#Epoch 17 with total epochs 300 at step 20 loss: 9.184219360351562 running average of batch loss 10.284041268484932, time 0.9426693916320801\n",
      "#Epoch 18 with total epochs 300 at step 0 loss: 9.729537963867188 running average of batch loss 9.729537963867188, time 0.9396674633026123\n",
      "#Epoch 18 with total epochs 300 at step 1 loss: 10.6119966506958 running average of batch loss 10.170767307281494, time 0.933661937713623\n",
      "#Epoch 18 with total epochs 300 at step 2 loss: 10.854156494140625 running average of batch loss 10.398563702901205, time 0.9336416721343994\n",
      "#Epoch 18 with total epochs 300 at step 3 loss: 10.009767532348633 running average of batch loss 10.301364660263062, time 0.9406657218933105\n",
      "#Epoch 18 with total epochs 300 at step 4 loss: 10.183265686035156 running average of batch loss 10.27774486541748, time 0.9296605587005615\n",
      "#Epoch 18 with total epochs 300 at step 5 loss: 10.371034622192383 running average of batch loss 10.293293158213297, time 0.9436719417572021\n",
      "#Epoch 18 with total epochs 300 at step 6 loss: 10.02164077758789 running average of batch loss 10.25448567526681, time 0.9396662712097168\n",
      "#Epoch 18 with total epochs 300 at step 7 loss: 9.909111976623535 running average of batch loss 10.211313962936401, time 0.9456713199615479\n",
      "#Epoch 18 with total epochs 300 at step 8 loss: 10.368203163146973 running average of batch loss 10.228746096293131, time 0.944671630859375\n",
      "#Epoch 18 with total epochs 300 at step 9 loss: 9.788956642150879 running average of batch loss 10.184767150878907, time 0.9466702938079834\n",
      "#Epoch 18 with total epochs 300 at step 10 loss: 9.18637466430664 running average of batch loss 10.094004197554154, time 0.9326636791229248\n",
      "#Epoch 18 with total epochs 300 at step 11 loss: 10.196720123291016 running average of batch loss 10.102563858032227, time 0.945669412612915\n",
      "#Epoch 18 with total epochs 300 at step 12 loss: 9.58368968963623 running average of batch loss 10.062650460463304, time 0.9306626319885254\n",
      "#Epoch 18 with total epochs 300 at step 13 loss: 8.910324096679688 running average of batch loss 9.98034143447876, time 0.9426686763763428\n",
      "#Epoch 18 with total epochs 300 at step 14 loss: 11.260204315185547 running average of batch loss 10.06566562652588, time 0.9416682720184326\n",
      "#Epoch 18 with total epochs 300 at step 15 loss: 9.619405746459961 running average of batch loss 10.037774384021759, time 0.9326605796813965\n",
      "#Epoch 18 with total epochs 300 at step 16 loss: 9.840250968933105 running average of batch loss 10.026155359604779, time 0.9386682510375977\n",
      "#Epoch 18 with total epochs 300 at step 17 loss: 10.670365333557129 running average of batch loss 10.061944802602133, time 0.9466702938079834\n",
      "#Epoch 18 with total epochs 300 at step 18 loss: 10.335299491882324 running average of batch loss 10.076331891511616, time 0.49034881591796875\n",
      "#Epoch 18 with total epochs 300 at step 19 loss: 10.385361671447754 running average of batch loss 10.091783380508422, time 0.5063624382019043\n",
      "#Epoch 18 with total epochs 300 at step 20 loss: 9.809867858886719 running average of batch loss 10.07835883185977, time 0.5183393955230713\n",
      "#Epoch 19 with total epochs 300 at step 0 loss: 10.071575164794922 running average of batch loss 10.071575164794922, time 0.5123343467712402\n",
      "#Epoch 19 with total epochs 300 at step 1 loss: 9.73444938659668 running average of batch loss 9.9030122756958, time 0.5183422565460205\n",
      "#Epoch 19 with total epochs 300 at step 2 loss: 10.237604141235352 running average of batch loss 10.014542897542318, time 0.5123357772827148\n",
      "#Epoch 19 with total epochs 300 at step 3 loss: 9.265824317932129 running average of batch loss 9.82736325263977, time 0.4883251190185547\n",
      "#Epoch 19 with total epochs 300 at step 4 loss: 9.201925277709961 running average of batch loss 9.702275657653809, time 0.4893491268157959\n",
      "#Epoch 19 with total epochs 300 at step 5 loss: 10.477104187011719 running average of batch loss 9.831413745880127, time 0.49633049964904785\n",
      "#Epoch 19 with total epochs 300 at step 6 loss: 9.90967845916748 running average of batch loss 9.842594419206891, time 0.5033562183380127\n",
      "#Epoch 19 with total epochs 300 at step 7 loss: 9.407210350036621 running average of batch loss 9.788171410560608, time 0.5183680057525635\n",
      "#Epoch 19 with total epochs 300 at step 8 loss: 9.943107604980469 running average of batch loss 9.805386543273926, time 0.514366626739502\n",
      "#Epoch 19 with total epochs 300 at step 9 loss: 10.254684448242188 running average of batch loss 9.850316333770753, time 0.5313763618469238\n",
      "#Epoch 19 with total epochs 300 at step 10 loss: 9.749361991882324 running average of batch loss 9.84113866632635, time 0.5063343048095703\n",
      "#Epoch 19 with total epochs 300 at step 11 loss: 9.76671028137207 running average of batch loss 9.834936300913492, time 0.5003325939178467\n",
      "#Epoch 19 with total epochs 300 at step 12 loss: 9.564338684082031 running average of batch loss 9.814121099618765, time 0.505333662033081\n",
      "#Epoch 19 with total epochs 300 at step 13 loss: 10.073163986206055 running average of batch loss 9.832624162946429, time 0.897613525390625\n",
      "#Epoch 19 with total epochs 300 at step 14 loss: 10.122586250305176 running average of batch loss 9.851954968770345, time 0.9486730098724365\n",
      "#Epoch 19 with total epochs 300 at step 15 loss: 10.835112571716309 running average of batch loss 9.913402318954468, time 0.9556779861450195\n",
      "#Epoch 19 with total epochs 300 at step 16 loss: 9.744379043579102 running average of batch loss 9.903459773344153, time 0.9616837501525879\n",
      "#Epoch 19 with total epochs 300 at step 17 loss: 10.567313194274902 running average of batch loss 9.940340518951416, time 0.9346632957458496\n",
      "#Epoch 19 with total epochs 300 at step 18 loss: 10.560467720031738 running average of batch loss 9.972978792692485, time 0.936664342880249\n",
      "#Epoch 19 with total epochs 300 at step 19 loss: 9.33667278289795 running average of batch loss 9.941163492202758, time 0.9326605796813965\n",
      "#Epoch 19 with total epochs 300 at step 20 loss: 9.753246307373047 running average of batch loss 9.932215054829916, time 0.9466722011566162\n",
      "#Epoch 20 with total epochs 300 at step 0 loss: 9.579019546508789 running average of batch loss 9.579019546508789, time 0.9416677951812744\n",
      "#Epoch 20 with total epochs 300 at step 1 loss: 9.742849349975586 running average of batch loss 9.660934448242188, time 0.9386658668518066\n",
      "#Epoch 20 with total epochs 300 at step 2 loss: 9.652495384216309 running average of batch loss 9.658121426900228, time 0.9386670589447021\n",
      "#Epoch 20 with total epochs 300 at step 3 loss: 9.605440139770508 running average of batch loss 9.644951105117798, time 0.9366645812988281\n",
      "#Epoch 20 with total epochs 300 at step 4 loss: 9.371482849121094 running average of batch loss 9.590257453918458, time 0.9446702003479004\n",
      "#Epoch 20 with total epochs 300 at step 5 loss: 10.20401382446289 running average of batch loss 9.69255018234253, time 0.935664176940918\n",
      "#Epoch 20 with total epochs 300 at step 6 loss: 10.640016555786133 running average of batch loss 9.827902521405901, time 0.9346635341644287\n",
      "#Epoch 20 with total epochs 300 at step 7 loss: 11.071252822875977 running average of batch loss 9.98332130908966, time 0.941669225692749\n",
      "#Epoch 20 with total epochs 300 at step 8 loss: 9.732144355773926 running average of batch loss 9.955412758721245, time 0.9446704387664795\n",
      "#Epoch 20 with total epochs 300 at step 9 loss: 9.355537414550781 running average of batch loss 9.8954252243042, time 0.9386677742004395\n",
      "#Epoch 20 with total epochs 300 at step 10 loss: 10.913368225097656 running average of batch loss 9.987965497103604, time 0.9436700344085693\n",
      "#Epoch 20 with total epochs 300 at step 11 loss: 9.460700035095215 running average of batch loss 9.944026708602905, time 0.9436702728271484\n",
      "#Epoch 20 with total epochs 300 at step 12 loss: 9.67477035522461 running average of batch loss 9.92331468141996, time 0.9396669864654541\n",
      "#Epoch 20 with total epochs 300 at step 13 loss: 10.226581573486328 running average of batch loss 9.944976602281843, time 0.9386675357818604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 20 with total epochs 300 at step 14 loss: 9.449691772460938 running average of batch loss 9.911957613627116, time 0.9386651515960693\n",
      "#Epoch 20 with total epochs 300 at step 15 loss: 9.844121932983398 running average of batch loss 9.907717883586884, time 0.9596800804138184\n",
      "#Epoch 20 with total epochs 300 at step 16 loss: 10.027118682861328 running average of batch loss 9.914741460014792, time 0.9486746788024902\n",
      "#Epoch 20 with total epochs 300 at step 17 loss: 9.65128231048584 running average of batch loss 9.900104840596518, time 0.9436695575714111\n",
      "#Epoch 20 with total epochs 300 at step 18 loss: 9.673036575317383 running average of batch loss 9.888153879266037, time 0.9346632957458496\n",
      "#Epoch 20 with total epochs 300 at step 19 loss: 9.975618362426758 running average of batch loss 9.892527103424072, time 0.9376657009124756\n",
      "#Epoch 20 with total epochs 300 at step 20 loss: 9.618792533874512 running average of batch loss 9.879492123921713, time 0.9346628189086914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peyman\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg difference between predicted and ground truth batch wise 10.439583041122983\n",
      "#Epoch 21 with total epochs 300 at step 0 loss: 9.932451248168945 running average of batch loss 9.932451248168945, time 0.511361837387085\n",
      "#Epoch 21 with total epochs 300 at step 1 loss: 10.038414001464844 running average of batch loss 9.985432624816895, time 0.9686887264251709\n",
      "#Epoch 21 with total epochs 300 at step 2 loss: 9.45712661743164 running average of batch loss 9.809330622355143, time 0.9456706047058105\n",
      "#Epoch 21 with total epochs 300 at step 3 loss: 10.364013671875 running average of batch loss 9.948001384735107, time 0.9406673908233643\n",
      "#Epoch 21 with total epochs 300 at step 4 loss: 9.078134536743164 running average of batch loss 9.774028015136718, time 0.9416687488555908\n",
      "#Epoch 21 with total epochs 300 at step 5 loss: 9.854509353637695 running average of batch loss 9.787441571553549, time 0.9596807956695557\n",
      "#Epoch 21 with total epochs 300 at step 6 loss: 10.079435348510742 running average of batch loss 9.829154968261719, time 0.9486749172210693\n",
      "#Epoch 21 with total epochs 300 at step 7 loss: 10.831087112426758 running average of batch loss 9.954396486282349, time 0.9296598434448242\n",
      "#Epoch 21 with total epochs 300 at step 8 loss: 9.870484352111816 running average of batch loss 9.945072915818956, time 0.9516754150390625\n",
      "#Epoch 21 with total epochs 300 at step 9 loss: 9.23176097869873 running average of batch loss 9.873741722106933, time 0.9386670589447021\n",
      "#Epoch 21 with total epochs 300 at step 10 loss: 9.241822242736816 running average of batch loss 9.81629449670965, time 0.93764328956604\n",
      "#Epoch 21 with total epochs 300 at step 11 loss: 9.845651626586914 running average of batch loss 9.818740924199423, time 0.939666748046875\n",
      "#Epoch 21 with total epochs 300 at step 12 loss: 9.760350227355957 running average of batch loss 9.81424933213454, time 0.9336390495300293\n",
      "#Epoch 21 with total epochs 300 at step 13 loss: 9.490604400634766 running average of batch loss 9.791131837027413, time 0.9406681060791016\n",
      "#Epoch 21 with total epochs 300 at step 14 loss: 9.54242992401123 running average of batch loss 9.774551709493002, time 0.9396679401397705\n",
      "#Epoch 21 with total epochs 300 at step 15 loss: 9.687477111816406 running average of batch loss 9.769109547138214, time 0.9306600093841553\n",
      "#Epoch 21 with total epochs 300 at step 16 loss: 9.508319854736328 running average of batch loss 9.753768976996927, time 0.9396665096282959\n",
      "#Epoch 21 with total epochs 300 at step 17 loss: 10.219768524169922 running average of batch loss 9.77965784072876, time 0.9396665096282959\n",
      "#Epoch 21 with total epochs 300 at step 18 loss: 10.038975715637207 running average of batch loss 9.793306149934468, time 0.9396674633026123\n",
      "#Epoch 21 with total epochs 300 at step 19 loss: 9.374466896057129 running average of batch loss 9.772364187240601, time 0.9466736316680908\n",
      "#Epoch 21 with total epochs 300 at step 20 loss: 10.112500190734863 running average of batch loss 9.788561139787946, time 0.9456725120544434\n",
      "#Epoch 22 with total epochs 300 at step 0 loss: 9.59193229675293 running average of batch loss 9.59193229675293, time 0.9306604862213135\n",
      "#Epoch 22 with total epochs 300 at step 1 loss: 9.984003067016602 running average of batch loss 9.787967681884766, time 0.933661937713623\n",
      "#Epoch 22 with total epochs 300 at step 2 loss: 9.989776611328125 running average of batch loss 9.855237325032553, time 0.9346446990966797\n",
      "#Epoch 22 with total epochs 300 at step 3 loss: 9.936580657958984 running average of batch loss 9.87557315826416, time 0.9416682720184326\n",
      "#Epoch 22 with total epochs 300 at step 4 loss: 8.742849349975586 running average of batch loss 9.649028396606445, time 0.9346630573272705\n",
      "#Epoch 22 with total epochs 300 at step 5 loss: 9.653036117553711 running average of batch loss 9.649696350097656, time 0.9576783180236816\n",
      "#Epoch 22 with total epochs 300 at step 6 loss: 9.59535026550293 running average of batch loss 9.641932623726982, time 0.9606592655181885\n",
      "#Epoch 22 with total epochs 300 at step 7 loss: 9.880086898803711 running average of batch loss 9.671701908111572, time 0.9436690807342529\n",
      "#Epoch 22 with total epochs 300 at step 8 loss: 10.046030044555664 running average of batch loss 9.713293923272026, time 0.9376657009124756\n",
      "#Epoch 22 with total epochs 300 at step 9 loss: 9.070934295654297 running average of batch loss 9.649057960510254, time 0.9686884880065918\n",
      "#Epoch 22 with total epochs 300 at step 10 loss: 10.298880577087402 running average of batch loss 9.70813274383545, time 0.9546775817871094\n",
      "#Epoch 22 with total epochs 300 at step 11 loss: 9.513667106628418 running average of batch loss 9.691927274068197, time 0.935664176940918\n",
      "#Epoch 22 with total epochs 300 at step 12 loss: 8.488118171691895 running average of batch loss 9.599326573885405, time 0.934220552444458\n",
      "#Epoch 22 with total epochs 300 at step 13 loss: 9.252559661865234 running average of batch loss 9.574557508741107, time 0.939666748046875\n",
      "#Epoch 22 with total epochs 300 at step 14 loss: 9.828691482543945 running average of batch loss 9.591499773661296, time 0.9416682720184326\n",
      "#Epoch 22 with total epochs 300 at step 15 loss: 10.341398239135742 running average of batch loss 9.638368427753448, time 0.9481887817382812\n",
      "#Epoch 22 with total epochs 300 at step 16 loss: 9.058810234069824 running average of batch loss 9.604276769301471, time 0.9356637001037598\n",
      "#Epoch 22 with total epochs 300 at step 17 loss: 10.412622451782227 running average of batch loss 9.649184862772623, time 0.9456713199615479\n",
      "#Epoch 22 with total epochs 300 at step 18 loss: 9.4793119430542 running average of batch loss 9.640244182787443, time 0.9462065696716309\n",
      "#Epoch 22 with total epochs 300 at step 19 loss: 9.435983657836914 running average of batch loss 9.630031156539918, time 0.938166618347168\n",
      "#Epoch 22 with total epochs 300 at step 20 loss: 9.207087516784668 running average of batch loss 9.60989098321824, time 0.9336638450622559\n",
      "#Epoch 23 with total epochs 300 at step 0 loss: 10.070785522460938 running average of batch loss 10.070785522460938, time 0.9451766014099121\n",
      "#Epoch 23 with total epochs 300 at step 1 loss: 9.868149757385254 running average of batch loss 9.969467639923096, time 0.9366655349731445\n",
      "#Epoch 23 with total epochs 300 at step 2 loss: 9.31336784362793 running average of batch loss 9.750767707824707, time 0.9416685104370117\n",
      "#Epoch 23 with total epochs 300 at step 3 loss: 9.613578796386719 running average of batch loss 9.71647047996521, time 0.9286601543426514\n",
      "#Epoch 23 with total epochs 300 at step 4 loss: 9.2694730758667 running average of batch loss 9.627070999145507, time 0.9426465034484863\n",
      "#Epoch 23 with total epochs 300 at step 5 loss: 9.888050079345703 running average of batch loss 9.670567512512207, time 0.9576799869537354\n",
      "#Epoch 23 with total epochs 300 at step 6 loss: 10.346136093139648 running average of batch loss 9.767077309744698, time 0.956679105758667\n",
      "#Epoch 23 with total epochs 300 at step 7 loss: 9.860899925231934 running average of batch loss 9.778805136680603, time 0.9436695575714111\n",
      "#Epoch 23 with total epochs 300 at step 8 loss: 10.076451301574707 running average of batch loss 9.811876932779947, time 0.9396669864654541\n",
      "#Epoch 23 with total epochs 300 at step 9 loss: 9.004014015197754 running average of batch loss 9.731090641021728, time 0.9556779861450195\n",
      "#Epoch 23 with total epochs 300 at step 10 loss: 8.877069473266602 running average of batch loss 9.65345235304399, time 0.9486734867095947\n",
      "#Epoch 23 with total epochs 300 at step 11 loss: 9.305176734924316 running average of batch loss 9.62442938486735, time 0.9596800804138184\n",
      "#Epoch 23 with total epochs 300 at step 12 loss: 9.022409439086914 running average of batch loss 9.578120158268856, time 0.9366626739501953\n",
      "#Epoch 23 with total epochs 300 at step 13 loss: 9.057819366455078 running average of batch loss 9.540955815996442, time 0.9396679401397705\n",
      "#Epoch 23 with total epochs 300 at step 14 loss: 9.190145492553711 running average of batch loss 9.517568461100261, time 0.9296596050262451\n",
      "#Epoch 23 with total epochs 300 at step 15 loss: 9.264869689941406 running average of batch loss 9.501774787902832, time 0.9372532367706299\n",
      "#Epoch 23 with total epochs 300 at step 16 loss: 9.361542701721191 running average of batch loss 9.493525841656853, time 0.9476733207702637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 23 with total epochs 300 at step 17 loss: 9.938831329345703 running average of batch loss 9.518265035417345, time 0.9386651515960693\n",
      "#Epoch 23 with total epochs 300 at step 18 loss: 9.59305191040039 running average of batch loss 9.522201186732241, time 0.928661584854126\n",
      "#Epoch 23 with total epochs 300 at step 19 loss: 9.36543083190918 running average of batch loss 9.514362668991089, time 0.9326615333557129\n",
      "#Epoch 23 with total epochs 300 at step 20 loss: 9.901739120483398 running average of batch loss 9.532809166681199, time 0.9406664371490479\n",
      "#Epoch 24 with total epochs 300 at step 0 loss: 9.520986557006836 running average of batch loss 9.520986557006836, time 0.9286606311798096\n",
      "#Epoch 24 with total epochs 300 at step 1 loss: 9.420721054077148 running average of batch loss 9.470853805541992, time 0.9386653900146484\n",
      "#Epoch 24 with total epochs 300 at step 2 loss: 9.508161544799805 running average of batch loss 9.48328971862793, time 0.9356410503387451\n",
      "#Epoch 24 with total epochs 300 at step 3 loss: 10.042182922363281 running average of batch loss 9.623013019561768, time 0.9286572933197021\n",
      "#Epoch 24 with total epochs 300 at step 4 loss: 10.391939163208008 running average of batch loss 9.776798248291016, time 0.9316375255584717\n",
      "#Epoch 24 with total epochs 300 at step 5 loss: 9.103250503540039 running average of batch loss 9.66454029083252, time 0.9646844863891602\n",
      "#Epoch 24 with total epochs 300 at step 6 loss: 9.716351509094238 running average of batch loss 9.671941893441337, time 0.9396660327911377\n",
      "#Epoch 24 with total epochs 300 at step 7 loss: 9.297163009643555 running average of batch loss 9.625094532966614, time 0.9426689147949219\n",
      "#Epoch 24 with total epochs 300 at step 8 loss: 8.785374641418457 running average of batch loss 9.531792322794596, time 0.9386658668518066\n",
      "#Epoch 24 with total epochs 300 at step 9 loss: 8.620885848999023 running average of batch loss 9.440701675415038, time 0.9616830348968506\n",
      "#Epoch 24 with total epochs 300 at step 10 loss: 9.199800491333008 running average of batch loss 9.418801567771219, time 0.9436695575714111\n",
      "#Epoch 24 with total epochs 300 at step 11 loss: 9.673025131225586 running average of batch loss 9.439986864725748, time 0.9506750106811523\n",
      "#Epoch 24 with total epochs 300 at step 12 loss: 9.662893295288086 running average of batch loss 9.457133513230543, time 0.9542114734649658\n",
      "#Epoch 24 with total epochs 300 at step 13 loss: 8.991840362548828 running average of batch loss 9.42389828818185, time 0.9436702728271484\n",
      "#Epoch 24 with total epochs 300 at step 14 loss: 9.62943172454834 running average of batch loss 9.43760051727295, time 0.9386653900146484\n",
      "#Epoch 24 with total epochs 300 at step 15 loss: 9.781963348388672 running average of batch loss 9.459123194217682, time 0.9366662502288818\n",
      "#Epoch 24 with total epochs 300 at step 16 loss: 9.231049537658691 running average of batch loss 9.445707096773035, time 0.9376652240753174\n",
      "#Epoch 24 with total epochs 300 at step 17 loss: 9.135847091674805 running average of batch loss 9.428492652045357, time 0.9289653301239014\n",
      "#Epoch 24 with total epochs 300 at step 18 loss: 9.735555648803711 running average of batch loss 9.44465386240106, time 0.930661678314209\n",
      "#Epoch 24 with total epochs 300 at step 19 loss: 9.556632995605469 running average of batch loss 9.45025281906128, time 0.9316608905792236\n",
      "#Epoch 24 with total epochs 300 at step 20 loss: 9.577098846435547 running average of batch loss 9.456293106079102, time 0.9386422634124756\n",
      "#Epoch 25 with total epochs 300 at step 0 loss: 9.272322654724121 running average of batch loss 9.272322654724121, time 0.9386670589447021\n",
      "#Epoch 25 with total epochs 300 at step 1 loss: 8.328863143920898 running average of batch loss 8.80059289932251, time 0.9286594390869141\n",
      "#Epoch 25 with total epochs 300 at step 2 loss: 9.692000389099121 running average of batch loss 9.097728729248047, time 0.9346632957458496\n",
      "#Epoch 25 with total epochs 300 at step 3 loss: 9.122673034667969 running average of batch loss 9.103964805603027, time 0.9436697959899902\n",
      "#Epoch 25 with total epochs 300 at step 4 loss: 8.806497573852539 running average of batch loss 9.04447135925293, time 0.9436681270599365\n",
      "#Epoch 25 with total epochs 300 at step 5 loss: 10.353802680969238 running average of batch loss 9.262693246205648, time 0.9366650581359863\n",
      "#Epoch 25 with total epochs 300 at step 6 loss: 8.614791870117188 running average of batch loss 9.17013590676444, time 0.9476711750030518\n",
      "#Epoch 25 with total epochs 300 at step 7 loss: 8.666277885437012 running average of batch loss 9.10715365409851, time 0.9396705627441406\n",
      "#Epoch 25 with total epochs 300 at step 8 loss: 9.385887145996094 running average of batch loss 9.138124042087131, time 0.9396665096282959\n",
      "#Epoch 25 with total epochs 300 at step 9 loss: 9.6160888671875 running average of batch loss 9.185920524597169, time 0.9566786289215088\n",
      "#Epoch 25 with total epochs 300 at step 10 loss: 9.105934143066406 running average of batch loss 9.1786490353671, time 0.9456708431243896\n",
      "#Epoch 25 with total epochs 300 at step 11 loss: 10.259483337402344 running average of batch loss 9.268718560536703, time 0.9386656284332275\n",
      "#Epoch 25 with total epochs 300 at step 12 loss: 8.824204444885254 running average of batch loss 9.234525167025053, time 0.9447526931762695\n",
      "#Epoch 25 with total epochs 300 at step 13 loss: 9.488641738891602 running average of batch loss 9.252676350729805, time 0.9446687698364258\n",
      "#Epoch 25 with total epochs 300 at step 14 loss: 8.801412582397461 running average of batch loss 9.222592099507649, time 0.9376673698425293\n",
      "#Epoch 25 with total epochs 300 at step 15 loss: 8.749637603759766 running average of batch loss 9.193032443523407, time 0.9296596050262451\n",
      "#Epoch 25 with total epochs 300 at step 16 loss: 9.787928581237793 running average of batch loss 9.228026333977194, time 0.9366638660430908\n",
      "#Epoch 25 with total epochs 300 at step 17 loss: 9.36709976196289 running average of batch loss 9.235752635531956, time 0.9256572723388672\n",
      "#Epoch 25 with total epochs 300 at step 18 loss: 8.850096702575684 running average of batch loss 9.215454954850046, time 0.9466743469238281\n",
      "#Epoch 25 with total epochs 300 at step 19 loss: 9.30248737335205 running average of batch loss 9.219806575775147, time 0.9296584129333496\n",
      "#Epoch 25 with total epochs 300 at step 20 loss: 9.489758491516113 running average of batch loss 9.232661428905669, time 0.9326636791229248\n",
      "#Epoch 26 with total epochs 300 at step 0 loss: 8.986814498901367 running average of batch loss 8.986814498901367, time 0.9306602478027344\n",
      "#Epoch 26 with total epochs 300 at step 1 loss: 9.348227500915527 running average of batch loss 9.167520999908447, time 0.9456722736358643\n",
      "#Epoch 26 with total epochs 300 at step 2 loss: 9.138312339782715 running average of batch loss 9.157784779866537, time 0.9376671314239502\n",
      "#Epoch 26 with total epochs 300 at step 3 loss: 9.131319999694824 running average of batch loss 9.151168584823608, time 0.9436695575714111\n",
      "#Epoch 26 with total epochs 300 at step 4 loss: 9.482430458068848 running average of batch loss 9.217420959472657, time 0.9626834392547607\n",
      "#Epoch 26 with total epochs 300 at step 5 loss: 9.555001258850098 running average of batch loss 9.27368434270223, time 0.9386663436889648\n",
      "#Epoch 26 with total epochs 300 at step 6 loss: 8.898120880126953 running average of batch loss 9.22003241947719, time 0.9436700344085693\n",
      "#Epoch 26 with total epochs 300 at step 7 loss: 9.57065486907959 running average of batch loss 9.26386022567749, time 0.9456706047058105\n",
      "#Epoch 26 with total epochs 300 at step 8 loss: 8.87344741821289 running average of batch loss 9.220481024848091, time 0.9526762962341309\n",
      "#Epoch 26 with total epochs 300 at step 9 loss: 9.162489891052246 running average of batch loss 9.214681911468507, time 0.9646849632263184\n",
      "#Epoch 26 with total epochs 300 at step 10 loss: 9.501639366149902 running average of batch loss 9.240768952803178, time 0.9426684379577637\n",
      "#Epoch 26 with total epochs 300 at step 11 loss: 10.224543571472168 running average of batch loss 9.322750171025595, time 0.9616808891296387\n",
      "#Epoch 26 with total epochs 300 at step 12 loss: 9.796150207519531 running average of batch loss 9.359165558448204, time 0.932194709777832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 26 with total epochs 300 at step 13 loss: 9.241751670837402 running average of batch loss 9.35077885219029, time 0.941669225692749\n",
      "#Epoch 26 with total epochs 300 at step 14 loss: 8.821216583251953 running average of batch loss 9.315474700927734, time 0.939666748046875\n",
      "#Epoch 26 with total epochs 300 at step 15 loss: 9.577323913574219 running average of batch loss 9.33184027671814, time 0.928659200668335\n",
      "#Epoch 26 with total epochs 300 at step 16 loss: 8.7820405960083 running average of batch loss 9.299499119029326, time 0.9376640319824219\n",
      "#Epoch 26 with total epochs 300 at step 17 loss: 9.060094833374023 running average of batch loss 9.286198880937365, time 0.9366664886474609\n",
      "#Epoch 26 with total epochs 300 at step 18 loss: 9.1691312789917 running average of batch loss 9.280037428203382, time 0.9372565746307373\n",
      "#Epoch 26 with total epochs 300 at step 19 loss: 8.656878471374512 running average of batch loss 9.24887948036194, time 0.9336626529693604\n",
      "#Epoch 26 with total epochs 300 at step 20 loss: 8.837983131408691 running average of batch loss 9.229312987554641, time 0.9376652240753174\n",
      "#Epoch 27 with total epochs 300 at step 0 loss: 8.845539093017578 running average of batch loss 8.845539093017578, time 0.9416673183441162\n",
      "#Epoch 27 with total epochs 300 at step 1 loss: 9.325706481933594 running average of batch loss 9.085622787475586, time 0.9336385726928711\n",
      "#Epoch 27 with total epochs 300 at step 2 loss: 9.37825870513916 running average of batch loss 9.183168093363443, time 0.936664342880249\n",
      "#Epoch 27 with total epochs 300 at step 3 loss: 8.745006561279297 running average of batch loss 9.073627710342407, time 0.9456708431243896\n",
      "#Epoch 27 with total epochs 300 at step 4 loss: 9.449056625366211 running average of batch loss 9.148713493347168, time 0.9396665096282959\n",
      "#Epoch 27 with total epochs 300 at step 5 loss: 8.693872451782227 running average of batch loss 9.072906653086344, time 0.9396653175354004\n",
      "#Epoch 27 with total epochs 300 at step 6 loss: 8.282509803771973 running average of batch loss 8.959992817470006, time 0.9476747512817383\n",
      "#Epoch 27 with total epochs 300 at step 7 loss: 9.267867088317871 running average of batch loss 8.998477101325989, time 0.9446704387664795\n",
      "#Epoch 27 with total epochs 300 at step 8 loss: 9.069352149963379 running average of batch loss 9.006352106730143, time 0.9306600093841553\n",
      "#Epoch 27 with total epochs 300 at step 9 loss: 8.816319465637207 running average of batch loss 8.98734884262085, time 0.9536759853363037\n",
      "#Epoch 27 with total epochs 300 at step 10 loss: 8.9224853515625 running average of batch loss 8.981452161615545, time 0.9556801319122314\n",
      "#Epoch 27 with total epochs 300 at step 11 loss: 10.101540565490723 running average of batch loss 9.074792861938477, time 0.9356625080108643\n",
      "#Epoch 27 with total epochs 300 at step 12 loss: 8.522359848022461 running average of batch loss 9.032298014714168, time 0.964686393737793\n",
      "#Epoch 27 with total epochs 300 at step 13 loss: 8.95882511138916 running average of batch loss 9.027049950190953, time 0.9366650581359863\n",
      "#Epoch 27 with total epochs 300 at step 14 loss: 8.635626792907715 running average of batch loss 9.000955073038737, time 0.9586794376373291\n",
      "#Epoch 27 with total epochs 300 at step 15 loss: 9.574407577514648 running average of batch loss 9.036795854568481, time 0.9416682720184326\n",
      "#Epoch 27 with total epochs 300 at step 16 loss: 8.694677352905273 running average of batch loss 9.016671236823587, time 0.9336519241333008\n",
      "#Epoch 27 with total epochs 300 at step 17 loss: 9.340173721313477 running average of batch loss 9.034643597073025, time 0.9556784629821777\n",
      "#Epoch 27 with total epochs 300 at step 18 loss: 9.04432487487793 running average of batch loss 9.035153138010125, time 0.9406654834747314\n",
      "#Epoch 27 with total epochs 300 at step 19 loss: 10.174040794372559 running average of batch loss 9.092097520828247, time 0.9446711540222168\n",
      "#Epoch 27 with total epochs 300 at step 20 loss: 9.450702667236328 running average of batch loss 9.109173956371489, time 0.9336633682250977\n",
      "#Epoch 28 with total epochs 300 at step 0 loss: 8.01545524597168 running average of batch loss 8.01545524597168, time 0.9376671314239502\n",
      "#Epoch 28 with total epochs 300 at step 1 loss: 9.079194068908691 running average of batch loss 8.547324657440186, time 0.9366648197174072\n",
      "#Epoch 28 with total epochs 300 at step 2 loss: 9.034055709838867 running average of batch loss 8.70956834157308, time 0.9376649856567383\n",
      "#Epoch 28 with total epochs 300 at step 3 loss: 8.903358459472656 running average of batch loss 8.758015871047974, time 0.9456713199615479\n",
      "#Epoch 28 with total epochs 300 at step 4 loss: 8.24405574798584 running average of batch loss 8.655223846435547, time 0.9406676292419434\n",
      "#Epoch 28 with total epochs 300 at step 5 loss: 9.817639350891113 running average of batch loss 8.848959763844809, time 0.9386649131774902\n",
      "#Epoch 28 with total epochs 300 at step 6 loss: 8.489314079284668 running average of batch loss 8.797581808907646, time 0.935542106628418\n",
      "#Epoch 28 with total epochs 300 at step 7 loss: 9.567893028259277 running average of batch loss 8.8938707113266, time 0.9316596984863281\n",
      "#Epoch 28 with total epochs 300 at step 8 loss: 9.270759582519531 running average of batch loss 8.935747252570259, time 0.9246556758880615\n",
      "#Epoch 28 with total epochs 300 at step 9 loss: 8.933154106140137 running average of batch loss 8.935487937927245, time 0.9296598434448242\n",
      "#Epoch 28 with total epochs 300 at step 10 loss: 9.316825866699219 running average of batch loss 8.970155022361062, time 0.9386653900146484\n",
      "#Epoch 28 with total epochs 300 at step 11 loss: 9.443119049072266 running average of batch loss 9.009568691253662, time 0.9356651306152344\n",
      "#Epoch 28 with total epochs 300 at step 12 loss: 8.692744255065918 running average of batch loss 8.985197580777681, time 0.9646844863891602\n",
      "#Epoch 28 with total epochs 300 at step 13 loss: 9.407981872558594 running average of batch loss 9.015396458762032, time 0.9336614608764648\n",
      "#Epoch 28 with total epochs 300 at step 14 loss: 9.513349533081055 running average of batch loss 9.048593330383301, time 0.9646837711334229\n",
      "#Epoch 28 with total epochs 300 at step 15 loss: 9.222142219543457 running average of batch loss 9.05944013595581, time 0.9466724395751953\n",
      "#Epoch 28 with total epochs 300 at step 16 loss: 8.582555770874023 running average of batch loss 9.03138811448041, time 0.9346630573272705\n",
      "#Epoch 28 with total epochs 300 at step 17 loss: 8.970632553100586 running average of batch loss 9.028012805514866, time 0.9286606311798096\n",
      "#Epoch 28 with total epochs 300 at step 18 loss: 9.294304847717285 running average of batch loss 9.042028176157098, time 0.9456710815429688\n",
      "#Epoch 28 with total epochs 300 at step 19 loss: 8.734054565429688 running average of batch loss 9.026629495620728, time 0.9396657943725586\n",
      "#Epoch 28 with total epochs 300 at step 20 loss: 8.434930801391602 running average of batch loss 8.998453367324103, time 0.9296610355377197\n",
      "#Epoch 29 with total epochs 300 at step 0 loss: 9.002828598022461 running average of batch loss 9.002828598022461, time 0.9472060203552246\n",
      "#Epoch 29 with total epochs 300 at step 1 loss: 9.231437683105469 running average of batch loss 9.117133140563965, time 0.9426684379577637\n",
      "#Epoch 29 with total epochs 300 at step 2 loss: 8.410918235778809 running average of batch loss 8.881728172302246, time 0.9286613464355469\n",
      "#Epoch 29 with total epochs 300 at step 3 loss: 9.743927955627441 running average of batch loss 9.097278118133545, time 0.9406676292419434\n",
      "#Epoch 29 with total epochs 300 at step 4 loss: 8.700599670410156 running average of batch loss 9.017942428588867, time 0.936664342880249\n",
      "#Epoch 29 with total epochs 300 at step 5 loss: 9.695918083190918 running average of batch loss 9.130938371022543, time 0.9356637001037598\n",
      "#Epoch 29 with total epochs 300 at step 6 loss: 8.765474319458008 running average of batch loss 9.078729220799037, time 0.9416680335998535\n",
      "#Epoch 29 with total epochs 300 at step 7 loss: 8.875646591186523 running average of batch loss 9.053343892097473, time 0.9321942329406738\n",
      "#Epoch 29 with total epochs 300 at step 8 loss: 8.991384506225586 running average of batch loss 9.046459515889486, time 0.9401679039001465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 29 with total epochs 300 at step 9 loss: 8.6297025680542 running average of batch loss 9.004783821105956, time 0.949613094329834\n",
      "#Epoch 29 with total epochs 300 at step 10 loss: 10.220380783081055 running average of batch loss 9.115292635830967, time 0.936664342880249\n",
      "#Epoch 29 with total epochs 300 at step 11 loss: 8.847508430480957 running average of batch loss 9.092977285385132, time 0.932664155960083\n",
      "#Epoch 29 with total epochs 300 at step 12 loss: 8.920774459838867 running average of batch loss 9.079730914189266, time 0.9496726989746094\n",
      "#Epoch 29 with total epochs 300 at step 13 loss: 9.092876434326172 running average of batch loss 9.08066987991333, time 0.9586992263793945\n",
      "#Epoch 29 with total epochs 300 at step 14 loss: 8.774468421936035 running average of batch loss 9.06025644938151, time 0.9321997165679932\n",
      "#Epoch 29 with total epochs 300 at step 15 loss: 9.146746635437012 running average of batch loss 9.06566208600998, time 0.9561784267425537\n",
      "#Epoch 29 with total epochs 300 at step 16 loss: 9.236226081848145 running average of batch loss 9.075695262235755, time 0.9371652603149414\n",
      "#Epoch 29 with total epochs 300 at step 17 loss: 9.122065544128418 running average of batch loss 9.078271389007568, time 0.954702615737915\n",
      "#Epoch 29 with total epochs 300 at step 18 loss: 8.869647979736328 running average of batch loss 9.06729120957224, time 0.9526760578155518\n",
      "#Epoch 29 with total epochs 300 at step 19 loss: 8.378727912902832 running average of batch loss 9.03286304473877, time 0.950674295425415\n",
      "#Epoch 29 with total epochs 300 at step 20 loss: 7.8530731201171875 running average of batch loss 8.976682572137742, time 0.9396672248840332\n",
      "#Epoch 30 with total epochs 300 at step 0 loss: 8.907795906066895 running average of batch loss 8.907795906066895, time 0.9426689147949219\n",
      "#Epoch 30 with total epochs 300 at step 1 loss: 7.667232513427734 running average of batch loss 8.287514209747314, time 0.9356644153594971\n",
      "#Epoch 30 with total epochs 300 at step 2 loss: 9.044258117675781 running average of batch loss 8.539762179056803, time 0.932661771774292\n",
      "#Epoch 30 with total epochs 300 at step 3 loss: 9.521476745605469 running average of batch loss 8.78519082069397, time 0.9383194446563721\n",
      "#Epoch 30 with total epochs 300 at step 4 loss: 10.189542770385742 running average of batch loss 9.066061210632324, time 0.9386649131774902\n",
      "#Epoch 30 with total epochs 300 at step 5 loss: 9.063726425170898 running average of batch loss 9.065672079722086, time 0.9276583194732666\n",
      "#Epoch 30 with total epochs 300 at step 6 loss: 8.29561710357666 running average of batch loss 8.955664225987025, time 0.938666582107544\n",
      "#Epoch 30 with total epochs 300 at step 7 loss: 9.118339538574219 running average of batch loss 8.975998640060425, time 0.9326610565185547\n",
      "#Epoch 30 with total epochs 300 at step 8 loss: 7.95284366607666 running average of batch loss 8.86231475406223, time 0.9266574382781982\n",
      "#Epoch 30 with total epochs 300 at step 9 loss: 8.535730361938477 running average of batch loss 8.829656314849853, time 0.9301965236663818\n",
      "#Epoch 30 with total epochs 300 at step 10 loss: 8.695390701293945 running average of batch loss 8.817450349981135, time 0.9446709156036377\n",
      "#Epoch 30 with total epochs 300 at step 11 loss: 9.585948944091797 running average of batch loss 8.881491899490356, time 0.9396688938140869\n",
      "#Epoch 30 with total epochs 300 at step 12 loss: 9.116781234741211 running average of batch loss 8.899591079125038, time 0.953676700592041\n",
      "#Epoch 30 with total epochs 300 at step 13 loss: 9.400659561157227 running average of batch loss 8.93538168498448, time 0.9326624870300293\n",
      "#Epoch 30 with total epochs 300 at step 14 loss: 8.252931594848633 running average of batch loss 8.889885012308756, time 0.9385883808135986\n",
      "#Epoch 30 with total epochs 300 at step 15 loss: 9.414334297180176 running average of batch loss 8.92266309261322, time 0.9472074508666992\n",
      "#Epoch 30 with total epochs 300 at step 16 loss: 8.972040176391602 running average of batch loss 8.925567626953125, time 0.9496855735778809\n",
      "#Epoch 30 with total epochs 300 at step 17 loss: 8.877306938171387 running average of batch loss 8.922886477576363, time 0.9572043418884277\n",
      "#Epoch 30 with total epochs 300 at step 18 loss: 8.821905136108398 running average of batch loss 8.917571670130679, time 0.9556770324707031\n",
      "#Epoch 30 with total epochs 300 at step 19 loss: 8.772092819213867 running average of batch loss 8.910297727584839, time 0.9466726779937744\n",
      "#Epoch 30 with total epochs 300 at step 20 loss: 9.961531639099121 running average of batch loss 8.960356485275994, time 0.9536778926849365\n",
      "#Epoch 31 with total epochs 300 at step 0 loss: 8.675312995910645 running average of batch loss 8.675312995910645, time 0.4913487434387207\n",
      "#Epoch 31 with total epochs 300 at step 1 loss: 8.592147827148438 running average of batch loss 8.633730411529541, time 0.8976385593414307\n",
      "#Epoch 31 with total epochs 300 at step 2 loss: 9.130949974060059 running average of batch loss 8.79947026570638, time 0.9496738910675049\n",
      "#Epoch 31 with total epochs 300 at step 3 loss: 8.583578109741211 running average of batch loss 8.745497226715088, time 0.9536778926849365\n",
      "#Epoch 31 with total epochs 300 at step 4 loss: 8.010215759277344 running average of batch loss 8.59844093322754, time 0.9496753215789795\n",
      "#Epoch 31 with total epochs 300 at step 5 loss: 9.221359252929688 running average of batch loss 8.702260653177897, time 0.9296584129333496\n",
      "#Epoch 31 with total epochs 300 at step 6 loss: 8.905465126037598 running average of batch loss 8.731289863586426, time 0.9419512748718262\n",
      "#Epoch 31 with total epochs 300 at step 7 loss: 8.172835350036621 running average of batch loss 8.6614830493927, time 0.9446706771850586\n",
      "#Epoch 31 with total epochs 300 at step 8 loss: 8.576879501342773 running average of batch loss 8.65208265516493, time 0.9321944713592529\n",
      "#Epoch 31 with total epochs 300 at step 9 loss: 8.727002143859863 running average of batch loss 8.659574604034423, time 0.9427058696746826\n",
      "#Epoch 31 with total epochs 300 at step 10 loss: 8.859359741210938 running average of batch loss 8.677736889232289, time 0.9306702613830566\n",
      "#Epoch 31 with total epochs 300 at step 11 loss: 8.416145324707031 running average of batch loss 8.655937592188517, time 0.9321603775024414\n",
      "#Epoch 31 with total epochs 300 at step 12 loss: 8.84907054901123 running average of batch loss 8.670793973482573, time 0.935166597366333\n",
      "#Epoch 31 with total epochs 300 at step 13 loss: 8.31393814086914 running average of batch loss 8.64530427115304, time 0.953676700592041\n",
      "#Epoch 31 with total epochs 300 at step 14 loss: 9.358110427856445 running average of batch loss 8.692824681599935, time 0.9402065277099609\n",
      "#Epoch 31 with total epochs 300 at step 15 loss: 8.74319076538086 running average of batch loss 8.695972561836243, time 0.9421906471252441\n",
      "#Epoch 31 with total epochs 300 at step 16 loss: 8.780814170837402 running average of batch loss 8.700963244718665, time 0.9356658458709717\n",
      "#Epoch 31 with total epochs 300 at step 17 loss: 9.153133392333984 running average of batch loss 8.726083808475071, time 0.936664342880249\n",
      "#Epoch 31 with total epochs 300 at step 18 loss: 8.661641120910645 running average of batch loss 8.722692088076943, time 0.9336624145507812\n",
      "#Epoch 31 with total epochs 300 at step 19 loss: 8.486262321472168 running average of batch loss 8.710870599746704, time 0.9416677951812744\n",
      "#Epoch 31 with total epochs 300 at step 20 loss: 8.233644485473633 running average of batch loss 8.688145546686082, time 0.9376645088195801\n",
      "#Epoch 32 with total epochs 300 at step 0 loss: 9.467841148376465 running average of batch loss 9.467841148376465, time 0.9401199817657471\n",
      "#Epoch 32 with total epochs 300 at step 1 loss: 9.458664894104004 running average of batch loss 9.463253021240234, time 0.9356639385223389\n",
      "#Epoch 32 with total epochs 300 at step 2 loss: 8.83607292175293 running average of batch loss 9.254192988077799, time 0.9356637001037598\n",
      "#Epoch 32 with total epochs 300 at step 3 loss: 7.836008548736572 running average of batch loss 8.899646878242493, time 0.9476709365844727\n",
      "#Epoch 32 with total epochs 300 at step 4 loss: 8.778307914733887 running average of batch loss 8.875379085540771, time 0.9416704177856445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 32 with total epochs 300 at step 5 loss: 8.051931381225586 running average of batch loss 8.738137801488241, time 0.9396655559539795\n",
      "#Epoch 32 with total epochs 300 at step 6 loss: 8.402912139892578 running average of batch loss 8.69024842126029, time 0.9326622486114502\n",
      "#Epoch 32 with total epochs 300 at step 7 loss: 8.357723236083984 running average of batch loss 8.64868277311325, time 0.944671630859375\n",
      "#Epoch 32 with total epochs 300 at step 8 loss: 7.904767036437988 running average of batch loss 8.566025469038221, time 0.935666561126709\n",
      "#Epoch 32 with total epochs 300 at step 9 loss: 9.290606498718262 running average of batch loss 8.638483572006226, time 0.9306602478027344\n",
      "#Epoch 32 with total epochs 300 at step 10 loss: 7.716784477233887 running average of batch loss 8.55469274520874, time 0.9516749382019043\n",
      "#Epoch 32 with total epochs 300 at step 11 loss: 9.346200942993164 running average of batch loss 8.620651761690775, time 0.9586813449859619\n",
      "#Epoch 32 with total epochs 300 at step 12 loss: 8.809884071350098 running average of batch loss 8.635208093203032, time 0.9706647396087646\n",
      "#Epoch 32 with total epochs 300 at step 13 loss: 8.752479553222656 running average of batch loss 8.643584626061577, time 0.9476468563079834\n",
      "#Epoch 32 with total epochs 300 at step 14 loss: 9.111881256103516 running average of batch loss 8.674804401397704, time 0.9456706047058105\n",
      "#Epoch 32 with total epochs 300 at step 15 loss: 8.447280883789062 running average of batch loss 8.660584181547165, time 0.9436683654785156\n",
      "#Epoch 32 with total epochs 300 at step 16 loss: 8.560225486755371 running average of batch loss 8.654680728912354, time 0.9426703453063965\n",
      "#Epoch 32 with total epochs 300 at step 17 loss: 8.097737312316895 running average of batch loss 8.623739427990383, time 0.9336624145507812\n",
      "#Epoch 32 with total epochs 300 at step 18 loss: 8.301334381103516 running average of batch loss 8.606770741312127, time 0.9436695575714111\n",
      "#Epoch 32 with total epochs 300 at step 19 loss: 8.195884704589844 running average of batch loss 8.586226439476013, time 0.9336624145507812\n",
      "#Epoch 32 with total epochs 300 at step 20 loss: 8.918989181518555 running average of batch loss 8.602072284335183, time 0.9426686763763428\n",
      "#Epoch 33 with total epochs 300 at step 0 loss: 8.45933723449707 running average of batch loss 8.45933723449707, time 0.9396655559539795\n",
      "#Epoch 33 with total epochs 300 at step 1 loss: 8.805822372436523 running average of batch loss 8.632579803466797, time 0.9416694641113281\n",
      "#Epoch 33 with total epochs 300 at step 2 loss: 8.236459732055664 running average of batch loss 8.500539779663086, time 0.9356625080108643\n",
      "#Epoch 33 with total epochs 300 at step 3 loss: 8.179286003112793 running average of batch loss 8.420226335525513, time 0.9416704177856445\n",
      "#Epoch 33 with total epochs 300 at step 4 loss: 9.29426097869873 running average of batch loss 8.595033264160156, time 0.934661865234375\n",
      "#Epoch 33 with total epochs 300 at step 5 loss: 8.078132629394531 running average of batch loss 8.508883158365885, time 0.93764328956604\n",
      "#Epoch 33 with total epochs 300 at step 6 loss: 8.366456985473633 running average of batch loss 8.488536562238421, time 0.9446704387664795\n",
      "#Epoch 33 with total epochs 300 at step 7 loss: 8.247148513793945 running average of batch loss 8.458363056182861, time 0.9376657009124756\n",
      "#Epoch 33 with total epochs 300 at step 8 loss: 8.682470321655273 running average of batch loss 8.483263863457573, time 0.934661865234375\n",
      "#Epoch 33 with total epochs 300 at step 9 loss: 8.018665313720703 running average of batch loss 8.436804008483886, time 0.9452080726623535\n",
      "#Epoch 33 with total epochs 300 at step 10 loss: 9.481352806091309 running average of batch loss 8.53176299008456, time 0.939666748046875\n",
      "#Epoch 33 with total epochs 300 at step 11 loss: 8.345746994018555 running average of batch loss 8.516261657079061, time 0.9486730098724365\n",
      "#Epoch 33 with total epochs 300 at step 12 loss: 8.846639633178711 running average of batch loss 8.541675347548265, time 0.9487054347991943\n",
      "#Epoch 33 with total epochs 300 at step 13 loss: 8.092229843139648 running average of batch loss 8.509572097233363, time 0.9476737976074219\n",
      "#Epoch 33 with total epochs 300 at step 14 loss: 8.413961410522461 running average of batch loss 8.503198051452637, time 0.9426448345184326\n",
      "#Epoch 33 with total epochs 300 at step 15 loss: 8.8336181640625 running average of batch loss 8.523849308490753, time 0.9486749172210693\n",
      "#Epoch 33 with total epochs 300 at step 16 loss: 8.36159896850586 running average of batch loss 8.514305170844583, time 0.940666913986206\n",
      "#Epoch 33 with total epochs 300 at step 17 loss: 7.977673530578613 running average of batch loss 8.484492301940918, time 0.9386646747589111\n",
      "#Epoch 33 with total epochs 300 at step 18 loss: 8.5143404006958 running average of batch loss 8.486063254506965, time 0.9536798000335693\n",
      "#Epoch 33 with total epochs 300 at step 19 loss: 8.215787887573242 running average of batch loss 8.472549486160279, time 0.9566788673400879\n",
      "#Epoch 33 with total epochs 300 at step 20 loss: 8.215471267700195 running average of batch loss 8.460307666233607, time 0.9596810340881348\n",
      "#Epoch 34 with total epochs 300 at step 0 loss: 8.547709465026855 running average of batch loss 8.547709465026855, time 0.9466722011566162\n",
      "#Epoch 34 with total epochs 300 at step 1 loss: 8.087897300720215 running average of batch loss 8.317803382873535, time 0.9586803913116455\n",
      "#Epoch 34 with total epochs 300 at step 2 loss: 8.29389476776123 running average of batch loss 8.309833844502768, time 0.9426684379577637\n",
      "#Epoch 34 with total epochs 300 at step 3 loss: 8.017008781433105 running average of batch loss 8.236627578735352, time 0.929659366607666\n",
      "#Epoch 34 with total epochs 300 at step 4 loss: 8.098016738891602 running average of batch loss 8.2089054107666, time 0.941666841506958\n",
      "#Epoch 34 with total epochs 300 at step 5 loss: 8.98324966430664 running average of batch loss 8.337962786356607, time 0.9386670589447021\n",
      "#Epoch 34 with total epochs 300 at step 6 loss: 8.369625091552734 running average of batch loss 8.342485972813197, time 0.939666748046875\n",
      "#Epoch 34 with total epochs 300 at step 7 loss: 8.476129531860352 running average of batch loss 8.359191417694092, time 0.9456708431243896\n",
      "#Epoch 34 with total epochs 300 at step 8 loss: 8.859347343444824 running average of batch loss 8.414764298333061, time 0.9396665096282959\n",
      "#Epoch 34 with total epochs 300 at step 9 loss: 8.283751487731934 running average of batch loss 8.401663017272949, time 0.9447011947631836\n",
      "#Epoch 34 with total epochs 300 at step 10 loss: 8.600178718566895 running average of batch loss 8.419709899208762, time 0.9401707649230957\n",
      "#Epoch 34 with total epochs 300 at step 11 loss: 8.024127960205078 running average of batch loss 8.386744737625122, time 0.9346628189086914\n",
      "#Epoch 34 with total epochs 300 at step 12 loss: 8.822157859802246 running average of batch loss 8.42023805471567, time 0.9416677951812744\n",
      "#Epoch 34 with total epochs 300 at step 13 loss: 7.871893882751465 running average of batch loss 8.381070613861084, time 0.9326603412628174\n",
      "#Epoch 34 with total epochs 300 at step 14 loss: 8.522223472595215 running average of batch loss 8.39048080444336, time 0.9376649856567383\n",
      "#Epoch 34 with total epochs 300 at step 15 loss: 8.744970321655273 running average of batch loss 8.412636399269104, time 0.9286575317382812\n",
      "#Epoch 34 with total epochs 300 at step 16 loss: 9.438841819763184 running average of batch loss 8.47300142400405, time 0.9366633892059326\n",
      "#Epoch 34 with total epochs 300 at step 17 loss: 8.102815628051758 running average of batch loss 8.452435546451145, time 0.9366672039031982\n",
      "#Epoch 34 with total epochs 300 at step 18 loss: 8.509109497070312 running average of batch loss 8.455418385957417, time 0.9606821537017822\n",
      "#Epoch 34 with total epochs 300 at step 19 loss: 8.938962936401367 running average of batch loss 8.479595613479614, time 0.9446702003479004\n",
      "#Epoch 34 with total epochs 300 at step 20 loss: 8.604574203491211 running average of batch loss 8.485546974908738, time 0.9276590347290039\n",
      "#Epoch 35 with total epochs 300 at step 0 loss: 7.9173431396484375 running average of batch loss 7.9173431396484375, time 0.9386663436889648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 35 with total epochs 300 at step 1 loss: 8.740824699401855 running average of batch loss 8.329083919525146, time 0.9736917018890381\n",
      "#Epoch 35 with total epochs 300 at step 2 loss: 8.477988243103027 running average of batch loss 8.378718694051107, time 0.933664083480835\n",
      "#Epoch 35 with total epochs 300 at step 3 loss: 9.096641540527344 running average of batch loss 8.558199405670166, time 0.957679033279419\n",
      "#Epoch 35 with total epochs 300 at step 4 loss: 7.543180465698242 running average of batch loss 8.355195617675781, time 0.9396662712097168\n",
      "#Epoch 35 with total epochs 300 at step 5 loss: 7.718881607055664 running average of batch loss 8.249143282572428, time 0.9346423149108887\n",
      "#Epoch 35 with total epochs 300 at step 6 loss: 8.593353271484375 running average of batch loss 8.298316138131279, time 0.9416682720184326\n",
      "#Epoch 35 with total epochs 300 at step 7 loss: 8.887645721435547 running average of batch loss 8.371982336044312, time 0.933661699295044\n",
      "#Epoch 35 with total epochs 300 at step 8 loss: 8.2088623046875 running average of batch loss 8.353857888115776, time 0.9336638450622559\n",
      "#Epoch 35 with total epochs 300 at step 9 loss: 8.597169876098633 running average of batch loss 8.378189086914062, time 0.9436697959899902\n",
      "#Epoch 35 with total epochs 300 at step 10 loss: 8.86070442199707 running average of batch loss 8.422054117376154, time 0.9406673908233643\n",
      "#Epoch 35 with total epochs 300 at step 11 loss: 7.626876354217529 running average of batch loss 8.355789303779602, time 0.9266574382781982\n",
      "#Epoch 35 with total epochs 300 at step 12 loss: 8.659744262695312 running average of batch loss 8.379170454465426, time 0.9366426467895508\n",
      "#Epoch 35 with total epochs 300 at step 13 loss: 8.43212890625 running average of batch loss 8.382953201021467, time 0.9446711540222168\n",
      "#Epoch 35 with total epochs 300 at step 14 loss: 9.32696533203125 running average of batch loss 8.445887343088787, time 0.9276587963104248\n",
      "#Epoch 35 with total epochs 300 at step 15 loss: 8.55886459350586 running average of batch loss 8.452948421239853, time 0.9436697959899902\n",
      "#Epoch 35 with total epochs 300 at step 16 loss: 8.205458641052246 running average of batch loss 8.438390198875876, time 0.9316625595092773\n",
      "#Epoch 35 with total epochs 300 at step 17 loss: 8.559134483337402 running average of batch loss 8.445098214679295, time 0.9436690807342529\n",
      "#Epoch 35 with total epochs 300 at step 18 loss: 8.346541404724121 running average of batch loss 8.439911014155337, time 0.939666748046875\n",
      "#Epoch 35 with total epochs 300 at step 19 loss: 8.6629056930542 running average of batch loss 8.45106074810028, time 0.9306600093841553\n",
      "#Epoch 35 with total epochs 300 at step 20 loss: 8.641852378845215 running average of batch loss 8.46014606385004, time 0.940669059753418\n",
      "#Epoch 36 with total epochs 300 at step 0 loss: 8.33249282836914 running average of batch loss 8.33249282836914, time 0.9606821537017822\n",
      "#Epoch 36 with total epochs 300 at step 1 loss: 7.956791400909424 running average of batch loss 8.144642114639282, time 0.9546759128570557\n",
      "#Epoch 36 with total epochs 300 at step 2 loss: 8.602045059204102 running average of batch loss 8.297109762827555, time 0.9376673698425293\n",
      "#Epoch 36 with total epochs 300 at step 3 loss: 8.707113265991211 running average of batch loss 8.39961063861847, time 0.9496734142303467\n",
      "#Epoch 36 with total epochs 300 at step 4 loss: 9.007098197937012 running average of batch loss 8.521108150482178, time 0.9446704387664795\n",
      "#Epoch 36 with total epochs 300 at step 5 loss: 8.26691722869873 running average of batch loss 8.478742996851603, time 0.9356637001037598\n",
      "#Epoch 36 with total epochs 300 at step 6 loss: 9.319405555725098 running average of batch loss 8.598837648119245, time 0.9364194869995117\n",
      "#Epoch 36 with total epochs 300 at step 7 loss: 8.246533393859863 running average of batch loss 8.554799616336823, time 0.935664176940918\n",
      "#Epoch 36 with total epochs 300 at step 8 loss: 7.706023216247559 running average of batch loss 8.460491127438015, time 0.9426674842834473\n",
      "#Epoch 36 with total epochs 300 at step 9 loss: 9.165648460388184 running average of batch loss 8.531006860733033, time 0.9341979026794434\n",
      "#Epoch 36 with total epochs 300 at step 10 loss: 8.202859878540039 running average of batch loss 8.501175316897305, time 0.9436683654785156\n",
      "#Epoch 36 with total epochs 300 at step 11 loss: 8.046747207641602 running average of batch loss 8.463306307792664, time 0.936664342880249\n",
      "#Epoch 36 with total epochs 300 at step 12 loss: 8.221366882324219 running average of batch loss 8.44469558275663, time 0.9406681060791016\n",
      "#Epoch 36 with total epochs 300 at step 13 loss: 8.655698776245117 running average of batch loss 8.45976723943438, time 0.931659460067749\n",
      "#Epoch 36 with total epochs 300 at step 14 loss: 8.226670265197754 running average of batch loss 8.444227441151936, time 0.9256577491760254\n",
      "#Epoch 36 with total epochs 300 at step 15 loss: 7.720122814178467 running average of batch loss 8.398970901966095, time 0.9356660842895508\n",
      "#Epoch 36 with total epochs 300 at step 16 loss: 8.100578308105469 running average of batch loss 8.381418396444882, time 0.9386656284332275\n",
      "#Epoch 36 with total epochs 300 at step 17 loss: 8.032358169555664 running average of batch loss 8.362026161617703, time 0.9276583194732666\n",
      "#Epoch 36 with total epochs 300 at step 18 loss: 8.344467163085938 running average of batch loss 8.36110200380024, time 0.9442203044891357\n",
      "#Epoch 36 with total epochs 300 at step 19 loss: 9.308319091796875 running average of batch loss 8.408462858200073, time 0.9446475505828857\n",
      "#Epoch 36 with total epochs 300 at step 20 loss: 8.017951011657715 running average of batch loss 8.389867055983771, time 0.9336414337158203\n",
      "#Epoch 37 with total epochs 300 at step 0 loss: 9.019561767578125 running average of batch loss 9.019561767578125, time 0.9686896800994873\n",
      "#Epoch 37 with total epochs 300 at step 1 loss: 8.724215507507324 running average of batch loss 8.871888637542725, time 0.9596810340881348\n",
      "#Epoch 37 with total epochs 300 at step 2 loss: 8.614965438842773 running average of batch loss 8.786247571309408, time 0.9516754150390625\n",
      "#Epoch 37 with total epochs 300 at step 3 loss: 8.134557723999023 running average of batch loss 8.623325109481812, time 0.9566788673400879\n",
      "#Epoch 37 with total epochs 300 at step 4 loss: 8.078859329223633 running average of batch loss 8.514431953430176, time 0.9516746997833252\n",
      "#Epoch 37 with total epochs 300 at step 5 loss: 8.344762802124023 running average of batch loss 8.486153761545816, time 0.9676861763000488\n",
      "#Epoch 37 with total epochs 300 at step 6 loss: 8.59644889831543 running average of batch loss 8.501910209655762, time 0.9366645812988281\n",
      "#Epoch 37 with total epochs 300 at step 7 loss: 8.562621116638184 running average of batch loss 8.509499073028564, time 0.9416453838348389\n",
      "#Epoch 37 with total epochs 300 at step 8 loss: 9.043254852294922 running average of batch loss 8.568805270724827, time 0.9396672248840332\n",
      "#Epoch 37 with total epochs 300 at step 9 loss: 8.984681129455566 running average of batch loss 8.610392856597901, time 0.9536778926849365\n",
      "#Epoch 37 with total epochs 300 at step 10 loss: 7.613948822021484 running average of batch loss 8.519807035272772, time 0.9406697750091553\n",
      "#Epoch 37 with total epochs 300 at step 11 loss: 7.910607814788818 running average of batch loss 8.469040433565775, time 0.9386658668518066\n",
      "#Epoch 37 with total epochs 300 at step 12 loss: 7.818502902984619 running average of batch loss 8.418999085059532, time 0.9276583194732666\n",
      "#Epoch 37 with total epochs 300 at step 13 loss: 8.855484962463379 running average of batch loss 8.450176647731237, time 0.9396657943725586\n",
      "#Epoch 37 with total epochs 300 at step 14 loss: 8.273306846618652 running average of batch loss 8.438385327657064, time 0.9456713199615479\n",
      "#Epoch 37 with total epochs 300 at step 15 loss: 8.083939552307129 running average of batch loss 8.416232466697693, time 0.9456727504730225\n",
      "#Epoch 37 with total epochs 300 at step 16 loss: 8.23891830444336 running average of batch loss 8.405802221859203, time 0.941666841506958\n",
      "#Epoch 37 with total epochs 300 at step 17 loss: 8.385513305664062 running average of batch loss 8.404675059848362, time 0.9346640110015869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 37 with total epochs 300 at step 18 loss: 7.833889961242676 running average of batch loss 8.374633738869115, time 0.9406700134277344\n",
      "#Epoch 37 with total epochs 300 at step 19 loss: 8.012894630432129 running average of batch loss 8.356546783447266, time 0.9436690807342529\n",
      "#Epoch 37 with total epochs 300 at step 20 loss: 8.493511199951172 running average of batch loss 8.36306889851888, time 0.9376668930053711\n",
      "#Epoch 38 with total epochs 300 at step 0 loss: 8.344484329223633 running average of batch loss 8.344484329223633, time 0.9446702003479004\n",
      "#Epoch 38 with total epochs 300 at step 1 loss: 7.90134334564209 running average of batch loss 8.122913837432861, time 0.9416675567626953\n",
      "#Epoch 38 with total epochs 300 at step 2 loss: 8.965561866760254 running average of batch loss 8.403796513875326, time 0.9316611289978027\n",
      "#Epoch 38 with total epochs 300 at step 3 loss: 7.812193870544434 running average of batch loss 8.255895853042603, time 0.9546771049499512\n",
      "#Epoch 38 with total epochs 300 at step 4 loss: 8.510970115661621 running average of batch loss 8.306910705566406, time 0.9436695575714111\n",
      "#Epoch 38 with total epochs 300 at step 5 loss: 8.218883514404297 running average of batch loss 8.292239507039389, time 0.9396655559539795\n",
      "#Epoch 38 with total epochs 300 at step 6 loss: 9.039752960205078 running average of batch loss 8.399027143205915, time 0.9516768455505371\n",
      "#Epoch 38 with total epochs 300 at step 7 loss: 7.893067836761475 running average of batch loss 8.33578222990036, time 0.9546763896942139\n",
      "#Epoch 38 with total epochs 300 at step 8 loss: 9.04833984375 running average of batch loss 8.414955298105875, time 0.9336621761322021\n",
      "#Epoch 38 with total epochs 300 at step 9 loss: 7.368871212005615 running average of batch loss 8.31034688949585, time 0.9366648197174072\n",
      "#Epoch 38 with total epochs 300 at step 10 loss: 8.058073997497559 running average of batch loss 8.287412990223277, time 0.9386649131774902\n",
      "#Epoch 38 with total epochs 300 at step 11 loss: 7.837807655334473 running average of batch loss 8.249945878982544, time 0.936643123626709\n",
      "#Epoch 38 with total epochs 300 at step 12 loss: 7.538055419921875 running average of batch loss 8.195185074439415, time 0.9296579360961914\n",
      "#Epoch 38 with total epochs 300 at step 13 loss: 7.888413429260254 running average of batch loss 8.173272814069476, time 0.9356656074523926\n",
      "#Epoch 38 with total epochs 300 at step 14 loss: 7.953985214233398 running average of batch loss 8.15865364074707, time 0.9276587963104248\n",
      "#Epoch 38 with total epochs 300 at step 15 loss: 8.22074031829834 running average of batch loss 8.162534058094025, time 0.9416697025299072\n",
      "#Epoch 38 with total epochs 300 at step 16 loss: 8.329422950744629 running average of batch loss 8.172351051779355, time 0.9476711750030518\n",
      "#Epoch 38 with total epochs 300 at step 17 loss: 8.057104110717773 running average of batch loss 8.1659484439426, time 0.937664270401001\n",
      "#Epoch 38 with total epochs 300 at step 18 loss: 7.825892448425293 running average of batch loss 8.148050759968005, time 0.9366636276245117\n",
      "#Epoch 38 with total epochs 300 at step 19 loss: 8.144020080566406 running average of batch loss 8.147849225997925, time 0.9286582469940186\n",
      "#Epoch 38 with total epochs 300 at step 20 loss: 7.7667460441589355 running average of batch loss 8.129701455434164, time 0.9266560077667236\n",
      "#Epoch 39 with total epochs 300 at step 0 loss: 8.199416160583496 running average of batch loss 8.199416160583496, time 0.9476733207702637\n",
      "#Epoch 39 with total epochs 300 at step 1 loss: 8.420334815979004 running average of batch loss 8.30987548828125, time 0.9456701278686523\n",
      "#Epoch 39 with total epochs 300 at step 2 loss: 8.13689136505127 running average of batch loss 8.252214113871256, time 0.9296610355377197\n",
      "#Epoch 39 with total epochs 300 at step 3 loss: 7.814661979675293 running average of batch loss 8.142826080322266, time 0.9406673908233643\n",
      "#Epoch 39 with total epochs 300 at step 4 loss: 8.32496166229248 running average of batch loss 8.179253196716308, time 0.9476726055145264\n",
      "#Epoch 39 with total epochs 300 at step 5 loss: 8.452466011047363 running average of batch loss 8.224788665771484, time 0.9386658668518066\n",
      "#Epoch 39 with total epochs 300 at step 6 loss: 8.103434562683105 running average of batch loss 8.207452365330287, time 0.959681510925293\n",
      "#Epoch 39 with total epochs 300 at step 7 loss: 7.583599090576172 running average of batch loss 8.129470705986023, time 0.9486734867095947\n",
      "#Epoch 39 with total epochs 300 at step 8 loss: 8.246613502502441 running average of batch loss 8.142486572265625, time 0.9406671524047852\n",
      "#Epoch 39 with total epochs 300 at step 9 loss: 8.831657409667969 running average of batch loss 8.21140365600586, time 0.9506733417510986\n",
      "#Epoch 39 with total epochs 300 at step 10 loss: 7.955833435058594 running average of batch loss 8.188169999556107, time 0.9366664886474609\n",
      "#Epoch 39 with total epochs 300 at step 11 loss: 7.866472244262695 running average of batch loss 8.161361853281656, time 0.9436690807342529\n",
      "#Epoch 39 with total epochs 300 at step 12 loss: 8.198663711547852 running average of batch loss 8.164231226994442, time 0.9406673908233643\n",
      "#Epoch 39 with total epochs 300 at step 13 loss: 8.384810447692871 running average of batch loss 8.179986885615758, time 0.9416670799255371\n",
      "#Epoch 39 with total epochs 300 at step 14 loss: 8.841629028320312 running average of batch loss 8.224096361796061, time 0.49234795570373535\n",
      "#Epoch 39 with total epochs 300 at step 15 loss: 8.607207298278809 running average of batch loss 8.248040795326233, time 0.5303769111633301\n",
      "#Epoch 39 with total epochs 300 at step 16 loss: 8.206145286560059 running average of batch loss 8.245576353634105, time 0.57840895652771\n",
      "#Epoch 39 with total epochs 300 at step 17 loss: 8.731067657470703 running average of batch loss 8.272548092736137, time 0.48334383964538574\n",
      "#Epoch 39 with total epochs 300 at step 18 loss: 8.195387840270996 running average of batch loss 8.26848702681692, time 0.6094319820404053\n",
      "#Epoch 39 with total epochs 300 at step 19 loss: 8.449240684509277 running average of batch loss 8.277524709701538, time 0.6054279804229736\n",
      "#Epoch 39 with total epochs 300 at step 20 loss: 8.13830280303955 running average of batch loss 8.270895095098586, time 0.49535179138183594\n",
      "#Epoch 40 with total epochs 300 at step 0 loss: 7.773538589477539 running average of batch loss 7.773538589477539, time 0.578411340713501\n",
      "#Epoch 40 with total epochs 300 at step 1 loss: 7.84486198425293 running average of batch loss 7.809200286865234, time 0.61043381690979\n",
      "#Epoch 40 with total epochs 300 at step 2 loss: 7.945211410522461 running average of batch loss 7.85453732808431, time 0.4933493137359619\n",
      "#Epoch 40 with total epochs 300 at step 3 loss: 8.524354934692383 running average of batch loss 8.021991729736328, time 0.4873471260070801\n",
      "#Epoch 40 with total epochs 300 at step 4 loss: 7.963161468505859 running average of batch loss 8.010225677490235, time 0.4883236885070801\n",
      "#Epoch 40 with total epochs 300 at step 5 loss: 8.487199783325195 running average of batch loss 8.08972136179606, time 0.487346887588501\n",
      "#Epoch 40 with total epochs 300 at step 6 loss: 7.923883438110352 running average of batch loss 8.06603022984096, time 0.48932576179504395\n",
      "#Epoch 40 with total epochs 300 at step 7 loss: 7.6056036949157715 running average of batch loss 8.008476912975311, time 0.491351842880249\n",
      "#Epoch 40 with total epochs 300 at step 8 loss: 7.513802528381348 running average of batch loss 7.9535130924648705, time 0.538384199142456\n",
      "#Epoch 40 with total epochs 300 at step 9 loss: 8.213711738586426 running average of batch loss 7.979532957077026, time 0.4893460273742676\n",
      "#Epoch 40 with total epochs 300 at step 10 loss: 8.64858627319336 running average of batch loss 8.040355985814875, time 0.48534584045410156\n",
      "#Epoch 40 with total epochs 300 at step 11 loss: 8.15694522857666 running average of batch loss 8.050071756045023, time 0.48734593391418457\n",
      "#Epoch 40 with total epochs 300 at step 12 loss: 7.449142932891846 running average of batch loss 8.003846461956318, time 0.4933500289916992\n",
      "#Epoch 40 with total epochs 300 at step 13 loss: 7.613442897796631 running average of batch loss 7.9759604930877686, time 0.48734569549560547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 40 with total epochs 300 at step 14 loss: 7.32962703704834 running average of batch loss 7.932871596018473, time 0.4843432903289795\n",
      "#Epoch 40 with total epochs 300 at step 15 loss: 8.062049865722656 running average of batch loss 7.940945237874985, time 0.4873504638671875\n",
      "#Epoch 40 with total epochs 300 at step 16 loss: 7.580345630645752 running average of batch loss 7.919733496273265, time 0.5023276805877686\n",
      "#Epoch 40 with total epochs 300 at step 17 loss: 7.846942901611328 running average of batch loss 7.915689574347602, time 0.49735546112060547\n",
      "#Epoch 40 with total epochs 300 at step 18 loss: 7.82155704498291 running average of batch loss 7.910735230696829, time 1.2048547267913818\n",
      "#Epoch 40 with total epochs 300 at step 19 loss: 8.057122230529785 running average of batch loss 7.918054580688477, time 1.0367345809936523\n",
      "#Epoch 40 with total epochs 300 at step 20 loss: 8.040529251098633 running average of batch loss 7.923886707850865, time 0.9746911525726318\n",
      "avg difference between predicted and ground truth batch wise 9.062134564178331\n",
      "#Epoch 41 with total epochs 300 at step 0 loss: 7.563292026519775 running average of batch loss 7.563292026519775, time 0.500354528427124\n",
      "#Epoch 41 with total epochs 300 at step 1 loss: 6.974600791931152 running average of batch loss 7.268946409225464, time 0.9126484394073486\n",
      "#Epoch 41 with total epochs 300 at step 2 loss: 8.319869995117188 running average of batch loss 7.619254271189372, time 0.9356627464294434\n",
      "#Epoch 41 with total epochs 300 at step 3 loss: 7.896456718444824 running average of batch loss 7.688554883003235, time 0.9376668930053711\n",
      "#Epoch 41 with total epochs 300 at step 4 loss: 8.020401000976562 running average of batch loss 7.7549241065979, time 0.9476723670959473\n",
      "#Epoch 41 with total epochs 300 at step 5 loss: 8.267003059387207 running average of batch loss 7.840270598729451, time 0.9396662712097168\n",
      "#Epoch 41 with total epochs 300 at step 6 loss: 7.279186248779297 running average of batch loss 7.7601156915937155, time 0.9336612224578857\n",
      "#Epoch 41 with total epochs 300 at step 7 loss: 6.558045864105225 running average of batch loss 7.609856963157654, time 0.9326639175415039\n",
      "#Epoch 41 with total epochs 300 at step 8 loss: 7.423354148864746 running average of batch loss 7.589134428236219, time 0.9346632957458496\n",
      "#Epoch 41 with total epochs 300 at step 9 loss: 7.833137035369873 running average of batch loss 7.613534688949585, time 0.9266562461853027\n",
      "#Epoch 41 with total epochs 300 at step 10 loss: 7.68709659576416 running average of batch loss 7.620222135023638, time 0.9296605587005615\n",
      "#Epoch 41 with total epochs 300 at step 11 loss: 8.669292449951172 running average of batch loss 7.707644661267598, time 0.9376671314239502\n",
      "#Epoch 41 with total epochs 300 at step 12 loss: 7.903141975402832 running average of batch loss 7.722682916201078, time 0.9266598224639893\n",
      "#Epoch 41 with total epochs 300 at step 13 loss: 8.073705673217773 running average of batch loss 7.747755970273699, time 0.9436700344085693\n",
      "#Epoch 41 with total epochs 300 at step 14 loss: 8.377646446228027 running average of batch loss 7.789748668670654, time 0.9396653175354004\n",
      "#Epoch 41 with total epochs 300 at step 15 loss: 7.125580787658691 running average of batch loss 7.748238176107407, time 0.9276595115661621\n",
      "#Epoch 41 with total epochs 300 at step 16 loss: 7.464228630065918 running average of batch loss 7.731531732222614, time 0.9496748447418213\n",
      "#Epoch 41 with total epochs 300 at step 17 loss: 7.855469703674316 running average of batch loss 7.738417175081041, time 0.9496736526489258\n",
      "#Epoch 41 with total epochs 300 at step 18 loss: 7.806570529937744 running average of batch loss 7.74200419375771, time 0.949674129486084\n",
      "#Epoch 41 with total epochs 300 at step 19 loss: 7.532463550567627 running average of batch loss 7.731527161598206, time 0.9518954753875732\n",
      "#Epoch 41 with total epochs 300 at step 20 loss: 8.306130409240723 running average of batch loss 7.758889221009754, time 0.9482417106628418\n",
      "#Epoch 42 with total epochs 300 at step 0 loss: 7.8232622146606445 running average of batch loss 7.8232622146606445, time 0.9428441524505615\n",
      "#Epoch 42 with total epochs 300 at step 1 loss: 7.799775123596191 running average of batch loss 7.811518669128418, time 0.9367167949676514\n",
      "#Epoch 42 with total epochs 300 at step 2 loss: 7.519386291503906 running average of batch loss 7.714141209920247, time 0.935340404510498\n",
      "#Epoch 42 with total epochs 300 at step 3 loss: 7.880249500274658 running average of batch loss 7.75566828250885, time 0.932319164276123\n",
      "#Epoch 42 with total epochs 300 at step 4 loss: 9.924345970153809 running average of batch loss 8.189403820037843, time 0.9437060356140137\n",
      "#Epoch 42 with total epochs 300 at step 5 loss: 7.573587894439697 running average of batch loss 8.08676783243815, time 0.9406681060791016\n",
      "#Epoch 42 with total epochs 300 at step 6 loss: 7.853535175323486 running average of batch loss 8.05344888142177, time 0.9396665096282959\n",
      "#Epoch 42 with total epochs 300 at step 7 loss: 7.938554286956787 running average of batch loss 8.039087057113647, time 0.9336612224578857\n",
      "#Epoch 42 with total epochs 300 at step 8 loss: 8.026537895202637 running average of batch loss 8.037692705790201, time 0.9426705837249756\n",
      "#Epoch 42 with total epochs 300 at step 9 loss: 8.237807273864746 running average of batch loss 8.057704162597656, time 0.9291942119598389\n",
      "#Epoch 42 with total epochs 300 at step 10 loss: 8.184830665588379 running average of batch loss 8.069261117414994, time 0.9411664009094238\n",
      "#Epoch 42 with total epochs 300 at step 11 loss: 7.086569786071777 running average of batch loss 7.9873701731363935, time 0.9491982460021973\n",
      "#Epoch 42 with total epochs 300 at step 12 loss: 7.43956184387207 running average of batch loss 7.945231070885291, time 0.9356634616851807\n",
      "#Epoch 42 with total epochs 300 at step 13 loss: 7.930732727050781 running average of batch loss 7.944195474897112, time 0.940666675567627\n",
      "#Epoch 42 with total epochs 300 at step 14 loss: 8.437971115112305 running average of batch loss 7.977113850911459, time 0.9436681270599365\n",
      "#Epoch 42 with total epochs 300 at step 15 loss: 7.84820556640625 running average of batch loss 7.969057083129883, time 0.9366660118103027\n",
      "#Epoch 42 with total epochs 300 at step 16 loss: 8.283251762390137 running average of batch loss 7.987539123086369, time 0.9482038021087646\n",
      "#Epoch 42 with total epochs 300 at step 17 loss: 7.496606826782227 running average of batch loss 7.960265106625027, time 0.9556782245635986\n",
      "#Epoch 42 with total epochs 300 at step 18 loss: 8.045197486877441 running average of batch loss 7.96473523190147, time 0.9466714859008789\n",
      "#Epoch 42 with total epochs 300 at step 19 loss: 7.98399019241333 running average of batch loss 7.965697979927063, time 0.9516754150390625\n",
      "#Epoch 42 with total epochs 300 at step 20 loss: 7.769700527191162 running average of batch loss 7.95636476789202, time 0.9556782245635986\n",
      "#Epoch 43 with total epochs 300 at step 0 loss: 7.8152546882629395 running average of batch loss 7.8152546882629395, time 0.9406671524047852\n",
      "#Epoch 43 with total epochs 300 at step 1 loss: 7.5673065185546875 running average of batch loss 7.6912806034088135, time 0.9386680126190186\n",
      "#Epoch 43 with total epochs 300 at step 2 loss: 7.786726951599121 running average of batch loss 7.723096052805583, time 0.9336614608764648\n",
      "#Epoch 43 with total epochs 300 at step 3 loss: 8.725381851196289 running average of batch loss 7.973667502403259, time 0.9356639385223389\n",
      "#Epoch 43 with total epochs 300 at step 4 loss: 7.765863418579102 running average of batch loss 7.932106685638428, time 0.9346632957458496\n",
      "#Epoch 43 with total epochs 300 at step 5 loss: 8.280383110046387 running average of batch loss 7.990152756373088, time 0.9256560802459717\n",
      "#Epoch 43 with total epochs 300 at step 6 loss: 7.881441116333008 running average of batch loss 7.974622522081647, time 0.9396681785583496\n",
      "#Epoch 43 with total epochs 300 at step 7 loss: 8.096702575683594 running average of batch loss 7.989882528781891, time 0.9321703910827637\n",
      "#Epoch 43 with total epochs 300 at step 8 loss: 7.6666579246521 running average of batch loss 7.953968683878581, time 0.9406678676605225\n",
      "#Epoch 43 with total epochs 300 at step 9 loss: 7.8886003494262695 running average of batch loss 7.947431850433349, time 0.9386663436889648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 43 with total epochs 300 at step 10 loss: 8.258788108825684 running average of batch loss 7.975736964832652, time 0.9406461715698242\n",
      "#Epoch 43 with total epochs 300 at step 11 loss: 7.550342559814453 running average of batch loss 7.940287431081136, time 0.9406452178955078\n",
      "#Epoch 43 with total epochs 300 at step 12 loss: 7.8250274658203125 running average of batch loss 7.931421279907227, time 0.9277188777923584\n",
      "#Epoch 43 with total epochs 300 at step 13 loss: 7.286964416503906 running average of batch loss 7.885388646806989, time 0.9341638088226318\n",
      "#Epoch 43 with total epochs 300 at step 14 loss: 7.038076400756836 running average of batch loss 7.828901163736979, time 0.9356653690338135\n",
      "#Epoch 43 with total epochs 300 at step 15 loss: 7.264881134033203 running average of batch loss 7.793649911880493, time 0.9516749382019043\n",
      "#Epoch 43 with total epochs 300 at step 16 loss: 7.880281448364258 running average of batch loss 7.798745884614832, time 0.9526762962341309\n",
      "#Epoch 43 with total epochs 300 at step 17 loss: 7.13814640045166 running average of batch loss 7.762045913272434, time 0.9346632957458496\n",
      "#Epoch 43 with total epochs 300 at step 18 loss: 7.543128967285156 running average of batch loss 7.750523968746788, time 0.936664342880249\n",
      "#Epoch 43 with total epochs 300 at step 19 loss: 7.6853742599487305 running average of batch loss 7.747266483306885, time 0.9426674842834473\n",
      "#Epoch 43 with total epochs 300 at step 20 loss: 7.698779106140137 running average of batch loss 7.744957560584659, time 0.9536788463592529\n",
      "#Epoch 44 with total epochs 300 at step 0 loss: 7.662558078765869 running average of batch loss 7.662558078765869, time 0.9266574382781982\n",
      "#Epoch 44 with total epochs 300 at step 1 loss: 7.382456302642822 running average of batch loss 7.522507190704346, time 0.9406661987304688\n",
      "#Epoch 44 with total epochs 300 at step 2 loss: 8.125604629516602 running average of batch loss 7.723539670308431, time 0.9336390495300293\n",
      "#Epoch 44 with total epochs 300 at step 3 loss: 7.490754127502441 running average of batch loss 7.665343284606934, time 0.9236540794372559\n",
      "#Epoch 44 with total epochs 300 at step 4 loss: 8.257216453552246 running average of batch loss 7.783717918395996, time 0.9406692981719971\n",
      "#Epoch 44 with total epochs 300 at step 5 loss: 7.412890911102295 running average of batch loss 7.721913417180379, time 0.9356634616851807\n",
      "#Epoch 44 with total epochs 300 at step 6 loss: 7.492466926574707 running average of batch loss 7.689135347093854, time 0.9346652030944824\n",
      "#Epoch 44 with total epochs 300 at step 7 loss: 7.871286392211914 running average of batch loss 7.711904227733612, time 0.9406671524047852\n",
      "#Epoch 44 with total epochs 300 at step 8 loss: 7.54008674621582 running average of batch loss 7.692813396453857, time 0.9396665096282959\n",
      "#Epoch 44 with total epochs 300 at step 9 loss: 7.224542617797852 running average of batch loss 7.645986318588257, time 0.932661771774292\n",
      "#Epoch 44 with total epochs 300 at step 10 loss: 7.210539817810059 running average of batch loss 7.606400273062966, time 0.9466705322265625\n",
      "#Epoch 44 with total epochs 300 at step 11 loss: 7.3326921463012695 running average of batch loss 7.583591262499492, time 0.9426712989807129\n",
      "#Epoch 44 with total epochs 300 at step 12 loss: 7.350395202636719 running average of batch loss 7.565653104048509, time 0.9356639385223389\n",
      "#Epoch 44 with total epochs 300 at step 13 loss: 7.518012046813965 running average of batch loss 7.562250171388898, time 0.9366631507873535\n",
      "#Epoch 44 with total epochs 300 at step 14 loss: 7.511049747467041 running average of batch loss 7.558836809794108, time 0.947674036026001\n",
      "#Epoch 44 with total epochs 300 at step 15 loss: 8.118062019348145 running average of batch loss 7.593788385391235, time 0.938666582107544\n",
      "#Epoch 44 with total epochs 300 at step 16 loss: 8.416207313537598 running average of batch loss 7.642165969399845, time 0.9576807022094727\n",
      "#Epoch 44 with total epochs 300 at step 17 loss: 7.043135166168213 running average of batch loss 7.608886480331421, time 0.952674388885498\n",
      "#Epoch 44 with total epochs 300 at step 18 loss: 7.678908824920654 running average of batch loss 7.612571866888749, time 0.9526774883270264\n",
      "#Epoch 44 with total epochs 300 at step 19 loss: 7.53367805480957 running average of batch loss 7.60862717628479, time 0.9566774368286133\n",
      "#Epoch 44 with total epochs 300 at step 20 loss: 7.261691570281982 running average of batch loss 7.592106433141799, time 0.9446718692779541\n",
      "#Epoch 45 with total epochs 300 at step 0 loss: 7.27427864074707 running average of batch loss 7.27427864074707, time 0.9276585578918457\n",
      "#Epoch 45 with total epochs 300 at step 1 loss: 7.452000141143799 running average of batch loss 7.363139390945435, time 0.9426689147949219\n",
      "#Epoch 45 with total epochs 300 at step 2 loss: 7.483036518096924 running average of batch loss 7.403105099995931, time 0.9306602478027344\n",
      "#Epoch 45 with total epochs 300 at step 3 loss: 7.6939496994018555 running average of batch loss 7.475816249847412, time 0.9206523895263672\n",
      "#Epoch 45 with total epochs 300 at step 4 loss: 7.43189811706543 running average of batch loss 7.467032623291016, time 0.9486761093139648\n",
      "#Epoch 45 with total epochs 300 at step 5 loss: 6.987446308135986 running average of batch loss 7.387101570765178, time 0.9416680335998535\n",
      "#Epoch 45 with total epochs 300 at step 6 loss: 7.314052581787109 running average of batch loss 7.376666000911167, time 0.9276614189147949\n",
      "#Epoch 45 with total epochs 300 at step 7 loss: 8.130264282226562 running average of batch loss 7.470865786075592, time 0.945232629776001\n",
      "#Epoch 45 with total epochs 300 at step 8 loss: 7.054902076721191 running average of batch loss 7.4246475961473255, time 0.9346635341644287\n",
      "#Epoch 45 with total epochs 300 at step 9 loss: 7.48374605178833 running average of batch loss 7.430557441711426, time 0.929659366607666\n",
      "#Epoch 45 with total epochs 300 at step 10 loss: 7.3566813468933105 running average of batch loss 7.423841433091597, time 0.9356644153594971\n",
      "#Epoch 45 with total epochs 300 at step 11 loss: 7.212876319885254 running average of batch loss 7.406261006991069, time 0.9406673908233643\n",
      "#Epoch 45 with total epochs 300 at step 12 loss: 7.360847473144531 running average of batch loss 7.402767658233643, time 0.9336626529693604\n",
      "#Epoch 45 with total epochs 300 at step 13 loss: 6.796682357788086 running average of batch loss 7.35947585105896, time 0.9416677951812744\n",
      "#Epoch 45 with total epochs 300 at step 14 loss: 7.141592979431152 running average of batch loss 7.344950326283773, time 0.9306387901306152\n",
      "#Epoch 45 with total epochs 300 at step 15 loss: 8.231593132019043 running average of batch loss 7.400365501642227, time 0.9276578426361084\n",
      "#Epoch 45 with total epochs 300 at step 16 loss: 7.540779113769531 running average of batch loss 7.40862512588501, time 0.9364688396453857\n",
      "#Epoch 45 with total epochs 300 at step 17 loss: 7.501060485839844 running average of batch loss 7.413760423660278, time 0.9356644153594971\n",
      "#Epoch 45 with total epochs 300 at step 18 loss: 7.263620853424072 running average of batch loss 7.405858341016267, time 0.9426693916320801\n",
      "#Epoch 45 with total epochs 300 at step 19 loss: 7.354049205780029 running average of batch loss 7.403267884254456, time 0.9276576042175293\n",
      "#Epoch 45 with total epochs 300 at step 20 loss: 7.334853649139404 running average of batch loss 7.400010063534691, time 0.9346630573272705\n",
      "#Epoch 46 with total epochs 300 at step 0 loss: 7.665998458862305 running average of batch loss 7.665998458862305, time 0.9516754150390625\n",
      "#Epoch 46 with total epochs 300 at step 1 loss: 7.799683570861816 running average of batch loss 7.7328410148620605, time 0.9496736526489258\n",
      "#Epoch 46 with total epochs 300 at step 2 loss: 7.159561634063721 running average of batch loss 7.54174788792928, time 0.9536752700805664\n",
      "#Epoch 46 with total epochs 300 at step 3 loss: 7.682319641113281 running average of batch loss 7.576890826225281, time 0.9596812725067139\n",
      "#Epoch 46 with total epochs 300 at step 4 loss: 7.663070201873779 running average of batch loss 7.5941267013549805, time 0.9276602268218994\n",
      "#Epoch 46 with total epochs 300 at step 5 loss: 7.071446895599365 running average of batch loss 7.507013400395711, time 0.9456729888916016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 46 with total epochs 300 at step 6 loss: 8.042957305908203 running average of batch loss 7.583576815468924, time 0.9346630573272705\n",
      "#Epoch 46 with total epochs 300 at step 7 loss: 7.266034126281738 running average of batch loss 7.543883979320526, time 0.9452128410339355\n",
      "#Epoch 46 with total epochs 300 at step 8 loss: 6.929148197174072 running average of batch loss 7.475580003526476, time 0.9436681270599365\n",
      "#Epoch 46 with total epochs 300 at step 9 loss: 7.006069183349609 running average of batch loss 7.428628921508789, time 0.9276363849639893\n",
      "#Epoch 46 with total epochs 300 at step 10 loss: 7.42647647857666 running average of batch loss 7.428433244878596, time 0.9426696300506592\n",
      "#Epoch 46 with total epochs 300 at step 11 loss: 7.692333698272705 running average of batch loss 7.450424949328105, time 0.9436695575714111\n",
      "#Epoch 46 with total epochs 300 at step 12 loss: 7.2960076332092285 running average of batch loss 7.438546694242037, time 0.9416682720184326\n",
      "#Epoch 46 with total epochs 300 at step 13 loss: 6.999711990356445 running average of batch loss 7.40720135825021, time 0.9396674633026123\n",
      "#Epoch 46 with total epochs 300 at step 14 loss: 7.5383477210998535 running average of batch loss 7.415944449106852, time 0.9356639385223389\n",
      "#Epoch 46 with total epochs 300 at step 15 loss: 7.381845474243164 running average of batch loss 7.413813263177872, time 0.9396669864654541\n",
      "#Epoch 46 with total epochs 300 at step 16 loss: 7.34618616104126 running average of batch loss 7.409835198346307, time 0.9426679611206055\n",
      "#Epoch 46 with total epochs 300 at step 17 loss: 8.137542724609375 running average of batch loss 7.45026339424981, time 0.9386653900146484\n",
      "#Epoch 46 with total epochs 300 at step 18 loss: 7.174347877502441 running average of batch loss 7.435741524947317, time 0.9296331405639648\n",
      "#Epoch 46 with total epochs 300 at step 19 loss: 7.53511905670166 running average of batch loss 7.440710401535034, time 0.9448983669281006\n",
      "#Epoch 46 with total epochs 300 at step 20 loss: 7.207604885101318 running average of batch loss 7.429610138847714, time 0.9406685829162598\n",
      "#Epoch 47 with total epochs 300 at step 0 loss: 7.402274131774902 running average of batch loss 7.402274131774902, time 0.924656867980957\n",
      "#Epoch 47 with total epochs 300 at step 1 loss: 7.131264686584473 running average of batch loss 7.2667694091796875, time 0.9376654624938965\n",
      "#Epoch 47 with total epochs 300 at step 2 loss: 7.70482063293457 running average of batch loss 7.412786483764648, time 0.959681510925293\n",
      "#Epoch 47 with total epochs 300 at step 3 loss: 7.255207061767578 running average of batch loss 7.373391628265381, time 0.9646849632263184\n",
      "#Epoch 47 with total epochs 300 at step 4 loss: 7.952874660491943 running average of batch loss 7.489288234710694, time 0.9476730823516846\n",
      "#Epoch 47 with total epochs 300 at step 5 loss: 7.489689826965332 running average of batch loss 7.489355166753133, time 0.9526762962341309\n",
      "#Epoch 47 with total epochs 300 at step 6 loss: 7.598100662231445 running average of batch loss 7.504890237535749, time 0.9526760578155518\n",
      "#Epoch 47 with total epochs 300 at step 7 loss: 7.164361953735352 running average of batch loss 7.4623242020606995, time 0.9336621761322021\n",
      "#Epoch 47 with total epochs 300 at step 8 loss: 6.68364143371582 running average of batch loss 7.375803894466824, time 0.9436690807342529\n",
      "#Epoch 47 with total epochs 300 at step 9 loss: 7.120614051818848 running average of batch loss 7.350284910202026, time 0.9376423358917236\n",
      "#Epoch 47 with total epochs 300 at step 10 loss: 7.563447952270508 running average of batch loss 7.369663368571889, time 0.9356660842895508\n",
      "#Epoch 47 with total epochs 300 at step 11 loss: 7.387960910797119 running average of batch loss 7.371188163757324, time 0.9436678886413574\n",
      "#Epoch 47 with total epochs 300 at step 12 loss: 6.882818222045898 running average of batch loss 7.333621245164138, time 0.9346663951873779\n",
      "#Epoch 47 with total epochs 300 at step 13 loss: 8.169778823852539 running average of batch loss 7.393346786499023, time 0.9306607246398926\n",
      "#Epoch 47 with total epochs 300 at step 14 loss: 7.457821846008301 running average of batch loss 7.397645123799642, time 0.9456703662872314\n",
      "#Epoch 47 with total epochs 300 at step 15 loss: 7.3744916915893555 running average of batch loss 7.396198034286499, time 0.9396672248840332\n",
      "#Epoch 47 with total epochs 300 at step 16 loss: 7.284412384033203 running average of batch loss 7.389622407801011, time 0.93166184425354\n",
      "#Epoch 47 with total epochs 300 at step 17 loss: 7.573369026184082 running average of batch loss 7.399830553266737, time 0.9386682510375977\n",
      "#Epoch 47 with total epochs 300 at step 18 loss: 6.5866312980651855 running average of batch loss 7.357030592466655, time 0.9436686038970947\n",
      "#Epoch 47 with total epochs 300 at step 19 loss: 7.110742092132568 running average of batch loss 7.344716167449951, time 0.934664249420166\n",
      "#Epoch 47 with total epochs 300 at step 20 loss: 8.160076141357422 running average of batch loss 7.383542832874117, time 0.944671630859375\n",
      "#Epoch 48 with total epochs 300 at step 0 loss: 8.541099548339844 running average of batch loss 8.541099548339844, time 0.9386672973632812\n",
      "#Epoch 48 with total epochs 300 at step 1 loss: 7.849195957183838 running average of batch loss 8.19514775276184, time 0.9586803913116455\n",
      "#Epoch 48 with total epochs 300 at step 2 loss: 6.897510051727295 running average of batch loss 7.762601852416992, time 0.9526748657226562\n",
      "#Epoch 48 with total epochs 300 at step 3 loss: 7.104633331298828 running average of batch loss 7.598109722137451, time 0.9456703662872314\n",
      "#Epoch 48 with total epochs 300 at step 4 loss: 7.125500679016113 running average of batch loss 7.503587913513184, time 0.9366657733917236\n",
      "#Epoch 48 with total epochs 300 at step 5 loss: 7.49025821685791 running average of batch loss 7.501366297403972, time 0.9546775817871094\n",
      "#Epoch 48 with total epochs 300 at step 6 loss: 7.4060750007629395 running average of batch loss 7.487753255026681, time 0.9726903438568115\n",
      "#Epoch 48 with total epochs 300 at step 7 loss: 7.414028167724609 running average of batch loss 7.478537619113922, time 0.9456713199615479\n",
      "#Epoch 48 with total epochs 300 at step 8 loss: 7.2314534187316895 running average of batch loss 7.451083819071452, time 0.9316606521606445\n",
      "#Epoch 48 with total epochs 300 at step 9 loss: 6.802689552307129 running average of batch loss 7.386244392395019, time 0.9396464824676514\n",
      "#Epoch 48 with total epochs 300 at step 10 loss: 7.22684383392334 running average of batch loss 7.371753432533958, time 0.9416701793670654\n",
      "#Epoch 48 with total epochs 300 at step 11 loss: 7.045093536376953 running average of batch loss 7.344531774520874, time 0.9346632957458496\n",
      "#Epoch 48 with total epochs 300 at step 12 loss: 7.588999271392822 running average of batch loss 7.363336966587947, time 0.9406678676605225\n",
      "#Epoch 48 with total epochs 300 at step 13 loss: 8.045045852661133 running average of batch loss 7.412030458450317, time 0.9446699619293213\n",
      "#Epoch 48 with total epochs 300 at step 14 loss: 6.826509475708008 running average of batch loss 7.372995726267496, time 0.9396669864654541\n",
      "#Epoch 48 with total epochs 300 at step 15 loss: 7.657186985015869 running average of batch loss 7.39075767993927, time 0.9346625804901123\n",
      "#Epoch 48 with total epochs 300 at step 16 loss: 7.234204292297363 running average of batch loss 7.381548657136805, time 0.9346635341644287\n",
      "#Epoch 48 with total epochs 300 at step 17 loss: 7.145585060119629 running average of batch loss 7.368439568413629, time 0.9396681785583496\n",
      "#Epoch 48 with total epochs 300 at step 18 loss: 6.831280708312988 running average of batch loss 7.340168049460964, time 0.9456710815429688\n",
      "#Epoch 48 with total epochs 300 at step 19 loss: 7.518410682678223 running average of batch loss 7.349080181121826, time 0.9376649856567383\n",
      "#Epoch 48 with total epochs 300 at step 20 loss: 6.914330959320068 running average of batch loss 7.328377837226505, time 0.9486730098724365\n",
      "#Epoch 49 with total epochs 300 at step 0 loss: 7.8502092361450195 running average of batch loss 7.8502092361450195, time 0.9466719627380371\n",
      "#Epoch 49 with total epochs 300 at step 1 loss: 7.341443061828613 running average of batch loss 7.595826148986816, time 0.9356632232666016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 49 with total epochs 300 at step 2 loss: 8.192927360534668 running average of batch loss 7.794859886169434, time 0.9466719627380371\n",
      "#Epoch 49 with total epochs 300 at step 3 loss: 8.0231351852417 running average of batch loss 7.8519287109375, time 0.9336633682250977\n",
      "#Epoch 49 with total epochs 300 at step 4 loss: 7.117010116577148 running average of batch loss 7.70494499206543, time 0.9456698894500732\n",
      "#Epoch 49 with total epochs 300 at step 5 loss: 7.846142768859863 running average of batch loss 7.728477954864502, time 0.9476723670959473\n",
      "#Epoch 49 with total epochs 300 at step 6 loss: 7.917008399963379 running average of batch loss 7.755410875592913, time 0.9666857719421387\n",
      "#Epoch 49 with total epochs 300 at step 7 loss: 7.371966361999512 running average of batch loss 7.707480311393738, time 0.9396665096282959\n",
      "#Epoch 49 with total epochs 300 at step 8 loss: 6.722827911376953 running average of batch loss 7.598074489169651, time 0.9346652030944824\n",
      "#Epoch 49 with total epochs 300 at step 9 loss: 7.591747283935547 running average of batch loss 7.59744176864624, time 0.939666748046875\n",
      "#Epoch 49 with total epochs 300 at step 10 loss: 7.484859943389893 running average of batch loss 7.5872070572593, time 0.9376637935638428\n",
      "#Epoch 49 with total epochs 300 at step 11 loss: 7.165836334228516 running average of batch loss 7.552092830340068, time 0.9362761974334717\n",
      "#Epoch 49 with total epochs 300 at step 12 loss: 7.031119346618652 running average of batch loss 7.512017946976882, time 0.9406671524047852\n",
      "#Epoch 49 with total epochs 300 at step 13 loss: 7.2360639572143555 running average of batch loss 7.49230694770813, time 0.9391872882843018\n",
      "#Epoch 49 with total epochs 300 at step 14 loss: 7.540001392364502 running average of batch loss 7.495486577351888, time 0.9351625442504883\n",
      "#Epoch 49 with total epochs 300 at step 15 loss: 7.750073432922363 running average of batch loss 7.511398255825043, time 0.9386694431304932\n",
      "#Epoch 49 with total epochs 300 at step 16 loss: 6.898710250854492 running average of batch loss 7.475357784944422, time 0.925656795501709\n",
      "#Epoch 49 with total epochs 300 at step 17 loss: 6.648387432098389 running average of batch loss 7.429414987564087, time 0.943669319152832\n",
      "#Epoch 49 with total epochs 300 at step 18 loss: 7.464939117431641 running average of batch loss 7.431284678609748, time 0.9446702003479004\n",
      "#Epoch 49 with total epochs 300 at step 19 loss: 7.748751640319824 running average of batch loss 7.447158026695251, time 0.9306604862213135\n",
      "#Epoch 49 with total epochs 300 at step 20 loss: 7.222789764404297 running average of batch loss 7.436473823729015, time 0.9356644153594971\n",
      "#Epoch 50 with total epochs 300 at step 0 loss: 6.4072675704956055 running average of batch loss 6.4072675704956055, time 0.9346647262573242\n",
      "#Epoch 50 with total epochs 300 at step 1 loss: 6.954243183135986 running average of batch loss 6.680755376815796, time 0.9376645088195801\n",
      "#Epoch 50 with total epochs 300 at step 2 loss: 7.00482702255249 running average of batch loss 6.788779258728027, time 0.9426720142364502\n",
      "#Epoch 50 with total epochs 300 at step 3 loss: 7.3762054443359375 running average of batch loss 6.935635805130005, time 0.9596796035766602\n",
      "#Epoch 50 with total epochs 300 at step 4 loss: 6.976858139038086 running average of batch loss 6.943880271911621, time 0.9536786079406738\n",
      "#Epoch 50 with total epochs 300 at step 5 loss: 7.545162200927734 running average of batch loss 7.04409392674764, time 0.9586806297302246\n",
      "#Epoch 50 with total epochs 300 at step 6 loss: 7.233099460601807 running average of batch loss 7.0710947172982355, time 0.9536762237548828\n",
      "#Epoch 50 with total epochs 300 at step 7 loss: 7.5082502365112305 running average of batch loss 7.12573915719986, time 0.9516751766204834\n",
      "#Epoch 50 with total epochs 300 at step 8 loss: 8.094481468200684 running average of batch loss 7.2333771917555065, time 0.9476714134216309\n",
      "#Epoch 50 with total epochs 300 at step 9 loss: 7.704481601715088 running average of batch loss 7.2804876327514645, time 0.9416699409484863\n",
      "#Epoch 50 with total epochs 300 at step 10 loss: 6.89804744720459 running average of batch loss 7.245720343156294, time 0.9366662502288818\n",
      "#Epoch 50 with total epochs 300 at step 11 loss: 7.149374008178711 running average of batch loss 7.237691481908162, time 0.9346621036529541\n",
      "#Epoch 50 with total epochs 300 at step 12 loss: 7.433657169342041 running average of batch loss 7.252765765556922, time 0.945671796798706\n",
      "#Epoch 50 with total epochs 300 at step 13 loss: 6.931601047515869 running average of batch loss 7.22982542855399, time 0.9396443367004395\n",
      "#Epoch 50 with total epochs 300 at step 14 loss: 7.092529296875 running average of batch loss 7.220672353108724, time 0.9326622486114502\n",
      "#Epoch 50 with total epochs 300 at step 15 loss: 7.767788410186768 running average of batch loss 7.254867106676102, time 0.9376652240753174\n",
      "#Epoch 50 with total epochs 300 at step 16 loss: 7.013240337371826 running average of batch loss 7.240653767305262, time 0.9336628913879395\n",
      "#Epoch 50 with total epochs 300 at step 17 loss: 6.877066135406494 running average of batch loss 7.220454454421997, time 0.940666675567627\n",
      "#Epoch 50 with total epochs 300 at step 18 loss: 7.614542007446289 running average of batch loss 7.24119590458117, time 0.9412155151367188\n",
      "#Epoch 50 with total epochs 300 at step 19 loss: 6.7088470458984375 running average of batch loss 7.214578461647034, time 0.9416923522949219\n",
      "#Epoch 50 with total epochs 300 at step 20 loss: 7.28792667388916 running average of batch loss 7.218071233658564, time 0.9406678676605225\n",
      "#Epoch 51 with total epochs 300 at step 0 loss: 7.479671478271484 running average of batch loss 7.479671478271484, time 0.4823439121246338\n",
      "#Epoch 51 with total epochs 300 at step 1 loss: 7.110963344573975 running average of batch loss 7.2953174114227295, time 0.87261962890625\n",
      "#Epoch 51 with total epochs 300 at step 2 loss: 7.281087398529053 running average of batch loss 7.290574073791504, time 0.9416677951812744\n",
      "#Epoch 51 with total epochs 300 at step 3 loss: 6.585769176483154 running average of batch loss 7.1143728494644165, time 0.9376652240753174\n",
      "#Epoch 51 with total epochs 300 at step 4 loss: 7.058937072753906 running average of batch loss 7.103285694122315, time 0.936664342880249\n",
      "#Epoch 51 with total epochs 300 at step 5 loss: 7.033312797546387 running average of batch loss 7.091623544692993, time 0.9316613674163818\n",
      "#Epoch 51 with total epochs 300 at step 6 loss: 7.004189968109131 running average of batch loss 7.079133033752441, time 0.964684247970581\n",
      "#Epoch 51 with total epochs 300 at step 7 loss: 7.515673637390137 running average of batch loss 7.133700609207153, time 0.935664176940918\n",
      "#Epoch 51 with total epochs 300 at step 8 loss: 7.230085372924805 running average of batch loss 7.144410027398004, time 0.9466714859008789\n",
      "#Epoch 51 with total epochs 300 at step 9 loss: 6.742162227630615 running average of batch loss 7.104185247421265, time 0.9696881771087646\n",
      "#Epoch 51 with total epochs 300 at step 10 loss: 7.286780834197998 running average of batch loss 7.120784846219149, time 0.9276583194732666\n",
      "#Epoch 51 with total epochs 300 at step 11 loss: 6.608468055725098 running average of batch loss 7.0780917803446455, time 0.9426703453063965\n",
      "#Epoch 51 with total epochs 300 at step 12 loss: 7.189373970031738 running average of batch loss 7.086651948782114, time 0.9456720352172852\n",
      "#Epoch 51 with total epochs 300 at step 13 loss: 6.939474582672119 running average of batch loss 7.0761392797742575, time 0.9316625595092773\n",
      "#Epoch 51 with total epochs 300 at step 14 loss: 7.1766180992126465 running average of batch loss 7.082837867736816, time 0.9406664371490479\n",
      "#Epoch 51 with total epochs 300 at step 15 loss: 7.028709411621094 running average of batch loss 7.079454839229584, time 0.9406447410583496\n",
      "#Epoch 51 with total epochs 300 at step 16 loss: 7.227260589599609 running average of batch loss 7.088149295133703, time 0.9426684379577637\n",
      "#Epoch 51 with total epochs 300 at step 17 loss: 7.25360107421875 running average of batch loss 7.097341060638428, time 0.9476721286773682\n",
      "#Epoch 51 with total epochs 300 at step 18 loss: 7.462888717651367 running average of batch loss 7.11658041100753, time 0.9366648197174072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 51 with total epochs 300 at step 19 loss: 6.872014045715332 running average of batch loss 7.10435209274292, time 0.9376637935638428\n",
      "#Epoch 51 with total epochs 300 at step 20 loss: 7.173624038696289 running average of batch loss 7.1076507568359375, time 0.944800615310669\n",
      "#Epoch 52 with total epochs 300 at step 0 loss: 7.266435146331787 running average of batch loss 7.266435146331787, time 0.9356634616851807\n",
      "#Epoch 52 with total epochs 300 at step 1 loss: 6.4769697189331055 running average of batch loss 6.871702432632446, time 0.9306602478027344\n",
      "#Epoch 52 with total epochs 300 at step 2 loss: 7.123758316040039 running average of batch loss 6.9557210604349775, time 0.9336938858032227\n",
      "#Epoch 52 with total epochs 300 at step 3 loss: 6.689918041229248 running average of batch loss 6.889270305633545, time 0.9431712627410889\n",
      "#Epoch 52 with total epochs 300 at step 4 loss: 7.565934658050537 running average of batch loss 7.024603176116943, time 0.9376659393310547\n",
      "#Epoch 52 with total epochs 300 at step 5 loss: 6.686306476593018 running average of batch loss 6.968220392862956, time 0.9366686344146729\n",
      "#Epoch 52 with total epochs 300 at step 6 loss: 6.830370903015137 running average of batch loss 6.948527608598981, time 0.9366645812988281\n",
      "#Epoch 52 with total epochs 300 at step 7 loss: 7.762577056884766 running average of batch loss 7.050283789634705, time 0.9296598434448242\n",
      "#Epoch 52 with total epochs 300 at step 8 loss: 6.694239139556885 running average of batch loss 7.010723272959392, time 0.958681583404541\n",
      "#Epoch 52 with total epochs 300 at step 9 loss: 7.083855152130127 running average of batch loss 7.0180364608764645, time 0.9306595325469971\n",
      "#Epoch 52 with total epochs 300 at step 10 loss: 6.755815029144287 running average of batch loss 6.9941981489008125, time 0.9516768455505371\n",
      "#Epoch 52 with total epochs 300 at step 11 loss: 7.4105634689331055 running average of batch loss 7.028895258903503, time 0.9421768188476562\n",
      "#Epoch 52 with total epochs 300 at step 12 loss: 7.450293064117432 running average of batch loss 7.06131047468919, time 0.9395637512207031\n",
      "#Epoch 52 with total epochs 300 at step 13 loss: 7.426631450653076 running average of batch loss 7.087404830115182, time 0.9406673908233643\n",
      "#Epoch 52 with total epochs 300 at step 14 loss: 7.271360397338867 running average of batch loss 7.099668534596761, time 0.9396677017211914\n",
      "#Epoch 52 with total epochs 300 at step 15 loss: 7.239721775054932 running average of batch loss 7.108421862125397, time 0.9416675567626953\n",
      "#Epoch 52 with total epochs 300 at step 16 loss: 7.209017753601074 running average of batch loss 7.114339267506319, time 0.9386653900146484\n",
      "#Epoch 52 with total epochs 300 at step 17 loss: 6.813016414642334 running average of batch loss 7.097599109013875, time 0.9321541786193848\n",
      "#Epoch 52 with total epochs 300 at step 18 loss: 7.357294082641602 running average of batch loss 7.111267265520598, time 0.971688985824585\n",
      "#Epoch 52 with total epochs 300 at step 19 loss: 7.4371137619018555 running average of batch loss 7.1275595903396605, time 0.9386649131774902\n",
      "#Epoch 52 with total epochs 300 at step 20 loss: 7.659974098205566 running average of batch loss 7.152912662142799, time 0.932661771774292\n",
      "#Epoch 53 with total epochs 300 at step 0 loss: 6.4654669761657715 running average of batch loss 6.4654669761657715, time 0.9416310787200928\n",
      "#Epoch 53 with total epochs 300 at step 1 loss: 7.083980560302734 running average of batch loss 6.774723768234253, time 0.9396657943725586\n",
      "#Epoch 53 with total epochs 300 at step 2 loss: 7.08364725112915 running average of batch loss 6.877698262532552, time 0.9366645812988281\n",
      "#Epoch 53 with total epochs 300 at step 3 loss: 7.363245964050293 running average of batch loss 6.999085187911987, time 0.9316608905792236\n",
      "#Epoch 53 with total epochs 300 at step 4 loss: 7.16230583190918 running average of batch loss 7.031729316711425, time 0.940666913986206\n",
      "#Epoch 53 with total epochs 300 at step 5 loss: 7.770204544067383 running average of batch loss 7.154808521270752, time 0.9316606521606445\n",
      "#Epoch 53 with total epochs 300 at step 6 loss: 6.912550926208496 running average of batch loss 7.120200293404715, time 0.9396688938140869\n",
      "#Epoch 53 with total epochs 300 at step 7 loss: 7.476536750793457 running average of batch loss 7.164742350578308, time 0.9496724605560303\n",
      "#Epoch 53 with total epochs 300 at step 8 loss: 6.599638938903809 running average of batch loss 7.101953082614475, time 0.9626843929290771\n",
      "#Epoch 53 with total epochs 300 at step 9 loss: 6.637357711791992 running average of batch loss 7.055493545532227, time 0.9486727714538574\n",
      "#Epoch 53 with total epochs 300 at step 10 loss: 7.3968634605407715 running average of batch loss 7.086527174169367, time 0.9436697959899902\n",
      "#Epoch 53 with total epochs 300 at step 11 loss: 7.420149326324463 running average of batch loss 7.114329020182292, time 0.9576787948608398\n",
      "#Epoch 53 with total epochs 300 at step 12 loss: 6.299349784851074 running average of batch loss 7.051638309772198, time 0.9446702003479004\n",
      "#Epoch 53 with total epochs 300 at step 13 loss: 7.553860664367676 running average of batch loss 7.087511335100446, time 0.9396669864654541\n",
      "#Epoch 53 with total epochs 300 at step 14 loss: 6.190474987030029 running average of batch loss 7.027708911895752, time 0.9416680335998535\n",
      "#Epoch 53 with total epochs 300 at step 15 loss: 7.358639717102051 running average of batch loss 7.048392087221146, time 0.9316604137420654\n",
      "#Epoch 53 with total epochs 300 at step 16 loss: 6.9857330322265625 running average of batch loss 7.044706260456758, time 0.9376661777496338\n",
      "#Epoch 53 with total epochs 300 at step 17 loss: 7.704336643218994 running average of batch loss 7.0813523928324384, time 0.9386651515960693\n",
      "#Epoch 53 with total epochs 300 at step 18 loss: 6.935812950134277 running average of batch loss 7.073692422164114, time 0.9356653690338135\n",
      "#Epoch 53 with total epochs 300 at step 19 loss: 6.626076698303223 running average of batch loss 7.05131163597107, time 0.9346637725830078\n",
      "#Epoch 53 with total epochs 300 at step 20 loss: 7.40803337097168 running average of batch loss 7.068298385256813, time 0.9406673908233643\n",
      "#Epoch 54 with total epochs 300 at step 0 loss: 6.332974910736084 running average of batch loss 6.332974910736084, time 0.9306590557098389\n",
      "#Epoch 54 with total epochs 300 at step 1 loss: 7.0564775466918945 running average of batch loss 6.694726228713989, time 0.9402415752410889\n",
      "#Epoch 54 with total epochs 300 at step 2 loss: 7.12419319152832 running average of batch loss 6.837881882985433, time 0.9466731548309326\n",
      "#Epoch 54 with total epochs 300 at step 3 loss: 7.18154239654541 running average of batch loss 6.923797011375427, time 0.9336624145507812\n",
      "#Epoch 54 with total epochs 300 at step 4 loss: 6.776120185852051 running average of batch loss 6.894261646270752, time 0.9406678676605225\n",
      "#Epoch 54 with total epochs 300 at step 5 loss: 6.6712565422058105 running average of batch loss 6.857094128926595, time 0.9446694850921631\n",
      "#Epoch 54 with total epochs 300 at step 6 loss: 6.834273338317871 running average of batch loss 6.853834015982492, time 0.9536769390106201\n",
      "#Epoch 54 with total epochs 300 at step 7 loss: 6.730990409851074 running average of batch loss 6.8384785652160645, time 0.9506733417510986\n",
      "#Epoch 54 with total epochs 300 at step 8 loss: 7.526611804962158 running average of batch loss 6.914937814076741, time 0.9576795101165771\n",
      "#Epoch 54 with total epochs 300 at step 9 loss: 6.567237854003906 running average of batch loss 6.880167818069458, time 0.9536769390106201\n",
      "#Epoch 54 with total epochs 300 at step 10 loss: 7.118059158325195 running average of batch loss 6.901794303547252, time 0.9456710815429688\n",
      "#Epoch 54 with total epochs 300 at step 11 loss: 6.663136959075928 running average of batch loss 6.881906191507976, time 0.9586796760559082\n",
      "#Epoch 54 with total epochs 300 at step 12 loss: 7.653018951416016 running average of batch loss 6.941222557654748, time 0.9276578426361084\n",
      "#Epoch 54 with total epochs 300 at step 13 loss: 6.861042499542236 running average of batch loss 6.935495410646711, time 0.9446690082550049\n",
      "#Epoch 54 with total epochs 300 at step 14 loss: 7.075566291809082 running average of batch loss 6.944833469390869, time 0.9376430511474609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 54 with total epochs 300 at step 15 loss: 7.01318359375 running average of batch loss 6.949105352163315, time 0.9346632957458496\n",
      "#Epoch 54 with total epochs 300 at step 16 loss: 6.644021987915039 running average of batch loss 6.931159271913416, time 0.9386646747589111\n",
      "#Epoch 54 with total epochs 300 at step 17 loss: 7.161263465881348 running average of batch loss 6.943942838244968, time 0.9316632747650146\n",
      "#Epoch 54 with total epochs 300 at step 18 loss: 6.901608467102051 running average of batch loss 6.941714713447972, time 0.9276585578918457\n",
      "#Epoch 54 with total epochs 300 at step 19 loss: 6.270744323730469 running average of batch loss 6.9081661939620975, time 0.9336612224578857\n",
      "#Epoch 54 with total epochs 300 at step 20 loss: 8.051351547241211 running average of batch loss 6.9626035917372935, time 0.9336638450622559\n",
      "#Epoch 55 with total epochs 300 at step 0 loss: 6.867175579071045 running average of batch loss 6.867175579071045, time 0.9336631298065186\n",
      "#Epoch 55 with total epochs 300 at step 1 loss: 7.783499717712402 running average of batch loss 7.325337648391724, time 0.9596817493438721\n",
      "#Epoch 55 with total epochs 300 at step 2 loss: 6.658610820770264 running average of batch loss 7.103095372517903, time 0.934664249420166\n",
      "#Epoch 55 with total epochs 300 at step 3 loss: 6.885227203369141 running average of batch loss 7.048628330230713, time 0.928659200668335\n",
      "#Epoch 55 with total epochs 300 at step 4 loss: 7.312697887420654 running average of batch loss 7.1014422416687015, time 0.9486727714538574\n",
      "#Epoch 55 with total epochs 300 at step 5 loss: 6.415713787078857 running average of batch loss 6.9871541659037275, time 0.9386472702026367\n",
      "#Epoch 55 with total epochs 300 at step 6 loss: 6.792966365814209 running average of batch loss 6.959413051605225, time 0.939666748046875\n",
      "#Epoch 55 with total epochs 300 at step 7 loss: 7.088926792144775 running average of batch loss 6.9756022691726685, time 0.9416677951812744\n",
      "#Epoch 55 with total epochs 300 at step 8 loss: 6.127130508422852 running average of batch loss 6.8813276290893555, time 0.9556782245635986\n",
      "#Epoch 55 with total epochs 300 at step 9 loss: 6.201974868774414 running average of batch loss 6.8133923530578615, time 0.9526760578155518\n",
      "#Epoch 55 with total epochs 300 at step 10 loss: 6.890374660491943 running average of batch loss 6.820390744642778, time 0.9556772708892822\n",
      "#Epoch 55 with total epochs 300 at step 11 loss: 6.780451774597168 running average of batch loss 6.817062497138977, time 0.9546761512756348\n",
      "#Epoch 55 with total epochs 300 at step 12 loss: 6.8675336837768555 running average of batch loss 6.820944896111121, time 0.9536786079406738\n",
      "#Epoch 55 with total epochs 300 at step 13 loss: 7.613857269287109 running average of batch loss 6.8775814941951205, time 0.9326605796813965\n",
      "#Epoch 55 with total epochs 300 at step 14 loss: 7.884485244750977 running average of batch loss 6.944708410898844, time 0.9306604862213135\n",
      "#Epoch 55 with total epochs 300 at step 15 loss: 7.312139511108398 running average of batch loss 6.9676728546619415, time 0.9366645812988281\n",
      "#Epoch 55 with total epochs 300 at step 16 loss: 6.418956279754639 running average of batch loss 6.935395409079159, time 0.9366631507873535\n",
      "#Epoch 55 with total epochs 300 at step 17 loss: 6.548962593078613 running average of batch loss 6.913926919301351, time 0.9416694641113281\n",
      "#Epoch 55 with total epochs 300 at step 18 loss: 7.301638126373291 running average of batch loss 6.934332772305138, time 0.9306607246398926\n",
      "#Epoch 55 with total epochs 300 at step 19 loss: 6.523285865783691 running average of batch loss 6.913780426979065, time 0.9356646537780762\n",
      "#Epoch 55 with total epochs 300 at step 20 loss: 7.284040451049805 running average of batch loss 6.9314118566967196, time 0.9466710090637207\n",
      "#Epoch 56 with total epochs 300 at step 0 loss: 6.928459167480469 running average of batch loss 6.928459167480469, time 0.9276368618011475\n",
      "#Epoch 56 with total epochs 300 at step 1 loss: 6.439094066619873 running average of batch loss 6.683776617050171, time 0.9366645812988281\n",
      "#Epoch 56 with total epochs 300 at step 2 loss: 7.104372501373291 running average of batch loss 6.823975245157878, time 0.9396660327911377\n",
      "#Epoch 56 with total epochs 300 at step 3 loss: 7.004524230957031 running average of batch loss 6.869112491607666, time 0.9346647262573242\n",
      "#Epoch 56 with total epochs 300 at step 4 loss: 7.265524864196777 running average of batch loss 6.9483949661254885, time 0.9406676292419434\n",
      "#Epoch 56 with total epochs 300 at step 5 loss: 6.940382957458496 running average of batch loss 6.947059631347656, time 0.9356637001037598\n",
      "#Epoch 56 with total epochs 300 at step 6 loss: 7.741005897521973 running average of batch loss 7.060480526515415, time 0.9336609840393066\n",
      "#Epoch 56 with total epochs 300 at step 7 loss: 7.485651969909668 running average of batch loss 7.113626956939697, time 0.9386680126190186\n",
      "#Epoch 56 with total epochs 300 at step 8 loss: 6.784718036651611 running average of batch loss 7.077081521352132, time 0.9416680335998535\n",
      "#Epoch 56 with total epochs 300 at step 9 loss: 7.30551815032959 running average of batch loss 7.099925184249878, time 0.9326608180999756\n",
      "#Epoch 56 with total epochs 300 at step 10 loss: 7.267396450042725 running average of batch loss 7.1151498447765, time 0.9326632022857666\n",
      "#Epoch 56 with total epochs 300 at step 11 loss: 6.777081489562988 running average of batch loss 7.086977481842041, time 0.9406683444976807\n",
      "#Epoch 56 with total epochs 300 at step 12 loss: 7.000598430633545 running average of batch loss 7.080332939441387, time 0.9496736526489258\n",
      "#Epoch 56 with total epochs 300 at step 13 loss: 7.543208599090576 running average of batch loss 7.113395486559186, time 0.9426677227020264\n",
      "#Epoch 56 with total epochs 300 at step 14 loss: 6.543891429901123 running average of batch loss 7.075428549448649, time 0.9406688213348389\n",
      "#Epoch 56 with total epochs 300 at step 15 loss: 6.918436050415039 running average of batch loss 7.0656165182590485, time 0.9616837501525879\n",
      "#Epoch 56 with total epochs 300 at step 16 loss: 6.9675188064575195 running average of batch loss 7.059846064623664, time 0.9446711540222168\n",
      "#Epoch 56 with total epochs 300 at step 17 loss: 6.699044704437256 running average of batch loss 7.039801544613308, time 0.9446704387664795\n",
      "#Epoch 56 with total epochs 300 at step 18 loss: 7.1313676834106445 running average of batch loss 7.044620815076326, time 0.9336614608764648\n",
      "#Epoch 56 with total epochs 300 at step 19 loss: 7.208961486816406 running average of batch loss 7.05283784866333, time 0.9396688938140869\n",
      "#Epoch 56 with total epochs 300 at step 20 loss: 6.959860801696777 running average of batch loss 7.048410370236351, time 0.9466705322265625\n",
      "#Epoch 57 with total epochs 300 at step 0 loss: 7.026956558227539 running average of batch loss 7.026956558227539, time 0.9276597499847412\n",
      "#Epoch 57 with total epochs 300 at step 1 loss: 6.870490074157715 running average of batch loss 6.948723316192627, time 0.9386646747589111\n",
      "#Epoch 57 with total epochs 300 at step 2 loss: 7.13975715637207 running average of batch loss 7.012401262919108, time 0.9376671314239502\n",
      "#Epoch 57 with total epochs 300 at step 3 loss: 6.986268997192383 running average of batch loss 7.005868196487427, time 0.9376654624938965\n",
      "#Epoch 57 with total epochs 300 at step 4 loss: 6.973299026489258 running average of batch loss 6.999354362487793, time 0.9426689147949219\n",
      "#Epoch 57 with total epochs 300 at step 5 loss: 7.058869361877441 running average of batch loss 7.009273529052734, time 0.9446687698364258\n",
      "#Epoch 57 with total epochs 300 at step 6 loss: 7.335201740264893 running average of batch loss 7.055834702083042, time 0.9356644153594971\n",
      "#Epoch 57 with total epochs 300 at step 7 loss: 6.412321090698242 running average of batch loss 6.975395500659943, time 0.9316620826721191\n",
      "#Epoch 57 with total epochs 300 at step 8 loss: 7.069374084472656 running average of batch loss 6.985837565528022, time 0.9406695365905762\n",
      "#Epoch 57 with total epochs 300 at step 9 loss: 6.652059555053711 running average of batch loss 6.952459764480591, time 0.938666820526123\n",
      "#Epoch 57 with total epochs 300 at step 10 loss: 6.898292541503906 running average of batch loss 6.94753547148271, time 0.9396657943725586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 57 with total epochs 300 at step 11 loss: 7.116164207458496 running average of batch loss 6.961587866147359, time 0.9496753215789795\n",
      "#Epoch 57 with total epochs 300 at step 12 loss: 6.92518424987793 running average of batch loss 6.958787587972788, time 0.9346647262573242\n",
      "#Epoch 57 with total epochs 300 at step 13 loss: 7.049259185791016 running average of batch loss 6.965249844959804, time 0.9416687488555908\n",
      "#Epoch 57 with total epochs 300 at step 14 loss: 6.590327262878418 running average of batch loss 6.940255006154378, time 0.9456710815429688\n",
      "#Epoch 57 with total epochs 300 at step 15 loss: 6.740085124969482 running average of batch loss 6.927744388580322, time 0.9436690807342529\n",
      "#Epoch 57 with total epochs 300 at step 16 loss: 6.5778656005859375 running average of batch loss 6.907163283404182, time 0.9446718692779541\n",
      "#Epoch 57 with total epochs 300 at step 17 loss: 7.24682092666626 running average of batch loss 6.9260331524742975, time 0.9756922721862793\n",
      "#Epoch 57 with total epochs 300 at step 18 loss: 6.764167785644531 running average of batch loss 6.9175139226411515, time 0.9636621475219727\n",
      "#Epoch 57 with total epochs 300 at step 19 loss: 6.143980979919434 running average of batch loss 6.878837275505066, time 0.9586560726165771\n",
      "#Epoch 57 with total epochs 300 at step 20 loss: 7.3310322761535645 running average of batch loss 6.900370370774042, time 0.9406692981719971\n",
      "#Epoch 58 with total epochs 300 at step 0 loss: 6.684324264526367 running average of batch loss 6.684324264526367, time 0.9396665096282959\n",
      "#Epoch 58 with total epochs 300 at step 1 loss: 6.797686576843262 running average of batch loss 6.7410054206848145, time 0.9366648197174072\n",
      "#Epoch 58 with total epochs 300 at step 2 loss: 7.22491455078125 running average of batch loss 6.902308464050293, time 0.9396665096282959\n",
      "#Epoch 58 with total epochs 300 at step 3 loss: 6.954339981079102 running average of batch loss 6.915316343307495, time 0.9386649131774902\n",
      "#Epoch 58 with total epochs 300 at step 4 loss: 7.02292013168335 running average of batch loss 6.936837100982666, time 0.9376673698425293\n",
      "#Epoch 58 with total epochs 300 at step 5 loss: 7.143823623657227 running average of batch loss 6.97133485476176, time 0.9416682720184326\n",
      "#Epoch 58 with total epochs 300 at step 6 loss: 7.521667003631592 running average of batch loss 7.049953733171735, time 0.9436700344085693\n",
      "#Epoch 58 with total epochs 300 at step 7 loss: 7.05042839050293 running average of batch loss 7.050013065338135, time 0.9386441707611084\n",
      "#Epoch 58 with total epochs 300 at step 8 loss: 6.987022876739502 running average of batch loss 7.043014155493842, time 0.9356639385223389\n",
      "#Epoch 58 with total epochs 300 at step 9 loss: 8.238540649414062 running average of batch loss 7.162566804885865, time 0.9416680335998535\n",
      "#Epoch 58 with total epochs 300 at step 10 loss: 6.398072242736816 running average of batch loss 7.093067299235951, time 0.9356629848480225\n",
      "#Epoch 58 with total epochs 300 at step 11 loss: 7.4319305419921875 running average of batch loss 7.12130590279897, time 0.936866283416748\n",
      "#Epoch 58 with total epochs 300 at step 12 loss: 7.70387077331543 running average of batch loss 7.166118585146391, time 0.939666748046875\n",
      "#Epoch 58 with total epochs 300 at step 13 loss: 7.091335773468018 running average of batch loss 7.1607769557407925, time 0.9396669864654541\n",
      "#Epoch 58 with total epochs 300 at step 14 loss: 6.711137771606445 running average of batch loss 7.130801010131836, time 0.9476706981658936\n",
      "#Epoch 58 with total epochs 300 at step 15 loss: 6.939327239990234 running average of batch loss 7.118833899497986, time 0.9406447410583496\n",
      "#Epoch 58 with total epochs 300 at step 16 loss: 6.123504161834717 running average of batch loss 7.0602850914001465, time 0.928659200668335\n",
      "#Epoch 58 with total epochs 300 at step 17 loss: 7.266502380371094 running average of batch loss 7.071741607454088, time 0.9346647262573242\n",
      "#Epoch 58 with total epochs 300 at step 18 loss: 6.844484329223633 running average of batch loss 7.059780698073538, time 0.9446711540222168\n",
      "#Epoch 58 with total epochs 300 at step 19 loss: 6.640101909637451 running average of batch loss 7.038796758651733, time 0.9606804847717285\n",
      "#Epoch 58 with total epochs 300 at step 20 loss: 6.6282453536987305 running average of batch loss 7.01924669174921, time 0.941669225692749\n",
      "#Epoch 59 with total epochs 300 at step 0 loss: 6.312756538391113 running average of batch loss 6.312756538391113, time 0.9526767730712891\n",
      "#Epoch 59 with total epochs 300 at step 1 loss: 6.657958984375 running average of batch loss 6.485357761383057, time 0.9516744613647461\n",
      "#Epoch 59 with total epochs 300 at step 2 loss: 6.386993885040283 running average of batch loss 6.452569802602132, time 0.9306621551513672\n",
      "#Epoch 59 with total epochs 300 at step 3 loss: 6.426080226898193 running average of batch loss 6.4459474086761475, time 0.9386658668518066\n",
      "#Epoch 59 with total epochs 300 at step 4 loss: 6.294877052307129 running average of batch loss 6.415733337402344, time 0.9416680335998535\n",
      "#Epoch 59 with total epochs 300 at step 5 loss: 6.362348556518555 running average of batch loss 6.406835873921712, time 0.9376654624938965\n",
      "#Epoch 59 with total epochs 300 at step 6 loss: 6.521574974060059 running average of batch loss 6.423227173941476, time 0.9396657943725586\n",
      "#Epoch 59 with total epochs 300 at step 7 loss: 6.289430141448975 running average of batch loss 6.406502544879913, time 0.938666820526123\n",
      "#Epoch 59 with total epochs 300 at step 8 loss: 6.368131637573242 running average of batch loss 6.402239110734728, time 0.9396653175354004\n",
      "#Epoch 59 with total epochs 300 at step 9 loss: 6.3721442222595215 running average of batch loss 6.399229621887207, time 0.9386672973632812\n",
      "#Epoch 59 with total epochs 300 at step 10 loss: 6.51704740524292 running average of batch loss 6.409940329464999, time 0.93166184425354\n",
      "#Epoch 59 with total epochs 300 at step 11 loss: 7.31664514541626 running average of batch loss 6.4854990641276045, time 0.9466702938079834\n",
      "#Epoch 59 with total epochs 300 at step 12 loss: 6.378310203552246 running average of batch loss 6.477253767160269, time 0.9336633682250977\n",
      "#Epoch 59 with total epochs 300 at step 13 loss: 6.936190605163574 running average of batch loss 6.51003496987479, time 0.935664176940918\n",
      "#Epoch 59 with total epochs 300 at step 14 loss: 5.939692497253418 running average of batch loss 6.472012138366699, time 0.9456710815429688\n",
      "#Epoch 59 with total epochs 300 at step 15 loss: 6.939655303955078 running average of batch loss 6.501239836215973, time 0.9446706771850586\n",
      "#Epoch 59 with total epochs 300 at step 16 loss: 7.065925598144531 running average of batch loss 6.534456645741182, time 0.9576797485351562\n",
      "#Epoch 59 with total epochs 300 at step 17 loss: 7.108434200286865 running average of batch loss 6.566344287660387, time 0.9306604862213135\n",
      "#Epoch 59 with total epochs 300 at step 18 loss: 7.4001665115356445 running average of batch loss 6.610229667864348, time 0.9556784629821777\n",
      "#Epoch 59 with total epochs 300 at step 19 loss: 7.2757887840271 running average of batch loss 6.643507623672486, time 0.9346621036529541\n",
      "#Epoch 59 with total epochs 300 at step 20 loss: 7.020240783691406 running average of batch loss 6.661447297959101, time 0.9676859378814697\n",
      "#Epoch 60 with total epochs 300 at step 0 loss: 6.386405944824219 running average of batch loss 6.386405944824219, time 0.9526777267456055\n",
      "#Epoch 60 with total epochs 300 at step 1 loss: 6.16195011138916 running average of batch loss 6.2741780281066895, time 0.9486730098724365\n",
      "#Epoch 60 with total epochs 300 at step 2 loss: 6.250107765197754 running average of batch loss 6.266154607137044, time 0.9636824131011963\n",
      "#Epoch 60 with total epochs 300 at step 3 loss: 6.660263538360596 running average of batch loss 6.364681839942932, time 0.9486744403839111\n",
      "#Epoch 60 with total epochs 300 at step 4 loss: 7.161430358886719 running average of batch loss 6.52403154373169, time 0.9406683444976807\n",
      "#Epoch 60 with total epochs 300 at step 5 loss: 6.8037190437316895 running average of batch loss 6.5706461270650225, time 0.9416694641113281\n",
      "#Epoch 60 with total epochs 300 at step 6 loss: 6.650209426879883 running average of batch loss 6.58201231275286, time 0.9366645812988281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 60 with total epochs 300 at step 7 loss: 6.677610874176025 running average of batch loss 6.593962132930756, time 0.940666675567627\n",
      "#Epoch 60 with total epochs 300 at step 8 loss: 7.536577224731445 running average of batch loss 6.698697143130833, time 0.9366633892059326\n",
      "#Epoch 60 with total epochs 300 at step 9 loss: 7.202517032623291 running average of batch loss 6.7490791320800785, time 0.9406678676605225\n",
      "#Epoch 60 with total epochs 300 at step 10 loss: 6.762948036193848 running average of batch loss 6.750339941544966, time 0.9396688938140869\n",
      "#Epoch 60 with total epochs 300 at step 11 loss: 6.127727031707764 running average of batch loss 6.698455532391866, time 0.9376654624938965\n",
      "#Epoch 60 with total epochs 300 at step 12 loss: 6.058506488800049 running average of batch loss 6.649228682884803, time 0.9336621761322021\n",
      "#Epoch 60 with total epochs 300 at step 13 loss: 6.5618181228637695 running average of batch loss 6.64298507145473, time 0.9386661052703857\n",
      "#Epoch 60 with total epochs 300 at step 14 loss: 6.585823059082031 running average of batch loss 6.639174270629883, time 0.932661771774292\n",
      "#Epoch 60 with total epochs 300 at step 15 loss: 7.277422904968262 running average of batch loss 6.6790648102760315, time 0.9346628189086914\n",
      "#Epoch 60 with total epochs 300 at step 16 loss: 6.692269325256348 running average of batch loss 6.679841546451344, time 0.9386661052703857\n",
      "#Epoch 60 with total epochs 300 at step 17 loss: 6.965648174285889 running average of batch loss 6.695719692442152, time 0.9396669864654541\n",
      "#Epoch 60 with total epochs 300 at step 18 loss: 7.213143825531006 running average of batch loss 6.722952541552092, time 0.9406661987304688\n",
      "#Epoch 60 with total epochs 300 at step 19 loss: 6.589074611663818 running average of batch loss 6.716258645057678, time 0.4923520088195801\n",
      "#Epoch 60 with total epochs 300 at step 20 loss: 6.455141544342041 running average of batch loss 6.703824497404552, time 0.5023298263549805\n",
      "avg difference between predicted and ground truth batch wise 8.124754764727184\n",
      "#Epoch 61 with total epochs 300 at step 0 loss: 6.372166633605957 running average of batch loss 6.372166633605957, time 0.48734521865844727\n",
      "#Epoch 61 with total epochs 300 at step 1 loss: 6.447075843811035 running average of batch loss 6.409621238708496, time 0.48932528495788574\n",
      "#Epoch 61 with total epochs 300 at step 2 loss: 6.608010292053223 running average of batch loss 6.475750923156738, time 0.49735164642333984\n",
      "#Epoch 61 with total epochs 300 at step 3 loss: 7.142169952392578 running average of batch loss 6.642355680465698, time 0.49832749366760254\n",
      "#Epoch 61 with total epochs 300 at step 4 loss: 6.553768157958984 running average of batch loss 6.624638175964355, time 0.5053305625915527\n",
      "#Epoch 61 with total epochs 300 at step 5 loss: 5.998244285583496 running average of batch loss 6.520239194234212, time 0.8375973701477051\n",
      "#Epoch 61 with total epochs 300 at step 6 loss: 6.560513973236084 running average of batch loss 6.525992734091623, time 0.9586789608001709\n",
      "#Epoch 61 with total epochs 300 at step 7 loss: 6.400088787078857 running average of batch loss 6.510254740715027, time 0.9606823921203613\n",
      "#Epoch 61 with total epochs 300 at step 8 loss: 6.601930618286133 running average of batch loss 6.520440949334039, time 0.9576799869537354\n",
      "#Epoch 61 with total epochs 300 at step 9 loss: 7.0605854988098145 running average of batch loss 6.574455404281617, time 0.9526779651641846\n",
      "#Epoch 61 with total epochs 300 at step 10 loss: 6.562356472015381 running average of batch loss 6.573355501348322, time 0.9446690082550049\n",
      "#Epoch 61 with total epochs 300 at step 11 loss: 6.922090530395508 running average of batch loss 6.602416753768921, time 0.9426705837249756\n",
      "#Epoch 61 with total epochs 300 at step 12 loss: 6.494314193725586 running average of batch loss 6.594101172227126, time 0.9386649131774902\n",
      "#Epoch 61 with total epochs 300 at step 13 loss: 6.77347993850708 running average of batch loss 6.6069139412471225, time 0.9246556758880615\n",
      "#Epoch 61 with total epochs 300 at step 14 loss: 6.707263946533203 running average of batch loss 6.613603941599528, time 0.9376652240753174\n",
      "#Epoch 61 with total epochs 300 at step 15 loss: 6.3574934005737305 running average of batch loss 6.597597032785416, time 0.9406661987304688\n",
      "#Epoch 61 with total epochs 300 at step 16 loss: 6.839704990386963 running average of batch loss 6.611838677350213, time 0.9416697025299072\n",
      "#Epoch 61 with total epochs 300 at step 17 loss: 6.114476680755615 running average of batch loss 6.58420745531718, time 0.939666748046875\n",
      "#Epoch 61 with total epochs 300 at step 18 loss: 6.526716232299805 running average of batch loss 6.581181601474159, time 0.9426681995391846\n",
      "#Epoch 61 with total epochs 300 at step 19 loss: 6.175459384918213 running average of batch loss 6.560895490646362, time 0.9396665096282959\n",
      "#Epoch 61 with total epochs 300 at step 20 loss: 6.977232456207275 running average of batch loss 6.5807210604349775, time 0.9406659603118896\n",
      "#Epoch 62 with total epochs 300 at step 0 loss: 6.984241962432861 running average of batch loss 6.984241962432861, time 0.9426705837249756\n",
      "#Epoch 62 with total epochs 300 at step 1 loss: 6.5847392082214355 running average of batch loss 6.784490585327148, time 0.9426689147949219\n",
      "#Epoch 62 with total epochs 300 at step 2 loss: 6.664056777954102 running average of batch loss 6.744345982869466, time 0.9416675567626953\n",
      "#Epoch 62 with total epochs 300 at step 3 loss: 6.367712020874023 running average of batch loss 6.6501874923706055, time 0.9376416206359863\n",
      "#Epoch 62 with total epochs 300 at step 4 loss: 6.459951877593994 running average of batch loss 6.612140369415283, time 0.9316649436950684\n",
      "#Epoch 62 with total epochs 300 at step 5 loss: 6.774539947509766 running average of batch loss 6.639206965764363, time 0.9426686763763428\n",
      "#Epoch 62 with total epochs 300 at step 6 loss: 6.085850715637207 running average of batch loss 6.560156072889056, time 0.944669246673584\n",
      "#Epoch 62 with total epochs 300 at step 7 loss: 7.133454322814941 running average of batch loss 6.631818354129791, time 0.9416680335998535\n",
      "#Epoch 62 with total epochs 300 at step 8 loss: 6.5268659591674805 running average of batch loss 6.6201569769117565, time 0.9346652030944824\n",
      "#Epoch 62 with total epochs 300 at step 9 loss: 6.5658392906188965 running average of batch loss 6.61472520828247, time 0.9336612224578857\n",
      "#Epoch 62 with total epochs 300 at step 10 loss: 6.714027404785156 running average of batch loss 6.623752680691806, time 0.9436731338500977\n",
      "#Epoch 62 with total epochs 300 at step 11 loss: 6.444295406341553 running average of batch loss 6.608797907829285, time 0.9386646747589111\n",
      "#Epoch 62 with total epochs 300 at step 12 loss: 6.424929618835449 running average of batch loss 6.594654193291297, time 0.951676607131958\n",
      "#Epoch 62 with total epochs 300 at step 13 loss: 6.059689044952393 running average of batch loss 6.556442396981375, time 0.9476742744445801\n",
      "#Epoch 62 with total epochs 300 at step 14 loss: 6.291328430175781 running average of batch loss 6.538768132527669, time 0.9576804637908936\n",
      "#Epoch 62 with total epochs 300 at step 15 loss: 6.287471771240234 running average of batch loss 6.523062109947205, time 0.9406678676605225\n",
      "#Epoch 62 with total epochs 300 at step 16 loss: 6.71659517288208 running average of batch loss 6.534446407766903, time 0.9276583194732666\n",
      "#Epoch 62 with total epochs 300 at step 17 loss: 6.4079179763793945 running average of batch loss 6.527417050467597, time 0.9406661987304688\n",
      "#Epoch 62 with total epochs 300 at step 18 loss: 6.4552836418151855 running average of batch loss 6.5236205552753646, time 0.9426693916320801\n",
      "#Epoch 62 with total epochs 300 at step 19 loss: 6.08656120300293 running average of batch loss 6.501767587661743, time 0.9306604862213135\n",
      "#Epoch 62 with total epochs 300 at step 20 loss: 6.925528049468994 running average of batch loss 6.521946657271612, time 0.9356632232666016\n",
      "#Epoch 63 with total epochs 300 at step 0 loss: 6.008834362030029 running average of batch loss 6.008834362030029, time 0.9356632232666016\n",
      "#Epoch 63 with total epochs 300 at step 1 loss: 6.686586856842041 running average of batch loss 6.347710609436035, time 0.9356646537780762\n",
      "#Epoch 63 with total epochs 300 at step 2 loss: 6.685123920440674 running average of batch loss 6.460181713104248, time 0.9396460056304932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 63 with total epochs 300 at step 3 loss: 6.246551513671875 running average of batch loss 6.406774163246155, time 0.9316613674163818\n",
      "#Epoch 63 with total epochs 300 at step 4 loss: 6.173955917358398 running average of batch loss 6.360210514068603, time 0.9416699409484863\n",
      "#Epoch 63 with total epochs 300 at step 5 loss: 6.450220108032227 running average of batch loss 6.375212113062541, time 0.9356658458709717\n",
      "#Epoch 63 with total epochs 300 at step 6 loss: 6.788254737854004 running average of batch loss 6.434218202318464, time 0.9406676292419434\n",
      "#Epoch 63 with total epochs 300 at step 7 loss: 6.027167320251465 running average of batch loss 6.383336842060089, time 0.9326615333557129\n",
      "#Epoch 63 with total epochs 300 at step 8 loss: 6.249658584594727 running average of batch loss 6.368483702341716, time 0.9376649856567383\n",
      "#Epoch 63 with total epochs 300 at step 9 loss: 6.60593843460083 running average of batch loss 6.392229175567627, time 0.9346635341644287\n",
      "#Epoch 63 with total epochs 300 at step 10 loss: 6.660153388977051 running average of batch loss 6.416585922241211, time 0.9436678886413574\n",
      "#Epoch 63 with total epochs 300 at step 11 loss: 6.61041259765625 running average of batch loss 6.432738145192464, time 0.9416701793670654\n",
      "#Epoch 63 with total epochs 300 at step 12 loss: 6.42080545425415 running average of batch loss 6.431820245889517, time 0.9316604137420654\n",
      "#Epoch 63 with total epochs 300 at step 13 loss: 6.739785194396973 running average of batch loss 6.453817742211478, time 0.9626832008361816\n",
      "#Epoch 63 with total epochs 300 at step 14 loss: 6.620635986328125 running average of batch loss 6.464938958485921, time 0.9576797485351562\n",
      "#Epoch 63 with total epochs 300 at step 15 loss: 6.539702415466309 running average of batch loss 6.469611674547195, time 0.9546773433685303\n",
      "#Epoch 63 with total epochs 300 at step 16 loss: 6.437579154968262 running average of batch loss 6.467727408689611, time 0.9486730098724365\n",
      "#Epoch 63 with total epochs 300 at step 17 loss: 6.219105243682861 running average of batch loss 6.453915066189236, time 0.9406676292419434\n",
      "#Epoch 63 with total epochs 300 at step 18 loss: 6.389988899230957 running average of batch loss 6.450550531086169, time 0.9396669864654541\n",
      "#Epoch 63 with total epochs 300 at step 19 loss: 6.15594482421875 running average of batch loss 6.435820245742798, time 0.9416689872741699\n",
      "#Epoch 63 with total epochs 300 at step 20 loss: 6.059671401977539 running average of batch loss 6.4179083960396905, time 0.9426689147949219\n",
      "#Epoch 64 with total epochs 300 at step 0 loss: 7.00874137878418 running average of batch loss 7.00874137878418, time 0.9316592216491699\n",
      "#Epoch 64 with total epochs 300 at step 1 loss: 6.875949382781982 running average of batch loss 6.942345380783081, time 0.9366652965545654\n",
      "#Epoch 64 with total epochs 300 at step 2 loss: 6.8572797775268555 running average of batch loss 6.913990179697673, time 0.9276576042175293\n",
      "#Epoch 64 with total epochs 300 at step 3 loss: 6.21976900100708 running average of batch loss 6.740434885025024, time 0.931659460067749\n",
      "#Epoch 64 with total epochs 300 at step 4 loss: 6.273197650909424 running average of batch loss 6.646987438201904, time 0.932661771774292\n",
      "#Epoch 64 with total epochs 300 at step 5 loss: 6.06266975402832 running average of batch loss 6.549601157506307, time 0.9416708946228027\n",
      "#Epoch 64 with total epochs 300 at step 6 loss: 6.151383876800537 running average of batch loss 6.49271297454834, time 0.9366641044616699\n",
      "#Epoch 64 with total epochs 300 at step 7 loss: 6.036020278930664 running average of batch loss 6.43562638759613, time 0.9286577701568604\n",
      "#Epoch 64 with total epochs 300 at step 8 loss: 6.177565097808838 running average of batch loss 6.406952910953098, time 0.933664083480835\n",
      "#Epoch 64 with total epochs 300 at step 9 loss: 6.311927318572998 running average of batch loss 6.397450351715088, time 0.9376425743103027\n",
      "#Epoch 64 with total epochs 300 at step 10 loss: 6.204474925994873 running average of batch loss 6.379907131195068, time 0.9426453113555908\n",
      "#Epoch 64 with total epochs 300 at step 11 loss: 7.370421409606934 running average of batch loss 6.46244998772939, time 0.9426703453063965\n",
      "#Epoch 64 with total epochs 300 at step 12 loss: 6.8213605880737305 running average of batch loss 6.490058495448186, time 0.937664270401001\n",
      "#Epoch 64 with total epochs 300 at step 13 loss: 5.917125701904297 running average of batch loss 6.449134724480765, time 0.9536769390106201\n",
      "#Epoch 64 with total epochs 300 at step 14 loss: 6.190443992614746 running average of batch loss 6.431888675689697, time 0.9386661052703857\n",
      "#Epoch 64 with total epochs 300 at step 15 loss: 6.653326511383057 running average of batch loss 6.445728540420532, time 0.9546773433685303\n",
      "#Epoch 64 with total epochs 300 at step 16 loss: 6.950143337249756 running average of batch loss 6.4753999990575455, time 0.9576795101165771\n",
      "#Epoch 64 with total epochs 300 at step 17 loss: 5.8962249755859375 running average of batch loss 6.443223608864678, time 0.9656851291656494\n",
      "#Epoch 64 with total epochs 300 at step 18 loss: 6.21927547454834 running average of batch loss 6.431436864953292, time 0.9316627979278564\n",
      "#Epoch 64 with total epochs 300 at step 19 loss: 5.9551215171813965 running average of batch loss 6.407621097564697, time 0.932661771774292\n",
      "#Epoch 64 with total epochs 300 at step 20 loss: 6.801149368286133 running average of batch loss 6.426360539027622, time 0.9336624145507812\n",
      "#Epoch 65 with total epochs 300 at step 0 loss: 6.430260181427002 running average of batch loss 6.430260181427002, time 0.9376647472381592\n",
      "#Epoch 65 with total epochs 300 at step 1 loss: 6.639120101928711 running average of batch loss 6.5346901416778564, time 0.9266579151153564\n",
      "#Epoch 65 with total epochs 300 at step 2 loss: 6.2716450691223145 running average of batch loss 6.447008450826009, time 0.9356639385223389\n",
      "#Epoch 65 with total epochs 300 at step 3 loss: 6.5920634269714355 running average of batch loss 6.483272194862366, time 0.9396686553955078\n",
      "#Epoch 65 with total epochs 300 at step 4 loss: 6.571958065032959 running average of batch loss 6.501009368896485, time 0.9326622486114502\n",
      "#Epoch 65 with total epochs 300 at step 5 loss: 6.641406536102295 running average of batch loss 6.524408896764119, time 0.941666841506958\n",
      "#Epoch 65 with total epochs 300 at step 6 loss: 6.08329963684082 running average of batch loss 6.461393288203648, time 0.9376654624938965\n",
      "#Epoch 65 with total epochs 300 at step 7 loss: 6.377103328704834 running average of batch loss 6.450857043266296, time 0.9316599369049072\n",
      "#Epoch 65 with total epochs 300 at step 8 loss: 6.245743274688721 running average of batch loss 6.428066624535455, time 0.9346647262573242\n",
      "#Epoch 65 with total epochs 300 at step 9 loss: 5.937420845031738 running average of batch loss 6.379002046585083, time 0.9426689147949219\n",
      "#Epoch 65 with total epochs 300 at step 10 loss: 6.043102741241455 running average of batch loss 6.348465746099299, time 0.9466712474822998\n",
      "#Epoch 65 with total epochs 300 at step 11 loss: 6.046573162078857 running average of batch loss 6.323308030764262, time 0.9406671524047852\n",
      "#Epoch 65 with total epochs 300 at step 12 loss: 6.819113254547119 running average of batch loss 6.361446894132174, time 0.9416687488555908\n",
      "#Epoch 65 with total epochs 300 at step 13 loss: 6.523910999298096 running average of batch loss 6.373051473072597, time 0.9606812000274658\n",
      "#Epoch 65 with total epochs 300 at step 14 loss: 6.198090553283691 running average of batch loss 6.361387411753337, time 0.9346621036529541\n",
      "#Epoch 65 with total epochs 300 at step 15 loss: 6.338736057281494 running average of batch loss 6.359971702098846, time 0.9676868915557861\n",
      "#Epoch 65 with total epochs 300 at step 16 loss: 6.2240118980407715 running average of batch loss 6.351974066566019, time 0.9556779861450195\n",
      "#Epoch 65 with total epochs 300 at step 17 loss: 6.817843437194824 running average of batch loss 6.377855698267619, time 0.9466710090637207\n",
      "#Epoch 65 with total epochs 300 at step 18 loss: 6.443870544433594 running average of batch loss 6.381330163855302, time 0.9596798419952393\n",
      "#Epoch 65 with total epochs 300 at step 19 loss: 5.943994522094727 running average of batch loss 6.359463381767273, time 0.9456706047058105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 65 with total epochs 300 at step 20 loss: 6.305145263671875 running average of batch loss 6.356876804715111, time 0.9426677227020264\n",
      "#Epoch 66 with total epochs 300 at step 0 loss: 6.294322967529297 running average of batch loss 6.294322967529297, time 0.9476757049560547\n",
      "#Epoch 66 with total epochs 300 at step 1 loss: 6.662616729736328 running average of batch loss 6.4784698486328125, time 0.937664270401001\n",
      "#Epoch 66 with total epochs 300 at step 2 loss: 6.679399013519287 running average of batch loss 6.545446236928304, time 0.9246342182159424\n",
      "#Epoch 66 with total epochs 300 at step 3 loss: 6.431339740753174 running average of batch loss 6.5169196128845215, time 0.9376673698425293\n",
      "#Epoch 66 with total epochs 300 at step 4 loss: 6.338367938995361 running average of batch loss 6.4812092781066895, time 0.9446690082550049\n",
      "#Epoch 66 with total epochs 300 at step 5 loss: 6.701826572418213 running average of batch loss 6.51797882715861, time 0.934664249420166\n",
      "#Epoch 66 with total epochs 300 at step 6 loss: 6.12088680267334 running average of batch loss 6.461251395089286, time 0.9386663436889648\n",
      "#Epoch 66 with total epochs 300 at step 7 loss: 6.490713596343994 running average of batch loss 6.464934170246124, time 0.9396684169769287\n",
      "#Epoch 66 with total epochs 300 at step 8 loss: 6.092304229736328 running average of batch loss 6.423530843522814, time 0.935664176940918\n",
      "#Epoch 66 with total epochs 300 at step 9 loss: 6.274008750915527 running average of batch loss 6.408578634262085, time 0.9406673908233643\n",
      "#Epoch 66 with total epochs 300 at step 10 loss: 6.172261714935303 running average of batch loss 6.38709527795965, time 0.9396665096282959\n",
      "#Epoch 66 with total epochs 300 at step 11 loss: 6.259387493133545 running average of batch loss 6.376452962557475, time 0.9376657009124756\n",
      "#Epoch 66 with total epochs 300 at step 12 loss: 6.311810493469238 running average of batch loss 6.371480464935303, time 0.9386649131774902\n",
      "#Epoch 66 with total epochs 300 at step 13 loss: 6.736475944519043 running average of batch loss 6.397551570619855, time 0.9386658668518066\n",
      "#Epoch 66 with total epochs 300 at step 14 loss: 5.777488708496094 running average of batch loss 6.3562140464782715, time 0.935664176940918\n",
      "#Epoch 66 with total epochs 300 at step 15 loss: 6.171101093292236 running average of batch loss 6.344644486904144, time 0.9556763172149658\n",
      "#Epoch 66 with total epochs 300 at step 16 loss: 6.403252601623535 running average of batch loss 6.348092023064108, time 0.9706916809082031\n",
      "#Epoch 66 with total epochs 300 at step 17 loss: 5.953747749328613 running average of batch loss 6.326184007856581, time 0.9346644878387451\n",
      "#Epoch 66 with total epochs 300 at step 18 loss: 6.55197811126709 running average of batch loss 6.3380679080360816, time 0.9506745338439941\n",
      "#Epoch 66 with total epochs 300 at step 19 loss: 6.067841529846191 running average of batch loss 6.324556589126587, time 0.9416685104370117\n",
      "#Epoch 66 with total epochs 300 at step 20 loss: 6.02025842666626 running average of batch loss 6.3100662004379995, time 0.9316613674163818\n",
      "#Epoch 67 with total epochs 300 at step 0 loss: 6.842608451843262 running average of batch loss 6.842608451843262, time 0.939666748046875\n",
      "#Epoch 67 with total epochs 300 at step 1 loss: 6.532838344573975 running average of batch loss 6.687723398208618, time 0.9336612224578857\n",
      "#Epoch 67 with total epochs 300 at step 2 loss: 6.794519424438477 running average of batch loss 6.723322073618571, time 0.9356658458709717\n",
      "#Epoch 67 with total epochs 300 at step 3 loss: 6.1004557609558105 running average of batch loss 6.567605495452881, time 0.9346630573272705\n",
      "#Epoch 67 with total epochs 300 at step 4 loss: 5.880866527557373 running average of batch loss 6.43025770187378, time 0.9446699619293213\n",
      "#Epoch 67 with total epochs 300 at step 5 loss: 6.700260162353516 running average of batch loss 6.475258111953735, time 0.9366657733917236\n",
      "#Epoch 67 with total epochs 300 at step 6 loss: 5.980812072753906 running average of batch loss 6.4046229634966165, time 0.9416685104370117\n",
      "#Epoch 67 with total epochs 300 at step 7 loss: 6.6566338539123535 running average of batch loss 6.436124324798584, time 0.9446690082550049\n",
      "#Epoch 67 with total epochs 300 at step 8 loss: 6.544290065765381 running average of batch loss 6.448142740461561, time 0.932664155960083\n",
      "#Epoch 67 with total epochs 300 at step 9 loss: 6.6078925132751465 running average of batch loss 6.46411771774292, time 0.9426674842834473\n",
      "#Epoch 67 with total epochs 300 at step 10 loss: 5.922732830047607 running average of batch loss 6.414900909770619, time 0.9356644153594971\n",
      "#Epoch 67 with total epochs 300 at step 11 loss: 6.339202880859375 running average of batch loss 6.408592740694682, time 0.9376442432403564\n",
      "#Epoch 67 with total epochs 300 at step 12 loss: 6.274580478668213 running average of batch loss 6.398284105154184, time 0.9336621761322021\n",
      "#Epoch 67 with total epochs 300 at step 13 loss: 6.044729232788086 running average of batch loss 6.373030185699463, time 0.9486722946166992\n",
      "#Epoch 67 with total epochs 300 at step 14 loss: 6.073585510253906 running average of batch loss 6.353067207336426, time 0.9286572933197021\n",
      "#Epoch 67 with total epochs 300 at step 15 loss: 5.916937351226807 running average of batch loss 6.325809091329575, time 0.9306614398956299\n",
      "#Epoch 67 with total epochs 300 at step 16 loss: 6.651611804962158 running average of batch loss 6.344973956837373, time 0.9396657943725586\n",
      "#Epoch 67 with total epochs 300 at step 17 loss: 5.670672416687012 running average of batch loss 6.3075127601623535, time 0.9326632022857666\n",
      "#Epoch 67 with total epochs 300 at step 18 loss: 6.233855247497559 running average of batch loss 6.303636048969469, time 0.9426684379577637\n",
      "#Epoch 67 with total epochs 300 at step 19 loss: 6.630999565124512 running average of batch loss 6.320004224777222, time 0.9546775817871094\n",
      "#Epoch 67 with total epochs 300 at step 20 loss: 6.706068992614746 running average of batch loss 6.3383882613409135, time 0.9516735076904297\n",
      "#Epoch 68 with total epochs 300 at step 0 loss: 6.253011226654053 running average of batch loss 6.253011226654053, time 0.9466731548309326\n",
      "#Epoch 68 with total epochs 300 at step 1 loss: 5.729588031768799 running average of batch loss 5.991299629211426, time 0.9486739635467529\n",
      "#Epoch 68 with total epochs 300 at step 2 loss: 6.4347825050354 running average of batch loss 6.139127254486084, time 0.9456720352172852\n",
      "#Epoch 68 with total epochs 300 at step 3 loss: 5.6548357009887695 running average of batch loss 6.018054366111755, time 0.9346652030944824\n",
      "#Epoch 68 with total epochs 300 at step 4 loss: 6.142581462860107 running average of batch loss 6.042959785461425, time 0.9396679401397705\n",
      "#Epoch 68 with total epochs 300 at step 5 loss: 6.3904337882995605 running average of batch loss 6.100872119267781, time 0.9286589622497559\n",
      "#Epoch 68 with total epochs 300 at step 6 loss: 6.574563503265381 running average of batch loss 6.168542316981724, time 0.9406671524047852\n",
      "#Epoch 68 with total epochs 300 at step 7 loss: 6.840761661529541 running average of batch loss 6.252569735050201, time 0.9396665096282959\n",
      "#Epoch 68 with total epochs 300 at step 8 loss: 6.210740566253662 running average of batch loss 6.247922049628364, time 0.9356639385223389\n",
      "#Epoch 68 with total epochs 300 at step 9 loss: 6.051663875579834 running average of batch loss 6.228296232223511, time 0.937664270401001\n",
      "#Epoch 68 with total epochs 300 at step 10 loss: 6.329641342163086 running average of batch loss 6.237509424036199, time 0.9356653690338135\n",
      "#Epoch 68 with total epochs 300 at step 11 loss: 6.379851818084717 running average of batch loss 6.249371290206909, time 0.940666913986206\n",
      "#Epoch 68 with total epochs 300 at step 12 loss: 6.517820835113525 running average of batch loss 6.270021255199726, time 0.9336624145507812\n",
      "#Epoch 68 with total epochs 300 at step 13 loss: 6.660943984985352 running average of batch loss 6.2979443073272705, time 0.9316599369049072\n",
      "#Epoch 68 with total epochs 300 at step 14 loss: 6.351179122924805 running average of batch loss 6.301493295033773, time 0.9316604137420654\n",
      "#Epoch 68 with total epochs 300 at step 15 loss: 5.734051704406738 running average of batch loss 6.266028195619583, time 0.9406697750091553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 68 with total epochs 300 at step 16 loss: 6.291977882385254 running average of batch loss 6.267554647782269, time 0.9416673183441162\n",
      "#Epoch 68 with total epochs 300 at step 17 loss: 6.203654766082764 running average of batch loss 6.264004654354519, time 0.9316599369049072\n",
      "#Epoch 68 with total epochs 300 at step 18 loss: 6.268031120300293 running average of batch loss 6.264216573614823, time 0.9406423568725586\n",
      "#Epoch 68 with total epochs 300 at step 19 loss: 5.749053955078125 running average of batch loss 6.238458442687988, time 0.9366655349731445\n",
      "#Epoch 68 with total epochs 300 at step 20 loss: 6.229455471038818 running average of batch loss 6.238029729752314, time 0.9286599159240723\n",
      "#Epoch 69 with total epochs 300 at step 0 loss: 6.417819976806641 running average of batch loss 6.417819976806641, time 0.9656846523284912\n",
      "#Epoch 69 with total epochs 300 at step 1 loss: 6.578679084777832 running average of batch loss 6.498249530792236, time 0.9566788673400879\n",
      "#Epoch 69 with total epochs 300 at step 2 loss: 6.371360778808594 running average of batch loss 6.455953280131022, time 0.9436695575714111\n",
      "#Epoch 69 with total epochs 300 at step 3 loss: 6.2608723640441895 running average of batch loss 6.407183051109314, time 0.9636838436126709\n",
      "#Epoch 69 with total epochs 300 at step 4 loss: 5.640678882598877 running average of batch loss 6.253882217407226, time 0.9356639385223389\n",
      "#Epoch 69 with total epochs 300 at step 5 loss: 6.066699981689453 running average of batch loss 6.222685178120931, time 0.9416682720184326\n",
      "#Epoch 69 with total epochs 300 at step 6 loss: 5.581252574920654 running average of batch loss 6.13105194909232, time 0.9456698894500732\n",
      "#Epoch 69 with total epochs 300 at step 7 loss: 6.063783645629883 running average of batch loss 6.122643411159515, time 0.9376664161682129\n",
      "#Epoch 69 with total epochs 300 at step 8 loss: 6.637734413146973 running average of batch loss 6.179875744713677, time 0.940666913986206\n",
      "#Epoch 69 with total epochs 300 at step 9 loss: 6.143939018249512 running average of batch loss 6.176282072067261, time 0.937666654586792\n",
      "#Epoch 69 with total epochs 300 at step 10 loss: 6.951716423034668 running average of batch loss 6.246776103973389, time 0.9386656284332275\n",
      "#Epoch 69 with total epochs 300 at step 11 loss: 5.748921871185303 running average of batch loss 6.205288251241048, time 0.9356639385223389\n",
      "#Epoch 69 with total epochs 300 at step 12 loss: 6.19830846786499 running average of batch loss 6.204751344827505, time 0.9396684169769287\n",
      "#Epoch 69 with total epochs 300 at step 13 loss: 5.801376819610596 running average of batch loss 6.175938878740583, time 0.9396660327911377\n",
      "#Epoch 69 with total epochs 300 at step 14 loss: 5.614227294921875 running average of batch loss 6.138491439819336, time 0.9306378364562988\n",
      "#Epoch 69 with total epochs 300 at step 15 loss: 6.280851364135742 running average of batch loss 6.147388935089111, time 0.9456489086151123\n",
      "#Epoch 69 with total epochs 300 at step 16 loss: 6.392427444458008 running average of batch loss 6.161802965051987, time 0.9396679401397705\n",
      "#Epoch 69 with total epochs 300 at step 17 loss: 6.285079002380371 running average of batch loss 6.168651633792454, time 0.929659366607666\n",
      "#Epoch 69 with total epochs 300 at step 18 loss: 5.950512886047363 running average of batch loss 6.1571706470690275, time 0.9386656284332275\n",
      "#Epoch 69 with total epochs 300 at step 19 loss: 6.506409645080566 running average of batch loss 6.174632596969604, time 0.9396650791168213\n",
      "#Epoch 69 with total epochs 300 at step 20 loss: 5.662921905517578 running average of batch loss 6.150265421186175, time 0.9356651306152344\n",
      "#Epoch 70 with total epochs 300 at step 0 loss: 6.457363128662109 running average of batch loss 6.457363128662109, time 0.9406676292419434\n",
      "#Epoch 70 with total epochs 300 at step 1 loss: 6.302270412445068 running average of batch loss 6.379816770553589, time 0.9436700344085693\n",
      "#Epoch 70 with total epochs 300 at step 2 loss: 5.419950008392334 running average of batch loss 6.059861183166504, time 0.9486744403839111\n",
      "#Epoch 70 with total epochs 300 at step 3 loss: 6.093786239624023 running average of batch loss 6.068342447280884, time 0.9586801528930664\n",
      "#Epoch 70 with total epochs 300 at step 4 loss: 6.358728408813477 running average of batch loss 6.126419639587402, time 0.9556779861450195\n",
      "#Epoch 70 with total epochs 300 at step 5 loss: 5.873500823974609 running average of batch loss 6.0842665036519366, time 0.9416680335998535\n",
      "#Epoch 70 with total epochs 300 at step 6 loss: 6.082925796508789 running average of batch loss 6.084074974060059, time 0.9426672458648682\n",
      "#Epoch 70 with total epochs 300 at step 7 loss: 6.093873500823975 running average of batch loss 6.085299789905548, time 0.9366650581359863\n",
      "#Epoch 70 with total epochs 300 at step 8 loss: 6.545363426208496 running average of batch loss 6.136417971716987, time 0.938666582107544\n",
      "#Epoch 70 with total epochs 300 at step 9 loss: 5.927876949310303 running average of batch loss 6.115563869476318, time 0.9456713199615479\n",
      "#Epoch 70 with total epochs 300 at step 10 loss: 6.442187786102295 running average of batch loss 6.145256952805952, time 0.9366638660430908\n",
      "#Epoch 70 with total epochs 300 at step 11 loss: 6.344715118408203 running average of batch loss 6.16187846660614, time 0.9316627979278564\n",
      "#Epoch 70 with total epochs 300 at step 12 loss: 6.126091957092285 running average of batch loss 6.159125658181997, time 0.9406678676605225\n",
      "#Epoch 70 with total epochs 300 at step 13 loss: 6.63686466217041 running average of batch loss 6.193249872752598, time 0.939666748046875\n",
      "#Epoch 70 with total epochs 300 at step 14 loss: 5.525731563568115 running average of batch loss 6.148748652140299, time 0.9366657733917236\n",
      "#Epoch 70 with total epochs 300 at step 15 loss: 6.292698383331299 running average of batch loss 6.157745510339737, time 0.9346630573272705\n",
      "#Epoch 70 with total epochs 300 at step 16 loss: 5.771023750305176 running average of batch loss 6.134997171514175, time 0.9346628189086914\n",
      "#Epoch 70 with total epochs 300 at step 17 loss: 6.1994404792785645 running average of batch loss 6.138577355278863, time 0.9356637001037598\n",
      "#Epoch 70 with total epochs 300 at step 18 loss: 6.2614030838012695 running average of batch loss 6.145041867306358, time 0.946671724319458\n",
      "#Epoch 70 with total epochs 300 at step 19 loss: 6.227355003356934 running average of batch loss 6.149157524108887, time 0.9356632232666016\n",
      "#Epoch 70 with total epochs 300 at step 20 loss: 6.1385498046875 running average of batch loss 6.14865239461263, time 0.9386661052703857\n",
      "#Epoch 71 with total epochs 300 at step 0 loss: 6.217728614807129 running average of batch loss 6.217728614807129, time 1.2338788509368896\n",
      "#Epoch 71 with total epochs 300 at step 1 loss: 6.559248447418213 running average of batch loss 6.388488531112671, time 0.969688892364502\n",
      "#Epoch 71 with total epochs 300 at step 2 loss: 6.4146928787231445 running average of batch loss 6.397223313649495, time 0.9406440258026123\n",
      "#Epoch 71 with total epochs 300 at step 3 loss: 5.904233932495117 running average of batch loss 6.273975968360901, time 0.9366629123687744\n",
      "#Epoch 71 with total epochs 300 at step 4 loss: 5.8374552726745605 running average of batch loss 6.1866718292236325, time 0.943671703338623\n",
      "#Epoch 71 with total epochs 300 at step 5 loss: 6.222057342529297 running average of batch loss 6.192569414774577, time 0.9316606521606445\n",
      "#Epoch 71 with total epochs 300 at step 6 loss: 6.583481311798096 running average of batch loss 6.248413971492222, time 0.9396665096282959\n",
      "#Epoch 71 with total epochs 300 at step 7 loss: 6.417340278625488 running average of batch loss 6.269529759883881, time 0.9646828174591064\n",
      "#Epoch 71 with total epochs 300 at step 8 loss: 6.042819023132324 running average of batch loss 6.244339678022596, time 0.9376661777496338\n",
      "#Epoch 71 with total epochs 300 at step 9 loss: 5.924263954162598 running average of batch loss 6.212332105636596, time 0.929661750793457\n",
      "#Epoch 71 with total epochs 300 at step 10 loss: 6.252250671386719 running average of batch loss 6.215961066159335, time 0.9396660327911377\n",
      "#Epoch 71 with total epochs 300 at step 11 loss: 6.323155403137207 running average of batch loss 6.224893927574158, time 0.9526519775390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 71 with total epochs 300 at step 12 loss: 6.741959571838379 running average of batch loss 6.264668207902175, time 0.9306607246398926\n",
      "#Epoch 71 with total epochs 300 at step 13 loss: 6.511870861053467 running average of batch loss 6.282325540270124, time 0.9346635341644287\n",
      "#Epoch 71 with total epochs 300 at step 14 loss: 5.6406941413879395 running average of batch loss 6.2395501136779785, time 0.946671724319458\n",
      "#Epoch 71 with total epochs 300 at step 15 loss: 6.106085300445557 running average of batch loss 6.231208562850952, time 0.9296610355377197\n",
      "#Epoch 71 with total epochs 300 at step 16 loss: 6.203451633453369 running average of batch loss 6.229575802298153, time 0.9506745338439941\n",
      "#Epoch 71 with total epochs 300 at step 17 loss: 6.306019306182861 running average of batch loss 6.233822663625081, time 0.9466705322265625\n",
      "#Epoch 71 with total epochs 300 at step 18 loss: 6.579873085021973 running average of batch loss 6.252035843698602, time 0.9416687488555908\n",
      "#Epoch 71 with total epochs 300 at step 19 loss: 6.3515472412109375 running average of batch loss 6.257011413574219, time 0.9376671314239502\n",
      "#Epoch 71 with total epochs 300 at step 20 loss: 5.787077903747559 running average of batch loss 6.234633627391997, time 0.9336645603179932\n",
      "#Epoch 72 with total epochs 300 at step 0 loss: 6.081944465637207 running average of batch loss 6.081944465637207, time 0.9366641044616699\n",
      "#Epoch 72 with total epochs 300 at step 1 loss: 5.90377950668335 running average of batch loss 5.992861986160278, time 0.9436678886413574\n",
      "#Epoch 72 with total epochs 300 at step 2 loss: 6.20621395111084 running average of batch loss 6.063979307810466, time 0.9346418380737305\n",
      "#Epoch 72 with total epochs 300 at step 3 loss: 6.848964214324951 running average of batch loss 6.260225534439087, time 0.9376654624938965\n",
      "#Epoch 72 with total epochs 300 at step 4 loss: 6.033846855163574 running average of batch loss 6.2149497985839846, time 0.940666675567627\n",
      "#Epoch 72 with total epochs 300 at step 5 loss: 6.652604103088379 running average of batch loss 6.28789218266805, time 0.9346640110015869\n",
      "#Epoch 72 with total epochs 300 at step 6 loss: 6.218573570251465 running average of batch loss 6.277989523751395, time 0.9416701793670654\n",
      "#Epoch 72 with total epochs 300 at step 7 loss: 5.966928005218506 running average of batch loss 6.239106833934784, time 0.9406673908233643\n",
      "#Epoch 72 with total epochs 300 at step 8 loss: 5.949300765991211 running average of batch loss 6.206906159718831, time 0.9396390914916992\n",
      "#Epoch 72 with total epochs 300 at step 9 loss: 5.910983562469482 running average of batch loss 6.177313899993896, time 0.9566802978515625\n",
      "#Epoch 72 with total epochs 300 at step 10 loss: 6.609985828399658 running average of batch loss 6.2166477116671475, time 0.9566788673400879\n",
      "#Epoch 72 with total epochs 300 at step 11 loss: 5.727190017700195 running average of batch loss 6.175859570503235, time 0.9606831073760986\n",
      "#Epoch 72 with total epochs 300 at step 12 loss: 5.800498008728027 running average of batch loss 6.146985604212834, time 0.9506745338439941\n",
      "#Epoch 72 with total epochs 300 at step 13 loss: 6.308206081390381 running average of batch loss 6.158501352582659, time 0.9466719627380371\n",
      "#Epoch 72 with total epochs 300 at step 14 loss: 6.278481483459473 running average of batch loss 6.166500027974447, time 0.943669319152832\n",
      "#Epoch 72 with total epochs 300 at step 15 loss: 6.016600608825684 running average of batch loss 6.157131314277649, time 0.9366424083709717\n",
      "#Epoch 72 with total epochs 300 at step 16 loss: 6.055926322937012 running average of batch loss 6.151178079492905, time 0.9426686763763428\n",
      "#Epoch 72 with total epochs 300 at step 17 loss: 6.423358917236328 running average of batch loss 6.166299237145318, time 0.9396424293518066\n",
      "#Epoch 72 with total epochs 300 at step 18 loss: 6.166899681091309 running average of batch loss 6.166330839458265, time 0.9366631507873535\n",
      "#Epoch 72 with total epochs 300 at step 19 loss: 5.795623779296875 running average of batch loss 6.147795486450195, time 0.9396677017211914\n",
      "#Epoch 72 with total epochs 300 at step 20 loss: 6.453544616699219 running average of batch loss 6.162354968843006, time 0.939666748046875\n",
      "#Epoch 73 with total epochs 300 at step 0 loss: 6.020862579345703 running average of batch loss 6.020862579345703, time 0.9356651306152344\n",
      "#Epoch 73 with total epochs 300 at step 1 loss: 6.228036403656006 running average of batch loss 6.1244494915008545, time 0.9446699619293213\n",
      "#Epoch 73 with total epochs 300 at step 2 loss: 5.834217071533203 running average of batch loss 6.027705351511638, time 0.935664176940918\n",
      "#Epoch 73 with total epochs 300 at step 3 loss: 6.261880874633789 running average of batch loss 6.086249232292175, time 0.9386661052703857\n",
      "#Epoch 73 with total epochs 300 at step 4 loss: 6.023221969604492 running average of batch loss 6.073643779754638, time 0.9346628189086914\n",
      "#Epoch 73 with total epochs 300 at step 5 loss: 5.95388650894165 running average of batch loss 6.053684234619141, time 0.9396681785583496\n",
      "#Epoch 73 with total epochs 300 at step 6 loss: 6.074662208557129 running average of batch loss 6.056681088038853, time 0.9396669864654541\n",
      "#Epoch 73 with total epochs 300 at step 7 loss: 6.0583343505859375 running average of batch loss 6.056887745857239, time 0.9386677742004395\n",
      "#Epoch 73 with total epochs 300 at step 8 loss: 6.425641059875488 running average of batch loss 6.097860336303711, time 0.9436695575714111\n",
      "#Epoch 73 with total epochs 300 at step 9 loss: 6.16731595993042 running average of batch loss 6.104805898666382, time 0.9596812725067139\n",
      "#Epoch 73 with total epochs 300 at step 10 loss: 5.722002983093262 running average of batch loss 6.07000563361428, time 0.9466714859008789\n",
      "#Epoch 73 with total epochs 300 at step 11 loss: 5.640829086303711 running average of batch loss 6.034240921338399, time 0.9576778411865234\n",
      "#Epoch 73 with total epochs 300 at step 12 loss: 6.19924259185791 running average of batch loss 6.0469333575322075, time 0.9396688938140869\n",
      "#Epoch 73 with total epochs 300 at step 13 loss: 5.831620693206787 running average of batch loss 6.031553881508963, time 0.9466714859008789\n",
      "#Epoch 73 with total epochs 300 at step 14 loss: 6.405064582824707 running average of batch loss 6.056454594930013, time 0.9536759853363037\n",
      "#Epoch 73 with total epochs 300 at step 15 loss: 5.762905120849609 running average of batch loss 6.038107752799988, time 0.9386656284332275\n",
      "#Epoch 73 with total epochs 300 at step 16 loss: 5.509937763214111 running average of batch loss 6.007038929883172, time 0.9266359806060791\n",
      "#Epoch 73 with total epochs 300 at step 17 loss: 6.3614935874938965 running average of batch loss 6.026730855305989, time 0.9346649646759033\n",
      "#Epoch 73 with total epochs 300 at step 18 loss: 6.099874973297119 running average of batch loss 6.0305805457265755, time 0.9446702003479004\n",
      "#Epoch 73 with total epochs 300 at step 19 loss: 5.760762691497803 running average of batch loss 6.0170896530151365, time 0.9356627464294434\n",
      "#Epoch 73 with total epochs 300 at step 20 loss: 7.141673564910889 running average of batch loss 6.070641267867315, time 0.939666748046875\n",
      "#Epoch 74 with total epochs 300 at step 0 loss: 6.3334126472473145 running average of batch loss 6.3334126472473145, time 0.9406673908233643\n",
      "#Epoch 74 with total epochs 300 at step 1 loss: 5.804588794708252 running average of batch loss 6.069000720977783, time 0.9366638660430908\n",
      "#Epoch 74 with total epochs 300 at step 2 loss: 6.032619953155518 running average of batch loss 6.056873798370361, time 0.9386436939239502\n",
      "#Epoch 74 with total epochs 300 at step 3 loss: 5.795449256896973 running average of batch loss 5.991517663002014, time 0.940669059753418\n",
      "#Epoch 74 with total epochs 300 at step 4 loss: 5.825429916381836 running average of batch loss 5.9583001136779785, time 0.935664176940918\n",
      "#Epoch 74 with total epochs 300 at step 5 loss: 5.8755669593811035 running average of batch loss 5.944511254628499, time 0.9346621036529541\n",
      "#Epoch 74 with total epochs 300 at step 6 loss: 5.881629943847656 running average of batch loss 5.935528210231236, time 0.9486737251281738\n",
      "#Epoch 74 with total epochs 300 at step 7 loss: 5.497879981994629 running average of batch loss 5.88082218170166, time 0.9396669864654541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 74 with total epochs 300 at step 8 loss: 6.073222637176514 running average of batch loss 5.902200010087755, time 0.9446699619293213\n",
      "#Epoch 74 with total epochs 300 at step 9 loss: 5.310548305511475 running average of batch loss 5.843034839630127, time 0.9416680335998535\n",
      "#Epoch 74 with total epochs 300 at step 10 loss: 5.614282131195068 running average of batch loss 5.822239138863304, time 0.9406671524047852\n",
      "#Epoch 74 with total epochs 300 at step 11 loss: 6.078526496887207 running average of batch loss 5.8435964186986284, time 0.937666654586792\n",
      "#Epoch 74 with total epochs 300 at step 12 loss: 5.955690383911133 running average of batch loss 5.852219031407283, time 0.9446704387664795\n",
      "#Epoch 74 with total epochs 300 at step 13 loss: 5.682103157043457 running average of batch loss 5.840067897524152, time 0.9396665096282959\n",
      "#Epoch 74 with total epochs 300 at step 14 loss: 6.001088619232178 running average of batch loss 5.850802612304688, time 0.9486720561981201\n",
      "#Epoch 74 with total epochs 300 at step 15 loss: 5.779929161071777 running average of batch loss 5.846373021602631, time 0.9556803703308105\n",
      "#Epoch 74 with total epochs 300 at step 16 loss: 5.9805707931518555 running average of batch loss 5.854267008164349, time 0.9506747722625732\n",
      "#Epoch 74 with total epochs 300 at step 17 loss: 5.841888904571533 running average of batch loss 5.853579335742527, time 0.9446702003479004\n",
      "#Epoch 74 with total epochs 300 at step 18 loss: 5.840301513671875 running average of batch loss 5.852880503001966, time 0.9386653900146484\n",
      "#Epoch 74 with total epochs 300 at step 19 loss: 5.972699165344238 running average of batch loss 5.858871436119079, time 0.9416460990905762\n",
      "#Epoch 74 with total epochs 300 at step 20 loss: 5.629275321960449 running average of batch loss 5.847938287825811, time 0.9296588897705078\n",
      "#Epoch 75 with total epochs 300 at step 0 loss: 6.3060808181762695 running average of batch loss 6.3060808181762695, time 0.9326629638671875\n",
      "#Epoch 75 with total epochs 300 at step 1 loss: 5.980722904205322 running average of batch loss 6.143401861190796, time 0.9396665096282959\n",
      "#Epoch 75 with total epochs 300 at step 2 loss: 6.136050224304199 running average of batch loss 6.140951315561931, time 0.9506525993347168\n",
      "#Epoch 75 with total epochs 300 at step 3 loss: 5.175490379333496 running average of batch loss 5.899586081504822, time 0.9326612949371338\n",
      "#Epoch 75 with total epochs 300 at step 4 loss: 5.768727779388428 running average of batch loss 5.873414421081543, time 0.9446702003479004\n",
      "#Epoch 75 with total epochs 300 at step 5 loss: 5.880971431732178 running average of batch loss 5.8746739228566485, time 0.9406683444976807\n",
      "#Epoch 75 with total epochs 300 at step 6 loss: 6.194182395935059 running average of batch loss 5.920317990439279, time 0.9416680335998535\n",
      "#Epoch 75 with total epochs 300 at step 7 loss: 6.035408973693848 running average of batch loss 5.9347043633461, time 0.9406664371490479\n",
      "#Epoch 75 with total epochs 300 at step 8 loss: 5.751650333404541 running average of batch loss 5.9143650266859265, time 0.9426710605621338\n",
      "#Epoch 75 with total epochs 300 at step 9 loss: 6.092609405517578 running average of batch loss 5.932189464569092, time 0.9336626529693604\n",
      "#Epoch 75 with total epochs 300 at step 10 loss: 5.4066009521484375 running average of batch loss 5.884408690712669, time 0.9386661052703857\n",
      "#Epoch 75 with total epochs 300 at step 11 loss: 6.348383903503418 running average of batch loss 5.9230732917785645, time 0.9316599369049072\n",
      "#Epoch 75 with total epochs 300 at step 12 loss: 5.743412971496582 running average of batch loss 5.909253267141489, time 0.9416708946228027\n",
      "#Epoch 75 with total epochs 300 at step 13 loss: 6.149008750915527 running average of batch loss 5.926378658839634, time 0.9396657943725586\n",
      "#Epoch 75 with total epochs 300 at step 14 loss: 6.450530052185059 running average of batch loss 5.961322085062663, time 0.9296600818634033\n",
      "#Epoch 75 with total epochs 300 at step 15 loss: 5.903118133544922 running average of batch loss 5.957684338092804, time 0.9406692981719971\n",
      "#Epoch 75 with total epochs 300 at step 16 loss: 5.614956378936768 running average of batch loss 5.937523869907155, time 0.9416682720184326\n",
      "#Epoch 75 with total epochs 300 at step 17 loss: 5.789247512817383 running average of batch loss 5.929286294513279, time 0.9446704387664795\n",
      "#Epoch 75 with total epochs 300 at step 18 loss: 5.560446739196777 running average of batch loss 5.909873686338726, time 0.9666857719421387\n",
      "#Epoch 75 with total epochs 300 at step 19 loss: 5.960003852844238 running average of batch loss 5.912380194664001, time 0.9516768455505371\n",
      "#Epoch 75 with total epochs 300 at step 20 loss: 4.976909637451172 running average of batch loss 5.867833977653866, time 0.932661771774292\n",
      "#Epoch 76 with total epochs 300 at step 0 loss: 5.551339149475098 running average of batch loss 5.551339149475098, time 0.9406678676605225\n",
      "#Epoch 76 with total epochs 300 at step 1 loss: 6.087471961975098 running average of batch loss 5.819405555725098, time 0.9406676292419434\n",
      "#Epoch 76 with total epochs 300 at step 2 loss: 5.866543769836426 running average of batch loss 5.835118293762207, time 0.940666913986206\n",
      "#Epoch 76 with total epochs 300 at step 3 loss: 6.158506870269775 running average of batch loss 5.915965437889099, time 0.940645694732666\n",
      "#Epoch 76 with total epochs 300 at step 4 loss: 5.95593786239624 running average of batch loss 5.9239599227905275, time 0.9456710815429688\n",
      "#Epoch 76 with total epochs 300 at step 5 loss: 6.294125556945801 running average of batch loss 5.985654195149739, time 0.9356627464294434\n",
      "#Epoch 76 with total epochs 300 at step 6 loss: 5.643685817718506 running average of batch loss 5.93680156980242, time 0.9356632232666016\n",
      "#Epoch 76 with total epochs 300 at step 7 loss: 6.035635948181152 running average of batch loss 5.949155867099762, time 0.9396660327911377\n",
      "#Epoch 76 with total epochs 300 at step 8 loss: 5.927393913269043 running average of batch loss 5.946737872229682, time 0.9296600818634033\n",
      "#Epoch 76 with total epochs 300 at step 9 loss: 5.590193748474121 running average of batch loss 5.911083459854126, time 0.9306619167327881\n",
      "#Epoch 76 with total epochs 300 at step 10 loss: 5.613953113555908 running average of batch loss 5.884071610190651, time 0.9356644153594971\n",
      "#Epoch 76 with total epochs 300 at step 11 loss: 6.47523307800293 running average of batch loss 5.933335065841675, time 0.9286575317382812\n",
      "#Epoch 76 with total epochs 300 at step 12 loss: 5.332359790802002 running average of batch loss 5.8871061985309305, time 0.9366679191589355\n",
      "#Epoch 76 with total epochs 300 at step 13 loss: 5.545765399932861 running average of batch loss 5.8627247129167825, time 0.9406673908233643\n",
      "#Epoch 76 with total epochs 300 at step 14 loss: 6.028133392333984 running average of batch loss 5.873751958211263, time 0.9376420974731445\n",
      "#Epoch 76 with total epochs 300 at step 15 loss: 5.738247871398926 running average of batch loss 5.865282952785492, time 0.9306600093841553\n",
      "#Epoch 76 with total epochs 300 at step 16 loss: 6.015102863311768 running average of batch loss 5.874095888698802, time 0.9456703662872314\n",
      "#Epoch 76 with total epochs 300 at step 17 loss: 5.549654006958008 running average of batch loss 5.8560713397132025, time 0.9406673908233643\n",
      "#Epoch 76 with total epochs 300 at step 18 loss: 6.087347030639648 running average of batch loss 5.868243744498805, time 0.9446687698364258\n",
      "#Epoch 76 with total epochs 300 at step 19 loss: 5.570865631103516 running average of batch loss 5.8533748388290405, time 0.9576807022094727\n",
      "#Epoch 76 with total epochs 300 at step 20 loss: 6.280569076538086 running average of batch loss 5.873717421577091, time 0.9436695575714111\n",
      "#Epoch 77 with total epochs 300 at step 0 loss: 6.0431694984436035 running average of batch loss 6.0431694984436035, time 0.9656877517700195\n",
      "#Epoch 77 with total epochs 300 at step 1 loss: 6.115361213684082 running average of batch loss 6.079265356063843, time 0.9346630573272705\n",
      "#Epoch 77 with total epochs 300 at step 2 loss: 6.189926624298096 running average of batch loss 6.116152445475261, time 0.9536771774291992\n",
      "#Epoch 77 with total epochs 300 at step 3 loss: 6.27405309677124 running average of batch loss 6.155627608299255, time 0.941666841506958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 77 with total epochs 300 at step 4 loss: 5.745545864105225 running average of batch loss 6.073611259460449, time 0.9456727504730225\n",
      "#Epoch 77 with total epochs 300 at step 5 loss: 5.513286590576172 running average of batch loss 5.980223814646403, time 0.937664270401001\n",
      "#Epoch 77 with total epochs 300 at step 6 loss: 5.823134422302246 running average of batch loss 5.957782472882952, time 0.9346623420715332\n",
      "#Epoch 77 with total epochs 300 at step 7 loss: 6.031569480895996 running average of batch loss 5.9670058488845825, time 0.9376683235168457\n",
      "#Epoch 77 with total epochs 300 at step 8 loss: 5.545513153076172 running average of batch loss 5.920173327128093, time 0.9336614608764648\n",
      "#Epoch 77 with total epochs 300 at step 9 loss: 5.663725852966309 running average of batch loss 5.894528579711914, time 0.9416677951812744\n",
      "#Epoch 77 with total epochs 300 at step 10 loss: 6.319507598876953 running average of batch loss 5.933163035999645, time 0.9266579151153564\n",
      "#Epoch 77 with total epochs 300 at step 11 loss: 5.829013347625732 running average of batch loss 5.924483895301819, time 0.9376645088195801\n",
      "#Epoch 77 with total epochs 300 at step 12 loss: 5.257814884185791 running average of batch loss 5.873201663677509, time 0.9296586513519287\n",
      "#Epoch 77 with total epochs 300 at step 13 loss: 5.586604118347168 running average of batch loss 5.852730410439627, time 0.939669132232666\n",
      "#Epoch 77 with total epochs 300 at step 14 loss: 5.910576343536377 running average of batch loss 5.85658680597941, time 0.9416670799255371\n",
      "#Epoch 77 with total epochs 300 at step 15 loss: 5.84335994720459 running average of batch loss 5.8557601273059845, time 0.9436700344085693\n",
      "#Epoch 77 with total epochs 300 at step 16 loss: 6.251535415649414 running average of batch loss 5.879041026620304, time 0.9356637001037598\n",
      "#Epoch 77 with total epochs 300 at step 17 loss: 5.522617340087891 running average of batch loss 5.859239710701837, time 0.9356632232666016\n",
      "#Epoch 77 with total epochs 300 at step 18 loss: 5.9495110511779785 running average of batch loss 5.863990833884792, time 0.9466719627380371\n",
      "#Epoch 77 with total epochs 300 at step 19 loss: 5.840347766876221 running average of batch loss 5.862808680534362, time 0.9336626529693604\n",
      "#Epoch 77 with total epochs 300 at step 20 loss: 6.090577602386475 running average of batch loss 5.873654819670177, time 0.9486746788024902\n",
      "#Epoch 78 with total epochs 300 at step 0 loss: 6.337832927703857 running average of batch loss 6.337832927703857, time 0.9446690082550049\n",
      "#Epoch 78 with total epochs 300 at step 1 loss: 5.888056755065918 running average of batch loss 6.112944841384888, time 0.9296605587005615\n",
      "#Epoch 78 with total epochs 300 at step 2 loss: 5.622006893157959 running average of batch loss 5.949298858642578, time 0.9546792507171631\n",
      "#Epoch 78 with total epochs 300 at step 3 loss: 5.897390842437744 running average of batch loss 5.93632185459137, time 0.957679033279419\n",
      "#Epoch 78 with total epochs 300 at step 4 loss: 5.301273345947266 running average of batch loss 5.809312152862549, time 0.952674388885498\n",
      "#Epoch 78 with total epochs 300 at step 5 loss: 5.321632385253906 running average of batch loss 5.728032191594441, time 0.9266607761383057\n",
      "#Epoch 78 with total epochs 300 at step 6 loss: 5.750061511993408 running average of batch loss 5.731179237365723, time 0.9376654624938965\n",
      "#Epoch 78 with total epochs 300 at step 7 loss: 5.64644718170166 running average of batch loss 5.720587730407715, time 0.9436686038970947\n",
      "#Epoch 78 with total epochs 300 at step 8 loss: 5.679959774017334 running average of batch loss 5.716073513031006, time 0.9376673698425293\n",
      "#Epoch 78 with total epochs 300 at step 9 loss: 6.015655040740967 running average of batch loss 5.746031665802002, time 0.9446702003479004\n",
      "#Epoch 78 with total epochs 300 at step 10 loss: 5.760368347167969 running average of batch loss 5.747335000471636, time 0.9396653175354004\n",
      "#Epoch 78 with total epochs 300 at step 11 loss: 5.925158977508545 running average of batch loss 5.762153665224711, time 0.9266583919525146\n",
      "#Epoch 78 with total epochs 300 at step 12 loss: 5.45654296875 running average of batch loss 5.738645150111272, time 0.943671703338623\n",
      "#Epoch 78 with total epochs 300 at step 13 loss: 5.636635780334473 running average of batch loss 5.731358766555786, time 0.9436695575714111\n",
      "#Epoch 78 with total epochs 300 at step 14 loss: 5.718018531799316 running average of batch loss 5.730469417572022, time 0.9366648197174072\n",
      "#Epoch 78 with total epochs 300 at step 15 loss: 5.644968509674072 running average of batch loss 5.7251256108284, time 0.9286587238311768\n",
      "#Epoch 78 with total epochs 300 at step 16 loss: 6.213741302490234 running average of batch loss 5.75386771033792, time 0.9406661987304688\n",
      "#Epoch 78 with total epochs 300 at step 17 loss: 5.781853675842285 running average of batch loss 5.755422486199273, time 0.9406692981719971\n",
      "#Epoch 78 with total epochs 300 at step 18 loss: 5.728684902191162 running average of batch loss 5.7540152449356885, time 0.940666913986206\n",
      "#Epoch 78 with total epochs 300 at step 19 loss: 6.47856330871582 running average of batch loss 5.7902426481246945, time 0.9346632957458496\n",
      "#Epoch 78 with total epochs 300 at step 20 loss: 6.388330459594727 running average of batch loss 5.818723020099458, time 0.9416682720184326\n",
      "#Epoch 79 with total epochs 300 at step 0 loss: 5.396442413330078 running average of batch loss 5.396442413330078, time 0.9396660327911377\n",
      "#Epoch 79 with total epochs 300 at step 1 loss: 5.687654972076416 running average of batch loss 5.542048692703247, time 0.9316613674163818\n",
      "#Epoch 79 with total epochs 300 at step 2 loss: 6.120337963104248 running average of batch loss 5.734811782836914, time 0.9286575317382812\n",
      "#Epoch 79 with total epochs 300 at step 3 loss: 5.782558917999268 running average of batch loss 5.746748566627502, time 0.9416687488555908\n",
      "#Epoch 79 with total epochs 300 at step 4 loss: 5.740354537963867 running average of batch loss 5.745469760894776, time 0.9306612014770508\n",
      "#Epoch 79 with total epochs 300 at step 5 loss: 5.483994483947754 running average of batch loss 5.7018905480702715, time 0.9416680335998535\n",
      "#Epoch 79 with total epochs 300 at step 6 loss: 6.3100199699401855 running average of batch loss 5.7887661797659735, time 0.9456729888916016\n",
      "#Epoch 79 with total epochs 300 at step 7 loss: 5.716383457183838 running average of batch loss 5.779718339443207, time 0.9466719627380371\n",
      "#Epoch 79 with total epochs 300 at step 8 loss: 5.347870826721191 running average of batch loss 5.731735282474094, time 0.9366648197174072\n",
      "#Epoch 79 with total epochs 300 at step 9 loss: 5.519359588623047 running average of batch loss 5.710497713088989, time 0.9376649856567383\n",
      "#Epoch 79 with total epochs 300 at step 10 loss: 5.955469131469727 running average of batch loss 5.732767842032692, time 0.9316599369049072\n",
      "#Epoch 79 with total epochs 300 at step 11 loss: 5.363559722900391 running average of batch loss 5.7020004987716675, time 0.9426703453063965\n",
      "#Epoch 79 with total epochs 300 at step 12 loss: 6.080249309539795 running average of batch loss 5.731096561138447, time 0.4893453121185303\n",
      "#Epoch 79 with total epochs 300 at step 13 loss: 5.976138114929199 running average of batch loss 5.748599529266357, time 0.5303781032562256\n",
      "#Epoch 79 with total epochs 300 at step 14 loss: 5.148008346557617 running average of batch loss 5.708560117085775, time 0.6094326972961426\n",
      "#Epoch 79 with total epochs 300 at step 15 loss: 6.056679725646973 running average of batch loss 5.73031759262085, time 0.49735236167907715\n",
      "#Epoch 79 with total epochs 300 at step 16 loss: 5.706011772155762 running average of batch loss 5.728887838475845, time 0.5874161720275879\n",
      "#Epoch 79 with total epochs 300 at step 17 loss: 6.288842678070068 running average of batch loss 5.759996440675524, time 0.6064300537109375\n",
      "#Epoch 79 with total epochs 300 at step 18 loss: 5.738735198974609 running average of batch loss 5.758877427954423, time 0.48834681510925293\n",
      "#Epoch 79 with total epochs 300 at step 19 loss: 6.122447967529297 running average of batch loss 5.777055954933166, time 0.5693783760070801\n",
      "#Epoch 79 with total epochs 300 at step 20 loss: 5.730173110961914 running average of batch loss 5.774823438553583, time 0.5053579807281494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 80 with total epochs 300 at step 0 loss: 5.206101417541504 running average of batch loss 5.206101417541504, time 0.4913492202758789\n",
      "#Epoch 80 with total epochs 300 at step 1 loss: 5.89707088470459 running average of batch loss 5.551586151123047, time 0.4983539581298828\n",
      "#Epoch 80 with total epochs 300 at step 2 loss: 6.814828395843506 running average of batch loss 5.9726668993632, time 0.508333683013916\n",
      "#Epoch 80 with total epochs 300 at step 3 loss: 5.516459941864014 running average of batch loss 5.858615159988403, time 0.49632906913757324\n",
      "#Epoch 80 with total epochs 300 at step 4 loss: 5.744456768035889 running average of batch loss 5.8357834815979, time 0.4983253479003906\n",
      "#Epoch 80 with total epochs 300 at step 5 loss: 5.587434768676758 running average of batch loss 5.794392029444377, time 0.5273799896240234\n",
      "#Epoch 80 with total epochs 300 at step 6 loss: 5.634274482727051 running average of batch loss 5.7715180941990445, time 0.5043318271636963\n",
      "#Epoch 80 with total epochs 300 at step 7 loss: 5.64576530456543 running average of batch loss 5.7557989954948425, time 0.5033295154571533\n",
      "#Epoch 80 with total epochs 300 at step 8 loss: 6.253576278686523 running average of batch loss 5.81110758251614, time 0.5033581256866455\n",
      "#Epoch 80 with total epochs 300 at step 9 loss: 5.802652835845947 running average of batch loss 5.8102621078491214, time 0.48934507369995117\n",
      "#Epoch 80 with total epochs 300 at step 10 loss: 6.1610517501831055 running average of batch loss 5.842152075334028, time 0.523374080657959\n",
      "#Epoch 80 with total epochs 300 at step 11 loss: 5.452775955200195 running average of batch loss 5.809704065322876, time 0.503354549407959\n",
      "#Epoch 80 with total epochs 300 at step 12 loss: 5.718305587768555 running average of batch loss 5.802673413203313, time 0.4963245391845703\n",
      "#Epoch 80 with total epochs 300 at step 13 loss: 6.220038890838623 running average of batch loss 5.832485233034406, time 0.4903256893157959\n",
      "#Epoch 80 with total epochs 300 at step 14 loss: 6.134583473205566 running average of batch loss 5.852625115712484, time 0.5163671970367432\n",
      "#Epoch 80 with total epochs 300 at step 15 loss: 6.545567035675049 running average of batch loss 5.895933985710144, time 0.4893500804901123\n",
      "#Epoch 80 with total epochs 300 at step 16 loss: 5.523582935333252 running average of batch loss 5.874030982746797, time 0.5403516292572021\n",
      "#Epoch 80 with total epochs 300 at step 17 loss: 5.932082653045654 running average of batch loss 5.877256075541179, time 0.5023360252380371\n",
      "#Epoch 80 with total epochs 300 at step 18 loss: 5.942078113555908 running average of batch loss 5.88066776175248, time 0.49532580375671387\n",
      "#Epoch 80 with total epochs 300 at step 19 loss: 5.921776294708252 running average of batch loss 5.882723188400268, time 0.5043561458587646\n",
      "#Epoch 80 with total epochs 300 at step 20 loss: 5.547035217285156 running average of batch loss 5.866738046918597, time 0.5003492832183838\n",
      "avg difference between predicted and ground truth batch wise 7.0922641521521985\n",
      "#Epoch 81 with total epochs 300 at step 0 loss: 5.428727149963379 running average of batch loss 5.428727149963379, time 0.4803478717803955\n",
      "#Epoch 81 with total epochs 300 at step 1 loss: 5.692136764526367 running average of batch loss 5.560431957244873, time 0.500328540802002\n",
      "#Epoch 81 with total epochs 300 at step 2 loss: 5.486450672149658 running average of batch loss 5.535771528879802, time 0.5003292560577393\n",
      "#Epoch 81 with total epochs 300 at step 3 loss: 5.942015171051025 running average of batch loss 5.637332439422607, time 0.507338285446167\n",
      "#Epoch 81 with total epochs 300 at step 4 loss: 6.090848922729492 running average of batch loss 5.728035736083984, time 0.49332427978515625\n",
      "#Epoch 81 with total epochs 300 at step 5 loss: 5.6608123779296875 running average of batch loss 5.7168318430582685, time 0.5013289451599121\n",
      "#Epoch 81 with total epochs 300 at step 6 loss: 5.525018692016602 running average of batch loss 5.68942996433803, time 0.4993295669555664\n",
      "#Epoch 81 with total epochs 300 at step 7 loss: 5.565149307250977 running average of batch loss 5.673894882202148, time 0.4963233470916748\n",
      "#Epoch 81 with total epochs 300 at step 8 loss: 6.003872871398926 running average of batch loss 5.710559103224012, time 0.4973268508911133\n",
      "#Epoch 81 with total epochs 300 at step 9 loss: 5.509855270385742 running average of batch loss 5.690488719940186, time 0.5013270378112793\n",
      "#Epoch 81 with total epochs 300 at step 10 loss: 5.452396392822266 running average of batch loss 5.668843962929466, time 0.5043327808380127\n",
      "#Epoch 81 with total epochs 300 at step 11 loss: 6.021066665649414 running average of batch loss 5.698195854822795, time 0.5023307800292969\n",
      "#Epoch 81 with total epochs 300 at step 12 loss: 5.8166303634643555 running average of batch loss 5.7073062016413765, time 0.5043280124664307\n",
      "#Epoch 81 with total epochs 300 at step 13 loss: 5.627274513244629 running average of batch loss 5.70158965247018, time 0.5033557415008545\n",
      "#Epoch 81 with total epochs 300 at step 14 loss: 5.9995880126953125 running average of batch loss 5.721456209818522, time 0.5123646259307861\n",
      "#Epoch 81 with total epochs 300 at step 15 loss: 5.876737117767334 running average of batch loss 5.731161266565323, time 0.49735283851623535\n",
      "#Epoch 81 with total epochs 300 at step 16 loss: 5.669477462768555 running average of batch loss 5.727532807518454, time 0.515366792678833\n",
      "#Epoch 81 with total epochs 300 at step 17 loss: 5.896047592163086 running average of batch loss 5.736894739998712, time 0.4970393180847168\n",
      "#Epoch 81 with total epochs 300 at step 18 loss: 5.725481033325195 running average of batch loss 5.736294018594842, time 0.5018322467803955\n",
      "#Epoch 81 with total epochs 300 at step 19 loss: 5.825808525085449 running average of batch loss 5.740769743919373, time 0.504331111907959\n",
      "#Epoch 81 with total epochs 300 at step 20 loss: 5.145793437957764 running average of batch loss 5.712437538873582, time 0.5188393592834473\n",
      "#Epoch 82 with total epochs 300 at step 0 loss: 5.6004958152771 running average of batch loss 5.6004958152771, time 0.5055990219116211\n",
      "#Epoch 82 with total epochs 300 at step 1 loss: 5.164000988006592 running average of batch loss 5.382248401641846, time 0.5144057273864746\n",
      "#Epoch 82 with total epochs 300 at step 2 loss: 5.878034591674805 running average of batch loss 5.547510464986165, time 0.5324456691741943\n",
      "#Epoch 82 with total epochs 300 at step 3 loss: 5.878391742706299 running average of batch loss 5.630230784416199, time 0.5108652114868164\n",
      "#Epoch 82 with total epochs 300 at step 4 loss: 5.949337959289551 running average of batch loss 5.694052219390869, time 2.9598824977874756\n",
      "#Epoch 82 with total epochs 300 at step 5 loss: 5.545439720153809 running average of batch loss 5.669283469518025, time 0.5603692531585693\n",
      "#Epoch 82 with total epochs 300 at step 6 loss: 5.493138790130615 running average of batch loss 5.644119943891253, time 0.5233771800994873\n",
      "#Epoch 82 with total epochs 300 at step 7 loss: 5.903331756591797 running average of batch loss 5.676521420478821, time 0.4993271827697754\n",
      "#Epoch 82 with total epochs 300 at step 8 loss: 5.900790691375732 running average of batch loss 5.7014402283562555, time 0.5033576488494873\n",
      "#Epoch 82 with total epochs 300 at step 9 loss: 5.691404342651367 running average of batch loss 5.700436639785766, time 0.5023553371429443\n",
      "#Epoch 82 with total epochs 300 at step 10 loss: 5.727841854095459 running average of batch loss 5.702928022904829, time 0.49935412406921387\n",
      "#Epoch 82 with total epochs 300 at step 11 loss: 5.479858875274658 running average of batch loss 5.684338927268982, time 0.48734593391418457\n",
      "#Epoch 82 with total epochs 300 at step 12 loss: 5.124919891357422 running average of batch loss 5.641306693737324, time 0.5003323554992676\n",
      "#Epoch 82 with total epochs 300 at step 13 loss: 5.732609272003174 running average of batch loss 5.647828306470599, time 0.49035000801086426\n",
      "#Epoch 82 with total epochs 300 at step 14 loss: 5.7300214767456055 running average of batch loss 5.653307851155599, time 0.5403554439544678\n",
      "#Epoch 82 with total epochs 300 at step 15 loss: 6.398143291473389 running average of batch loss 5.699860066175461, time 0.49732518196105957\n",
      "#Epoch 82 with total epochs 300 at step 16 loss: 5.662998199462891 running average of batch loss 5.6976917210747215, time 0.557373046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 82 with total epochs 300 at step 17 loss: 6.0553998947143555 running average of batch loss 5.717564397388035, time 0.5033271312713623\n",
      "#Epoch 82 with total epochs 300 at step 18 loss: 6.004741668701172 running average of batch loss 5.7326789906150415, time 0.48932838439941406\n",
      "#Epoch 82 with total epochs 300 at step 19 loss: 5.543382167816162 running average of batch loss 5.723214149475098, time 0.509331464767456\n",
      "#Epoch 82 with total epochs 300 at step 20 loss: 5.438188076019287 running average of batch loss 5.709641479310536, time 0.5233736038208008\n",
      "#Epoch 83 with total epochs 300 at step 0 loss: 6.18391752243042 running average of batch loss 6.18391752243042, time 0.49332714080810547\n",
      "#Epoch 83 with total epochs 300 at step 1 loss: 5.375522613525391 running average of batch loss 5.779720067977905, time 0.5003247261047363\n",
      "#Epoch 83 with total epochs 300 at step 2 loss: 5.401249885559082 running average of batch loss 5.653563340504964, time 0.5223739147186279\n",
      "#Epoch 83 with total epochs 300 at step 3 loss: 5.558837413787842 running average of batch loss 5.629881858825684, time 0.5674052238464355\n",
      "#Epoch 83 with total epochs 300 at step 4 loss: 5.3118109703063965 running average of batch loss 5.566267681121826, time 0.49735164642333984\n",
      "#Epoch 83 with total epochs 300 at step 5 loss: 5.721686363220215 running average of batch loss 5.592170794804891, time 0.539386510848999\n",
      "#Epoch 83 with total epochs 300 at step 6 loss: 5.677443981170654 running average of batch loss 5.604352678571429, time 0.4933199882507324\n",
      "#Epoch 83 with total epochs 300 at step 7 loss: 5.0578508377075195 running average of batch loss 5.53603994846344, time 0.5033605098724365\n",
      "#Epoch 83 with total epochs 300 at step 8 loss: 5.554001808166504 running average of batch loss 5.538035710652669, time 0.49532389640808105\n",
      "#Epoch 83 with total epochs 300 at step 9 loss: 5.549381256103516 running average of batch loss 5.539170265197754, time 0.5023283958435059\n",
      "#Epoch 83 with total epochs 300 at step 10 loss: 5.530177116394043 running average of batch loss 5.538352706215599, time 0.4963233470916748\n",
      "#Epoch 83 with total epochs 300 at step 11 loss: 5.726844310760498 running average of batch loss 5.554060339927673, time 0.5273752212524414\n",
      "#Epoch 83 with total epochs 300 at step 12 loss: 5.561092376708984 running average of batch loss 5.554601265833928, time 0.5153343677520752\n",
      "#Epoch 83 with total epochs 300 at step 13 loss: 5.62025260925293 running average of batch loss 5.559290647506714, time 2.7209322452545166\n",
      "#Epoch 83 with total epochs 300 at step 14 loss: 5.29163932800293 running average of batch loss 5.541447226206461, time 0.5073604583740234\n",
      "#Epoch 83 with total epochs 300 at step 15 loss: 5.348902702331543 running average of batch loss 5.529413193464279, time 0.515338659286499\n",
      "#Epoch 83 with total epochs 300 at step 16 loss: 5.6843109130859375 running average of batch loss 5.538524824030259, time 0.489346981048584\n",
      "#Epoch 83 with total epochs 300 at step 17 loss: 5.715562343597412 running average of batch loss 5.54836024178399, time 0.4873237609863281\n",
      "#Epoch 83 with total epochs 300 at step 18 loss: 5.800577163696289 running average of batch loss 5.5616348166214795, time 0.48734521865844727\n",
      "#Epoch 83 with total epochs 300 at step 19 loss: 5.74006986618042 running average of batch loss 5.570556569099426, time 0.4883456230163574\n",
      "#Epoch 83 with total epochs 300 at step 20 loss: 5.220409870147705 running average of batch loss 5.553882916768392, time 0.48832249641418457\n",
      "#Epoch 84 with total epochs 300 at step 0 loss: 5.474834442138672 running average of batch loss 5.474834442138672, time 0.49034762382507324\n",
      "#Epoch 84 with total epochs 300 at step 1 loss: 5.327695369720459 running average of batch loss 5.401264905929565, time 0.48834753036499023\n",
      "#Epoch 84 with total epochs 300 at step 2 loss: 5.0823073387146 running average of batch loss 5.29494571685791, time 0.4983530044555664\n",
      "#Epoch 84 with total epochs 300 at step 3 loss: 6.190391540527344 running average of batch loss 5.5188071727752686, time 0.48834681510925293\n",
      "#Epoch 84 with total epochs 300 at step 4 loss: 5.356733322143555 running average of batch loss 5.486392402648926, time 0.4893476963043213\n",
      "#Epoch 84 with total epochs 300 at step 5 loss: 5.386568069458008 running average of batch loss 5.4697550137837725, time 0.48834729194641113\n",
      "#Epoch 84 with total epochs 300 at step 6 loss: 5.114801406860352 running average of batch loss 5.4190473556518555, time 0.48534488677978516\n",
      "#Epoch 84 with total epochs 300 at step 7 loss: 5.619546413421631 running average of batch loss 5.444109737873077, time 0.4883458614349365\n",
      "#Epoch 84 with total epochs 300 at step 8 loss: 5.784299850463867 running average of batch loss 5.481908639272054, time 0.4883460998535156\n",
      "#Epoch 84 with total epochs 300 at step 9 loss: 5.4277777671813965 running average of batch loss 5.476495552062988, time 0.48834681510925293\n",
      "#Epoch 84 with total epochs 300 at step 10 loss: 5.685245990753174 running average of batch loss 5.495472864671187, time 0.4873223304748535\n",
      "#Epoch 84 with total epochs 300 at step 11 loss: 5.614287853240967 running average of batch loss 5.505374113718669, time 0.48932552337646484\n",
      "#Epoch 84 with total epochs 300 at step 12 loss: 5.898508548736572 running average of batch loss 5.535615224104661, time 0.4883239269256592\n",
      "#Epoch 84 with total epochs 300 at step 13 loss: 5.492076396942139 running average of batch loss 5.5325053078787665, time 0.4913513660430908\n",
      "#Epoch 84 with total epochs 300 at step 14 loss: 6.383322238922119 running average of batch loss 5.58922643661499, time 0.5023322105407715\n",
      "#Epoch 84 with total epochs 300 at step 15 loss: 5.272333145141602 running average of batch loss 5.569420605897903, time 0.5013563632965088\n",
      "#Epoch 84 with total epochs 300 at step 16 loss: 6.073572635650635 running average of batch loss 5.5990766076480645, time 0.49535107612609863\n",
      "#Epoch 84 with total epochs 300 at step 17 loss: 5.502861022949219 running average of batch loss 5.593731297387017, time 0.5043590068817139\n",
      "#Epoch 84 with total epochs 300 at step 18 loss: 5.7048492431640625 running average of batch loss 5.599579610322651, time 0.5763823986053467\n",
      "#Epoch 84 with total epochs 300 at step 19 loss: 5.516446113586426 running average of batch loss 5.59542293548584, time 0.5744080543518066\n",
      "#Epoch 84 with total epochs 300 at step 20 loss: 5.628124713897705 running average of batch loss 5.596980163029262, time 0.49132466316223145\n",
      "#Epoch 85 with total epochs 300 at step 0 loss: 5.790425777435303 running average of batch loss 5.790425777435303, time 0.560399055480957\n",
      "#Epoch 85 with total epochs 300 at step 1 loss: 5.50939416885376 running average of batch loss 5.649909973144531, time 0.559396505355835\n",
      "#Epoch 85 with total epochs 300 at step 2 loss: 5.608889579772949 running average of batch loss 5.636236508687337, time 0.550391435623169\n",
      "#Epoch 85 with total epochs 300 at step 3 loss: 5.194691181182861 running average of batch loss 5.525850176811218, time 0.5643761157989502\n",
      "#Epoch 85 with total epochs 300 at step 4 loss: 5.33095645904541 running average of batch loss 5.486871433258057, time 0.562394380569458\n",
      "#Epoch 85 with total epochs 300 at step 5 loss: 5.893356800079346 running average of batch loss 5.5546189943949384, time 0.49233031272888184\n",
      "#Epoch 85 with total epochs 300 at step 6 loss: 5.193896293640137 running average of batch loss 5.503087180001395, time 0.558396577835083\n",
      "#Epoch 85 with total epochs 300 at step 7 loss: 5.5093278884887695 running average of batch loss 5.503867268562317, time 0.576409101486206\n",
      "#Epoch 85 with total epochs 300 at step 8 loss: 5.322534561157227 running average of batch loss 5.483719189961751, time 0.5754094123840332\n",
      "#Epoch 85 with total epochs 300 at step 9 loss: 5.851066589355469 running average of batch loss 5.520453929901123, time 0.4883453845977783\n",
      "#Epoch 85 with total epochs 300 at step 10 loss: 6.301114559173584 running average of batch loss 5.591423078016802, time 0.5493903160095215\n",
      "#Epoch 85 with total epochs 300 at step 11 loss: 5.188352584838867 running average of batch loss 5.557833870251973, time 0.5543885231018066\n",
      "#Epoch 85 with total epochs 300 at step 12 loss: 5.784472942352295 running average of batch loss 5.575267645028921, time 0.5563962459564209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 85 with total epochs 300 at step 13 loss: 5.967859745025635 running average of batch loss 5.60330993788583, time 0.48932337760925293\n",
      "#Epoch 85 with total epochs 300 at step 14 loss: 5.4473724365234375 running average of batch loss 5.59291410446167, time 0.5503907203674316\n",
      "#Epoch 85 with total epochs 300 at step 15 loss: 5.187093257904053 running average of batch loss 5.567550301551819, time 0.5383815765380859\n",
      "#Epoch 85 with total epochs 300 at step 16 loss: 5.340569972991943 running average of batch loss 5.554198517518885, time 0.4933507442474365\n",
      "#Epoch 85 with total epochs 300 at step 17 loss: 5.18704891204834 running average of batch loss 5.533801317214966, time 0.538384199142456\n",
      "#Epoch 85 with total epochs 300 at step 18 loss: 6.2936177253723145 running average of batch loss 5.5737916544864055, time 0.507331132888794\n",
      "#Epoch 85 with total epochs 300 at step 19 loss: 5.553254127502441 running average of batch loss 5.572764778137207, time 0.5453870296478271\n",
      "#Epoch 85 with total epochs 300 at step 20 loss: 5.673473358154297 running average of batch loss 5.5775604248046875, time 0.5403823852539062\n",
      "#Epoch 86 with total epochs 300 at step 0 loss: 5.57718563079834 running average of batch loss 5.57718563079834, time 0.500354528427124\n",
      "#Epoch 86 with total epochs 300 at step 1 loss: 5.30638313293457 running average of batch loss 5.441784381866455, time 0.5473887920379639\n",
      "#Epoch 86 with total epochs 300 at step 2 loss: 6.4394636154174805 running average of batch loss 5.774344126383464, time 0.5413839817047119\n",
      "#Epoch 86 with total epochs 300 at step 3 loss: 5.796809196472168 running average of batch loss 5.77996039390564, time 0.48932600021362305\n",
      "#Epoch 86 with total epochs 300 at step 4 loss: 5.504218578338623 running average of batch loss 5.724812030792236, time 0.5393834114074707\n",
      "#Epoch 86 with total epochs 300 at step 5 loss: 5.559222221374512 running average of batch loss 5.697213729222615, time 0.4893229007720947\n",
      "#Epoch 86 with total epochs 300 at step 6 loss: 5.858908176422119 running average of batch loss 5.720312935965402, time 0.5564193725585938\n",
      "#Epoch 86 with total epochs 300 at step 7 loss: 5.586808681488037 running average of batch loss 5.703624904155731, time 0.5433862209320068\n",
      "#Epoch 86 with total epochs 300 at step 8 loss: 5.616241455078125 running average of batch loss 5.693915632035997, time 0.48632168769836426\n",
      "#Epoch 86 with total epochs 300 at step 9 loss: 6.0023603439331055 running average of batch loss 5.724760103225708, time 0.4933505058288574\n",
      "#Epoch 86 with total epochs 300 at step 10 loss: 6.2065324783325195 running average of batch loss 5.768557591871782, time 0.5443906784057617\n",
      "#Epoch 86 with total epochs 300 at step 11 loss: 5.340475559234619 running average of batch loss 5.7328840891520185, time 0.5203659534454346\n",
      "#Epoch 86 with total epochs 300 at step 12 loss: 5.368757724761963 running average of batch loss 5.7048743688143215, time 0.5213706493377686\n",
      "#Epoch 86 with total epochs 300 at step 13 loss: 6.04595422744751 running average of batch loss 5.729237215859549, time 0.5403835773468018\n",
      "#Epoch 86 with total epochs 300 at step 14 loss: 5.973676681518555 running average of batch loss 5.745533180236817, time 0.5403842926025391\n",
      "#Epoch 86 with total epochs 300 at step 15 loss: 6.082241535186768 running average of batch loss 5.766577452421188, time 0.5403809547424316\n",
      "#Epoch 86 with total epochs 300 at step 16 loss: 5.966660022735596 running average of batch loss 5.778347015380859, time 0.49735379219055176\n",
      "#Epoch 86 with total epochs 300 at step 17 loss: 5.619510173797607 running average of batch loss 5.769522746404012, time 0.5233719348907471\n",
      "#Epoch 86 with total epochs 300 at step 18 loss: 5.106661796569824 running average of batch loss 5.734635327991686, time 0.5403609275817871\n",
      "#Epoch 86 with total epochs 300 at step 19 loss: 5.208073616027832 running average of batch loss 5.708307242393493, time 0.5383858680725098\n",
      "#Epoch 86 with total epochs 300 at step 20 loss: 6.044032573699951 running average of batch loss 5.724294162931896, time 0.5563955307006836\n",
      "#Epoch 87 with total epochs 300 at step 0 loss: 5.075254440307617 running average of batch loss 5.075254440307617, time 0.5383601188659668\n",
      "#Epoch 87 with total epochs 300 at step 1 loss: 5.5612030029296875 running average of batch loss 5.318228721618652, time 0.543365478515625\n",
      "#Epoch 87 with total epochs 300 at step 2 loss: 5.115316390991211 running average of batch loss 5.250591278076172, time 0.5303523540496826\n",
      "#Epoch 87 with total epochs 300 at step 3 loss: 5.924111843109131 running average of batch loss 5.418971419334412, time 0.5383830070495605\n",
      "#Epoch 87 with total epochs 300 at step 4 loss: 5.769017219543457 running average of batch loss 5.4889805793762205, time 0.5403838157653809\n",
      "#Epoch 87 with total epochs 300 at step 5 loss: 5.797812461853027 running average of batch loss 5.5404525597890215, time 0.5473887920379639\n",
      "#Epoch 87 with total epochs 300 at step 6 loss: 5.634611129760742 running average of batch loss 5.553903784070696, time 0.5233707427978516\n",
      "#Epoch 87 with total epochs 300 at step 7 loss: 5.882053375244141 running average of batch loss 5.594922482967377, time 0.5323803424835205\n",
      "#Epoch 87 with total epochs 300 at step 8 loss: 5.661095142364502 running average of batch loss 5.602275000678168, time 0.5373818874359131\n",
      "#Epoch 87 with total epochs 300 at step 9 loss: 5.152937412261963 running average of batch loss 5.557341241836548, time 0.5373804569244385\n",
      "#Epoch 87 with total epochs 300 at step 10 loss: 5.741810321807861 running average of batch loss 5.574111158197576, time 0.5363798141479492\n",
      "#Epoch 87 with total epochs 300 at step 11 loss: 5.363029479980469 running average of batch loss 5.55652101834615, time 0.5383820533752441\n",
      "#Epoch 87 with total epochs 300 at step 12 loss: 5.532470703125 running average of batch loss 5.55467099409837, time 0.5293760299682617\n",
      "#Epoch 87 with total epochs 300 at step 13 loss: 5.633036136627197 running average of batch loss 5.5602685042790005, time 0.5173430442810059\n",
      "#Epoch 87 with total epochs 300 at step 14 loss: 5.903255462646484 running average of batch loss 5.5831343015035, time 0.530379056930542\n",
      "#Epoch 87 with total epochs 300 at step 15 loss: 5.310022830963135 running average of batch loss 5.566064834594727, time 0.487321138381958\n",
      "#Epoch 87 with total epochs 300 at step 16 loss: 5.867334365844727 running average of batch loss 5.58378657172708, time 0.48734617233276367\n",
      "#Epoch 87 with total epochs 300 at step 17 loss: 5.318948745727539 running average of batch loss 5.56907335917155, time 0.5303795337677002\n",
      "#Epoch 87 with total epochs 300 at step 18 loss: 5.302078723907471 running average of batch loss 5.555021009947124, time 0.4923272132873535\n",
      "#Epoch 87 with total epochs 300 at step 19 loss: 4.994772911071777 running average of batch loss 5.527008605003357, time 0.5433871746063232\n",
      "#Epoch 87 with total epochs 300 at step 20 loss: 5.164132118225098 running average of batch loss 5.50972877229963, time 0.5243732929229736\n",
      "#Epoch 88 with total epochs 300 at step 0 loss: 5.2524590492248535 running average of batch loss 5.2524590492248535, time 0.528374195098877\n",
      "#Epoch 88 with total epochs 300 at step 1 loss: 5.1325154304504395 running average of batch loss 5.1924872398376465, time 0.5303750038146973\n",
      "#Epoch 88 with total epochs 300 at step 2 loss: 5.9997663497924805 running average of batch loss 5.461580276489258, time 0.5263504981994629\n",
      "#Epoch 88 with total epochs 300 at step 3 loss: 5.349593162536621 running average of batch loss 5.433583498001099, time 0.5263726711273193\n",
      "#Epoch 88 with total epochs 300 at step 4 loss: 5.712507724761963 running average of batch loss 5.489368343353272, time 0.49434852600097656\n",
      "#Epoch 88 with total epochs 300 at step 5 loss: 5.700563430786133 running average of batch loss 5.524567524592082, time 0.537381649017334\n",
      "#Epoch 88 with total epochs 300 at step 6 loss: 5.099246978759766 running average of batch loss 5.463807446616037, time 0.527374267578125\n",
      "#Epoch 88 with total epochs 300 at step 7 loss: 5.345773696899414 running average of batch loss 5.449053227901459, time 0.4913501739501953\n",
      "#Epoch 88 with total epochs 300 at step 8 loss: 5.045754432678223 running average of batch loss 5.404242250654432, time 0.5253727436065674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 88 with total epochs 300 at step 9 loss: 5.747518062591553 running average of batch loss 5.438569831848144, time 0.5203697681427002\n",
      "#Epoch 88 with total epochs 300 at step 10 loss: 5.111649513244629 running average of batch loss 5.4088498028841885, time 0.5073599815368652\n",
      "#Epoch 88 with total epochs 300 at step 11 loss: 5.512526512145996 running average of batch loss 5.417489528656006, time 0.5393829345703125\n",
      "#Epoch 88 with total epochs 300 at step 12 loss: 5.536413192749023 running average of batch loss 5.426637502817007, time 0.5263736248016357\n",
      "#Epoch 88 with total epochs 300 at step 13 loss: 5.6869378089904785 running average of batch loss 5.445230381829398, time 0.5403838157653809\n",
      "#Epoch 88 with total epochs 300 at step 14 loss: 5.299339294433594 running average of batch loss 5.435504309336344, time 0.5253729820251465\n",
      "#Epoch 88 with total epochs 300 at step 15 loss: 5.451180458068848 running average of batch loss 5.436484068632126, time 0.4873473644256592\n",
      "#Epoch 88 with total epochs 300 at step 16 loss: 5.295949935913086 running average of batch loss 5.42821735494277, time 0.4873344898223877\n",
      "#Epoch 88 with total epochs 300 at step 17 loss: 5.310135841369629 running average of batch loss 5.421657270855373, time 0.533379077911377\n",
      "#Epoch 88 with total epochs 300 at step 18 loss: 5.55356502532959 running average of batch loss 5.428599784248753, time 0.5263745784759521\n",
      "#Epoch 88 with total epochs 300 at step 19 loss: 5.108796119689941 running average of batch loss 5.412609601020813, time 0.49432897567749023\n",
      "#Epoch 88 with total epochs 300 at step 20 loss: 6.038393497467041 running average of batch loss 5.442408834184919, time 0.5233445167541504\n",
      "#Epoch 89 with total epochs 300 at step 0 loss: 5.070021152496338 running average of batch loss 5.070021152496338, time 0.541386604309082\n",
      "#Epoch 89 with total epochs 300 at step 1 loss: 5.480603218078613 running average of batch loss 5.275312185287476, time 0.5313763618469238\n",
      "#Epoch 89 with total epochs 300 at step 2 loss: 5.3365278244018555 running average of batch loss 5.2957173983256025, time 0.5253720283508301\n",
      "#Epoch 89 with total epochs 300 at step 3 loss: 5.428089141845703 running average of batch loss 5.328810334205627, time 0.4893472194671631\n",
      "#Epoch 89 with total epochs 300 at step 4 loss: 5.6263108253479 running average of batch loss 5.388310432434082, time 0.5283770561218262\n",
      "#Epoch 89 with total epochs 300 at step 5 loss: 5.74885368347168 running average of batch loss 5.448400974273682, time 0.5053331851959229\n",
      "#Epoch 89 with total epochs 300 at step 6 loss: 5.981410503387451 running average of batch loss 5.524545192718506, time 0.48932409286499023\n",
      "#Epoch 89 with total epochs 300 at step 7 loss: 5.744961738586426 running average of batch loss 5.552097260951996, time 0.5533933639526367\n",
      "#Epoch 89 with total epochs 300 at step 8 loss: 4.987584114074707 running average of batch loss 5.4893735779656305, time 0.5253643989562988\n",
      "#Epoch 89 with total epochs 300 at step 9 loss: 4.952960968017578 running average of batch loss 5.435732316970825, time 0.5373497009277344\n",
      "#Epoch 89 with total epochs 300 at step 10 loss: 5.751844882965088 running average of batch loss 5.464469822970304, time 0.5363824367523193\n",
      "#Epoch 89 with total epochs 300 at step 11 loss: 5.729128360748291 running average of batch loss 5.486524701118469, time 0.4993324279785156\n",
      "#Epoch 89 with total epochs 300 at step 12 loss: 5.398936748504639 running average of batch loss 5.479787166302021, time 0.5373625755310059\n",
      "#Epoch 89 with total epochs 300 at step 13 loss: 5.592202663421631 running average of batch loss 5.487816844667707, time 0.5233724117279053\n",
      "#Epoch 89 with total epochs 300 at step 14 loss: 5.056657791137695 running average of batch loss 5.459072907765706, time 0.5313572883605957\n",
      "#Epoch 89 with total epochs 300 at step 15 loss: 5.2460479736328125 running average of batch loss 5.4457588493824005, time 0.49235081672668457\n",
      "#Epoch 89 with total epochs 300 at step 16 loss: 5.03432035446167 running average of batch loss 5.421556584975299, time 0.5323777198791504\n",
      "#Epoch 89 with total epochs 300 at step 17 loss: 5.147948741912842 running average of batch loss 5.406356149249607, time 0.5243730545043945\n",
      "#Epoch 89 with total epochs 300 at step 18 loss: 5.467790126800537 running average of batch loss 5.409589516489129, time 0.4893474578857422\n",
      "#Epoch 89 with total epochs 300 at step 19 loss: 5.804699420928955 running average of batch loss 5.429345011711121, time 0.5103616714477539\n",
      "#Epoch 89 with total epochs 300 at step 20 loss: 4.9316816329956055 running average of batch loss 5.40564675558181, time 0.5303776264190674\n",
      "#Epoch 90 with total epochs 300 at step 0 loss: 5.716979026794434 running average of batch loss 5.716979026794434, time 0.5253744125366211\n",
      "#Epoch 90 with total epochs 300 at step 1 loss: 4.924103260040283 running average of batch loss 5.320541143417358, time 0.519343376159668\n",
      "#Epoch 90 with total epochs 300 at step 2 loss: 5.094646453857422 running average of batch loss 5.245242913564046, time 0.5233733654022217\n",
      "#Epoch 90 with total epochs 300 at step 3 loss: 5.4342451095581055 running average of batch loss 5.292493462562561, time 0.4873223304748535\n",
      "#Epoch 90 with total epochs 300 at step 4 loss: 5.586503982543945 running average of batch loss 5.3512955665588375, time 0.48632335662841797\n",
      "#Epoch 90 with total epochs 300 at step 5 loss: 5.316372394561768 running average of batch loss 5.345475037892659, time 0.49034929275512695\n",
      "#Epoch 90 with total epochs 300 at step 6 loss: 5.47376823425293 running average of batch loss 5.363802637372698, time 0.5023300647735596\n",
      "#Epoch 90 with total epochs 300 at step 7 loss: 5.222792625427246 running average of batch loss 5.346176385879517, time 0.49034976959228516\n",
      "#Epoch 90 with total epochs 300 at step 8 loss: 5.807216167449951 running average of batch loss 5.397403028276232, time 0.5303757190704346\n",
      "#Epoch 90 with total epochs 300 at step 9 loss: 5.746466636657715 running average of batch loss 5.43230938911438, time 0.5323793888092041\n",
      "#Epoch 90 with total epochs 300 at step 10 loss: 5.233458042144775 running average of batch loss 5.414231993935325, time 0.4913496971130371\n",
      "#Epoch 90 with total epochs 300 at step 11 loss: 5.53286075592041 running average of batch loss 5.424117724100749, time 0.5283534526824951\n",
      "#Epoch 90 with total epochs 300 at step 12 loss: 5.82889461517334 running average of batch loss 5.455254408029409, time 0.4873173236846924\n",
      "#Epoch 90 with total epochs 300 at step 13 loss: 5.318781852722168 running average of batch loss 5.445506368364606, time 0.4873213768005371\n",
      "#Epoch 90 with total epochs 300 at step 14 loss: 5.248223304748535 running average of batch loss 5.432354164123535, time 0.5343573093414307\n",
      "#Epoch 90 with total epochs 300 at step 15 loss: 5.122713565826416 running average of batch loss 5.413001626729965, time 0.5253732204437256\n",
      "#Epoch 90 with total epochs 300 at step 16 loss: 5.849400520324707 running average of batch loss 5.438672149882597, time 0.5303773880004883\n",
      "#Epoch 90 with total epochs 300 at step 17 loss: 5.468226909637451 running average of batch loss 5.440314080980089, time 0.5003359317779541\n",
      "#Epoch 90 with total epochs 300 at step 18 loss: 5.5459160804748535 running average of batch loss 5.445872080953498, time 0.48932528495788574\n",
      "#Epoch 90 with total epochs 300 at step 19 loss: 4.852530479431152 running average of batch loss 5.4162050008773805, time 0.5283749103546143\n",
      "#Epoch 90 with total epochs 300 at step 20 loss: 5.763559341430664 running average of batch loss 5.43274568376087, time 0.5393822193145752\n",
      "#Epoch 91 with total epochs 300 at step 0 loss: 4.667967796325684 running average of batch loss 4.667967796325684, time 0.5013551712036133\n",
      "#Epoch 91 with total epochs 300 at step 1 loss: 5.46785306930542 running average of batch loss 5.067910432815552, time 0.5203707218170166\n",
      "#Epoch 91 with total epochs 300 at step 2 loss: 5.292722225189209 running average of batch loss 5.1428476969401045, time 0.5043365955352783\n",
      "#Epoch 91 with total epochs 300 at step 3 loss: 4.986306190490723 running average of batch loss 5.103712320327759, time 0.5283656120300293\n",
      "#Epoch 91 with total epochs 300 at step 4 loss: 5.217665195465088 running average of batch loss 5.126502895355225, time 0.527374267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 91 with total epochs 300 at step 5 loss: 5.214547157287598 running average of batch loss 5.14117693901062, time 0.5243728160858154\n",
      "#Epoch 91 with total epochs 300 at step 6 loss: 5.325918197631836 running average of batch loss 5.16756854738508, time 0.5263724327087402\n",
      "#Epoch 91 with total epochs 300 at step 7 loss: 5.722161769866943 running average of batch loss 5.2368927001953125, time 0.5263733863830566\n",
      "#Epoch 91 with total epochs 300 at step 8 loss: 5.930887222290039 running average of batch loss 5.314003202650282, time 0.5283756256103516\n",
      "#Epoch 91 with total epochs 300 at step 9 loss: 5.5435357093811035 running average of batch loss 5.336956453323364, time 0.5313777923583984\n",
      "#Epoch 91 with total epochs 300 at step 10 loss: 5.2254767417907715 running average of batch loss 5.326821934093129, time 0.5273749828338623\n",
      "#Epoch 91 with total epochs 300 at step 11 loss: 5.568253993988037 running average of batch loss 5.346941272417705, time 0.5203652381896973\n",
      "#Epoch 91 with total epochs 300 at step 12 loss: 5.563839435577393 running average of batch loss 5.363625746506911, time 0.5233728885650635\n",
      "#Epoch 91 with total epochs 300 at step 13 loss: 5.183013439178467 running average of batch loss 5.350724867412022, time 0.5323770046234131\n",
      "#Epoch 91 with total epochs 300 at step 14 loss: 5.001169204711914 running average of batch loss 5.327421156565348, time 0.5273735523223877\n",
      "#Epoch 91 with total epochs 300 at step 15 loss: 5.050967693328857 running average of batch loss 5.310142815113068, time 0.5303812026977539\n",
      "#Epoch 91 with total epochs 300 at step 16 loss: 5.379847049713135 running average of batch loss 5.314243064207189, time 0.5233960151672363\n",
      "#Epoch 91 with total epochs 300 at step 17 loss: 5.714117050170898 running average of batch loss 5.336458285649617, time 0.5213463306427002\n",
      "#Epoch 91 with total epochs 300 at step 18 loss: 5.359576225280762 running average of batch loss 5.337675019314415, time 0.5343809127807617\n",
      "#Epoch 91 with total epochs 300 at step 19 loss: 5.582333087921143 running average of batch loss 5.349907922744751, time 0.530376672744751\n",
      "#Epoch 91 with total epochs 300 at step 20 loss: 5.119726181030273 running average of batch loss 5.338946887425014, time 0.48834776878356934\n",
      "#Epoch 92 with total epochs 300 at step 0 loss: 5.188961982727051 running average of batch loss 5.188961982727051, time 0.5313785076141357\n",
      "#Epoch 92 with total epochs 300 at step 1 loss: 5.739473342895508 running average of batch loss 5.464217662811279, time 0.5233480930328369\n",
      "#Epoch 92 with total epochs 300 at step 2 loss: 6.07016134262085 running average of batch loss 5.66619888941447, time 0.5233719348907471\n",
      "#Epoch 92 with total epochs 300 at step 3 loss: 5.782894134521484 running average of batch loss 5.695372700691223, time 0.5253498554229736\n",
      "#Epoch 92 with total epochs 300 at step 4 loss: 5.428361892700195 running average of batch loss 5.641970539093018, time 0.5303528308868408\n",
      "#Epoch 92 with total epochs 300 at step 5 loss: 5.738208770751953 running average of batch loss 5.658010244369507, time 0.5293757915496826\n",
      "#Epoch 92 with total epochs 300 at step 6 loss: 5.697854995727539 running average of batch loss 5.663702351706369, time 0.5213701725006104\n",
      "#Epoch 92 with total epochs 300 at step 7 loss: 5.311965465545654 running average of batch loss 5.619735240936279, time 0.48834776878356934\n",
      "#Epoch 92 with total epochs 300 at step 8 loss: 5.144859313964844 running average of batch loss 5.566971249050564, time 0.5273499488830566\n",
      "#Epoch 92 with total epochs 300 at step 9 loss: 5.538766860961914 running average of batch loss 5.564150810241699, time 0.5253736972808838\n",
      "#Epoch 92 with total epochs 300 at step 10 loss: 5.6074910163879395 running average of batch loss 5.568090828982267, time 0.5233476161956787\n",
      "#Epoch 92 with total epochs 300 at step 11 loss: 5.400411605834961 running average of batch loss 5.554117560386658, time 0.5243678092956543\n",
      "#Epoch 92 with total epochs 300 at step 12 loss: 5.0560526847839355 running average of batch loss 5.515804877647986, time 0.5253698825836182\n",
      "#Epoch 92 with total epochs 300 at step 13 loss: 5.414711952209473 running average of batch loss 5.508583954402378, time 0.5223979949951172\n",
      "#Epoch 92 with total epochs 300 at step 14 loss: 5.814216613769531 running average of batch loss 5.528959465026856, time 0.4923250675201416\n",
      "#Epoch 92 with total epochs 300 at step 15 loss: 5.847043991088867 running average of batch loss 5.548839747905731, time 0.5273749828338623\n",
      "#Epoch 92 with total epochs 300 at step 16 loss: 5.298768997192383 running average of batch loss 5.534129703746123, time 0.4873466491699219\n",
      "#Epoch 92 with total epochs 300 at step 17 loss: 4.861861228942871 running average of batch loss 5.496781455145942, time 0.5313770771026611\n",
      "#Epoch 92 with total epochs 300 at step 18 loss: 4.961615085601807 running average of batch loss 5.468614804117303, time 0.4923512935638428\n",
      "#Epoch 92 with total epochs 300 at step 19 loss: 5.1973066329956055 running average of batch loss 5.455049395561218, time 0.5303764343261719\n",
      "#Epoch 92 with total epochs 300 at step 20 loss: 5.272131443023682 running average of batch loss 5.446339016868954, time 0.48634767532348633\n",
      "#Epoch 93 with total epochs 300 at step 0 loss: 5.21003532409668 running average of batch loss 5.21003532409668, time 0.48834681510925293\n",
      "#Epoch 93 with total epochs 300 at step 1 loss: 4.961678981781006 running average of batch loss 5.085857152938843, time 0.5113635063171387\n",
      "#Epoch 93 with total epochs 300 at step 2 loss: 4.853487014770508 running average of batch loss 5.0084004402160645, time 0.48834776878356934\n",
      "#Epoch 93 with total epochs 300 at step 3 loss: 5.199908256530762 running average of batch loss 5.056277394294739, time 0.4873228073120117\n",
      "#Epoch 93 with total epochs 300 at step 4 loss: 5.086451530456543 running average of batch loss 5.062312221527099, time 0.5123379230499268\n",
      "#Epoch 93 with total epochs 300 at step 5 loss: 5.736108779907227 running average of batch loss 5.174611647923787, time 0.48932552337646484\n",
      "#Epoch 93 with total epochs 300 at step 6 loss: 5.3495073318481445 running average of batch loss 5.199596745627267, time 0.49933290481567383\n",
      "#Epoch 93 with total epochs 300 at step 7 loss: 4.6517839431762695 running average of batch loss 5.131120145320892, time 0.488323450088501\n",
      "#Epoch 93 with total epochs 300 at step 8 loss: 4.909283638000488 running average of batch loss 5.106471644507514, time 0.5243449211120605\n",
      "#Epoch 93 with total epochs 300 at step 9 loss: 5.237527847290039 running average of batch loss 5.119577264785766, time 0.5523920059204102\n",
      "#Epoch 93 with total epochs 300 at step 10 loss: 5.450755596160889 running average of batch loss 5.149684385819868, time 0.5033574104309082\n",
      "#Epoch 93 with total epochs 300 at step 11 loss: 5.274318695068359 running average of batch loss 5.160070578257243, time 0.4873478412628174\n",
      "#Epoch 93 with total epochs 300 at step 12 loss: 4.974517345428467 running average of batch loss 5.145797252655029, time 0.49034929275512695\n",
      "#Epoch 93 with total epochs 300 at step 13 loss: 4.81635856628418 running average of batch loss 5.1222659179142545, time 0.4883232116699219\n",
      "#Epoch 93 with total epochs 300 at step 14 loss: 5.913282871246338 running average of batch loss 5.175000381469727, time 0.4893219470977783\n",
      "#Epoch 93 with total epochs 300 at step 15 loss: 6.02093505859375 running average of batch loss 5.227871298789978, time 0.5023307800292969\n",
      "#Epoch 93 with total epochs 300 at step 16 loss: 5.330631732940674 running average of batch loss 5.233916030210607, time 0.5013320446014404\n",
      "#Epoch 93 with total epochs 300 at step 17 loss: 5.066636085510254 running average of batch loss 5.224622699949476, time 0.5263726711273193\n",
      "#Epoch 93 with total epochs 300 at step 18 loss: 5.05216121673584 running average of batch loss 5.215545779780338, time 0.4893217086791992\n",
      "#Epoch 93 with total epochs 300 at step 19 loss: 5.040477275848389 running average of batch loss 5.20679235458374, time 0.4883289337158203\n",
      "#Epoch 93 with total epochs 300 at step 20 loss: 5.392243385314941 running average of batch loss 5.21562335604713, time 0.5103323459625244\n",
      "#Epoch 94 with total epochs 300 at step 0 loss: 5.484800338745117 running average of batch loss 5.484800338745117, time 0.5203731060028076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 94 with total epochs 300 at step 1 loss: 5.722602367401123 running average of batch loss 5.60370135307312, time 0.4983558654785156\n",
      "#Epoch 94 with total epochs 300 at step 2 loss: 5.145956516265869 running average of batch loss 5.451119740804036, time 0.5093367099761963\n",
      "#Epoch 94 with total epochs 300 at step 3 loss: 4.966688632965088 running average of batch loss 5.330011963844299, time 0.5333802700042725\n",
      "#Epoch 94 with total epochs 300 at step 4 loss: 5.294593334197998 running average of batch loss 5.322928237915039, time 0.48632192611694336\n",
      "#Epoch 94 with total epochs 300 at step 5 loss: 5.035786151885986 running average of batch loss 5.275071223576863, time 0.5033586025238037\n",
      "#Epoch 94 with total epochs 300 at step 6 loss: 4.923396110534668 running average of batch loss 5.224831921713693, time 0.5083353519439697\n",
      "#Epoch 94 with total epochs 300 at step 7 loss: 4.93235969543457 running average of batch loss 5.1882728934288025, time 0.5033304691314697\n",
      "#Epoch 94 with total epochs 300 at step 8 loss: 5.420289039611816 running average of batch loss 5.214052465226915, time 0.4863436222076416\n",
      "#Epoch 94 with total epochs 300 at step 9 loss: 5.437995910644531 running average of batch loss 5.236446809768677, time 0.48734569549560547\n",
      "#Epoch 94 with total epochs 300 at step 10 loss: 5.240381240844727 running average of batch loss 5.236804485321045, time 0.5253732204437256\n",
      "#Epoch 94 with total epochs 300 at step 11 loss: 5.238091468811035 running average of batch loss 5.2369117339452105, time 0.4873471260070801\n",
      "#Epoch 94 with total epochs 300 at step 12 loss: 5.518407821655273 running average of batch loss 5.258565279153677, time 0.4873232841491699\n",
      "#Epoch 94 with total epochs 300 at step 13 loss: 5.345224857330322 running average of batch loss 5.2647552490234375, time 0.5403847694396973\n",
      "#Epoch 94 with total epochs 300 at step 14 loss: 5.216396808624268 running average of batch loss 5.261531352996826, time 0.5053331851959229\n",
      "#Epoch 94 with total epochs 300 at step 15 loss: 5.445140361785889 running average of batch loss 5.273006916046143, time 0.4953267574310303\n",
      "#Epoch 94 with total epochs 300 at step 16 loss: 5.007768630981445 running average of batch loss 5.257404663983514, time 0.488323450088501\n",
      "#Epoch 94 with total epochs 300 at step 17 loss: 5.055025100708008 running average of batch loss 5.246161354912652, time 0.521348237991333\n",
      "#Epoch 94 with total epochs 300 at step 18 loss: 5.010952472686768 running average of batch loss 5.233781940058658, time 0.4893465042114258\n",
      "#Epoch 94 with total epochs 300 at step 19 loss: 5.288959980010986 running average of batch loss 5.236540842056274, time 0.49034833908081055\n",
      "#Epoch 94 with total epochs 300 at step 20 loss: 5.014227390289307 running average of batch loss 5.225954487210228, time 0.5013570785522461\n",
      "#Epoch 95 with total epochs 300 at step 0 loss: 5.3479132652282715 running average of batch loss 5.3479132652282715, time 0.49034833908081055\n",
      "#Epoch 95 with total epochs 300 at step 1 loss: 4.991352081298828 running average of batch loss 5.16963267326355, time 0.525374174118042\n",
      "#Epoch 95 with total epochs 300 at step 2 loss: 5.748350143432617 running average of batch loss 5.362538496653239, time 0.49735426902770996\n",
      "#Epoch 95 with total epochs 300 at step 3 loss: 5.953261375427246 running average of batch loss 5.510219216346741, time 0.5153732299804688\n",
      "#Epoch 95 with total epochs 300 at step 4 loss: 5.062180519104004 running average of batch loss 5.420611476898193, time 0.4893472194671631\n",
      "#Epoch 95 with total epochs 300 at step 5 loss: 5.026397705078125 running average of batch loss 5.354909181594849, time 0.531378984451294\n",
      "#Epoch 95 with total epochs 300 at step 6 loss: 4.888762474060059 running average of batch loss 5.288316794804165, time 0.5023317337036133\n",
      "#Epoch 95 with total epochs 300 at step 7 loss: 5.431293487548828 running average of batch loss 5.306188881397247, time 0.5043292045593262\n",
      "#Epoch 95 with total epochs 300 at step 8 loss: 5.284909248352051 running average of batch loss 5.303824477725559, time 0.4873476028442383\n",
      "#Epoch 95 with total epochs 300 at step 9 loss: 5.136840343475342 running average of batch loss 5.287126064300537, time 0.5233712196350098\n",
      "#Epoch 95 with total epochs 300 at step 10 loss: 5.3503007888793945 running average of batch loss 5.292869221080434, time 0.4863455295562744\n",
      "#Epoch 95 with total epochs 300 at step 11 loss: 5.278104782104492 running average of batch loss 5.2916388511657715, time 0.5053601264953613\n",
      "#Epoch 95 with total epochs 300 at step 12 loss: 5.015241622924805 running average of batch loss 5.270377525916467, time 0.5243730545043945\n",
      "#Epoch 95 with total epochs 300 at step 13 loss: 5.483631134033203 running average of batch loss 5.2856099264962335, time 0.5083327293395996\n",
      "#Epoch 95 with total epochs 300 at step 14 loss: 5.4338860511779785 running average of batch loss 5.295495001475016, time 0.48534607887268066\n",
      "#Epoch 95 with total epochs 300 at step 15 loss: 5.991268157958984 running average of batch loss 5.338980823755264, time 0.5063610076904297\n",
      "#Epoch 95 with total epochs 300 at step 16 loss: 5.421789169311523 running average of batch loss 5.343851902905633, time 0.5013313293457031\n",
      "#Epoch 95 with total epochs 300 at step 17 loss: 5.392671585083008 running average of batch loss 5.346564107471043, time 0.49034786224365234\n",
      "#Epoch 95 with total epochs 300 at step 18 loss: 5.4614739418029785 running average of batch loss 5.352611993488512, time 0.5233731269836426\n",
      "#Epoch 95 with total epochs 300 at step 19 loss: 5.3357462882995605 running average of batch loss 5.351768708229065, time 0.5263524055480957\n",
      "#Epoch 95 with total epochs 300 at step 20 loss: 5.9220733642578125 running average of batch loss 5.378926072801862, time 0.48932623863220215\n",
      "#Epoch 96 with total epochs 300 at step 0 loss: 5.1914520263671875 running average of batch loss 5.1914520263671875, time 0.5033533573150635\n",
      "#Epoch 96 with total epochs 300 at step 1 loss: 5.075797080993652 running average of batch loss 5.13362455368042, time 0.4933512210845947\n",
      "#Epoch 96 with total epochs 300 at step 2 loss: 5.9644341468811035 running average of batch loss 5.4105610847473145, time 0.48834896087646484\n",
      "#Epoch 96 with total epochs 300 at step 3 loss: 5.23875617980957 running average of batch loss 5.367609858512878, time 0.5303778648376465\n",
      "#Epoch 96 with total epochs 300 at step 4 loss: 5.307520389556885 running average of batch loss 5.35559196472168, time 0.4933280944824219\n",
      "#Epoch 96 with total epochs 300 at step 5 loss: 4.9820027351379395 running average of batch loss 5.29332709312439, time 0.48834753036499023\n",
      "#Epoch 96 with total epochs 300 at step 6 loss: 5.586557865142822 running average of batch loss 5.335217203412737, time 0.4943501949310303\n",
      "#Epoch 96 with total epochs 300 at step 7 loss: 4.993013381958008 running average of batch loss 5.292441725730896, time 0.5003557205200195\n",
      "#Epoch 96 with total epochs 300 at step 8 loss: 5.352657794952393 running average of batch loss 5.2991324000888405, time 0.49034762382507324\n",
      "#Epoch 96 with total epochs 300 at step 9 loss: 5.185606956481934 running average of batch loss 5.287779855728149, time 0.49034953117370605\n",
      "#Epoch 96 with total epochs 300 at step 10 loss: 5.157957553863525 running average of batch loss 5.275977828285911, time 0.5073409080505371\n",
      "#Epoch 96 with total epochs 300 at step 11 loss: 5.424168586730957 running average of batch loss 5.288327058156331, time 0.49732184410095215\n",
      "#Epoch 96 with total epochs 300 at step 12 loss: 5.47480583190918 running average of batch loss 5.302671579214243, time 0.4993290901184082\n",
      "#Epoch 96 with total epochs 300 at step 13 loss: 5.373422622680664 running average of batch loss 5.30772522517613, time 0.488325834274292\n",
      "#Epoch 96 with total epochs 300 at step 14 loss: 4.978117942810059 running average of batch loss 5.285751406351725, time 0.49935412406921387\n",
      "#Epoch 96 with total epochs 300 at step 15 loss: 5.2041707038879395 running average of batch loss 5.280652612447739, time 0.4903256893157959\n",
      "#Epoch 96 with total epochs 300 at step 16 loss: 5.474282264709473 running average of batch loss 5.292042591992547, time 0.5513629913330078\n",
      "#Epoch 96 with total epochs 300 at step 17 loss: 4.7307305335998535 running average of batch loss 5.260858588748508, time 0.49132561683654785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 96 with total epochs 300 at step 18 loss: 5.440495491027832 running average of batch loss 5.270313162552683, time 0.48732471466064453\n",
      "#Epoch 96 with total epochs 300 at step 19 loss: 4.799856662750244 running average of batch loss 5.246790337562561, time 0.49434709548950195\n",
      "#Epoch 96 with total epochs 300 at step 20 loss: 5.0057501792907715 running average of batch loss 5.235312234787714, time 0.515343427658081\n",
      "#Epoch 97 with total epochs 300 at step 0 loss: 5.343541145324707 running average of batch loss 5.343541145324707, time 0.487346887588501\n",
      "#Epoch 97 with total epochs 300 at step 1 loss: 5.201207160949707 running average of batch loss 5.272374153137207, time 0.4913506507873535\n",
      "#Epoch 97 with total epochs 300 at step 2 loss: 5.081701278686523 running average of batch loss 5.2088165283203125, time 0.5293753147125244\n",
      "#Epoch 97 with total epochs 300 at step 3 loss: 5.499303817749023 running average of batch loss 5.28143835067749, time 0.48834896087646484\n",
      "#Epoch 97 with total epochs 300 at step 4 loss: 5.319836139678955 running average of batch loss 5.289117908477783, time 0.5033397674560547\n",
      "#Epoch 97 with total epochs 300 at step 5 loss: 5.365506649017334 running average of batch loss 5.301849365234375, time 0.4953277111053467\n",
      "#Epoch 97 with total epochs 300 at step 6 loss: 5.5002760887146 running average of batch loss 5.330196040017264, time 0.487346887588501\n",
      "#Epoch 97 with total epochs 300 at step 7 loss: 5.2960333824157715 running average of batch loss 5.325925707817078, time 0.48834729194641113\n",
      "#Epoch 97 with total epochs 300 at step 8 loss: 5.080781936645508 running average of batch loss 5.298687511020237, time 0.4883451461791992\n",
      "#Epoch 97 with total epochs 300 at step 9 loss: 4.9438581466674805 running average of batch loss 5.263204574584961, time 0.48932385444641113\n",
      "#Epoch 97 with total epochs 300 at step 10 loss: 5.16826868057251 running average of batch loss 5.254574038765647, time 0.48732471466064453\n",
      "#Epoch 97 with total epochs 300 at step 11 loss: 5.3795166015625 running average of batch loss 5.264985918998718, time 0.48834657669067383\n",
      "#Epoch 97 with total epochs 300 at step 12 loss: 4.877697944641113 running average of batch loss 5.235194536355825, time 0.48834824562072754\n",
      "#Epoch 97 with total epochs 300 at step 13 loss: 4.913822650909424 running average of batch loss 5.2122394016810825, time 0.49835920333862305\n",
      "#Epoch 97 with total epochs 300 at step 14 loss: 5.285001277923584 running average of batch loss 5.2170901934305824, time 0.5123364925384521\n",
      "#Epoch 97 with total epochs 300 at step 15 loss: 5.482985019683838 running average of batch loss 5.233708620071411, time 0.48734569549560547\n",
      "#Epoch 97 with total epochs 300 at step 16 loss: 5.1380109786987305 running average of batch loss 5.228079347049489, time 0.4983539581298828\n",
      "#Epoch 97 with total epochs 300 at step 17 loss: 5.4029221534729 running average of batch loss 5.237792836295234, time 0.5063562393188477\n",
      "#Epoch 97 with total epochs 300 at step 18 loss: 5.683761119842529 running average of batch loss 5.261264851218776, time 0.5503907203674316\n",
      "#Epoch 97 with total epochs 300 at step 19 loss: 5.54746150970459 running average of batch loss 5.275574684143066, time 0.5023629665374756\n",
      "#Epoch 97 with total epochs 300 at step 20 loss: 5.262293815612793 running average of batch loss 5.274942261832101, time 0.5283482074737549\n",
      "#Epoch 98 with total epochs 300 at step 0 loss: 5.7577385902404785 running average of batch loss 5.7577385902404785, time 0.4893474578857422\n",
      "#Epoch 98 with total epochs 300 at step 1 loss: 5.088916778564453 running average of batch loss 5.423327684402466, time 0.5033600330352783\n",
      "#Epoch 98 with total epochs 300 at step 2 loss: 5.4497480392456055 running average of batch loss 5.432134469350179, time 0.49532341957092285\n",
      "#Epoch 98 with total epochs 300 at step 3 loss: 5.076767444610596 running average of batch loss 5.343292713165283, time 0.4993314743041992\n",
      "#Epoch 98 with total epochs 300 at step 4 loss: 5.569721221923828 running average of batch loss 5.388578414916992, time 0.4903287887573242\n",
      "#Epoch 98 with total epochs 300 at step 5 loss: 5.527895450592041 running average of batch loss 5.411797920862834, time 0.521371603012085\n",
      "#Epoch 98 with total epochs 300 at step 6 loss: 5.56845760345459 running average of batch loss 5.434177875518799, time 0.4933485984802246\n",
      "#Epoch 98 with total epochs 300 at step 7 loss: 5.493475437164307 running average of batch loss 5.441590070724487, time 0.517343282699585\n",
      "#Epoch 98 with total epochs 300 at step 8 loss: 5.503316879272461 running average of batch loss 5.448448605007595, time 0.4863462448120117\n",
      "#Epoch 98 with total epochs 300 at step 9 loss: 4.563365459442139 running average of batch loss 5.35994029045105, time 0.49935460090637207\n",
      "#Epoch 98 with total epochs 300 at step 10 loss: 5.891422271728516 running average of batch loss 5.408256834203547, time 0.5563948154449463\n",
      "#Epoch 98 with total epochs 300 at step 11 loss: 5.327935695648193 running average of batch loss 5.401563405990601, time 0.5293779373168945\n",
      "#Epoch 98 with total epochs 300 at step 12 loss: 5.403204441070557 running average of batch loss 5.401689639458289, time 0.4883239269256592\n",
      "#Epoch 98 with total epochs 300 at step 13 loss: 5.320548057556152 running average of batch loss 5.395893812179565, time 0.5153384208679199\n",
      "#Epoch 98 with total epochs 300 at step 14 loss: 5.900844573974609 running average of batch loss 5.429557196299235, time 0.48932456970214844\n",
      "#Epoch 98 with total epochs 300 at step 15 loss: 4.835104465484619 running average of batch loss 5.3924039006233215, time 0.48932719230651855\n",
      "#Epoch 98 with total epochs 300 at step 16 loss: 4.878162384033203 running average of batch loss 5.362154399647432, time 0.4993305206298828\n",
      "#Epoch 98 with total epochs 300 at step 17 loss: 5.4832000732421875 running average of batch loss 5.368879159291585, time 0.5163676738739014\n",
      "#Epoch 98 with total epochs 300 at step 18 loss: 5.784759044647217 running average of batch loss 5.390767574310303, time 0.48635005950927734\n",
      "#Epoch 98 with total epochs 300 at step 19 loss: 4.504161834716797 running average of batch loss 5.346437287330628, time 0.4993398189544678\n",
      "#Epoch 98 with total epochs 300 at step 20 loss: 4.886714935302734 running average of batch loss 5.32454574675787, time 0.4883241653442383\n",
      "#Epoch 99 with total epochs 300 at step 0 loss: 5.300851821899414 running average of batch loss 5.300851821899414, time 0.4893476963043213\n",
      "#Epoch 99 with total epochs 300 at step 1 loss: 5.4154372215271 running average of batch loss 5.358144521713257, time 0.4883453845977783\n",
      "#Epoch 99 with total epochs 300 at step 2 loss: 4.562739372253418 running average of batch loss 5.0930094718933105, time 0.5093622207641602\n",
      "#Epoch 99 with total epochs 300 at step 3 loss: 5.100899696350098 running average of batch loss 5.094982028007507, time 0.5363850593566895\n",
      "#Epoch 99 with total epochs 300 at step 4 loss: 5.165311813354492 running average of batch loss 5.109047985076904, time 0.5133624076843262\n",
      "#Epoch 99 with total epochs 300 at step 5 loss: 5.597029685974121 running average of batch loss 5.1903782685597735, time 0.48933911323547363\n",
      "#Epoch 99 with total epochs 300 at step 6 loss: 5.01740026473999 running average of batch loss 5.165667125156948, time 0.4893496036529541\n",
      "#Epoch 99 with total epochs 300 at step 7 loss: 5.603699684143066 running average of batch loss 5.220421195030212, time 0.5043315887451172\n",
      "#Epoch 99 with total epochs 300 at step 8 loss: 5.319698333740234 running average of batch loss 5.231451988220215, time 0.5073611736297607\n",
      "#Epoch 99 with total epochs 300 at step 9 loss: 5.134848117828369 running average of batch loss 5.22179160118103, time 0.48834753036499023\n",
      "#Epoch 99 with total epochs 300 at step 10 loss: 5.488610744476318 running average of batch loss 5.2460478869351475, time 0.5023579597473145\n",
      "#Epoch 99 with total epochs 300 at step 11 loss: 4.7603607177734375 running average of batch loss 5.205573956171672, time 0.5043323040008545\n",
      "#Epoch 99 with total epochs 300 at step 12 loss: 4.9712371826171875 running average of batch loss 5.187548050513635, time 0.49632954597473145\n",
      "#Epoch 99 with total epochs 300 at step 13 loss: 4.70036506652832 running average of batch loss 5.152749265943255, time 0.4893209934234619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 99 with total epochs 300 at step 14 loss: 5.085784912109375 running average of batch loss 5.1482849756876625, time 0.5303771495819092\n",
      "#Epoch 99 with total epochs 300 at step 15 loss: 5.281881809234619 running average of batch loss 5.1566347777843475, time 0.5053324699401855\n",
      "#Epoch 99 with total epochs 300 at step 16 loss: 5.729835510253906 running average of batch loss 5.190352467929616, time 0.5033352375030518\n",
      "#Epoch 99 with total epochs 300 at step 17 loss: 5.504278659820557 running average of batch loss 5.207792811923557, time 0.4873480796813965\n",
      "#Epoch 99 with total epochs 300 at step 18 loss: 4.723265171051025 running average of batch loss 5.182291357140792, time 0.5013282299041748\n",
      "#Epoch 99 with total epochs 300 at step 19 loss: 5.3356146812438965 running average of batch loss 5.189957523345948, time 0.4923272132873535\n",
      "#Epoch 99 with total epochs 300 at step 20 loss: 5.240981101989746 running average of batch loss 5.192387217567081, time 0.5033345222473145\n",
      "#Epoch 100 with total epochs 300 at step 0 loss: 5.1473002433776855 running average of batch loss 5.1473002433776855, time 0.5023565292358398\n",
      "#Epoch 100 with total epochs 300 at step 1 loss: 4.848948955535889 running average of batch loss 4.998124599456787, time 0.489349365234375\n",
      "#Epoch 100 with total epochs 300 at step 2 loss: 4.962841033935547 running average of batch loss 4.986363410949707, time 0.4963257312774658\n",
      "#Epoch 100 with total epochs 300 at step 3 loss: 4.849847316741943 running average of batch loss 4.952234387397766, time 0.49934983253479004\n",
      "#Epoch 100 with total epochs 300 at step 4 loss: 5.008548259735107 running average of batch loss 4.963497161865234, time 0.48834657669067383\n",
      "#Epoch 100 with total epochs 300 at step 5 loss: 5.366098403930664 running average of batch loss 5.03059736887614, time 0.4903249740600586\n",
      "#Epoch 100 with total epochs 300 at step 6 loss: 4.820808410644531 running average of batch loss 5.000627517700195, time 0.5333809852600098\n",
      "#Epoch 100 with total epochs 300 at step 7 loss: 4.792843341827393 running average of batch loss 4.974654495716095, time 0.4863584041595459\n",
      "#Epoch 100 with total epochs 300 at step 8 loss: 5.109813690185547 running average of batch loss 4.9896721839904785, time 0.4923269748687744\n",
      "#Epoch 100 with total epochs 300 at step 9 loss: 5.140695571899414 running average of batch loss 5.004774522781372, time 0.5203449726104736\n",
      "#Epoch 100 with total epochs 300 at step 10 loss: 5.687458515167236 running average of batch loss 5.066836703907359, time 0.49034810066223145\n",
      "#Epoch 100 with total epochs 300 at step 11 loss: 5.23190975189209 running average of batch loss 5.080592791239421, time 0.5213701725006104\n",
      "#Epoch 100 with total epochs 300 at step 12 loss: 4.771877765655518 running average of batch loss 5.056845481579121, time 0.498354434967041\n",
      "#Epoch 100 with total epochs 300 at step 13 loss: 5.007112503051758 running average of batch loss 5.053293125970023, time 0.5143654346466064\n",
      "#Epoch 100 with total epochs 300 at step 14 loss: 5.233644962310791 running average of batch loss 5.065316581726075, time 0.4893507957458496\n",
      "#Epoch 100 with total epochs 300 at step 15 loss: 5.383049964904785 running average of batch loss 5.085174918174744, time 0.5073597431182861\n",
      "#Epoch 100 with total epochs 300 at step 16 loss: 5.009238243103027 running average of batch loss 5.080708054935231, time 0.5283751487731934\n",
      "#Epoch 100 with total epochs 300 at step 17 loss: 5.518038272857666 running average of batch loss 5.105004178153144, time 0.48834824562072754\n",
      "#Epoch 100 with total epochs 300 at step 18 loss: 5.575272560119629 running average of batch loss 5.129755145625064, time 0.4963526725769043\n",
      "#Epoch 100 with total epochs 300 at step 19 loss: 4.901236534118652 running average of batch loss 5.1183292150497435, time 0.4943509101867676\n",
      "#Epoch 100 with total epochs 300 at step 20 loss: 4.948918342590332 running average of batch loss 5.110262030646915, time 0.48734617233276367\n",
      "avg difference between predicted and ground truth batch wise 6.796977819289481\n",
      "#Epoch 101 with total epochs 300 at step 0 loss: 5.1978068351745605 running average of batch loss 5.1978068351745605, time 0.4893467426300049\n",
      "#Epoch 101 with total epochs 300 at step 1 loss: 4.99476432800293 running average of batch loss 5.096285581588745, time 0.523371696472168\n",
      "#Epoch 101 with total epochs 300 at step 2 loss: 5.156239986419678 running average of batch loss 5.116270383199056, time 0.5033550262451172\n",
      "#Epoch 101 with total epochs 300 at step 3 loss: 4.676946640014648 running average of batch loss 5.006439447402954, time 0.4873213768005371\n",
      "#Epoch 101 with total epochs 300 at step 4 loss: 4.925661087036133 running average of batch loss 4.99028377532959, time 0.4863452911376953\n",
      "#Epoch 101 with total epochs 300 at step 5 loss: 4.669477462768555 running average of batch loss 4.936816056569417, time 0.509361743927002\n",
      "#Epoch 101 with total epochs 300 at step 6 loss: 5.393043518066406 running average of batch loss 5.001991408211844, time 0.4873471260070801\n",
      "#Epoch 101 with total epochs 300 at step 7 loss: 4.707121849060059 running average of batch loss 4.965132713317871, time 0.48834705352783203\n",
      "#Epoch 101 with total epochs 300 at step 8 loss: 5.4418158531188965 running average of batch loss 5.018097506629096, time 0.5043344497680664\n",
      "#Epoch 101 with total epochs 300 at step 9 loss: 5.257630348205566 running average of batch loss 5.042050790786743, time 0.5033557415008545\n",
      "#Epoch 101 with total epochs 300 at step 10 loss: 4.773687839508057 running average of batch loss 5.017654158852317, time 0.48632311820983887\n",
      "#Epoch 101 with total epochs 300 at step 11 loss: 5.440865993499756 running average of batch loss 5.052921811739604, time 0.48732542991638184\n",
      "#Epoch 101 with total epochs 300 at step 12 loss: 5.437613487243652 running average of batch loss 5.082513479086069, time 0.508336067199707\n",
      "#Epoch 101 with total epochs 300 at step 13 loss: 5.33466911315918 running average of batch loss 5.1005245958055765, time 0.49833011627197266\n",
      "#Epoch 101 with total epochs 300 at step 14 loss: 5.261569499969482 running average of batch loss 5.111260922749837, time 0.4893496036529541\n",
      "#Epoch 101 with total epochs 300 at step 15 loss: 4.759953022003174 running average of batch loss 5.089304178953171, time 0.5023303031921387\n",
      "#Epoch 101 with total epochs 300 at step 16 loss: 4.864721298217773 running average of batch loss 5.076093421262853, time 0.5003561973571777\n",
      "#Epoch 101 with total epochs 300 at step 17 loss: 5.176224231719971 running average of batch loss 5.081656244066027, time 0.4893476963043213\n",
      "#Epoch 101 with total epochs 300 at step 18 loss: 4.912932395935059 running average of batch loss 5.072776041532817, time 0.4873232841491699\n",
      "#Epoch 101 with total epochs 300 at step 19 loss: 5.470691680908203 running average of batch loss 5.092671823501587, time 0.49132490158081055\n",
      "#Epoch 101 with total epochs 300 at step 20 loss: 5.121176242828369 running average of batch loss 5.094029176802862, time 0.48734617233276367\n",
      "#Epoch 102 with total epochs 300 at step 0 loss: 4.973658084869385 running average of batch loss 4.973658084869385, time 0.4863462448120117\n",
      "#Epoch 102 with total epochs 300 at step 1 loss: 4.9716477394104 running average of batch loss 4.972652912139893, time 0.4873232841491699\n",
      "#Epoch 102 with total epochs 300 at step 2 loss: 5.311300277709961 running average of batch loss 5.085535367329915, time 0.4883229732513428\n",
      "#Epoch 102 with total epochs 300 at step 3 loss: 4.931380748748779 running average of batch loss 5.046996712684631, time 0.4863460063934326\n",
      "#Epoch 102 with total epochs 300 at step 4 loss: 5.111105918884277 running average of batch loss 5.05981855392456, time 0.48834705352783203\n",
      "#Epoch 102 with total epochs 300 at step 5 loss: 4.914269924163818 running average of batch loss 5.0355604489644366, time 0.48734593391418457\n",
      "#Epoch 102 with total epochs 300 at step 6 loss: 5.208036422729492 running average of batch loss 5.060199873788016, time 0.4863462448120117\n",
      "#Epoch 102 with total epochs 300 at step 7 loss: 4.994218826293945 running average of batch loss 5.051952242851257, time 0.491349458694458\n",
      "#Epoch 102 with total epochs 300 at step 8 loss: 5.465855598449707 running average of batch loss 5.097941504584418, time 0.48834657669067383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 102 with total epochs 300 at step 9 loss: 5.074133396148682 running average of batch loss 5.095560693740845, time 0.4863450527191162\n",
      "#Epoch 102 with total epochs 300 at step 10 loss: 4.926244258880615 running average of batch loss 5.080168290571733, time 0.49034786224365234\n",
      "#Epoch 102 with total epochs 300 at step 11 loss: 5.047849178314209 running average of batch loss 5.077475031216939, time 0.48534703254699707\n",
      "#Epoch 102 with total epochs 300 at step 12 loss: 5.024302959442139 running average of batch loss 5.073384871849647, time 0.4863450527191162\n",
      "#Epoch 102 with total epochs 300 at step 13 loss: 5.180126190185547 running average of batch loss 5.081009251730783, time 0.48834681510925293\n",
      "#Epoch 102 with total epochs 300 at step 14 loss: 5.029223442077637 running average of batch loss 5.077556864420573, time 0.4883460998535156\n",
      "#Epoch 102 with total epochs 300 at step 15 loss: 5.707701683044434 running average of batch loss 5.116940915584564, time 0.48834681510925293\n",
      "#Epoch 102 with total epochs 300 at step 16 loss: 5.037265777587891 running average of batch loss 5.1122541427612305, time 0.48834753036499023\n",
      "#Epoch 102 with total epochs 300 at step 17 loss: 5.630153656005859 running average of batch loss 5.141026337941487, time 0.48632335662841797\n",
      "#Epoch 102 with total epochs 300 at step 18 loss: 5.200350761413574 running average of batch loss 5.144148676018966, time 0.4883236885070801\n",
      "#Epoch 102 with total epochs 300 at step 19 loss: 5.16201639175415 running average of batch loss 5.145042061805725, time 0.4873476028442383\n",
      "#Epoch 102 with total epochs 300 at step 20 loss: 5.238459587097168 running average of batch loss 5.149490515391032, time 0.4973275661468506\n",
      "#Epoch 103 with total epochs 300 at step 0 loss: 5.252753257751465 running average of batch loss 5.252753257751465, time 0.5093615055084229\n",
      "#Epoch 103 with total epochs 300 at step 1 loss: 4.601222038269043 running average of batch loss 4.926987648010254, time 0.4983539581298828\n",
      "#Epoch 103 with total epochs 300 at step 2 loss: 4.816046237945557 running average of batch loss 4.8900071779886884, time 0.49735331535339355\n",
      "#Epoch 103 with total epochs 300 at step 3 loss: 4.761319160461426 running average of batch loss 4.857835173606873, time 0.526374101638794\n",
      "#Epoch 103 with total epochs 300 at step 4 loss: 5.130054950714111 running average of batch loss 4.91227912902832, time 0.4863462448120117\n",
      "#Epoch 103 with total epochs 300 at step 5 loss: 5.164173126220703 running average of batch loss 4.954261461893718, time 0.48834753036499023\n",
      "#Epoch 103 with total epochs 300 at step 6 loss: 5.131460666656494 running average of batch loss 4.9795756340026855, time 0.5463571548461914\n",
      "#Epoch 103 with total epochs 300 at step 7 loss: 5.357055187225342 running average of batch loss 5.026760578155518, time 0.4903256893157959\n",
      "#Epoch 103 with total epochs 300 at step 8 loss: 5.093522071838379 running average of batch loss 5.034178521898058, time 0.5313816070556641\n",
      "#Epoch 103 with total epochs 300 at step 9 loss: 4.783588409423828 running average of batch loss 5.009119510650635, time 0.5083341598510742\n",
      "#Epoch 103 with total epochs 300 at step 10 loss: 4.986530780792236 running average of batch loss 5.007065989754417, time 0.48932409286499023\n",
      "#Epoch 103 with total epochs 300 at step 11 loss: 5.299678325653076 running average of batch loss 5.031450351079305, time 0.49232912063598633\n",
      "#Epoch 103 with total epochs 300 at step 12 loss: 5.319633960723877 running average of batch loss 5.053618321051965, time 0.507359504699707\n",
      "#Epoch 103 with total epochs 300 at step 13 loss: 5.1258978843688965 running average of batch loss 5.058781147003174, time 0.53037428855896\n",
      "#Epoch 103 with total epochs 300 at step 14 loss: 4.9636311531066895 running average of batch loss 5.052437814076741, time 0.48732495307922363\n",
      "#Epoch 103 with total epochs 300 at step 15 loss: 5.151055812835693 running average of batch loss 5.058601438999176, time 0.4983220100402832\n",
      "#Epoch 103 with total epochs 300 at step 16 loss: 4.812485218048096 running average of batch loss 5.044124014237347, time 0.49735283851623535\n",
      "#Epoch 103 with total epochs 300 at step 17 loss: 5.200510025024414 running average of batch loss 5.0528121259477405, time 0.48834681510925293\n",
      "#Epoch 103 with total epochs 300 at step 18 loss: 4.7680888175964355 running average of batch loss 5.037826688666093, time 0.5423858165740967\n",
      "#Epoch 103 with total epochs 300 at step 19 loss: 5.145115852355957 running average of batch loss 5.043191146850586, time 0.4873466491699219\n",
      "#Epoch 103 with total epochs 300 at step 20 loss: 5.005512237548828 running average of batch loss 5.041396913074312, time 0.48734569549560547\n",
      "#Epoch 104 with total epochs 300 at step 0 loss: 5.000463008880615 running average of batch loss 5.000463008880615, time 0.5223729610443115\n",
      "#Epoch 104 with total epochs 300 at step 1 loss: 5.06658411026001 running average of batch loss 5.0335235595703125, time 0.4953296184539795\n",
      "#Epoch 104 with total epochs 300 at step 2 loss: 4.799625873565674 running average of batch loss 4.955557664235433, time 0.4883248805999756\n",
      "#Epoch 104 with total epochs 300 at step 3 loss: 5.6326799392700195 running average of batch loss 5.12483823299408, time 0.5023288726806641\n",
      "#Epoch 104 with total epochs 300 at step 4 loss: 5.255709171295166 running average of batch loss 5.151012420654297, time 0.5523941516876221\n",
      "#Epoch 104 with total epochs 300 at step 5 loss: 4.668776512145996 running average of batch loss 5.070639769236247, time 0.5063319206237793\n",
      "#Epoch 104 with total epochs 300 at step 6 loss: 4.495575428009033 running average of batch loss 4.988487720489502, time 0.5363812446594238\n",
      "#Epoch 104 with total epochs 300 at step 7 loss: 5.000699520111084 running average of batch loss 4.9900141954422, time 0.4923543930053711\n",
      "#Epoch 104 with total epochs 300 at step 8 loss: 4.468620777130127 running average of batch loss 4.932081593407525, time 0.5013279914855957\n",
      "#Epoch 104 with total epochs 300 at step 9 loss: 5.447984218597412 running average of batch loss 4.983671855926514, time 0.4963259696960449\n",
      "#Epoch 104 with total epochs 300 at step 10 loss: 5.748805999755859 running average of batch loss 5.053229505365545, time 0.48834753036499023\n",
      "#Epoch 104 with total epochs 300 at step 11 loss: 5.175919532775879 running average of batch loss 5.063453674316406, time 0.5423622131347656\n",
      "#Epoch 104 with total epochs 300 at step 12 loss: 4.738916397094727 running average of batch loss 5.038489268376277, time 0.5113644599914551\n",
      "#Epoch 104 with total epochs 300 at step 13 loss: 5.247902870178223 running average of batch loss 5.053447382790702, time 0.49034929275512695\n",
      "#Epoch 104 with total epochs 300 at step 14 loss: 5.023874759674072 running average of batch loss 5.051475874582926, time 0.5303537845611572\n",
      "#Epoch 104 with total epochs 300 at step 15 loss: 5.354693412780762 running average of batch loss 5.070426970720291, time 0.5003328323364258\n",
      "#Epoch 104 with total epochs 300 at step 16 loss: 4.86604118347168 running average of batch loss 5.058404277352726, time 0.504359245300293\n",
      "#Epoch 104 with total epochs 300 at step 17 loss: 4.85039758682251 running average of batch loss 5.0468483501010475, time 0.52437424659729\n",
      "#Epoch 104 with total epochs 300 at step 18 loss: 4.882213592529297 running average of batch loss 5.038183362860429, time 0.5003511905670166\n",
      "#Epoch 104 with total epochs 300 at step 19 loss: 4.74948787689209 running average of batch loss 5.023748588562012, time 0.5253732204437256\n",
      "#Epoch 104 with total epochs 300 at step 20 loss: 4.792804718017578 running average of batch loss 5.0127512613932295, time 0.5253732204437256\n",
      "#Epoch 105 with total epochs 300 at step 0 loss: 5.260632514953613 running average of batch loss 5.260632514953613, time 0.5003368854522705\n",
      "#Epoch 105 with total epochs 300 at step 1 loss: 5.271599769592285 running average of batch loss 5.266116142272949, time 0.496326208114624\n",
      "#Epoch 105 with total epochs 300 at step 2 loss: 5.03729248046875 running average of batch loss 5.189841588338216, time 0.5123372077941895\n",
      "#Epoch 105 with total epochs 300 at step 3 loss: 4.923053741455078 running average of batch loss 5.123144626617432, time 0.48734593391418457\n",
      "#Epoch 105 with total epochs 300 at step 4 loss: 5.180715084075928 running average of batch loss 5.134658718109131, time 0.5553936958312988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 105 with total epochs 300 at step 5 loss: 5.110836029052734 running average of batch loss 5.1306882699330645, time 0.487346887588501\n",
      "#Epoch 105 with total epochs 300 at step 6 loss: 4.923258304595947 running average of batch loss 5.101055417742048, time 0.4883253574371338\n",
      "#Epoch 105 with total epochs 300 at step 7 loss: 5.057982444763184 running average of batch loss 5.09567129611969, time 0.5043323040008545\n",
      "#Epoch 105 with total epochs 300 at step 8 loss: 5.05505895614624 running average of batch loss 5.091158813900417, time 0.4883260726928711\n",
      "#Epoch 105 with total epochs 300 at step 9 loss: 4.743049144744873 running average of batch loss 5.056347846984863, time 0.48832082748413086\n",
      "#Epoch 105 with total epochs 300 at step 10 loss: 5.131743431091309 running average of batch loss 5.06320199099454, time 0.48932385444641113\n",
      "#Epoch 105 with total epochs 300 at step 11 loss: 4.782979965209961 running average of batch loss 5.039850155512492, time 0.5273792743682861\n",
      "#Epoch 105 with total epochs 300 at step 12 loss: 4.683597087860107 running average of batch loss 5.0124460733853855, time 0.48834681510925293\n",
      "#Epoch 105 with total epochs 300 at step 13 loss: 5.001951694488525 running average of batch loss 5.011696474892752, time 0.5213725566864014\n",
      "#Epoch 105 with total epochs 300 at step 14 loss: 5.327378749847412 running average of batch loss 5.03274195988973, time 0.5223472118377686\n",
      "#Epoch 105 with total epochs 300 at step 15 loss: 4.761070251464844 running average of batch loss 5.015762478113174, time 0.506331205368042\n",
      "#Epoch 105 with total epochs 300 at step 16 loss: 4.814591884613037 running average of batch loss 5.003928913789637, time 0.5393850803375244\n",
      "#Epoch 105 with total epochs 300 at step 17 loss: 5.504505157470703 running average of batch loss 5.031738705105251, time 0.4893486499786377\n",
      "#Epoch 105 with total epochs 300 at step 18 loss: 4.772915363311768 running average of batch loss 5.018116423958226, time 0.526374340057373\n",
      "#Epoch 105 with total epochs 300 at step 19 loss: 4.845142841339111 running average of batch loss 5.009467744827271, time 0.489346981048584\n",
      "#Epoch 105 with total epochs 300 at step 20 loss: 5.338338851928711 running average of batch loss 5.025128273736863, time 0.4873471260070801\n",
      "#Epoch 106 with total epochs 300 at step 0 loss: 4.408089637756348 running average of batch loss 4.408089637756348, time 0.491349458694458\n",
      "#Epoch 106 with total epochs 300 at step 1 loss: 5.1559858322143555 running average of batch loss 4.782037734985352, time 0.5223722457885742\n",
      "#Epoch 106 with total epochs 300 at step 2 loss: 4.976344585418701 running average of batch loss 4.846806685129802, time 0.48834991455078125\n",
      "#Epoch 106 with total epochs 300 at step 3 loss: 5.441640377044678 running average of batch loss 4.9955151081085205, time 0.4883244037628174\n",
      "#Epoch 106 with total epochs 300 at step 4 loss: 4.525417804718018 running average of batch loss 4.90149564743042, time 0.48834705352783203\n",
      "#Epoch 106 with total epochs 300 at step 5 loss: 4.846377372741699 running average of batch loss 4.892309268315633, time 0.49034881591796875\n",
      "#Epoch 106 with total epochs 300 at step 6 loss: 5.27752685546875 running average of batch loss 4.94734035219465, time 0.5313520431518555\n",
      "#Epoch 106 with total epochs 300 at step 7 loss: 5.306203842163086 running average of batch loss 4.992198288440704, time 0.48734569549560547\n",
      "#Epoch 106 with total epochs 300 at step 8 loss: 4.9031453132629395 running average of batch loss 4.982303513420953, time 0.4883239269256592\n",
      "#Epoch 106 with total epochs 300 at step 9 loss: 4.591517448425293 running average of batch loss 4.943224906921387, time 0.4893479347229004\n",
      "#Epoch 106 with total epochs 300 at step 10 loss: 4.969085693359375 running average of batch loss 4.945575887506658, time 0.5233712196350098\n",
      "#Epoch 106 with total epochs 300 at step 11 loss: 4.972159385681152 running average of batch loss 4.947791179021199, time 0.48834872245788574\n",
      "#Epoch 106 with total epochs 300 at step 12 loss: 4.779472827911377 running average of batch loss 4.934843613551213, time 0.5123388767242432\n",
      "#Epoch 106 with total epochs 300 at step 13 loss: 4.614044666290283 running average of batch loss 4.911929403032575, time 0.49535226821899414\n",
      "#Epoch 106 with total epochs 300 at step 14 loss: 4.6719865798950195 running average of batch loss 4.895933214823405, time 0.5403704643249512\n",
      "#Epoch 106 with total epochs 300 at step 15 loss: 5.166666030883789 running average of batch loss 4.912854015827179, time 0.5073292255401611\n",
      "#Epoch 106 with total epochs 300 at step 16 loss: 4.632388591766357 running average of batch loss 4.896356049705954, time 0.5013272762298584\n",
      "#Epoch 106 with total epochs 300 at step 17 loss: 5.217555522918701 running average of batch loss 4.91420046488444, time 0.5423858165740967\n",
      "#Epoch 106 with total epochs 300 at step 18 loss: 4.821060657501221 running average of batch loss 4.909298369759007, time 0.5053362846374512\n",
      "#Epoch 106 with total epochs 300 at step 19 loss: 4.415040969848633 running average of batch loss 4.884585499763489, time 0.5263757705688477\n",
      "#Epoch 106 with total epochs 300 at step 20 loss: 5.163546085357666 running average of batch loss 4.897869337172735, time 0.5233719348907471\n",
      "#Epoch 107 with total epochs 300 at step 0 loss: 4.94705867767334 running average of batch loss 4.94705867767334, time 0.4873464107513428\n",
      "#Epoch 107 with total epochs 300 at step 1 loss: 4.7692742347717285 running average of batch loss 4.858166456222534, time 0.5333809852600098\n",
      "#Epoch 107 with total epochs 300 at step 2 loss: 4.978731632232666 running average of batch loss 4.898354848225911, time 0.5303752422332764\n",
      "#Epoch 107 with total epochs 300 at step 3 loss: 4.62690544128418 running average of batch loss 4.8304924964904785, time 0.487346887588501\n",
      "#Epoch 107 with total epochs 300 at step 4 loss: 4.790684223175049 running average of batch loss 4.822530841827392, time 0.504357099533081\n",
      "#Epoch 107 with total epochs 300 at step 5 loss: 4.909017086029053 running average of batch loss 4.836945215861003, time 0.5213696956634521\n",
      "#Epoch 107 with total epochs 300 at step 6 loss: 4.980582237243652 running average of batch loss 4.857464790344238, time 0.4893479347229004\n",
      "#Epoch 107 with total epochs 300 at step 7 loss: 5.305441856384277 running average of batch loss 4.913461923599243, time 0.4893481731414795\n",
      "#Epoch 107 with total epochs 300 at step 8 loss: 4.9329633712768555 running average of batch loss 4.915628751118978, time 0.5243725776672363\n",
      "#Epoch 107 with total epochs 300 at step 9 loss: 5.166024208068848 running average of batch loss 4.940668296813965, time 0.49132227897644043\n",
      "#Epoch 107 with total epochs 300 at step 10 loss: 5.377388000488281 running average of batch loss 4.980370088057085, time 0.5093629360198975\n",
      "#Epoch 107 with total epochs 300 at step 11 loss: 4.772681713104248 running average of batch loss 4.963062723477681, time 0.4883451461791992\n",
      "#Epoch 107 with total epochs 300 at step 12 loss: 4.818319320678711 running average of batch loss 4.951928615570068, time 0.5253732204437256\n",
      "#Epoch 107 with total epochs 300 at step 13 loss: 5.966711044311523 running average of batch loss 5.024413074765887, time 0.48834753036499023\n",
      "#Epoch 107 with total epochs 300 at step 14 loss: 4.898625373840332 running average of batch loss 5.016027228037516, time 0.5523910522460938\n",
      "#Epoch 107 with total epochs 300 at step 15 loss: 4.693589210510254 running average of batch loss 4.995874851942062, time 0.49235057830810547\n",
      "#Epoch 107 with total epochs 300 at step 16 loss: 5.624088287353516 running average of batch loss 5.032828583436854, time 0.5283756256103516\n",
      "#Epoch 107 with total epochs 300 at step 17 loss: 4.804919719696045 running average of batch loss 5.020166979895698, time 0.48831939697265625\n",
      "#Epoch 107 with total epochs 300 at step 18 loss: 4.786452293395996 running average of batch loss 5.007866206922029, time 0.5093410015106201\n",
      "#Epoch 107 with total epochs 300 at step 19 loss: 5.027056694030762 running average of batch loss 5.008825731277466, time 0.5063366889953613\n",
      "#Epoch 107 with total epochs 300 at step 20 loss: 4.8923749923706055 running average of batch loss 5.003280457996187, time 0.5033318996429443\n",
      "#Epoch 108 with total epochs 300 at step 0 loss: 5.425398826599121 running average of batch loss 5.425398826599121, time 0.5153670310974121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 108 with total epochs 300 at step 1 loss: 4.694540977478027 running average of batch loss 5.059969902038574, time 0.5193333625793457\n",
      "#Epoch 108 with total epochs 300 at step 2 loss: 5.025997638702393 running average of batch loss 5.048645814259847, time 0.48534464836120605\n",
      "#Epoch 108 with total epochs 300 at step 3 loss: 5.0626301765441895 running average of batch loss 5.052141904830933, time 0.487346887588501\n",
      "#Epoch 108 with total epochs 300 at step 4 loss: 4.318973541259766 running average of batch loss 4.905508232116699, time 0.5243740081787109\n",
      "#Epoch 108 with total epochs 300 at step 5 loss: 5.0503644943237305 running average of batch loss 4.929650942484538, time 0.4873201847076416\n",
      "#Epoch 108 with total epochs 300 at step 6 loss: 4.819530487060547 running average of batch loss 4.913919448852539, time 0.48632192611694336\n",
      "#Epoch 108 with total epochs 300 at step 7 loss: 4.998693466186523 running average of batch loss 4.924516201019287, time 0.5143356323242188\n",
      "#Epoch 108 with total epochs 300 at step 8 loss: 5.240487098693848 running average of batch loss 4.959624078538683, time 0.523371696472168\n",
      "#Epoch 108 with total epochs 300 at step 9 loss: 4.950689792633057 running average of batch loss 4.95873064994812, time 0.49034762382507324\n",
      "#Epoch 108 with total epochs 300 at step 10 loss: 5.126416206359863 running average of batch loss 4.973974791440097, time 0.48834872245788574\n",
      "#Epoch 108 with total epochs 300 at step 11 loss: 4.967622756958008 running average of batch loss 4.973445455233256, time 0.5073318481445312\n",
      "#Epoch 108 with total epochs 300 at step 12 loss: 5.37034273147583 running average of batch loss 5.003976014944223, time 0.523371696472168\n",
      "#Epoch 108 with total epochs 300 at step 13 loss: 5.283306121826172 running average of batch loss 5.023928165435791, time 0.5193705558776855\n",
      "#Epoch 108 with total epochs 300 at step 14 loss: 5.032115936279297 running average of batch loss 5.024474016825358, time 0.49332404136657715\n",
      "#Epoch 108 with total epochs 300 at step 15 loss: 4.553090572357178 running average of batch loss 4.995012551546097, time 0.5053603649139404\n",
      "#Epoch 108 with total epochs 300 at step 16 loss: 5.141377925872803 running average of batch loss 5.003622279447668, time 0.5103356838226318\n",
      "#Epoch 108 with total epochs 300 at step 17 loss: 4.728200435638428 running average of batch loss 4.98832106590271, time 0.5473897457122803\n",
      "#Epoch 108 with total epochs 300 at step 18 loss: 5.153575897216797 running average of batch loss 4.997018688603451, time 0.48734617233276367\n",
      "#Epoch 108 with total epochs 300 at step 19 loss: 4.489071846008301 running average of batch loss 4.971621346473694, time 0.49235033988952637\n",
      "#Epoch 108 with total epochs 300 at step 20 loss: 4.891441822052002 running average of batch loss 4.9678032738821845, time 0.5253500938415527\n",
      "#Epoch 109 with total epochs 300 at step 0 loss: 4.860690593719482 running average of batch loss 4.860690593719482, time 0.4873228073120117\n",
      "#Epoch 109 with total epochs 300 at step 1 loss: 4.796546936035156 running average of batch loss 4.828618764877319, time 0.5383822917938232\n",
      "#Epoch 109 with total epochs 300 at step 2 loss: 5.173386096954346 running average of batch loss 4.943541208902995, time 0.48834753036499023\n",
      "#Epoch 109 with total epochs 300 at step 3 loss: 5.177313327789307 running average of batch loss 5.001984238624573, time 0.5233447551727295\n",
      "#Epoch 109 with total epochs 300 at step 4 loss: 4.658806800842285 running average of batch loss 4.933348751068115, time 0.4883277416229248\n",
      "#Epoch 109 with total epochs 300 at step 5 loss: 4.640953063964844 running average of batch loss 4.884616136550903, time 0.488323450088501\n",
      "#Epoch 109 with total epochs 300 at step 6 loss: 4.789702415466309 running average of batch loss 4.871057033538818, time 0.48732495307922363\n",
      "#Epoch 109 with total epochs 300 at step 7 loss: 4.9560065269470215 running average of batch loss 4.881675720214844, time 0.48834729194641113\n",
      "#Epoch 109 with total epochs 300 at step 8 loss: 4.841949462890625 running average of batch loss 4.877261691623264, time 0.49034857749938965\n",
      "#Epoch 109 with total epochs 300 at step 9 loss: 5.1070027351379395 running average of batch loss 4.900235795974732, time 0.4893479347229004\n",
      "#Epoch 109 with total epochs 300 at step 10 loss: 4.772695541381836 running average of batch loss 4.888641227375377, time 0.48932361602783203\n",
      "#Epoch 109 with total epochs 300 at step 11 loss: 5.314988136291504 running average of batch loss 4.924170136451721, time 0.48834753036499023\n",
      "#Epoch 109 with total epochs 300 at step 12 loss: 5.0174713134765625 running average of batch loss 4.9313471500690165, time 0.4893467426300049\n",
      "#Epoch 109 with total epochs 300 at step 13 loss: 5.065073490142822 running average of batch loss 4.94089903150286, time 0.5293729305267334\n",
      "#Epoch 109 with total epochs 300 at step 14 loss: 4.911369800567627 running average of batch loss 4.938930416107178, time 0.48932433128356934\n",
      "#Epoch 109 with total epochs 300 at step 15 loss: 4.459964752197266 running average of batch loss 4.908995062112808, time 0.48932409286499023\n",
      "#Epoch 109 with total epochs 300 at step 16 loss: 5.1659674644470215 running average of batch loss 4.9241110857795265, time 0.48734569549560547\n",
      "#Epoch 109 with total epochs 300 at step 17 loss: 4.796819686889648 running average of batch loss 4.917039341396755, time 0.4893496036529541\n",
      "#Epoch 109 with total epochs 300 at step 18 loss: 5.214195251464844 running average of batch loss 4.932679126137181, time 0.4883463382720947\n",
      "#Epoch 109 with total epochs 300 at step 19 loss: 4.75318717956543 running average of batch loss 4.923704528808594, time 0.4883229732513428\n",
      "#Epoch 109 with total epochs 300 at step 20 loss: 4.714670181274414 running average of batch loss 4.913750512259347, time 0.5283794403076172\n",
      "#Epoch 110 with total epochs 300 at step 0 loss: 5.116693496704102 running average of batch loss 5.116693496704102, time 0.5073390007019043\n",
      "#Epoch 110 with total epochs 300 at step 1 loss: 4.988143444061279 running average of batch loss 5.05241847038269, time 0.5033566951751709\n",
      "#Epoch 110 with total epochs 300 at step 2 loss: 4.5908403396606445 running average of batch loss 4.898559093475342, time 0.5033552646636963\n",
      "#Epoch 110 with total epochs 300 at step 3 loss: 4.9220075607299805 running average of batch loss 4.9044212102890015, time 0.5033292770385742\n",
      "#Epoch 110 with total epochs 300 at step 4 loss: 4.775094509124756 running average of batch loss 4.878555870056152, time 0.48632383346557617\n",
      "#Epoch 110 with total epochs 300 at step 5 loss: 5.175508499145508 running average of batch loss 4.928047974904378, time 0.49935436248779297\n",
      "#Epoch 110 with total epochs 300 at step 6 loss: 4.94393253326416 running average of batch loss 4.930317197527204, time 0.5263731479644775\n",
      "#Epoch 110 with total epochs 300 at step 7 loss: 4.681947708129883 running average of batch loss 4.899271011352539, time 0.48932433128356934\n",
      "#Epoch 110 with total epochs 300 at step 8 loss: 5.313762664794922 running average of batch loss 4.945325639512804, time 0.5243716239929199\n",
      "#Epoch 110 with total epochs 300 at step 9 loss: 5.0331621170043945 running average of batch loss 4.9541092872619625, time 0.5033590793609619\n",
      "#Epoch 110 with total epochs 300 at step 10 loss: 4.525361061096191 running average of batch loss 4.915132175792348, time 0.5023324489593506\n",
      "#Epoch 110 with total epochs 300 at step 11 loss: 4.853872299194336 running average of batch loss 4.910027186075847, time 0.5033292770385742\n",
      "#Epoch 110 with total epochs 300 at step 12 loss: 5.389786720275879 running average of batch loss 4.946931765629695, time 0.5043327808380127\n",
      "#Epoch 110 with total epochs 300 at step 13 loss: 4.9840922355651855 running average of batch loss 4.949586084910801, time 0.5093624591827393\n",
      "#Epoch 110 with total epochs 300 at step 14 loss: 5.52653169631958 running average of batch loss 4.988049125671386, time 0.49832677841186523\n",
      "#Epoch 110 with total epochs 300 at step 15 loss: 5.135281562805176 running average of batch loss 4.9972511529922485, time 0.506359338760376\n",
      "#Epoch 110 with total epochs 300 at step 16 loss: 4.826871871948242 running average of batch loss 4.987228842342601, time 0.5033342838287354\n",
      "#Epoch 110 with total epochs 300 at step 17 loss: 4.7957563400268555 running average of batch loss 4.9765914811028376, time 0.4893472194671631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 110 with total epochs 300 at step 18 loss: 5.283542633056641 running average of batch loss 4.9927468048898795, time 0.4933502674102783\n",
      "#Epoch 110 with total epochs 300 at step 19 loss: 4.92092227935791 running average of batch loss 4.989155578613281, time 0.48734617233276367\n",
      "#Epoch 110 with total epochs 300 at step 20 loss: 5.012500762939453 running average of batch loss 4.990267254057384, time 0.5063333511352539\n",
      "#Epoch 111 with total epochs 300 at step 0 loss: 4.503066539764404 running average of batch loss 4.503066539764404, time 0.5153658390045166\n",
      "#Epoch 111 with total epochs 300 at step 1 loss: 4.697234153747559 running average of batch loss 4.6001503467559814, time 0.5253739356994629\n",
      "#Epoch 111 with total epochs 300 at step 2 loss: 4.984345436096191 running average of batch loss 4.728215376536052, time 0.4883229732513428\n",
      "#Epoch 111 with total epochs 300 at step 3 loss: 4.267930507659912 running average of batch loss 4.613144159317017, time 0.4873237609863281\n",
      "#Epoch 111 with total epochs 300 at step 4 loss: 4.847495079040527 running average of batch loss 4.660014343261719, time 0.5033581256866455\n",
      "#Epoch 111 with total epochs 300 at step 5 loss: 4.9911980628967285 running average of batch loss 4.715211629867554, time 0.48534440994262695\n",
      "#Epoch 111 with total epochs 300 at step 6 loss: 4.943566799163818 running average of batch loss 4.747833796909878, time 0.5063605308532715\n",
      "#Epoch 111 with total epochs 300 at step 7 loss: 4.936247825622559 running average of batch loss 4.771385550498962, time 0.48632287979125977\n",
      "#Epoch 111 with total epochs 300 at step 8 loss: 5.103099822998047 running average of batch loss 4.80824269188775, time 0.5243444442749023\n",
      "#Epoch 111 with total epochs 300 at step 9 loss: 4.91908073425293 running average of batch loss 4.819326496124267, time 0.48834872245788574\n",
      "#Epoch 111 with total epochs 300 at step 10 loss: 5.13711404800415 running average of batch loss 4.8482162735678935, time 0.49034786224365234\n",
      "#Epoch 111 with total epochs 300 at step 11 loss: 5.079036235809326 running average of batch loss 4.867451270421346, time 0.4963080883026123\n",
      "#Epoch 111 with total epochs 300 at step 12 loss: 4.485953330993652 running average of batch loss 4.838105275080754, time 0.5309007167816162\n",
      "#Epoch 111 with total epochs 300 at step 13 loss: 4.980344295501709 running average of batch loss 4.848265205110822, time 0.48784780502319336\n",
      "#Epoch 111 with total epochs 300 at step 14 loss: 4.863132953643799 running average of batch loss 4.849256388346354, time 0.4855079650878906\n",
      "#Epoch 111 with total epochs 300 at step 15 loss: 4.7630205154418945 running average of batch loss 4.843866646289825, time 0.49188756942749023\n",
      "#Epoch 111 with total epochs 300 at step 16 loss: 4.540450572967529 running average of batch loss 4.8260186419767495, time 0.48932361602783203\n",
      "#Epoch 111 with total epochs 300 at step 17 loss: 4.761806964874268 running average of batch loss 4.822451326582167, time 0.5093395709991455\n",
      "#Epoch 111 with total epochs 300 at step 18 loss: 4.833428382873535 running average of batch loss 4.823029066386976, time 0.49939942359924316\n",
      "#Epoch 111 with total epochs 300 at step 19 loss: 5.362569808959961 running average of batch loss 4.850006103515625, time 0.4925990104675293\n",
      "#Epoch 111 with total epochs 300 at step 20 loss: 4.546474456787109 running average of batch loss 4.835552215576172, time 0.4905095100402832\n",
      "#Epoch 112 with total epochs 300 at step 0 loss: 4.633116245269775 running average of batch loss 4.633116245269775, time 0.5266013145446777\n",
      "#Epoch 112 with total epochs 300 at step 1 loss: 4.877224445343018 running average of batch loss 4.7551703453063965, time 0.4889225959777832\n",
      "#Epoch 112 with total epochs 300 at step 2 loss: 5.373544692993164 running average of batch loss 4.961295127868652, time 0.49085092544555664\n",
      "#Epoch 112 with total epochs 300 at step 3 loss: 4.970127582550049 running average of batch loss 4.9635032415390015, time 0.5053601264953613\n",
      "#Epoch 112 with total epochs 300 at step 4 loss: 4.602962493896484 running average of batch loss 4.891395092010498, time 0.5113635063171387\n",
      "#Epoch 112 with total epochs 300 at step 5 loss: 4.676413059234619 running average of batch loss 4.8555647532145185, time 0.5063397884368896\n",
      "#Epoch 112 with total epochs 300 at step 6 loss: 4.448629379272461 running average of batch loss 4.797431128365653, time 0.5033299922943115\n",
      "#Epoch 112 with total epochs 300 at step 7 loss: 4.690446376800537 running average of batch loss 4.784058034420013, time 0.5043578147888184\n",
      "#Epoch 112 with total epochs 300 at step 8 loss: 4.690378189086914 running average of batch loss 4.773649162716335, time 0.5003540515899658\n",
      "#Epoch 112 with total epochs 300 at step 9 loss: 4.857673645019531 running average of batch loss 4.782051610946655, time 0.532379150390625\n",
      "#Epoch 112 with total epochs 300 at step 10 loss: 4.909665107727051 running average of batch loss 4.793652837926691, time 0.48932433128356934\n",
      "#Epoch 112 with total epochs 300 at step 11 loss: 4.806812763214111 running average of batch loss 4.79474949836731, time 0.4883246421813965\n",
      "#Epoch 112 with total epochs 300 at step 12 loss: 5.080331802368164 running average of batch loss 4.816717367905837, time 0.49034929275512695\n",
      "#Epoch 112 with total epochs 300 at step 13 loss: 5.267124652862549 running average of batch loss 4.8488893168313165, time 0.48834729194641113\n",
      "#Epoch 112 with total epochs 300 at step 14 loss: 4.373530864715576 running average of batch loss 4.817198753356934, time 0.4943513870239258\n",
      "#Epoch 112 with total epochs 300 at step 15 loss: 5.174108505249023 running average of batch loss 4.839505612850189, time 0.4883301258087158\n",
      "#Epoch 112 with total epochs 300 at step 16 loss: 4.805883884429932 running average of batch loss 4.837527864119586, time 0.503328800201416\n",
      "#Epoch 112 with total epochs 300 at step 17 loss: 4.672633171081543 running average of batch loss 4.828367047839695, time 0.48932480812072754\n",
      "#Epoch 112 with total epochs 300 at step 18 loss: 4.663312911987305 running average of batch loss 4.81967998805799, time 0.5313539505004883\n",
      "#Epoch 112 with total epochs 300 at step 19 loss: 4.46919059753418 running average of batch loss 4.8021555185318, time 0.4893484115600586\n",
      "#Epoch 112 with total epochs 300 at step 20 loss: 4.608325004577637 running average of batch loss 4.7929254940577914, time 0.5353817939758301\n",
      "#Epoch 113 with total epochs 300 at step 0 loss: 4.681163787841797 running average of batch loss 4.681163787841797, time 0.487323522567749\n",
      "#Epoch 113 with total epochs 300 at step 1 loss: 4.794314861297607 running average of batch loss 4.737739324569702, time 0.4873232841491699\n",
      "#Epoch 113 with total epochs 300 at step 2 loss: 5.160694599151611 running average of batch loss 4.878724416097005, time 0.48632192611694336\n",
      "#Epoch 113 with total epochs 300 at step 3 loss: 4.890087127685547 running average of batch loss 4.881565093994141, time 0.48734545707702637\n",
      "#Epoch 113 with total epochs 300 at step 4 loss: 4.808450698852539 running average of batch loss 4.86694221496582, time 0.4873237609863281\n",
      "#Epoch 113 with total epochs 300 at step 5 loss: 5.017920017242432 running average of batch loss 4.892105182011922, time 0.4883229732513428\n",
      "#Epoch 113 with total epochs 300 at step 6 loss: 4.741438865661621 running average of batch loss 4.8705814225333075, time 0.48932552337646484\n",
      "#Epoch 113 with total epochs 300 at step 7 loss: 5.039128303527832 running average of batch loss 4.891649782657623, time 0.5293495655059814\n",
      "#Epoch 113 with total epochs 300 at step 8 loss: 4.731636047363281 running average of batch loss 4.87387047873603, time 0.5053296089172363\n",
      "#Epoch 113 with total epochs 300 at step 9 loss: 5.381856918334961 running average of batch loss 4.9246691226959225, time 0.5083374977111816\n",
      "#Epoch 113 with total epochs 300 at step 10 loss: 4.5378007888793945 running average of batch loss 4.8894992741671475, time 0.5193700790405273\n",
      "#Epoch 113 with total epochs 300 at step 11 loss: 4.879976749420166 running average of batch loss 4.888705730438232, time 0.49132347106933594\n",
      "#Epoch 113 with total epochs 300 at step 12 loss: 4.548684120178223 running average of batch loss 4.862550221956694, time 0.5293772220611572\n",
      "#Epoch 113 with total epochs 300 at step 13 loss: 5.164216041564941 running average of batch loss 4.88409778050014, time 0.4973282814025879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 113 with total epochs 300 at step 14 loss: 4.760322093963623 running average of batch loss 4.875846068064372, time 0.4873197078704834\n",
      "#Epoch 113 with total epochs 300 at step 15 loss: 4.88798189163208 running average of batch loss 4.8766045570373535, time 0.5013296604156494\n",
      "#Epoch 113 with total epochs 300 at step 16 loss: 5.005935192108154 running average of batch loss 4.884212241453283, time 0.4863467216491699\n",
      "#Epoch 113 with total epochs 300 at step 17 loss: 4.747260570526123 running average of batch loss 4.876603815290663, time 0.49332737922668457\n",
      "#Epoch 113 with total epochs 300 at step 18 loss: 4.3207926750183105 running average of batch loss 4.847350597381592, time 0.4863471984863281\n",
      "#Epoch 113 with total epochs 300 at step 19 loss: 5.221709251403809 running average of batch loss 4.8660685300827025, time 0.4943552017211914\n",
      "#Epoch 113 with total epochs 300 at step 20 loss: 4.517734050750732 running average of batch loss 4.849481173924038, time 0.5053555965423584\n",
      "#Epoch 114 with total epochs 300 at step 0 loss: 4.689230918884277 running average of batch loss 4.689230918884277, time 0.49632787704467773\n",
      "#Epoch 114 with total epochs 300 at step 1 loss: 4.46699857711792 running average of batch loss 4.578114748001099, time 0.4883260726928711\n",
      "#Epoch 114 with total epochs 300 at step 2 loss: 4.5351176261901855 running average of batch loss 4.563782374064128, time 0.49535131454467773\n",
      "#Epoch 114 with total epochs 300 at step 3 loss: 4.983625411987305 running average of batch loss 4.668743133544922, time 0.48834729194641113\n",
      "#Epoch 114 with total epochs 300 at step 4 loss: 4.994577884674072 running average of batch loss 4.733910083770752, time 0.535358190536499\n",
      "#Epoch 114 with total epochs 300 at step 5 loss: 5.331743240356445 running average of batch loss 4.833548943201701, time 0.5153653621673584\n",
      "#Epoch 114 with total epochs 300 at step 6 loss: 4.939674377441406 running average of batch loss 4.848709719521659, time 0.4953286647796631\n",
      "#Epoch 114 with total epochs 300 at step 7 loss: 4.614340305328369 running average of batch loss 4.819413542747498, time 0.48632335662841797\n",
      "#Epoch 114 with total epochs 300 at step 8 loss: 4.780867576599121 running average of batch loss 4.8151306576199, time 0.4983527660369873\n",
      "#Epoch 114 with total epochs 300 at step 9 loss: 4.150915145874023 running average of batch loss 4.748709106445313, time 0.49034833908081055\n",
      "#Epoch 114 with total epochs 300 at step 10 loss: 4.375875949859619 running average of batch loss 4.714815183119341, time 0.4883241653442383\n",
      "#Epoch 114 with total epochs 300 at step 11 loss: 4.3977508544921875 running average of batch loss 4.688393155733745, time 0.5063612461090088\n",
      "#Epoch 114 with total epochs 300 at step 12 loss: 4.735960006713867 running average of batch loss 4.692052144270677, time 0.5223703384399414\n",
      "#Epoch 114 with total epochs 300 at step 13 loss: 4.563784599304199 running average of batch loss 4.682890176773071, time 0.48831987380981445\n",
      "#Epoch 114 with total epochs 300 at step 14 loss: 4.798018455505371 running average of batch loss 4.690565395355224, time 0.48932433128356934\n",
      "#Epoch 114 with total epochs 300 at step 15 loss: 5.216742038726807 running average of batch loss 4.7234514355659485, time 0.48734426498413086\n",
      "#Epoch 114 with total epochs 300 at step 16 loss: 4.852530479431152 running average of batch loss 4.731044320499196, time 0.48734569549560547\n",
      "#Epoch 114 with total epochs 300 at step 17 loss: 4.7173967361450195 running average of batch loss 4.730286121368408, time 0.48534560203552246\n",
      "#Epoch 114 with total epochs 300 at step 18 loss: 4.958133220672607 running average of batch loss 4.742278073963366, time 0.4893467426300049\n",
      "#Epoch 114 with total epochs 300 at step 19 loss: 4.379861354827881 running average of batch loss 4.724157238006592, time 0.48932385444641113\n",
      "#Epoch 114 with total epochs 300 at step 20 loss: 4.691263198852539 running average of batch loss 4.722590855189732, time 0.5073587894439697\n",
      "#Epoch 115 with total epochs 300 at step 0 loss: 4.536413192749023 running average of batch loss 4.536413192749023, time 0.4873237609863281\n",
      "#Epoch 115 with total epochs 300 at step 1 loss: 4.786227226257324 running average of batch loss 4.661320209503174, time 0.513364315032959\n",
      "#Epoch 115 with total epochs 300 at step 2 loss: 4.522932529449463 running average of batch loss 4.6151909828186035, time 0.4983525276184082\n",
      "#Epoch 115 with total epochs 300 at step 3 loss: 4.966325759887695 running average of batch loss 4.7029746770858765, time 0.48932385444641113\n",
      "#Epoch 115 with total epochs 300 at step 4 loss: 4.773030757904053 running average of batch loss 4.716985893249512, time 0.4863448143005371\n",
      "#Epoch 115 with total epochs 300 at step 5 loss: 4.889931678771973 running average of batch loss 4.745810190836589, time 0.5133626461029053\n",
      "#Epoch 115 with total epochs 300 at step 6 loss: 5.229087829589844 running average of batch loss 4.814849853515625, time 0.4863457679748535\n",
      "#Epoch 115 with total epochs 300 at step 7 loss: 4.583405017852783 running average of batch loss 4.78591924905777, time 0.499356746673584\n",
      "#Epoch 115 with total epochs 300 at step 8 loss: 4.911128044128418 running average of batch loss 4.7998313373989525, time 0.5213682651519775\n",
      "#Epoch 115 with total epochs 300 at step 9 loss: 4.762149810791016 running average of batch loss 4.796063184738159, time 0.5053360462188721\n",
      "#Epoch 115 with total epochs 300 at step 10 loss: 5.313474655151367 running average of batch loss 4.84310059113936, time 0.48632073402404785\n",
      "#Epoch 115 with total epochs 300 at step 11 loss: 4.760700702667236 running average of batch loss 4.836233933766683, time 0.5253736972808838\n",
      "#Epoch 115 with total epochs 300 at step 12 loss: 4.539752960205078 running average of batch loss 4.813427705031175, time 0.48834848403930664\n",
      "#Epoch 115 with total epochs 300 at step 13 loss: 5.430771350860596 running average of batch loss 4.857523679733276, time 0.53037428855896\n",
      "#Epoch 115 with total epochs 300 at step 14 loss: 5.090324401855469 running average of batch loss 4.873043727874756, time 0.4873466491699219\n",
      "#Epoch 115 with total epochs 300 at step 15 loss: 4.9626240730285645 running average of batch loss 4.878642499446869, time 0.4893229007720947\n",
      "#Epoch 115 with total epochs 300 at step 16 loss: 4.272027015686035 running average of batch loss 4.842959235696232, time 0.5263733863830566\n",
      "#Epoch 115 with total epochs 300 at step 17 loss: 4.5621657371521 running average of batch loss 4.827359596888225, time 0.4913499355316162\n",
      "#Epoch 115 with total epochs 300 at step 18 loss: 4.777775287628174 running average of batch loss 4.824749896400853, time 0.5263724327087402\n",
      "#Epoch 115 with total epochs 300 at step 19 loss: 5.263370990753174 running average of batch loss 4.846680951118469, time 0.4873483180999756\n",
      "#Epoch 115 with total epochs 300 at step 20 loss: 4.412731170654297 running average of batch loss 4.826016675858271, time 0.49632883071899414\n",
      "#Epoch 116 with total epochs 300 at step 0 loss: 4.993410110473633 running average of batch loss 4.993410110473633, time 0.4893460273742676\n",
      "#Epoch 116 with total epochs 300 at step 1 loss: 4.745983123779297 running average of batch loss 4.869696617126465, time 0.4873504638671875\n",
      "#Epoch 116 with total epochs 300 at step 2 loss: 5.06119441986084 running average of batch loss 4.933529218037923, time 0.4913487434387207\n",
      "#Epoch 116 with total epochs 300 at step 3 loss: 4.801851749420166 running average of batch loss 4.900609850883484, time 0.5113346576690674\n",
      "#Epoch 116 with total epochs 300 at step 4 loss: 4.562636852264404 running average of batch loss 4.833015251159668, time 0.49034976959228516\n",
      "#Epoch 116 with total epochs 300 at step 5 loss: 4.140610218048096 running average of batch loss 4.717614412307739, time 0.4943265914916992\n",
      "#Epoch 116 with total epochs 300 at step 6 loss: 4.968181610107422 running average of batch loss 4.753409726279123, time 0.5313763618469238\n",
      "#Epoch 116 with total epochs 300 at step 7 loss: 4.8117899894714355 running average of batch loss 4.760707259178162, time 0.4893472194671631\n",
      "#Epoch 116 with total epochs 300 at step 8 loss: 4.321170806884766 running average of batch loss 4.711869875590007, time 0.5273749828338623\n",
      "#Epoch 116 with total epochs 300 at step 9 loss: 4.726292610168457 running average of batch loss 4.713312149047852, time 0.4863452911376953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 116 with total epochs 300 at step 10 loss: 5.056829452514648 running average of batch loss 4.7445409948175605, time 0.48834776878356934\n",
      "#Epoch 116 with total epochs 300 at step 11 loss: 4.451160430908203 running average of batch loss 4.72009261449178, time 0.4893319606781006\n",
      "#Epoch 116 with total epochs 300 at step 12 loss: 5.060734748840332 running average of batch loss 4.746295855595515, time 0.4883236885070801\n",
      "#Epoch 116 with total epochs 300 at step 13 loss: 4.927643299102783 running average of batch loss 4.759249244417463, time 0.4893476963043213\n",
      "#Epoch 116 with total epochs 300 at step 14 loss: 4.630861282348633 running average of batch loss 4.7506900469462074, time 0.49031853675842285\n",
      "#Epoch 116 with total epochs 300 at step 15 loss: 5.043647289276123 running average of batch loss 4.768999874591827, time 0.48932385444641113\n",
      "#Epoch 116 with total epochs 300 at step 16 loss: 4.5263895988464355 running average of batch loss 4.754728681900922, time 0.4903244972229004\n",
      "#Epoch 116 with total epochs 300 at step 17 loss: 4.75015115737915 running average of batch loss 4.754474374983046, time 0.4873471260070801\n",
      "#Epoch 116 with total epochs 300 at step 18 loss: 5.324071884155273 running average of batch loss 4.784453191255269, time 0.4913303852081299\n",
      "#Epoch 116 with total epochs 300 at step 19 loss: 5.104767799377441 running average of batch loss 4.800468921661377, time 0.4993281364440918\n",
      "#Epoch 116 with total epochs 300 at step 20 loss: 4.608762264251709 running average of batch loss 4.791340033213298, time 0.4943222999572754\n",
      "#Epoch 117 with total epochs 300 at step 0 loss: 4.657155513763428 running average of batch loss 4.657155513763428, time 0.5243704319000244\n",
      "#Epoch 117 with total epochs 300 at step 1 loss: 5.097131252288818 running average of batch loss 4.877143383026123, time 0.4903252124786377\n",
      "#Epoch 117 with total epochs 300 at step 2 loss: 4.815185070037842 running average of batch loss 4.856490612030029, time 0.48734617233276367\n",
      "#Epoch 117 with total epochs 300 at step 3 loss: 4.970951557159424 running average of batch loss 4.885105848312378, time 0.48834729194641113\n",
      "#Epoch 117 with total epochs 300 at step 4 loss: 4.920815467834473 running average of batch loss 4.8922477722167965, time 0.5263760089874268\n",
      "#Epoch 117 with total epochs 300 at step 5 loss: 4.925666332244873 running average of batch loss 4.8978175322214765, time 0.5093581676483154\n",
      "#Epoch 117 with total epochs 300 at step 6 loss: 4.483633041381836 running average of batch loss 4.838648319244385, time 0.48932886123657227\n",
      "#Epoch 117 with total epochs 300 at step 7 loss: 4.639816761016846 running average of batch loss 4.813794374465942, time 0.49332118034362793\n",
      "#Epoch 117 with total epochs 300 at step 8 loss: 5.04247522354126 running average of batch loss 4.839203357696533, time 0.5253736972808838\n",
      "#Epoch 117 with total epochs 300 at step 9 loss: 5.151844501495361 running average of batch loss 4.870467472076416, time 0.48932409286499023\n",
      "#Epoch 117 with total epochs 300 at step 10 loss: 4.426418304443359 running average of batch loss 4.830099365927956, time 0.4973266124725342\n",
      "#Epoch 117 with total epochs 300 at step 11 loss: 4.5498762130737305 running average of batch loss 4.8067474365234375, time 0.5013289451599121\n",
      "#Epoch 117 with total epochs 300 at step 12 loss: 4.785287380218506 running average of batch loss 4.805096662961519, time 0.5043323040008545\n",
      "#Epoch 117 with total epochs 300 at step 13 loss: 5.162704944610596 running average of batch loss 4.830640111650739, time 0.48634839057922363\n",
      "#Epoch 117 with total epochs 300 at step 14 loss: 4.736964702606201 running average of batch loss 4.824395084381104, time 0.4903230667114258\n",
      "#Epoch 117 with total epochs 300 at step 15 loss: 4.367180347442627 running average of batch loss 4.795819163322449, time 0.5413839817047119\n",
      "#Epoch 117 with total epochs 300 at step 16 loss: 4.86933708190918 running average of batch loss 4.800143746768727, time 0.5024142265319824\n",
      "#Epoch 117 with total epochs 300 at step 17 loss: 4.541592121124268 running average of batch loss 4.7857797675662574, time 0.5251204967498779\n",
      "#Epoch 117 with total epochs 300 at step 18 loss: 4.602197170257568 running average of batch loss 4.776117525602642, time 0.5178978443145752\n",
      "#Epoch 117 with total epochs 300 at step 19 loss: 4.357090473175049 running average of batch loss 4.755166172981262, time 0.49733448028564453\n",
      "#Epoch 117 with total epochs 300 at step 20 loss: 4.575663089752197 running average of batch loss 4.746618407113211, time 0.5073509216308594\n",
      "#Epoch 118 with total epochs 300 at step 0 loss: 5.058804512023926 running average of batch loss 5.058804512023926, time 0.4883553981781006\n",
      "#Epoch 118 with total epochs 300 at step 1 loss: 5.044665336608887 running average of batch loss 5.051734924316406, time 0.49088358879089355\n",
      "#Epoch 118 with total epochs 300 at step 2 loss: 4.592090606689453 running average of batch loss 4.898520151774089, time 0.5128872394561768\n",
      "#Epoch 118 with total epochs 300 at step 3 loss: 4.474014759063721 running average of batch loss 4.792393803596497, time 0.5003941059112549\n",
      "#Epoch 118 with total epochs 300 at step 4 loss: 4.54325008392334 running average of batch loss 4.742565059661866, time 0.49236392974853516\n",
      "#Epoch 118 with total epochs 300 at step 5 loss: 5.074134826660156 running average of batch loss 4.797826687494914, time 0.4913454055786133\n",
      "#Epoch 118 with total epochs 300 at step 6 loss: 4.472630023956299 running average of batch loss 4.751370021275112, time 0.5093951225280762\n",
      "#Epoch 118 with total epochs 300 at step 7 loss: 4.459230422973633 running average of batch loss 4.714852571487427, time 0.48987531661987305\n",
      "#Epoch 118 with total epochs 300 at step 8 loss: 4.85607385635376 running average of batch loss 4.730543825361464, time 0.49034881591796875\n",
      "#Epoch 118 with total epochs 300 at step 9 loss: 4.697015762329102 running average of batch loss 4.727191019058227, time 0.5253732204437256\n",
      "#Epoch 118 with total epochs 300 at step 10 loss: 4.499168395996094 running average of batch loss 4.706461689688942, time 0.4983549118041992\n",
      "#Epoch 118 with total epochs 300 at step 11 loss: 4.824790000915527 running average of batch loss 4.716322382291158, time 0.5263745784759521\n",
      "#Epoch 118 with total epochs 300 at step 12 loss: 4.88901424407959 running average of batch loss 4.729606371659499, time 0.4873220920562744\n",
      "#Epoch 118 with total epochs 300 at step 13 loss: 4.780806541442871 running average of batch loss 4.733263526644025, time 0.4983527660369873\n",
      "#Epoch 118 with total epochs 300 at step 14 loss: 4.827491760253906 running average of batch loss 4.739545408884684, time 0.4873464107513428\n",
      "#Epoch 118 with total epochs 300 at step 15 loss: 4.621406078338623 running average of batch loss 4.732161700725555, time 0.5153653621673584\n",
      "#Epoch 118 with total epochs 300 at step 16 loss: 4.262429237365723 running average of batch loss 4.704530379351447, time 0.48632121086120605\n",
      "#Epoch 118 with total epochs 300 at step 17 loss: 4.515446662902832 running average of batch loss 4.694025728437635, time 0.48934459686279297\n",
      "#Epoch 118 with total epochs 300 at step 18 loss: 5.095932960510254 running average of batch loss 4.715178740651984, time 0.4933502674102783\n",
      "#Epoch 118 with total epochs 300 at step 19 loss: 4.731805324554443 running average of batch loss 4.716010069847107, time 0.4873483180999756\n",
      "#Epoch 118 with total epochs 300 at step 20 loss: 4.560804843902588 running average of batch loss 4.70861934480213, time 0.48632216453552246\n",
      "#Epoch 119 with total epochs 300 at step 0 loss: 4.565046310424805 running average of batch loss 4.565046310424805, time 0.506333589553833\n",
      "#Epoch 119 with total epochs 300 at step 1 loss: 4.951476097106934 running average of batch loss 4.758261203765869, time 0.4873218536376953\n",
      "#Epoch 119 with total epochs 300 at step 2 loss: 4.3614888191223145 running average of batch loss 4.626003742218018, time 0.5433814525604248\n",
      "#Epoch 119 with total epochs 300 at step 3 loss: 4.839758396148682 running average of batch loss 4.679442405700684, time 0.49034881591796875\n",
      "#Epoch 119 with total epochs 300 at step 4 loss: 4.8203816413879395 running average of batch loss 4.707630252838134, time 0.49734926223754883\n",
      "#Epoch 119 with total epochs 300 at step 5 loss: 4.8406572341918945 running average of batch loss 4.729801416397095, time 0.4913492202758789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 119 with total epochs 300 at step 6 loss: 4.575092315673828 running average of batch loss 4.707700116293771, time 0.5353817939758301\n",
      "#Epoch 119 with total epochs 300 at step 7 loss: 4.972713470458984 running average of batch loss 4.740826785564423, time 0.48834681510925293\n",
      "#Epoch 119 with total epochs 300 at step 8 loss: 4.858459949493408 running average of batch loss 4.753897137112087, time 0.49935483932495117\n",
      "#Epoch 119 with total epochs 300 at step 9 loss: 4.6308913230896 running average of batch loss 4.7415965557098385, time 0.48634791374206543\n",
      "#Epoch 119 with total epochs 300 at step 10 loss: 4.436531066894531 running average of batch loss 4.713863329453901, time 0.4963521957397461\n",
      "#Epoch 119 with total epochs 300 at step 11 loss: 5.078282356262207 running average of batch loss 4.744231581687927, time 0.5333797931671143\n",
      "#Epoch 119 with total epochs 300 at step 12 loss: 5.130810737609863 running average of batch loss 4.773968439835769, time 0.4993295669555664\n",
      "#Epoch 119 with total epochs 300 at step 13 loss: 4.655345439910889 running average of batch loss 4.765495368412563, time 0.4893214702606201\n",
      "#Epoch 119 with total epochs 300 at step 14 loss: 4.67985725402832 running average of batch loss 4.7597861607869465, time 0.4993550777435303\n",
      "#Epoch 119 with total epochs 300 at step 15 loss: 4.441990375518799 running average of batch loss 4.739923924207687, time 0.48832058906555176\n",
      "#Epoch 119 with total epochs 300 at step 16 loss: 5.054001808166504 running average of batch loss 4.758399093852324, time 0.5053315162658691\n",
      "#Epoch 119 with total epochs 300 at step 17 loss: 4.424905776977539 running average of batch loss 4.73987168735928, time 0.5003533363342285\n",
      "#Epoch 119 with total epochs 300 at step 18 loss: 4.748287677764893 running average of batch loss 4.740314634222734, time 0.5243725776672363\n",
      "#Epoch 119 with total epochs 300 at step 19 loss: 4.5607829093933105 running average of batch loss 4.731338047981263, time 0.4863464832305908\n",
      "#Epoch 119 with total epochs 300 at step 20 loss: 4.932376384735107 running average of batch loss 4.740911302112398, time 0.48834729194641113\n",
      "#Epoch 120 with total epochs 300 at step 0 loss: 4.6901750564575195 running average of batch loss 4.6901750564575195, time 0.48734593391418457\n",
      "#Epoch 120 with total epochs 300 at step 1 loss: 4.5261454582214355 running average of batch loss 4.6081602573394775, time 0.4913489818572998\n",
      "#Epoch 120 with total epochs 300 at step 2 loss: 4.16848611831665 running average of batch loss 4.461602210998535, time 0.48834705352783203\n",
      "#Epoch 120 with total epochs 300 at step 3 loss: 4.266629219055176 running average of batch loss 4.412858963012695, time 0.4883241653442383\n",
      "#Epoch 120 with total epochs 300 at step 4 loss: 4.351250648498535 running average of batch loss 4.400537300109863, time 0.48834872245788574\n",
      "#Epoch 120 with total epochs 300 at step 5 loss: 4.685842514038086 running average of batch loss 4.4480881690979, time 0.4883232116699219\n",
      "#Epoch 120 with total epochs 300 at step 6 loss: 4.631468772888184 running average of batch loss 4.474285398210798, time 0.5303773880004883\n",
      "#Epoch 120 with total epochs 300 at step 7 loss: 4.5973286628723145 running average of batch loss 4.4896658062934875, time 0.48932480812072754\n",
      "#Epoch 120 with total epochs 300 at step 8 loss: 4.443492412567139 running average of batch loss 4.484535429212782, time 0.526350736618042\n",
      "#Epoch 120 with total epochs 300 at step 9 loss: 5.023279190063477 running average of batch loss 4.538409805297851, time 0.4883232116699219\n",
      "#Epoch 120 with total epochs 300 at step 10 loss: 4.733974456787109 running average of batch loss 4.556188409978693, time 0.48732495307922363\n",
      "#Epoch 120 with total epochs 300 at step 11 loss: 4.572620868682861 running average of batch loss 4.557557781537374, time 0.5543920993804932\n",
      "#Epoch 120 with total epochs 300 at step 12 loss: 4.8279523849487305 running average of batch loss 4.578357366415171, time 0.5173678398132324\n",
      "#Epoch 120 with total epochs 300 at step 13 loss: 4.8548150062561035 running average of batch loss 4.598104340689523, time 0.5127420425415039\n",
      "#Epoch 120 with total epochs 300 at step 14 loss: 4.588007926940918 running average of batch loss 4.597431246439616, time 0.5545947551727295\n",
      "#Epoch 120 with total epochs 300 at step 15 loss: 4.521206378936768 running average of batch loss 4.592667192220688, time 0.4893789291381836\n",
      "#Epoch 120 with total epochs 300 at step 16 loss: 4.583157539367676 running average of batch loss 4.592107800876393, time 0.5154197216033936\n",
      "#Epoch 120 with total epochs 300 at step 17 loss: 5.064225673675537 running average of batch loss 4.618336571587457, time 0.5034098625183105\n",
      "#Epoch 120 with total epochs 300 at step 18 loss: 5.135594367980957 running average of batch loss 4.645560666134483, time 0.4903888702392578\n",
      "#Epoch 120 with total epochs 300 at step 19 loss: 5.210514545440674 running average of batch loss 4.673808360099793, time 0.4933793544769287\n",
      "#Epoch 120 with total epochs 300 at step 20 loss: 4.386185646057129 running average of batch loss 4.660112040383475, time 0.5118834972381592\n",
      "avg difference between predicted and ground truth batch wise 6.480471546615874\n",
      "#Epoch 121 with total epochs 300 at step 0 loss: 4.332498073577881 running average of batch loss 4.332498073577881, time 0.4943535327911377\n",
      "#Epoch 121 with total epochs 300 at step 1 loss: 4.567905902862549 running average of batch loss 4.450201988220215, time 0.5363805294036865\n",
      "#Epoch 121 with total epochs 300 at step 2 loss: 4.297874927520752 running average of batch loss 4.399426301320394, time 0.4863455295562744\n",
      "#Epoch 121 with total epochs 300 at step 3 loss: 4.588491439819336 running average of batch loss 4.446692585945129, time 0.48334288597106934\n",
      "#Epoch 121 with total epochs 300 at step 4 loss: 4.413713455200195 running average of batch loss 4.440096759796143, time 0.4863443374633789\n",
      "#Epoch 121 with total epochs 300 at step 5 loss: 4.057289123535156 running average of batch loss 4.3762954870859785, time 0.5033576488494873\n",
      "#Epoch 121 with total epochs 300 at step 6 loss: 4.732541084289551 running average of batch loss 4.427187715257917, time 0.486346960067749\n",
      "#Epoch 121 with total epochs 300 at step 7 loss: 4.851984024047852 running average of batch loss 4.480287253856659, time 0.49432921409606934\n",
      "#Epoch 121 with total epochs 300 at step 8 loss: 4.461040496826172 running average of batch loss 4.478148725297716, time 0.49935173988342285\n",
      "#Epoch 121 with total epochs 300 at step 9 loss: 5.084744453430176 running average of batch loss 4.538808298110962, time 0.5373818874359131\n",
      "#Epoch 121 with total epochs 300 at step 10 loss: 4.5141754150390625 running average of batch loss 4.536568945104426, time 0.5003299713134766\n",
      "#Epoch 121 with total epochs 300 at step 11 loss: 4.4130659103393555 running average of batch loss 4.5262770255406695, time 0.5223724842071533\n",
      "#Epoch 121 with total epochs 300 at step 12 loss: 4.37656307220459 running average of batch loss 4.514760567591741, time 0.4873208999633789\n",
      "#Epoch 121 with total epochs 300 at step 13 loss: 4.923441410064697 running average of batch loss 4.543952056339809, time 0.4873218536376953\n",
      "#Epoch 121 with total epochs 300 at step 14 loss: 5.070569038391113 running average of batch loss 4.579059855143229, time 0.5073332786560059\n",
      "#Epoch 121 with total epochs 300 at step 15 loss: 4.765655040740967 running average of batch loss 4.590722054243088, time 0.48834657669067383\n",
      "#Epoch 121 with total epochs 300 at step 16 loss: 4.729173183441162 running average of batch loss 4.598866238313563, time 0.502356767654419\n",
      "#Epoch 121 with total epochs 300 at step 17 loss: 4.5113935470581055 running average of batch loss 4.594006644354926, time 0.5223729610443115\n",
      "#Epoch 121 with total epochs 300 at step 18 loss: 4.973883152008057 running average of batch loss 4.614000144757722, time 0.487323522567749\n",
      "#Epoch 121 with total epochs 300 at step 19 loss: 4.6377854347229 running average of batch loss 4.615189409255981, time 0.4883260726928711\n",
      "#Epoch 121 with total epochs 300 at step 20 loss: 4.4860944747924805 running average of batch loss 4.609042031424386, time 0.48734569549560547\n",
      "#Epoch 122 with total epochs 300 at step 0 loss: 4.6275529861450195 running average of batch loss 4.6275529861450195, time 0.4893474578857422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 122 with total epochs 300 at step 1 loss: 4.719027042388916 running average of batch loss 4.673290014266968, time 0.49535155296325684\n",
      "#Epoch 122 with total epochs 300 at step 2 loss: 4.544437408447266 running average of batch loss 4.6303391456604, time 0.489349365234375\n",
      "#Epoch 122 with total epochs 300 at step 3 loss: 4.528659343719482 running average of batch loss 4.604919195175171, time 0.5273487567901611\n",
      "#Epoch 122 with total epochs 300 at step 4 loss: 5.057509899139404 running average of batch loss 4.695437335968018, time 0.5383822917938232\n",
      "#Epoch 122 with total epochs 300 at step 5 loss: 4.647718906402588 running average of batch loss 4.687484264373779, time 0.49234986305236816\n",
      "#Epoch 122 with total epochs 300 at step 6 loss: 4.769931316375732 running average of batch loss 4.699262414659772, time 0.48534440994262695\n",
      "#Epoch 122 with total epochs 300 at step 7 loss: 4.610191345214844 running average of batch loss 4.6881285309791565, time 0.5073328018188477\n",
      "#Epoch 122 with total epochs 300 at step 8 loss: 4.712919235229492 running average of batch loss 4.690883053673638, time 0.49034881591796875\n",
      "#Epoch 122 with total epochs 300 at step 9 loss: 4.758495330810547 running average of batch loss 4.697644281387329, time 0.48632097244262695\n",
      "#Epoch 122 with total epochs 300 at step 10 loss: 4.547907829284668 running average of batch loss 4.684031876650724, time 0.48932504653930664\n",
      "#Epoch 122 with total epochs 300 at step 11 loss: 4.587705612182617 running average of batch loss 4.676004687945048, time 0.5243732929229736\n",
      "#Epoch 122 with total epochs 300 at step 12 loss: 4.806785583496094 running average of batch loss 4.68606475683359, time 0.488323450088501\n",
      "#Epoch 122 with total epochs 300 at step 13 loss: 5.007280349731445 running average of batch loss 4.709008727754865, time 0.4943277835845947\n",
      "#Epoch 122 with total epochs 300 at step 14 loss: 4.607863426208496 running average of batch loss 4.702265707651774, time 0.4863240718841553\n",
      "#Epoch 122 with total epochs 300 at step 15 loss: 4.662900924682617 running average of batch loss 4.699805408716202, time 0.48832249641418457\n",
      "#Epoch 122 with total epochs 300 at step 16 loss: 4.415823936462402 running average of batch loss 4.683100616230684, time 0.48932433128356934\n",
      "#Epoch 122 with total epochs 300 at step 17 loss: 4.873861312866211 running average of batch loss 4.693698432710436, time 0.49632763862609863\n",
      "#Epoch 122 with total epochs 300 at step 18 loss: 5.309648513793945 running average of batch loss 4.72611685803062, time 0.488323450088501\n",
      "#Epoch 122 with total epochs 300 at step 19 loss: 4.287168502807617 running average of batch loss 4.70416944026947, time 0.48830676078796387\n",
      "#Epoch 122 with total epochs 300 at step 20 loss: 4.7046918869018555 running average of batch loss 4.704194318680536, time 0.5223710536956787\n",
      "#Epoch 123 with total epochs 300 at step 0 loss: 4.696885585784912 running average of batch loss 4.696885585784912, time 0.4873216152191162\n",
      "#Epoch 123 with total epochs 300 at step 1 loss: 4.338207721710205 running average of batch loss 4.517546653747559, time 0.4893491268157959\n",
      "#Epoch 123 with total epochs 300 at step 2 loss: 4.007838249206543 running average of batch loss 4.347643852233887, time 0.5373518466949463\n",
      "#Epoch 123 with total epochs 300 at step 3 loss: 4.167685508728027 running average of batch loss 4.302654266357422, time 0.5243504047393799\n",
      "#Epoch 123 with total epochs 300 at step 4 loss: 4.372893810272217 running average of batch loss 4.316702175140381, time 0.4973275661468506\n",
      "#Epoch 123 with total epochs 300 at step 5 loss: 4.801066875457764 running average of batch loss 4.397429625193278, time 0.500352144241333\n",
      "#Epoch 123 with total epochs 300 at step 6 loss: 4.720485210418701 running average of batch loss 4.443580423082624, time 0.5013277530670166\n",
      "#Epoch 123 with total epochs 300 at step 7 loss: 4.785419464111328 running average of batch loss 4.486310303211212, time 0.4883248805999756\n",
      "#Epoch 123 with total epochs 300 at step 8 loss: 4.60554838180542 running average of batch loss 4.499558978610569, time 0.4893460273742676\n",
      "#Epoch 123 with total epochs 300 at step 9 loss: 4.740088939666748 running average of batch loss 4.523611974716187, time 0.4923248291015625\n",
      "#Epoch 123 with total epochs 300 at step 10 loss: 4.321058750152588 running average of batch loss 4.505198045210405, time 0.4893224239349365\n",
      "#Epoch 123 with total epochs 300 at step 11 loss: 4.850800037384033 running average of batch loss 4.533998211224874, time 0.5253732204437256\n",
      "#Epoch 123 with total epochs 300 at step 12 loss: 4.78753137588501 running average of batch loss 4.553500762352576, time 0.48534440994262695\n",
      "#Epoch 123 with total epochs 300 at step 13 loss: 4.747676849365234 running average of batch loss 4.567370482853481, time 0.5283501148223877\n",
      "#Epoch 123 with total epochs 300 at step 14 loss: 4.2764787673950195 running average of batch loss 4.547977701822917, time 0.4863467216491699\n",
      "#Epoch 123 with total epochs 300 at step 15 loss: 4.473522186279297 running average of batch loss 4.54332423210144, time 0.5293757915496826\n",
      "#Epoch 123 with total epochs 300 at step 16 loss: 4.672118186950684 running average of batch loss 4.550900347092572, time 0.48534345626831055\n",
      "#Epoch 123 with total epochs 300 at step 17 loss: 4.55863618850708 running average of batch loss 4.551330116060045, time 0.48534512519836426\n",
      "#Epoch 123 with total epochs 300 at step 18 loss: 4.508465766906738 running average of batch loss 4.5490740976835555, time 0.4873225688934326\n",
      "#Epoch 123 with total epochs 300 at step 19 loss: 4.8374433517456055 running average of batch loss 4.563492560386658, time 0.488323450088501\n",
      "#Epoch 123 with total epochs 300 at step 20 loss: 4.722908973693848 running average of batch loss 4.57108381816319, time 0.5343801975250244\n",
      "#Epoch 124 with total epochs 300 at step 0 loss: 4.5152459144592285 running average of batch loss 4.5152459144592285, time 0.48732423782348633\n",
      "#Epoch 124 with total epochs 300 at step 1 loss: 5.206745624542236 running average of batch loss 4.860995769500732, time 0.4863452911376953\n",
      "#Epoch 124 with total epochs 300 at step 2 loss: 4.387170314788818 running average of batch loss 4.703053951263428, time 0.49532628059387207\n",
      "#Epoch 124 with total epochs 300 at step 3 loss: 5.198347568511963 running average of batch loss 4.8268773555755615, time 0.48834705352783203\n",
      "#Epoch 124 with total epochs 300 at step 4 loss: 4.604605674743652 running average of batch loss 4.78242301940918, time 0.49234962463378906\n",
      "#Epoch 124 with total epochs 300 at step 5 loss: 4.674440383911133 running average of batch loss 4.764425913492839, time 0.49332690238952637\n",
      "#Epoch 124 with total epochs 300 at step 6 loss: 4.5595784187316895 running average of batch loss 4.7351619856698175, time 0.48834753036499023\n",
      "#Epoch 124 with total epochs 300 at step 7 loss: 4.388163089752197 running average of batch loss 4.691787123680115, time 0.5233712196350098\n",
      "#Epoch 124 with total epochs 300 at step 8 loss: 4.187968730926514 running average of batch loss 4.635807302263048, time 0.5193452835083008\n",
      "#Epoch 124 with total epochs 300 at step 9 loss: 4.766181945800781 running average of batch loss 4.648844766616821, time 0.5323784351348877\n",
      "#Epoch 124 with total epochs 300 at step 10 loss: 4.843118667602539 running average of batch loss 4.666506030342796, time 0.501356840133667\n",
      "#Epoch 124 with total epochs 300 at step 11 loss: 4.519353866577148 running average of batch loss 4.654243350028992, time 0.4873230457305908\n",
      "#Epoch 124 with total epochs 300 at step 12 loss: 4.974366188049316 running average of batch loss 4.678868183722863, time 0.5013365745544434\n",
      "#Epoch 124 with total epochs 300 at step 13 loss: 4.395751953125 running average of batch loss 4.658645595823016, time 0.5033299922943115\n",
      "#Epoch 124 with total epochs 300 at step 14 loss: 4.932737350463867 running average of batch loss 4.6769183794657385, time 0.5033321380615234\n",
      "#Epoch 124 with total epochs 300 at step 15 loss: 4.983325481414795 running average of batch loss 4.696068823337555, time 0.4873464107513428\n",
      "#Epoch 124 with total epochs 300 at step 16 loss: 4.294044494628906 running average of batch loss 4.672420333413517, time 0.48832011222839355\n",
      "#Epoch 124 with total epochs 300 at step 17 loss: 4.424654960632324 running average of batch loss 4.658655590481228, time 0.4883244037628174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 124 with total epochs 300 at step 18 loss: 4.545145511627197 running average of batch loss 4.6526813758047005, time 0.5053610801696777\n",
      "#Epoch 124 with total epochs 300 at step 19 loss: 4.051634311676025 running average of batch loss 4.622629022598266, time 0.49832582473754883\n",
      "#Epoch 124 with total epochs 300 at step 20 loss: 4.594590187072754 running average of batch loss 4.621293839954195, time 0.5323777198791504\n",
      "#Epoch 125 with total epochs 300 at step 0 loss: 4.64299201965332 running average of batch loss 4.64299201965332, time 0.48834657669067383\n",
      "#Epoch 125 with total epochs 300 at step 1 loss: 4.753180503845215 running average of batch loss 4.698086261749268, time 0.5333547592163086\n",
      "#Epoch 125 with total epochs 300 at step 2 loss: 4.414266586303711 running average of batch loss 4.603479703267415, time 0.48734593391418457\n",
      "#Epoch 125 with total epochs 300 at step 3 loss: 4.513748645782471 running average of batch loss 4.581046938896179, time 0.4993572235107422\n",
      "#Epoch 125 with total epochs 300 at step 4 loss: 4.861273288726807 running average of batch loss 4.637092208862304, time 0.49632930755615234\n",
      "#Epoch 125 with total epochs 300 at step 5 loss: 4.605384349822998 running average of batch loss 4.631807565689087, time 0.48834800720214844\n",
      "#Epoch 125 with total epochs 300 at step 6 loss: 4.45137357711792 running average of batch loss 4.606031281607492, time 0.49833011627197266\n",
      "#Epoch 125 with total epochs 300 at step 7 loss: 4.874932765960693 running average of batch loss 4.639643967151642, time 0.5033543109893799\n",
      "#Epoch 125 with total epochs 300 at step 8 loss: 4.332042694091797 running average of batch loss 4.6054660479227705, time 0.48834848403930664\n",
      "#Epoch 125 with total epochs 300 at step 9 loss: 4.96484375 running average of batch loss 4.6414038181304935, time 0.48834919929504395\n",
      "#Epoch 125 with total epochs 300 at step 10 loss: 4.78358793258667 running average of batch loss 4.654329646717418, time 0.5033328533172607\n",
      "#Epoch 125 with total epochs 300 at step 11 loss: 3.92366886138916 running average of batch loss 4.5934412479400635, time 0.5063376426696777\n",
      "#Epoch 125 with total epochs 300 at step 12 loss: 4.775750637054443 running average of batch loss 4.607465047102708, time 0.4913489818572998\n",
      "#Epoch 125 with total epochs 300 at step 13 loss: 4.449916362762451 running average of batch loss 4.5962115696498325, time 0.5303776264190674\n",
      "#Epoch 125 with total epochs 300 at step 14 loss: 5.6703877449035645 running average of batch loss 4.667823314666748, time 0.4903247356414795\n",
      "#Epoch 125 with total epochs 300 at step 15 loss: 4.493709564208984 running average of batch loss 4.656941205263138, time 0.5353796482086182\n",
      "#Epoch 125 with total epochs 300 at step 16 loss: 4.5353617668151855 running average of batch loss 4.6497894735897285, time 0.5093629360198975\n",
      "#Epoch 125 with total epochs 300 at step 17 loss: 4.475370407104492 running average of batch loss 4.64009952545166, time 0.5223708152770996\n",
      "#Epoch 125 with total epochs 300 at step 18 loss: 4.518895626068115 running average of batch loss 4.633720372852526, time 0.4873464107513428\n",
      "#Epoch 125 with total epochs 300 at step 19 loss: 4.127643585205078 running average of batch loss 4.6084165334701535, time 0.48832178115844727\n",
      "#Epoch 125 with total epochs 300 at step 20 loss: 4.524492263793945 running average of batch loss 4.604420139676049, time 0.48932576179504395\n",
      "#Epoch 126 with total epochs 300 at step 0 loss: 4.814900875091553 running average of batch loss 4.814900875091553, time 0.5393836498260498\n",
      "#Epoch 126 with total epochs 300 at step 1 loss: 4.238546848297119 running average of batch loss 4.526723861694336, time 0.48732423782348633\n",
      "#Epoch 126 with total epochs 300 at step 2 loss: 4.565396308898926 running average of batch loss 4.539614677429199, time 0.5133376121520996\n",
      "#Epoch 126 with total epochs 300 at step 3 loss: 4.704361915588379 running average of batch loss 4.580801486968994, time 0.48834705352783203\n",
      "#Epoch 126 with total epochs 300 at step 4 loss: 4.066357612609863 running average of batch loss 4.477912712097168, time 0.48832225799560547\n",
      "#Epoch 126 with total epochs 300 at step 5 loss: 4.7347517013549805 running average of batch loss 4.520719210306804, time 0.5333786010742188\n",
      "#Epoch 126 with total epochs 300 at step 6 loss: 4.834856986999512 running average of batch loss 4.5655960355486185, time 0.48932552337646484\n",
      "#Epoch 126 with total epochs 300 at step 7 loss: 4.582161903381348 running average of batch loss 4.56766676902771, time 0.5393824577331543\n",
      "#Epoch 126 with total epochs 300 at step 8 loss: 4.724719047546387 running average of batch loss 4.585117022196452, time 0.5163676738739014\n",
      "#Epoch 126 with total epochs 300 at step 9 loss: 4.784012317657471 running average of batch loss 4.605006551742553, time 0.5003294944763184\n",
      "#Epoch 126 with total epochs 300 at step 10 loss: 4.494507312774658 running average of batch loss 4.594961166381836, time 0.48632311820983887\n",
      "#Epoch 126 with total epochs 300 at step 11 loss: 5.037932395935059 running average of batch loss 4.6318754355112715, time 0.48734521865844727\n",
      "#Epoch 126 with total epochs 300 at step 12 loss: 4.472935676574707 running average of batch loss 4.619649300208459, time 0.5123629570007324\n",
      "#Epoch 126 with total epochs 300 at step 13 loss: 4.349859714508057 running average of batch loss 4.600378615515573, time 0.49833059310913086\n",
      "#Epoch 126 with total epochs 300 at step 14 loss: 4.827557563781738 running average of batch loss 4.615523878733317, time 0.48732900619506836\n",
      "#Epoch 126 with total epochs 300 at step 15 loss: 4.480139255523682 running average of batch loss 4.607062339782715, time 0.4953269958496094\n",
      "#Epoch 126 with total epochs 300 at step 16 loss: 4.522968292236328 running average of batch loss 4.602115631103516, time 0.48834896087646484\n",
      "#Epoch 126 with total epochs 300 at step 17 loss: 4.5452752113342285 running average of batch loss 4.598957830005222, time 0.5073285102844238\n",
      "#Epoch 126 with total epochs 300 at step 18 loss: 4.427538871765137 running average of batch loss 4.589935779571533, time 0.5253524780273438\n",
      "#Epoch 126 with total epochs 300 at step 19 loss: 4.413662433624268 running average of batch loss 4.58112211227417, time 0.48834919929504395\n",
      "#Epoch 126 with total epochs 300 at step 20 loss: 4.419299602508545 running average of batch loss 4.573416278475807, time 0.4863450527191162\n",
      "#Epoch 127 with total epochs 300 at step 0 loss: 4.229073524475098 running average of batch loss 4.229073524475098, time 0.48734474182128906\n",
      "#Epoch 127 with total epochs 300 at step 1 loss: 4.459519863128662 running average of batch loss 4.34429669380188, time 0.4863467216491699\n",
      "#Epoch 127 with total epochs 300 at step 2 loss: 4.349425792694092 running average of batch loss 4.346006393432617, time 0.4893479347229004\n",
      "#Epoch 127 with total epochs 300 at step 3 loss: 4.635313034057617 running average of batch loss 4.418333053588867, time 0.5343799591064453\n",
      "#Epoch 127 with total epochs 300 at step 4 loss: 4.728464603424072 running average of batch loss 4.480359363555908, time 0.48835086822509766\n",
      "#Epoch 127 with total epochs 300 at step 5 loss: 3.962759494781494 running average of batch loss 4.394092718760173, time 0.5363774299621582\n",
      "#Epoch 127 with total epochs 300 at step 6 loss: 4.76505184173584 running average of batch loss 4.447086879185268, time 0.48834729194641113\n",
      "#Epoch 127 with total epochs 300 at step 7 loss: 4.9438090324401855 running average of batch loss 4.509177148342133, time 0.48831844329833984\n",
      "#Epoch 127 with total epochs 300 at step 8 loss: 4.584376811981201 running average of batch loss 4.517532666524251, time 0.4873325824737549\n",
      "#Epoch 127 with total epochs 300 at step 9 loss: 4.932229518890381 running average of batch loss 4.559002351760864, time 0.48632335662841797\n",
      "#Epoch 127 with total epochs 300 at step 10 loss: 4.593283653259277 running average of batch loss 4.562118833715266, time 0.5093355178833008\n",
      "#Epoch 127 with total epochs 300 at step 11 loss: 4.845294952392578 running average of batch loss 4.5857168436050415, time 0.4983530044555664\n",
      "#Epoch 127 with total epochs 300 at step 12 loss: 4.413243293762207 running average of batch loss 4.572449647463285, time 0.526374340057373\n",
      "#Epoch 127 with total epochs 300 at step 13 loss: 4.317417621612549 running average of batch loss 4.554233074188232, time 0.49235010147094727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 127 with total epochs 300 at step 14 loss: 4.883286476135254 running average of batch loss 4.576169967651367, time 0.546389102935791\n",
      "#Epoch 127 with total epochs 300 at step 15 loss: 4.451011657714844 running average of batch loss 4.5683475732803345, time 0.48932313919067383\n",
      "#Epoch 127 with total epochs 300 at step 16 loss: 4.621090412139893 running average of batch loss 4.57145009321325, time 0.535381555557251\n",
      "#Epoch 127 with total epochs 300 at step 17 loss: 4.65387487411499 running average of batch loss 4.57602924770779, time 0.48632359504699707\n",
      "#Epoch 127 with total epochs 300 at step 18 loss: 5.345247268676758 running average of batch loss 4.616514406706157, time 0.5263736248016357\n",
      "#Epoch 127 with total epochs 300 at step 19 loss: 4.7060546875 running average of batch loss 4.62099142074585, time 0.5173428058624268\n",
      "#Epoch 127 with total epochs 300 at step 20 loss: 4.496559143066406 running average of batch loss 4.615066074189686, time 0.509361743927002\n",
      "#Epoch 128 with total epochs 300 at step 0 loss: 4.079319477081299 running average of batch loss 4.079319477081299, time 0.4863457679748535\n",
      "#Epoch 128 with total epochs 300 at step 1 loss: 4.535402297973633 running average of batch loss 4.307360887527466, time 0.5303735733032227\n",
      "#Epoch 128 with total epochs 300 at step 2 loss: 4.379650592803955 running average of batch loss 4.331457455952962, time 0.4853198528289795\n",
      "#Epoch 128 with total epochs 300 at step 3 loss: 4.782650947570801 running average of batch loss 4.444255828857422, time 0.4873232841491699\n",
      "#Epoch 128 with total epochs 300 at step 4 loss: 4.717804908752441 running average of batch loss 4.498965644836426, time 0.5233714580535889\n",
      "#Epoch 128 with total epochs 300 at step 5 loss: 4.749538898468018 running average of batch loss 4.540727853775024, time 0.5603992938995361\n",
      "#Epoch 128 with total epochs 300 at step 6 loss: 4.36006498336792 running average of batch loss 4.514918872288296, time 0.5033595561981201\n",
      "#Epoch 128 with total epochs 300 at step 7 loss: 4.422512054443359 running average of batch loss 4.503368020057678, time 0.4963536262512207\n",
      "#Epoch 128 with total epochs 300 at step 8 loss: 4.490372180938721 running average of batch loss 4.50192403793335, time 0.48632121086120605\n",
      "#Epoch 128 with total epochs 300 at step 9 loss: 4.058600425720215 running average of batch loss 4.4575916767120365, time 0.5063354969024658\n",
      "#Epoch 128 with total epochs 300 at step 10 loss: 4.825700283050537 running average of batch loss 4.491056095470082, time 0.4863460063934326\n",
      "#Epoch 128 with total epochs 300 at step 11 loss: 4.250814914703369 running average of batch loss 4.471035997072856, time 0.4983558654785156\n",
      "#Epoch 128 with total epochs 300 at step 12 loss: 4.69056510925293 running average of batch loss 4.487922851855938, time 0.49935388565063477\n",
      "#Epoch 128 with total epochs 300 at step 13 loss: 3.9385290145874023 running average of batch loss 4.448680434908185, time 0.5173373222351074\n",
      "#Epoch 128 with total epochs 300 at step 14 loss: 4.662274360656738 running average of batch loss 4.462920029958089, time 0.49034905433654785\n",
      "#Epoch 128 with total epochs 300 at step 15 loss: 4.356894016265869 running average of batch loss 4.456293404102325, time 0.4873232841491699\n",
      "#Epoch 128 with total epochs 300 at step 16 loss: 4.981931686401367 running average of batch loss 4.487213303061092, time 0.4893462657928467\n",
      "#Epoch 128 with total epochs 300 at step 17 loss: 4.547341346740723 running average of batch loss 4.490553749932183, time 0.5253582000732422\n",
      "#Epoch 128 with total epochs 300 at step 18 loss: 4.527276039123535 running average of batch loss 4.492486501994886, time 0.48832035064697266\n",
      "#Epoch 128 with total epochs 300 at step 19 loss: 4.624518394470215 running average of batch loss 4.499088096618652, time 0.5333559513092041\n",
      "#Epoch 128 with total epochs 300 at step 20 loss: 4.606710910797119 running average of batch loss 4.5042129925319125, time 0.4863448143005371\n",
      "#Epoch 129 with total epochs 300 at step 0 loss: 5.087796211242676 running average of batch loss 5.087796211242676, time 0.5453896522521973\n",
      "#Epoch 129 with total epochs 300 at step 1 loss: 4.266449451446533 running average of batch loss 4.6771228313446045, time 0.5243704319000244\n",
      "#Epoch 129 with total epochs 300 at step 2 loss: 4.2764692306518555 running average of batch loss 4.5435716311136884, time 0.4883463382720947\n",
      "#Epoch 129 with total epochs 300 at step 3 loss: 4.497866153717041 running average of batch loss 4.532145261764526, time 0.49234986305236816\n",
      "#Epoch 129 with total epochs 300 at step 4 loss: 4.397321701049805 running average of batch loss 4.505180549621582, time 0.48834681510925293\n",
      "#Epoch 129 with total epochs 300 at step 5 loss: 4.343255043029785 running average of batch loss 4.478192965189616, time 0.5273745059967041\n",
      "#Epoch 129 with total epochs 300 at step 6 loss: 4.507725238800049 running average of batch loss 4.482411861419678, time 0.5013556480407715\n",
      "#Epoch 129 with total epochs 300 at step 7 loss: 4.246243953704834 running average of batch loss 4.452890872955322, time 0.49034857749938965\n",
      "#Epoch 129 with total epochs 300 at step 8 loss: 4.3977203369140625 running average of batch loss 4.446760813395183, time 0.5223712921142578\n",
      "#Epoch 129 with total epochs 300 at step 9 loss: 4.408489227294922 running average of batch loss 4.442933654785156, time 0.48932433128356934\n",
      "#Epoch 129 with total epochs 300 at step 10 loss: 4.2326812744140625 running average of batch loss 4.4238198020241475, time 0.5273752212524414\n",
      "#Epoch 129 with total epochs 300 at step 11 loss: 4.458739280700684 running average of batch loss 4.426729758580525, time 0.5303761959075928\n",
      "#Epoch 129 with total epochs 300 at step 12 loss: 4.142735481262207 running average of batch loss 4.404884044940655, time 0.5013558864593506\n",
      "#Epoch 129 with total epochs 300 at step 13 loss: 4.681950092315674 running average of batch loss 4.424674476896014, time 0.5023560523986816\n",
      "#Epoch 129 with total epochs 300 at step 14 loss: 4.595886707305908 running average of batch loss 4.436088625590006, time 0.5363826751708984\n",
      "#Epoch 129 with total epochs 300 at step 15 loss: 4.251559734344482 running average of batch loss 4.424555569887161, time 0.5563955307006836\n",
      "#Epoch 129 with total epochs 300 at step 16 loss: 4.370697021484375 running average of batch loss 4.421387419981115, time 0.48834657669067383\n",
      "#Epoch 129 with total epochs 300 at step 17 loss: 4.442200660705566 running average of batch loss 4.422543711132473, time 0.4913492202758789\n",
      "#Epoch 129 with total epochs 300 at step 18 loss: 4.289735317230225 running average of batch loss 4.415553795663934, time 0.4863452911376953\n",
      "#Epoch 129 with total epochs 300 at step 19 loss: 4.676462173461914 running average of batch loss 4.428599214553833, time 0.4933509826660156\n",
      "#Epoch 129 with total epochs 300 at step 20 loss: 4.446927070617676 running average of batch loss 4.429471969604492, time 0.4853215217590332\n",
      "#Epoch 130 with total epochs 300 at step 0 loss: 4.6455397605896 running average of batch loss 4.6455397605896, time 0.48734569549560547\n",
      "#Epoch 130 with total epochs 300 at step 1 loss: 4.357812881469727 running average of batch loss 4.501676321029663, time 0.48834753036499023\n",
      "#Epoch 130 with total epochs 300 at step 2 loss: 4.450353622436523 running average of batch loss 4.48456875483195, time 0.48534679412841797\n",
      "#Epoch 130 with total epochs 300 at step 3 loss: 4.576935291290283 running average of batch loss 4.507660388946533, time 0.4873197078704834\n",
      "#Epoch 130 with total epochs 300 at step 4 loss: 4.642395496368408 running average of batch loss 4.534607410430908, time 0.5063602924346924\n",
      "#Epoch 130 with total epochs 300 at step 5 loss: 4.624951362609863 running average of batch loss 4.549664735794067, time 0.49132561683654785\n",
      "#Epoch 130 with total epochs 300 at step 6 loss: 4.844461917877197 running average of batch loss 4.5917786189488, time 0.48632192611694336\n",
      "#Epoch 130 with total epochs 300 at step 7 loss: 4.796213150024414 running average of batch loss 4.617332935333252, time 0.4923279285430908\n",
      "#Epoch 130 with total epochs 300 at step 8 loss: 4.755807876586914 running average of batch loss 4.632719039916992, time 0.5083341598510742\n",
      "#Epoch 130 with total epochs 300 at step 9 loss: 4.3941545486450195 running average of batch loss 4.608862590789795, time 0.49332594871520996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 130 with total epochs 300 at step 10 loss: 4.271603107452393 running average of batch loss 4.578202637759122, time 0.48534440994262695\n",
      "#Epoch 130 with total epochs 300 at step 11 loss: 4.856038570404053 running average of batch loss 4.601355632146199, time 0.48632311820983887\n",
      "#Epoch 130 with total epochs 300 at step 12 loss: 4.617323875427246 running average of batch loss 4.602583958552434, time 0.4973318576812744\n",
      "#Epoch 130 with total epochs 300 at step 13 loss: 4.864984035491943 running average of batch loss 4.62132682119097, time 0.5043578147888184\n",
      "#Epoch 130 with total epochs 300 at step 14 loss: 4.938474178314209 running average of batch loss 4.642469978332519, time 0.4883463382720947\n",
      "#Epoch 130 with total epochs 300 at step 15 loss: 4.335631847381592 running average of batch loss 4.6232925951480865, time 0.4953289031982422\n",
      "#Epoch 130 with total epochs 300 at step 16 loss: 4.310756206512451 running average of batch loss 4.604908101698932, time 0.5013325214385986\n",
      "#Epoch 130 with total epochs 300 at step 17 loss: 4.40487003326416 running average of batch loss 4.593794875674778, time 0.49535036087036133\n",
      "#Epoch 130 with total epochs 300 at step 18 loss: 3.978532075881958 running average of batch loss 4.561412623054103, time 0.48632383346557617\n",
      "#Epoch 130 with total epochs 300 at step 19 loss: 4.777105808258057 running average of batch loss 4.572197282314301, time 0.505359411239624\n",
      "#Epoch 130 with total epochs 300 at step 20 loss: 4.218708038330078 running average of batch loss 4.555364461172195, time 0.5173444747924805\n",
      "#Epoch 131 with total epochs 300 at step 0 loss: 4.386496067047119 running average of batch loss 4.386496067047119, time 0.5083596706390381\n",
      "#Epoch 131 with total epochs 300 at step 1 loss: 4.927237510681152 running average of batch loss 4.656866788864136, time 0.4973297119140625\n",
      "#Epoch 131 with total epochs 300 at step 2 loss: 4.595414638519287 running average of batch loss 4.6363827387491865, time 0.4853212833404541\n",
      "#Epoch 131 with total epochs 300 at step 3 loss: 4.624955177307129 running average of batch loss 4.633525848388672, time 0.48932671546936035\n",
      "#Epoch 131 with total epochs 300 at step 4 loss: 4.290532112121582 running average of batch loss 4.564927101135254, time 0.4863247871398926\n",
      "#Epoch 131 with total epochs 300 at step 5 loss: 4.52347469329834 running average of batch loss 4.5580183664957685, time 0.5013527870178223\n",
      "#Epoch 131 with total epochs 300 at step 6 loss: 4.292112827301025 running average of batch loss 4.520031860896519, time 0.4883251190185547\n",
      "#Epoch 131 with total epochs 300 at step 7 loss: 4.777120590209961 running average of batch loss 4.5521679520606995, time 0.5193405151367188\n",
      "#Epoch 131 with total epochs 300 at step 8 loss: 4.522497177124023 running average of batch loss 4.548871199289958, time 0.5143654346466064\n",
      "#Epoch 131 with total epochs 300 at step 9 loss: 4.163117408752441 running average of batch loss 4.510295820236206, time 0.4993588924407959\n",
      "#Epoch 131 with total epochs 300 at step 10 loss: 4.692134857177734 running average of batch loss 4.526826641776345, time 0.5033314228057861\n",
      "#Epoch 131 with total epochs 300 at step 11 loss: 4.599681854248047 running average of batch loss 4.53289790948232, time 0.5053355693817139\n",
      "#Epoch 131 with total epochs 300 at step 12 loss: 4.307510852813721 running average of batch loss 4.515560443584736, time 0.48834800720214844\n",
      "#Epoch 131 with total epochs 300 at step 13 loss: 3.9869039058685303 running average of batch loss 4.477799262319293, time 0.5143389701843262\n",
      "#Epoch 131 with total epochs 300 at step 14 loss: 4.088787078857422 running average of batch loss 4.451865116755168, time 0.502356767654419\n",
      "#Epoch 131 with total epochs 300 at step 15 loss: 4.799298286437988 running average of batch loss 4.473579689860344, time 0.487351655960083\n",
      "#Epoch 131 with total epochs 300 at step 16 loss: 4.317266464233398 running average of batch loss 4.4643847942352295, time 0.5043632984161377\n",
      "#Epoch 131 with total epochs 300 at step 17 loss: 4.367547512054443 running average of batch loss 4.459004945225185, time 0.5013518333435059\n",
      "#Epoch 131 with total epochs 300 at step 18 loss: 4.099223613739014 running average of batch loss 4.440069085673282, time 0.4873232841491699\n",
      "#Epoch 131 with total epochs 300 at step 19 loss: 4.336465835571289 running average of batch loss 4.434888923168183, time 0.4883239269256592\n",
      "#Epoch 131 with total epochs 300 at step 20 loss: 4.371233940124512 running average of batch loss 4.431857733499436, time 0.4873473644256592\n",
      "#Epoch 132 with total epochs 300 at step 0 loss: 4.791961193084717 running average of batch loss 4.791961193084717, time 0.4863443374633789\n",
      "#Epoch 132 with total epochs 300 at step 1 loss: 4.763458251953125 running average of batch loss 4.777709722518921, time 0.48932337760925293\n",
      "#Epoch 132 with total epochs 300 at step 2 loss: 4.851076602935791 running average of batch loss 4.802165349324544, time 0.4883236885070801\n",
      "#Epoch 132 with total epochs 300 at step 3 loss: 3.9230639934539795 running average of batch loss 4.582390010356903, time 0.4893472194671631\n",
      "#Epoch 132 with total epochs 300 at step 4 loss: 4.620871543884277 running average of batch loss 4.590086317062378, time 0.4903261661529541\n",
      "#Epoch 132 with total epochs 300 at step 5 loss: 4.697656154632568 running average of batch loss 4.608014623324077, time 0.4883244037628174\n",
      "#Epoch 132 with total epochs 300 at step 6 loss: 4.216256141662598 running average of batch loss 4.552049125943865, time 0.4913496971130371\n",
      "#Epoch 132 with total epochs 300 at step 7 loss: 3.9302818775177 running average of batch loss 4.4743282198905945, time 0.48632311820983887\n",
      "#Epoch 132 with total epochs 300 at step 8 loss: 4.621131896972656 running average of batch loss 4.4906397395663795, time 0.48732495307922363\n",
      "#Epoch 132 with total epochs 300 at step 9 loss: 4.191697597503662 running average of batch loss 4.460745525360108, time 0.4863457679748535\n",
      "#Epoch 132 with total epochs 300 at step 10 loss: 4.668634414672852 running average of batch loss 4.47964451529763, time 0.48734593391418457\n",
      "#Epoch 132 with total epochs 300 at step 11 loss: 4.534839630126953 running average of batch loss 4.484244108200073, time 0.48734617233276367\n",
      "#Epoch 132 with total epochs 300 at step 12 loss: 4.076423645019531 running average of batch loss 4.452873303340032, time 0.4903531074523926\n",
      "#Epoch 132 with total epochs 300 at step 13 loss: 4.952884674072266 running average of batch loss 4.488588401249477, time 0.5083346366882324\n",
      "#Epoch 132 with total epochs 300 at step 14 loss: 4.584538459777832 running average of batch loss 4.494985071818034, time 0.5133461952209473\n",
      "#Epoch 132 with total epochs 300 at step 15 loss: 4.441336631774902 running average of batch loss 4.491632044315338, time 0.5023298263549805\n",
      "#Epoch 132 with total epochs 300 at step 16 loss: 4.375800609588623 running average of batch loss 4.484818430507884, time 0.4883263111114502\n",
      "#Epoch 132 with total epochs 300 at step 17 loss: 4.083600044250488 running average of batch loss 4.462528520160252, time 0.5073337554931641\n",
      "#Epoch 132 with total epochs 300 at step 18 loss: 4.394365310668945 running average of batch loss 4.4589409828186035, time 0.48932337760925293\n",
      "#Epoch 132 with total epochs 300 at step 19 loss: 3.7875499725341797 running average of batch loss 4.425371432304383, time 0.487346887588501\n",
      "#Epoch 132 with total epochs 300 at step 20 loss: 4.681262493133545 running average of batch loss 4.437556720915294, time 0.525374174118042\n",
      "#Epoch 133 with total epochs 300 at step 0 loss: 4.622942924499512 running average of batch loss 4.622942924499512, time 0.48632264137268066\n",
      "#Epoch 133 with total epochs 300 at step 1 loss: 4.3078765869140625 running average of batch loss 4.465409755706787, time 0.4943265914916992\n",
      "#Epoch 133 with total epochs 300 at step 2 loss: 4.27126407623291 running average of batch loss 4.400694529215495, time 0.5043597221374512\n",
      "#Epoch 133 with total epochs 300 at step 3 loss: 4.751363754272461 running average of batch loss 4.488361835479736, time 0.4983539581298828\n",
      "#Epoch 133 with total epochs 300 at step 4 loss: 4.829257965087891 running average of batch loss 4.556541061401367, time 0.48834705352783203\n",
      "#Epoch 133 with total epochs 300 at step 5 loss: 4.106588840484619 running average of batch loss 4.481549024581909, time 0.5313761234283447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 133 with total epochs 300 at step 6 loss: 4.52887487411499 running average of batch loss 4.488309860229492, time 0.4983546733856201\n",
      "#Epoch 133 with total epochs 300 at step 7 loss: 4.652820587158203 running average of batch loss 4.508873701095581, time 0.5243716239929199\n",
      "#Epoch 133 with total epochs 300 at step 8 loss: 4.4970574378967285 running average of batch loss 4.507560782962376, time 0.5073971748352051\n",
      "#Epoch 133 with total epochs 300 at step 9 loss: 4.820627212524414 running average of batch loss 4.538867425918579, time 0.4903221130371094\n",
      "#Epoch 133 with total epochs 300 at step 10 loss: 4.705390930175781 running average of batch loss 4.554005926305598, time 0.49535369873046875\n",
      "#Epoch 133 with total epochs 300 at step 11 loss: 4.146698474884033 running average of batch loss 4.520063638687134, time 0.5203657150268555\n",
      "#Epoch 133 with total epochs 300 at step 12 loss: 4.151731014251709 running average of batch loss 4.491730359884409, time 0.4903230667114258\n",
      "#Epoch 133 with total epochs 300 at step 13 loss: 4.376224040985107 running average of batch loss 4.483479908534458, time 0.530376672744751\n",
      "#Epoch 133 with total epochs 300 at step 14 loss: 4.442037105560303 running average of batch loss 4.480717055002848, time 0.487346887588501\n",
      "#Epoch 133 with total epochs 300 at step 15 loss: 4.874017238616943 running average of batch loss 4.505298316478729, time 0.5353784561157227\n",
      "#Epoch 133 with total epochs 300 at step 16 loss: 4.28423547744751 running average of batch loss 4.492294620065128, time 0.4993555545806885\n",
      "#Epoch 133 with total epochs 300 at step 17 loss: 4.719879150390625 running average of batch loss 4.504938205083211, time 0.524371862411499\n",
      "#Epoch 133 with total epochs 300 at step 18 loss: 4.3728556632995605 running average of batch loss 4.497986492357756, time 0.48832130432128906\n",
      "#Epoch 133 with total epochs 300 at step 19 loss: 4.565682888031006 running average of batch loss 4.501371312141418, time 0.5363810062408447\n",
      "#Epoch 133 with total epochs 300 at step 20 loss: 4.422001838684082 running average of batch loss 4.4975918134053545, time 0.4963514804840088\n",
      "#Epoch 134 with total epochs 300 at step 0 loss: 4.84572696685791 running average of batch loss 4.84572696685791, time 0.5243716239929199\n",
      "#Epoch 134 with total epochs 300 at step 1 loss: 4.182527542114258 running average of batch loss 4.514127254486084, time 0.48734593391418457\n",
      "#Epoch 134 with total epochs 300 at step 2 loss: 4.305344581604004 running average of batch loss 4.444533030192058, time 0.5373756885528564\n",
      "#Epoch 134 with total epochs 300 at step 3 loss: 4.442073822021484 running average of batch loss 4.443918228149414, time 0.4873220920562744\n",
      "#Epoch 134 with total epochs 300 at step 4 loss: 4.735246658325195 running average of batch loss 4.50218391418457, time 0.5013294219970703\n",
      "#Epoch 134 with total epochs 300 at step 5 loss: 4.473443508148193 running average of batch loss 4.497393846511841, time 0.498354434967041\n",
      "#Epoch 134 with total epochs 300 at step 6 loss: 4.194055080413818 running average of batch loss 4.454059737069266, time 0.48534464836120605\n",
      "#Epoch 134 with total epochs 300 at step 7 loss: 4.2729411125183105 running average of batch loss 4.431419909000397, time 0.4913482666015625\n",
      "#Epoch 134 with total epochs 300 at step 8 loss: 4.164572238922119 running average of batch loss 4.4017701678805885, time 0.5383825302124023\n",
      "#Epoch 134 with total epochs 300 at step 9 loss: 4.465490341186523 running average of batch loss 4.408142185211181, time 0.48932576179504395\n",
      "#Epoch 134 with total epochs 300 at step 10 loss: 4.262095928192139 running average of batch loss 4.394865252754905, time 0.48734545707702637\n",
      "#Epoch 134 with total epochs 300 at step 11 loss: 4.574945449829102 running average of batch loss 4.409871935844421, time 0.486344575881958\n",
      "#Epoch 134 with total epochs 300 at step 12 loss: 4.451700687408447 running average of batch loss 4.413089532118577, time 0.48832178115844727\n",
      "#Epoch 134 with total epochs 300 at step 13 loss: 4.311438083648682 running average of batch loss 4.4058287143707275, time 0.48834729194641113\n",
      "#Epoch 134 with total epochs 300 at step 14 loss: 4.159658908843994 running average of batch loss 4.389417394002279, time 0.4873225688934326\n",
      "#Epoch 134 with total epochs 300 at step 15 loss: 4.264406204223633 running average of batch loss 4.381604194641113, time 0.49034786224365234\n",
      "#Epoch 134 with total epochs 300 at step 16 loss: 4.270935535430908 running average of batch loss 4.375094273511102, time 0.5283763408660889\n",
      "#Epoch 134 with total epochs 300 at step 17 loss: 4.529892921447754 running average of batch loss 4.383694198396471, time 0.48734426498413086\n",
      "#Epoch 134 with total epochs 300 at step 18 loss: 3.9723124504089355 running average of batch loss 4.362042527449758, time 0.487346887588501\n",
      "#Epoch 134 with total epochs 300 at step 19 loss: 4.027798175811768 running average of batch loss 4.345330309867859, time 0.5213701725006104\n",
      "#Epoch 134 with total epochs 300 at step 20 loss: 4.963229656219482 running average of batch loss 4.374754088265555, time 0.49034905433654785\n",
      "#Epoch 135 with total epochs 300 at step 0 loss: 4.310605525970459 running average of batch loss 4.310605525970459, time 0.4873464107513428\n",
      "#Epoch 135 with total epochs 300 at step 1 loss: 4.370079517364502 running average of batch loss 4.3403425216674805, time 0.48632264137268066\n",
      "#Epoch 135 with total epochs 300 at step 2 loss: 4.583401203155518 running average of batch loss 4.421362082163493, time 0.4883444309234619\n",
      "#Epoch 135 with total epochs 300 at step 3 loss: 4.435546875 running average of batch loss 4.42490828037262, time 0.4863455295562744\n",
      "#Epoch 135 with total epochs 300 at step 4 loss: 4.511989593505859 running average of batch loss 4.442324542999268, time 0.48834681510925293\n",
      "#Epoch 135 with total epochs 300 at step 5 loss: 4.886671543121338 running average of batch loss 4.516382376352946, time 0.4863443374633789\n",
      "#Epoch 135 with total epochs 300 at step 6 loss: 3.963542938232422 running average of batch loss 4.4374053137643, time 0.5233452320098877\n",
      "#Epoch 135 with total epochs 300 at step 7 loss: 4.402120590209961 running average of batch loss 4.432994723320007, time 0.5363802909851074\n",
      "#Epoch 135 with total epochs 300 at step 8 loss: 4.114786148071289 running average of batch loss 4.397638214959039, time 0.4963538646697998\n",
      "#Epoch 135 with total epochs 300 at step 9 loss: 4.080399990081787 running average of batch loss 4.365914392471313, time 0.5253727436065674\n",
      "#Epoch 135 with total epochs 300 at step 10 loss: 4.318514823913574 running average of batch loss 4.361605340784246, time 0.5183675289154053\n",
      "#Epoch 135 with total epochs 300 at step 11 loss: 4.153229713439941 running average of batch loss 4.344240705172221, time 0.49132585525512695\n",
      "#Epoch 135 with total epochs 300 at step 12 loss: 4.387056827545166 running average of batch loss 4.347534253047063, time 0.5333552360534668\n",
      "#Epoch 135 with total epochs 300 at step 13 loss: 4.306563854217529 running average of batch loss 4.344607795987811, time 0.4893534183502197\n",
      "#Epoch 135 with total epochs 300 at step 14 loss: 4.51143741607666 running average of batch loss 4.355729770660401, time 0.5123350620269775\n",
      "#Epoch 135 with total epochs 300 at step 15 loss: 4.535383224487305 running average of batch loss 4.366958111524582, time 0.49034857749938965\n",
      "#Epoch 135 with total epochs 300 at step 16 loss: 4.048638820648193 running average of batch loss 4.3482334473553825, time 0.515366792678833\n",
      "#Epoch 135 with total epochs 300 at step 17 loss: 4.551701068878174 running average of batch loss 4.3595372041066485, time 0.5613982677459717\n",
      "#Epoch 135 with total epochs 300 at step 18 loss: 4.24968147277832 running average of batch loss 4.353755323510421, time 0.49034833908081055\n",
      "#Epoch 135 with total epochs 300 at step 19 loss: 4.291679859161377 running average of batch loss 4.350651550292969, time 0.5073606967926025\n",
      "#Epoch 135 with total epochs 300 at step 20 loss: 4.6934638023376465 running average of batch loss 4.3669759432474775, time 0.4943521022796631\n",
      "#Epoch 136 with total epochs 300 at step 0 loss: 4.494513988494873 running average of batch loss 4.494513988494873, time 0.4993298053741455\n",
      "#Epoch 136 with total epochs 300 at step 1 loss: 4.987518787384033 running average of batch loss 4.741016387939453, time 0.5313742160797119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 136 with total epochs 300 at step 2 loss: 4.607800483703613 running average of batch loss 4.696611086527507, time 0.4873201847076416\n",
      "#Epoch 136 with total epochs 300 at step 3 loss: 3.9410715103149414 running average of batch loss 4.507726192474365, time 0.4943523406982422\n",
      "#Epoch 136 with total epochs 300 at step 4 loss: 3.864084243774414 running average of batch loss 4.378997802734375, time 0.5003316402435303\n",
      "#Epoch 136 with total epochs 300 at step 5 loss: 4.115625381469727 running average of batch loss 4.335102399190267, time 0.5253472328186035\n",
      "#Epoch 136 with total epochs 300 at step 6 loss: 4.285038471221924 running average of batch loss 4.327950409480503, time 0.5243725776672363\n",
      "#Epoch 136 with total epochs 300 at step 7 loss: 5.105589866638184 running average of batch loss 4.425155341625214, time 0.4873223304748535\n",
      "#Epoch 136 with total epochs 300 at step 8 loss: 4.154747009277344 running average of batch loss 4.395109971364339, time 0.4873232841491699\n",
      "#Epoch 136 with total epochs 300 at step 9 loss: 4.264133930206299 running average of batch loss 4.382012367248535, time 0.5013570785522461\n",
      "#Epoch 136 with total epochs 300 at step 10 loss: 4.532080173492432 running average of batch loss 4.39565489508889, time 0.4883265495300293\n",
      "#Epoch 136 with total epochs 300 at step 11 loss: 4.502871036529541 running average of batch loss 4.404589573542277, time 0.5013282299041748\n",
      "#Epoch 136 with total epochs 300 at step 12 loss: 4.535885334014893 running average of batch loss 4.414689247424786, time 0.4853222370147705\n",
      "#Epoch 136 with total epochs 300 at step 13 loss: 4.354971885681152 running average of batch loss 4.410423721585955, time 0.5013570785522461\n",
      "#Epoch 136 with total epochs 300 at step 14 loss: 4.31510066986084 running average of batch loss 4.404068851470948, time 0.5323750972747803\n",
      "#Epoch 136 with total epochs 300 at step 15 loss: 4.471548557281494 running average of batch loss 4.4082863330841064, time 0.49132633209228516\n",
      "#Epoch 136 with total epochs 300 at step 16 loss: 4.652223587036133 running average of batch loss 4.422635583316579, time 0.49832677841186523\n",
      "#Epoch 136 with total epochs 300 at step 17 loss: 4.325225353240967 running average of batch loss 4.417223903867933, time 0.5183675289154053\n",
      "#Epoch 136 with total epochs 300 at step 18 loss: 4.38067102432251 running average of batch loss 4.415300068102385, time 0.5323560237884521\n",
      "#Epoch 136 with total epochs 300 at step 19 loss: 4.328013896942139 running average of batch loss 4.410935759544373, time 0.49032139778137207\n",
      "#Epoch 136 with total epochs 300 at step 20 loss: 4.392925262451172 running average of batch loss 4.410078116825649, time 0.4883244037628174\n",
      "#Epoch 137 with total epochs 300 at step 0 loss: 4.944451808929443 running average of batch loss 4.944451808929443, time 0.49234962463378906\n",
      "#Epoch 137 with total epochs 300 at step 1 loss: 4.829995155334473 running average of batch loss 4.887223482131958, time 0.4883451461791992\n",
      "#Epoch 137 with total epochs 300 at step 2 loss: 4.173295497894287 running average of batch loss 4.649247487386067, time 0.4863452911376953\n",
      "#Epoch 137 with total epochs 300 at step 3 loss: 4.763391494750977 running average of batch loss 4.677783489227295, time 0.48534560203552246\n",
      "#Epoch 137 with total epochs 300 at step 4 loss: 4.069119930267334 running average of batch loss 4.556050777435303, time 0.4863452911376953\n",
      "#Epoch 137 with total epochs 300 at step 5 loss: 5.090000629425049 running average of batch loss 4.645042419433594, time 0.4863452911376953\n",
      "#Epoch 137 with total epochs 300 at step 6 loss: 4.131383895874023 running average of batch loss 4.571662630353655, time 0.48734593391418457\n",
      "#Epoch 137 with total epochs 300 at step 7 loss: 3.816617965698242 running average of batch loss 4.4772820472717285, time 0.4893481731414795\n",
      "#Epoch 137 with total epochs 300 at step 8 loss: 4.1990814208984375 running average of batch loss 4.446370866563585, time 0.5263760089874268\n",
      "#Epoch 137 with total epochs 300 at step 9 loss: 4.679915904998779 running average of batch loss 4.4697253704071045, time 0.48832201957702637\n",
      "#Epoch 137 with total epochs 300 at step 10 loss: 4.244828701019287 running average of batch loss 4.449280218644575, time 0.4893460273742676\n",
      "#Epoch 137 with total epochs 300 at step 11 loss: 4.796106338500977 running average of batch loss 4.478182395299275, time 0.5243496894836426\n",
      "#Epoch 137 with total epochs 300 at step 12 loss: 4.786909580230713 running average of batch loss 4.501930640294002, time 0.4883248805999756\n",
      "#Epoch 137 with total epochs 300 at step 13 loss: 4.714330673217773 running average of batch loss 4.517102071217129, time 0.4863457679748535\n",
      "#Epoch 137 with total epochs 300 at step 14 loss: 4.203127384185791 running average of batch loss 4.496170425415039, time 0.49132776260375977\n",
      "#Epoch 137 with total epochs 300 at step 15 loss: 4.191396236419678 running average of batch loss 4.477122038602829, time 0.5403814315795898\n",
      "#Epoch 137 with total epochs 300 at step 16 loss: 3.923309803009033 running average of batch loss 4.444544848273782, time 0.503359317779541\n",
      "#Epoch 137 with total epochs 300 at step 17 loss: 4.240440845489502 running average of batch loss 4.433205737007989, time 0.48631858825683594\n",
      "#Epoch 137 with total epochs 300 at step 18 loss: 4.200559139251709 running average of batch loss 4.420961179231343, time 0.5103633403778076\n",
      "#Epoch 137 with total epochs 300 at step 19 loss: 4.2630720138549805 running average of batch loss 4.413066720962524, time 0.507357120513916\n",
      "#Epoch 137 with total epochs 300 at step 20 loss: 4.22352933883667 running average of batch loss 4.404041131337483, time 0.48632192611694336\n",
      "#Epoch 138 with total epochs 300 at step 0 loss: 4.227709770202637 running average of batch loss 4.227709770202637, time 0.48432302474975586\n",
      "#Epoch 138 with total epochs 300 at step 1 loss: 4.401128768920898 running average of batch loss 4.314419269561768, time 0.49234986305236816\n",
      "#Epoch 138 with total epochs 300 at step 2 loss: 4.284074306488037 running average of batch loss 4.304304281870524, time 0.5133373737335205\n",
      "#Epoch 138 with total epochs 300 at step 3 loss: 4.4250264167785645 running average of batch loss 4.334484815597534, time 0.49132752418518066\n",
      "#Epoch 138 with total epochs 300 at step 4 loss: 4.2788166999816895 running average of batch loss 4.323351192474365, time 0.5013566017150879\n",
      "#Epoch 138 with total epochs 300 at step 5 loss: 4.395419597625732 running average of batch loss 4.335362593332927, time 0.5233709812164307\n",
      "#Epoch 138 with total epochs 300 at step 6 loss: 4.707052707672119 running average of batch loss 4.388461181095669, time 0.487337589263916\n",
      "#Epoch 138 with total epochs 300 at step 7 loss: 4.531538963317871 running average of batch loss 4.406345903873444, time 0.48834824562072754\n",
      "#Epoch 138 with total epochs 300 at step 8 loss: 4.215424537658691 running average of batch loss 4.385132418738471, time 0.506333589553833\n",
      "#Epoch 138 with total epochs 300 at step 9 loss: 4.48688268661499 running average of batch loss 4.395307445526123, time 0.4863457679748535\n",
      "#Epoch 138 with total epochs 300 at step 10 loss: 4.234562873840332 running average of batch loss 4.380694302645597, time 0.48732805252075195\n",
      "#Epoch 138 with total epochs 300 at step 11 loss: 4.020452499389648 running average of batch loss 4.350674152374268, time 0.5213701725006104\n",
      "#Epoch 138 with total epochs 300 at step 12 loss: 4.257259845733643 running average of batch loss 4.343488436478835, time 0.48834872245788574\n",
      "#Epoch 138 with total epochs 300 at step 13 loss: 4.396571159362793 running average of batch loss 4.3472800595419745, time 0.5263748168945312\n",
      "#Epoch 138 with total epochs 300 at step 14 loss: 4.080879211425781 running average of batch loss 4.329520003000895, time 0.4973278045654297\n",
      "#Epoch 138 with total epochs 300 at step 15 loss: 3.976100444793701 running average of batch loss 4.307431280612946, time 0.5223696231842041\n",
      "#Epoch 138 with total epochs 300 at step 16 loss: 4.561532974243164 running average of batch loss 4.322378439061782, time 0.48734545707702637\n",
      "#Epoch 138 with total epochs 300 at step 17 loss: 4.4325385093688965 running average of batch loss 4.3284984429677325, time 0.4883229732513428\n",
      "#Epoch 138 with total epochs 300 at step 18 loss: 4.133063793182373 running average of batch loss 4.318212408768503, time 0.5043594837188721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 138 with total epochs 300 at step 19 loss: 4.416329860687256 running average of batch loss 4.323118281364441, time 0.526374340057373\n",
      "#Epoch 138 with total epochs 300 at step 20 loss: 4.256453990936279 running average of batch loss 4.319943791344052, time 0.4993302822113037\n",
      "#Epoch 139 with total epochs 300 at step 0 loss: 4.426852226257324 running average of batch loss 4.426852226257324, time 0.4873232841491699\n",
      "#Epoch 139 with total epochs 300 at step 1 loss: 4.6288275718688965 running average of batch loss 4.52783989906311, time 0.5513911247253418\n",
      "#Epoch 139 with total epochs 300 at step 2 loss: 4.34383487701416 running average of batch loss 4.46650489171346, time 0.49034786224365234\n",
      "#Epoch 139 with total epochs 300 at step 3 loss: 4.472582817077637 running average of batch loss 4.468024373054504, time 0.5453860759735107\n",
      "#Epoch 139 with total epochs 300 at step 4 loss: 4.201725959777832 running average of batch loss 4.41476469039917, time 0.5013570785522461\n",
      "#Epoch 139 with total epochs 300 at step 5 loss: 4.587430477142334 running average of batch loss 4.44354232152303, time 0.4883236885070801\n",
      "#Epoch 139 with total epochs 300 at step 6 loss: 4.3158392906188965 running average of batch loss 4.425299031393869, time 0.5103673934936523\n",
      "#Epoch 139 with total epochs 300 at step 7 loss: 4.004483222961426 running average of batch loss 4.372697055339813, time 0.5083341598510742\n",
      "#Epoch 139 with total epochs 300 at step 8 loss: 3.9593276977539062 running average of batch loss 4.326767126719157, time 0.5033583641052246\n",
      "#Epoch 139 with total epochs 300 at step 9 loss: 4.391870975494385 running average of batch loss 4.3332775115966795, time 0.49034690856933594\n",
      "#Epoch 139 with total epochs 300 at step 10 loss: 4.339167594909668 running average of batch loss 4.333812973716042, time 0.5253729820251465\n",
      "#Epoch 139 with total epochs 300 at step 11 loss: 4.454786777496338 running average of batch loss 4.343894124031067, time 0.48734617233276367\n",
      "#Epoch 139 with total epochs 300 at step 12 loss: 4.383330345153809 running average of batch loss 4.346927679502047, time 0.48534440994262695\n",
      "#Epoch 139 with total epochs 300 at step 13 loss: 4.01009464263916 running average of batch loss 4.322868176868984, time 0.4893479347229004\n",
      "#Epoch 139 with total epochs 300 at step 14 loss: 4.432135105133057 running average of batch loss 4.330152638753256, time 0.48834753036499023\n",
      "#Epoch 139 with total epochs 300 at step 15 loss: 4.559441089630127 running average of batch loss 4.34448316693306, time 0.4883239269256592\n",
      "#Epoch 139 with total epochs 300 at step 16 loss: 4.063671112060547 running average of batch loss 4.3279648107640885, time 0.5213701725006104\n",
      "#Epoch 139 with total epochs 300 at step 17 loss: 3.942091464996338 running average of batch loss 4.30652740266588, time 0.4893474578857422\n",
      "#Epoch 139 with total epochs 300 at step 18 loss: 4.308987617492676 running average of batch loss 4.306656887656764, time 0.5233728885650635\n",
      "#Epoch 139 with total epochs 300 at step 19 loss: 4.331104755401611 running average of batch loss 4.3078792810440065, time 0.4873213768005371\n",
      "#Epoch 139 with total epochs 300 at step 20 loss: 4.441313743591309 running average of batch loss 4.314233303070068, time 0.48834705352783203\n",
      "#Epoch 140 with total epochs 300 at step 0 loss: 3.9897713661193848 running average of batch loss 3.9897713661193848, time 0.48832225799560547\n",
      "#Epoch 140 with total epochs 300 at step 1 loss: 4.097890377044678 running average of batch loss 4.043830871582031, time 0.48734569549560547\n",
      "#Epoch 140 with total epochs 300 at step 2 loss: 4.7561187744140625 running average of batch loss 4.281260172526042, time 0.48834776878356934\n",
      "#Epoch 140 with total epochs 300 at step 3 loss: 3.895925521850586 running average of batch loss 4.184926509857178, time 0.4923224449157715\n",
      "#Epoch 140 with total epochs 300 at step 4 loss: 3.8888702392578125 running average of batch loss 4.125715255737305, time 0.48832273483276367\n",
      "#Epoch 140 with total epochs 300 at step 5 loss: 4.152846336364746 running average of batch loss 4.130237102508545, time 0.48932385444641113\n",
      "#Epoch 140 with total epochs 300 at step 6 loss: 4.680673122406006 running average of batch loss 4.208870819636753, time 0.48732447624206543\n",
      "#Epoch 140 with total epochs 300 at step 7 loss: 4.37799072265625 running average of batch loss 4.230010807514191, time 0.486346960067749\n",
      "#Epoch 140 with total epochs 300 at step 8 loss: 4.224984169006348 running average of batch loss 4.229452292124431, time 0.5453863143920898\n",
      "#Epoch 140 with total epochs 300 at step 9 loss: 4.23484992980957 running average of batch loss 4.229992055892945, time 0.48834776878356934\n",
      "#Epoch 140 with total epochs 300 at step 10 loss: 4.349603652954102 running average of batch loss 4.240865837443959, time 0.523371696472168\n",
      "#Epoch 140 with total epochs 300 at step 11 loss: 4.2316575050354 running average of batch loss 4.240098476409912, time 0.4873220920562744\n",
      "#Epoch 140 with total epochs 300 at step 12 loss: 4.290571212768555 running average of batch loss 4.243980994591346, time 0.49833178520202637\n",
      "#Epoch 140 with total epochs 300 at step 13 loss: 4.249240398406982 running average of batch loss 4.244356666292463, time 0.48834657669067383\n",
      "#Epoch 140 with total epochs 300 at step 14 loss: 4.5823564529418945 running average of batch loss 4.266889985402425, time 0.5313527584075928\n",
      "#Epoch 140 with total epochs 300 at step 15 loss: 4.369051456451416 running average of batch loss 4.273275077342987, time 0.48932409286499023\n",
      "#Epoch 140 with total epochs 300 at step 16 loss: 4.032740116119385 running average of batch loss 4.259125961976893, time 0.5233480930328369\n",
      "#Epoch 140 with total epochs 300 at step 17 loss: 4.141385555267334 running average of batch loss 4.252584828270806, time 0.4873232841491699\n",
      "#Epoch 140 with total epochs 300 at step 18 loss: 4.362399101257324 running average of batch loss 4.258364526849044, time 0.5053603649139404\n",
      "#Epoch 140 with total epochs 300 at step 19 loss: 3.88529896736145 running average of batch loss 4.239711248874665, time 0.5033330917358398\n",
      "#Epoch 140 with total epochs 300 at step 20 loss: 4.586085796356201 running average of batch loss 4.256205274945214, time 0.5053496360778809\n",
      "avg difference between predicted and ground truth batch wise 6.109952058826174\n",
      "#Epoch 141 with total epochs 300 at step 0 loss: 4.693829536437988 running average of batch loss 4.693829536437988, time 0.5203700065612793\n",
      "#Epoch 141 with total epochs 300 at step 1 loss: 4.395038604736328 running average of batch loss 4.544434070587158, time 0.48834967613220215\n",
      "#Epoch 141 with total epochs 300 at step 2 loss: 4.021023273468018 running average of batch loss 4.369963804880778, time 0.497326135635376\n",
      "#Epoch 141 with total epochs 300 at step 3 loss: 4.339015960693359 running average of batch loss 4.362226843833923, time 0.4873237609863281\n",
      "#Epoch 141 with total epochs 300 at step 4 loss: 4.3593525886535645 running average of batch loss 4.361651992797851, time 0.493328332901001\n",
      "#Epoch 141 with total epochs 300 at step 5 loss: 4.522176742553711 running average of batch loss 4.388406117757161, time 0.49734950065612793\n",
      "#Epoch 141 with total epochs 300 at step 6 loss: 4.137806415557861 running average of batch loss 4.352606160300119, time 0.5233714580535889\n",
      "#Epoch 141 with total epochs 300 at step 7 loss: 4.136432647705078 running average of batch loss 4.3255844712257385, time 0.49034762382507324\n",
      "#Epoch 141 with total epochs 300 at step 8 loss: 4.353002548217773 running average of batch loss 4.3286309242248535, time 0.526374340057373\n",
      "#Epoch 141 with total epochs 300 at step 9 loss: 3.879504919052124 running average of batch loss 4.28371832370758, time 0.48832201957702637\n",
      "#Epoch 141 with total epochs 300 at step 10 loss: 4.2742462158203125 running average of batch loss 4.282857222990557, time 0.5273737907409668\n",
      "#Epoch 141 with total epochs 300 at step 11 loss: 4.507802963256836 running average of batch loss 4.30160270134608, time 0.4963560104370117\n",
      "#Epoch 141 with total epochs 300 at step 12 loss: 4.147205829620361 running average of batch loss 4.28972601890564, time 0.4963526725769043\n",
      "#Epoch 141 with total epochs 300 at step 13 loss: 4.093265533447266 running average of batch loss 4.275693127087185, time 0.5203695297241211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 141 with total epochs 300 at step 14 loss: 4.02508020401001 running average of batch loss 4.258985598882039, time 0.5133664608001709\n",
      "#Epoch 141 with total epochs 300 at step 15 loss: 3.979539394378662 running average of batch loss 4.241520211100578, time 0.5063581466674805\n",
      "#Epoch 141 with total epochs 300 at step 16 loss: 4.441503524780273 running average of batch loss 4.253283935434678, time 0.5263516902923584\n",
      "#Epoch 141 with total epochs 300 at step 17 loss: 5.0574798583984375 running average of batch loss 4.2979614867104425, time 0.5003566741943359\n",
      "#Epoch 141 with total epochs 300 at step 18 loss: 4.159944534301758 running average of batch loss 4.290697436583669, time 0.5243492126464844\n",
      "#Epoch 141 with total epochs 300 at step 19 loss: 3.976304054260254 running average of batch loss 4.274977767467499, time 0.4913511276245117\n",
      "#Epoch 141 with total epochs 300 at step 20 loss: 4.9160051345825195 running average of batch loss 4.3055028801872615, time 0.4893496036529541\n",
      "#Epoch 142 with total epochs 300 at step 0 loss: 4.443139553070068 running average of batch loss 4.443139553070068, time 0.4893481731414795\n",
      "#Epoch 142 with total epochs 300 at step 1 loss: 4.238569259643555 running average of batch loss 4.3408544063568115, time 0.48932647705078125\n",
      "#Epoch 142 with total epochs 300 at step 2 loss: 4.488156318664551 running average of batch loss 4.389955043792725, time 0.48834753036499023\n",
      "#Epoch 142 with total epochs 300 at step 3 loss: 4.266170978546143 running average of batch loss 4.359009027481079, time 0.49034786224365234\n",
      "#Epoch 142 with total epochs 300 at step 4 loss: 4.606144905090332 running average of batch loss 4.40843620300293, time 0.4893472194671631\n",
      "#Epoch 142 with total epochs 300 at step 5 loss: 4.088339328765869 running average of batch loss 4.35508672396342, time 0.5433862209320068\n",
      "#Epoch 142 with total epochs 300 at step 6 loss: 4.1365251541137695 running average of batch loss 4.323863642556327, time 0.4893472194671631\n",
      "#Epoch 142 with total epochs 300 at step 7 loss: 4.542453765869141 running average of batch loss 4.3511874079704285, time 0.5263738632202148\n",
      "#Epoch 142 with total epochs 300 at step 8 loss: 4.218727111816406 running average of batch loss 4.336469597286648, time 0.4893474578857422\n",
      "#Epoch 142 with total epochs 300 at step 9 loss: 3.8769309520721436 running average of batch loss 4.290515732765198, time 0.5273749828338623\n",
      "#Epoch 142 with total epochs 300 at step 10 loss: 4.125683307647705 running average of batch loss 4.275530966845426, time 0.48834729194641113\n",
      "#Epoch 142 with total epochs 300 at step 11 loss: 4.70814323425293 running average of batch loss 4.311581989129384, time 0.4873228073120117\n",
      "#Epoch 142 with total epochs 300 at step 12 loss: 4.185356140136719 running average of batch loss 4.301872308437641, time 0.4893455505371094\n",
      "#Epoch 142 with total epochs 300 at step 13 loss: 3.808523654937744 running average of batch loss 4.266633118901934, time 0.48734569549560547\n",
      "#Epoch 142 with total epochs 300 at step 14 loss: 4.564186096191406 running average of batch loss 4.286469984054565, time 0.4893496036529541\n",
      "#Epoch 142 with total epochs 300 at step 15 loss: 4.161868572235107 running average of batch loss 4.278682395815849, time 0.5293498039245605\n",
      "#Epoch 142 with total epochs 300 at step 16 loss: 4.350070953369141 running average of batch loss 4.282881722730749, time 0.5243730545043945\n",
      "#Epoch 142 with total epochs 300 at step 17 loss: 4.553776741027832 running average of batch loss 4.297931445969476, time 0.4873228073120117\n",
      "#Epoch 142 with total epochs 300 at step 18 loss: 4.354615211486816 running average of batch loss 4.300914802049336, time 0.4873466491699219\n",
      "#Epoch 142 with total epochs 300 at step 19 loss: 4.2716898918151855 running average of batch loss 4.299453556537628, time 0.5393819808959961\n",
      "#Epoch 142 with total epochs 300 at step 20 loss: 4.528203964233398 running average of batch loss 4.31034643309457, time 0.48734593391418457\n",
      "#Epoch 143 with total epochs 300 at step 0 loss: 4.232699871063232 running average of batch loss 4.232699871063232, time 0.4873476028442383\n",
      "#Epoch 143 with total epochs 300 at step 1 loss: 4.259947299957275 running average of batch loss 4.246323585510254, time 0.5033531188964844\n",
      "#Epoch 143 with total epochs 300 at step 2 loss: 4.62951135635376 running average of batch loss 4.374052842458089, time 0.5263757705688477\n",
      "#Epoch 143 with total epochs 300 at step 3 loss: 4.479231834411621 running average of batch loss 4.400347590446472, time 0.49132657051086426\n",
      "#Epoch 143 with total epochs 300 at step 4 loss: 3.9842920303344727 running average of batch loss 4.317136478424072, time 0.5013244152069092\n",
      "#Epoch 143 with total epochs 300 at step 5 loss: 3.958643913269043 running average of batch loss 4.2573877175649, time 0.4933488368988037\n",
      "#Epoch 143 with total epochs 300 at step 6 loss: 4.312625408172607 running average of batch loss 4.2652788162231445, time 0.5093345642089844\n",
      "#Epoch 143 with total epochs 300 at step 7 loss: 5.007556915283203 running average of batch loss 4.358063578605652, time 0.5113375186920166\n",
      "#Epoch 143 with total epochs 300 at step 8 loss: 3.9060585498809814 running average of batch loss 4.307840797636244, time 0.4883451461791992\n",
      "#Epoch 143 with total epochs 300 at step 9 loss: 4.335659503936768 running average of batch loss 4.310622668266296, time 0.49034976959228516\n",
      "#Epoch 143 with total epochs 300 at step 10 loss: 3.933347702026367 running average of batch loss 4.276324944062666, time 0.49735021591186523\n",
      "#Epoch 143 with total epochs 300 at step 11 loss: 4.018024921417236 running average of batch loss 4.254799942175548, time 0.48632192611694336\n",
      "#Epoch 143 with total epochs 300 at step 12 loss: 4.3594865798950195 running average of batch loss 4.26285276046166, time 0.4893467426300049\n",
      "#Epoch 143 with total epochs 300 at step 13 loss: 4.1854376792907715 running average of batch loss 4.257323111806597, time 0.5233714580535889\n",
      "#Epoch 143 with total epochs 300 at step 14 loss: 4.188231945037842 running average of batch loss 4.252717034022013, time 0.48734617233276367\n",
      "#Epoch 143 with total epochs 300 at step 15 loss: 4.507577419281006 running average of batch loss 4.2686458081007, time 0.5283758640289307\n",
      "#Epoch 143 with total epochs 300 at step 16 loss: 4.197180271148682 running average of batch loss 4.264441952985876, time 0.4873199462890625\n",
      "#Epoch 143 with total epochs 300 at step 17 loss: 4.2785468101501465 running average of batch loss 4.265225556161669, time 0.5323774814605713\n",
      "#Epoch 143 with total epochs 300 at step 18 loss: 4.016650199890137 running average of batch loss 4.252142642673693, time 0.48833680152893066\n",
      "#Epoch 143 with total epochs 300 at step 19 loss: 4.41208553314209 running average of batch loss 4.260139787197113, time 0.4893484115600586\n",
      "#Epoch 143 with total epochs 300 at step 20 loss: 4.216395378112793 running average of batch loss 4.258056720097859, time 0.48831868171691895\n",
      "#Epoch 144 with total epochs 300 at step 0 loss: 4.237987518310547 running average of batch loss 4.237987518310547, time 0.4923522472381592\n",
      "#Epoch 144 with total epochs 300 at step 1 loss: 4.333624839782715 running average of batch loss 4.285806179046631, time 0.4963247776031494\n",
      "#Epoch 144 with total epochs 300 at step 2 loss: 4.611656665802002 running average of batch loss 4.394423007965088, time 0.532355546951294\n",
      "#Epoch 144 with total epochs 300 at step 3 loss: 4.078746318817139 running average of batch loss 4.315503835678101, time 0.4893479347229004\n",
      "#Epoch 144 with total epochs 300 at step 4 loss: 4.189394950866699 running average of batch loss 4.29028205871582, time 0.5203502178192139\n",
      "#Epoch 144 with total epochs 300 at step 5 loss: 4.088521957397461 running average of batch loss 4.256655375162761, time 0.5023281574249268\n",
      "#Epoch 144 with total epochs 300 at step 6 loss: 4.391234397888184 running average of batch loss 4.275880949837821, time 0.5093615055084229\n",
      "#Epoch 144 with total epochs 300 at step 7 loss: 4.207484722137451 running average of batch loss 4.267331421375275, time 0.5083627700805664\n",
      "#Epoch 144 with total epochs 300 at step 8 loss: 4.0653886795043945 running average of batch loss 4.244893338945177, time 0.49832916259765625\n",
      "#Epoch 144 with total epochs 300 at step 9 loss: 4.377934455871582 running average of batch loss 4.258197450637818, time 0.4973263740539551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 144 with total epochs 300 at step 10 loss: 4.456472873687744 running average of batch loss 4.276222489096901, time 0.5213687419891357\n",
      "#Epoch 144 with total epochs 300 at step 11 loss: 4.588393211364746 running average of batch loss 4.302236715952556, time 0.48932313919067383\n",
      "#Epoch 144 with total epochs 300 at step 12 loss: 4.570123195648193 running average of batch loss 4.3228433682368355, time 0.521369218826294\n",
      "#Epoch 144 with total epochs 300 at step 13 loss: 4.424069404602051 running average of batch loss 4.330073799405779, time 0.48834705352783203\n",
      "#Epoch 144 with total epochs 300 at step 14 loss: 4.274136066436768 running average of batch loss 4.3263446172078455, time 0.49034905433654785\n",
      "#Epoch 144 with total epochs 300 at step 15 loss: 4.351539134979248 running average of batch loss 4.327919274568558, time 0.488344669342041\n",
      "#Epoch 144 with total epochs 300 at step 16 loss: 4.274313449859619 running average of batch loss 4.32476599076215, time 0.48932719230651855\n",
      "#Epoch 144 with total epochs 300 at step 17 loss: 4.006823539733887 running average of batch loss 4.307102521260579, time 0.5223708152770996\n",
      "#Epoch 144 with total epochs 300 at step 18 loss: 4.270231246948242 running average of batch loss 4.305161927875719, time 0.49034643173217773\n",
      "#Epoch 144 with total epochs 300 at step 19 loss: 4.121414661407471 running average of batch loss 4.295974564552307, time 0.5263738632202148\n",
      "#Epoch 144 with total epochs 300 at step 20 loss: 4.071868419647217 running average of batch loss 4.285302843366351, time 0.4893486499786377\n",
      "#Epoch 145 with total epochs 300 at step 0 loss: 4.104107856750488 running average of batch loss 4.104107856750488, time 0.4933502674102783\n",
      "#Epoch 145 with total epochs 300 at step 1 loss: 4.336772918701172 running average of batch loss 4.22044038772583, time 0.527376651763916\n",
      "#Epoch 145 with total epochs 300 at step 2 loss: 3.8688509464263916 running average of batch loss 4.103243907292684, time 0.4883232116699219\n",
      "#Epoch 145 with total epochs 300 at step 3 loss: 3.94319486618042 running average of batch loss 4.063231647014618, time 0.48932623863220215\n",
      "#Epoch 145 with total epochs 300 at step 4 loss: 4.460275650024414 running average of batch loss 4.142640447616577, time 0.4893474578857422\n",
      "#Epoch 145 with total epochs 300 at step 5 loss: 4.278545379638672 running average of batch loss 4.165291269620259, time 0.49735331535339355\n",
      "#Epoch 145 with total epochs 300 at step 6 loss: 4.509827613830566 running average of batch loss 4.2145107473645895, time 0.4913516044616699\n",
      "#Epoch 145 with total epochs 300 at step 7 loss: 4.278007507324219 running average of batch loss 4.222447842359543, time 0.4933476448059082\n",
      "#Epoch 145 with total epochs 300 at step 8 loss: 4.2699127197265625 running average of batch loss 4.227721717622545, time 0.4933500289916992\n",
      "#Epoch 145 with total epochs 300 at step 9 loss: 4.404809951782227 running average of batch loss 4.245430541038513, time 0.5143373012542725\n",
      "#Epoch 145 with total epochs 300 at step 10 loss: 4.010422229766846 running average of batch loss 4.2240661491047256, time 0.5003325939178467\n",
      "#Epoch 145 with total epochs 300 at step 11 loss: 3.740527868270874 running average of batch loss 4.183771292368571, time 0.49332714080810547\n",
      "#Epoch 145 with total epochs 300 at step 12 loss: 4.095975875854492 running average of batch loss 4.177017798790565, time 0.5353798866271973\n",
      "#Epoch 145 with total epochs 300 at step 13 loss: 4.223639965057373 running average of batch loss 4.180347953523908, time 0.5093653202056885\n",
      "#Epoch 145 with total epochs 300 at step 14 loss: 4.326150417327881 running average of batch loss 4.190068117777506, time 0.49631834030151367\n",
      "#Epoch 145 with total epochs 300 at step 15 loss: 4.148726463317871 running average of batch loss 4.187484264373779, time 0.5103325843811035\n",
      "#Epoch 145 with total epochs 300 at step 16 loss: 4.4899516105651855 running average of batch loss 4.205276461208568, time 0.49234938621520996\n",
      "#Epoch 145 with total epochs 300 at step 17 loss: 4.259072303771973 running average of batch loss 4.2082651191287574, time 0.48834800720214844\n",
      "#Epoch 145 with total epochs 300 at step 18 loss: 4.0537824630737305 running average of batch loss 4.200134453020598, time 0.4883251190185547\n",
      "#Epoch 145 with total epochs 300 at step 19 loss: 4.151331901550293 running average of batch loss 4.197694325447083, time 0.5083329677581787\n",
      "#Epoch 145 with total epochs 300 at step 20 loss: 3.9899044036865234 running average of batch loss 4.187799567268009, time 0.4883236885070801\n",
      "#Epoch 146 with total epochs 300 at step 0 loss: 4.133124351501465 running average of batch loss 4.133124351501465, time 0.528374195098877\n",
      "#Epoch 146 with total epochs 300 at step 1 loss: 4.226613998413086 running average of batch loss 4.179869174957275, time 0.4913492202758789\n",
      "#Epoch 146 with total epochs 300 at step 2 loss: 3.872555732727051 running average of batch loss 4.077431360880534, time 0.5373818874359131\n",
      "#Epoch 146 with total epochs 300 at step 3 loss: 4.1690778732299805 running average of batch loss 4.1003429889678955, time 0.5053589344024658\n",
      "#Epoch 146 with total epochs 300 at step 4 loss: 4.393082618713379 running average of batch loss 4.158890914916992, time 0.5353753566741943\n",
      "#Epoch 146 with total epochs 300 at step 5 loss: 4.195009231567383 running average of batch loss 4.164910634358724, time 0.5033574104309082\n",
      "#Epoch 146 with total epochs 300 at step 6 loss: 4.280789852142334 running average of batch loss 4.181464808327811, time 0.569404125213623\n",
      "#Epoch 146 with total epochs 300 at step 7 loss: 4.220312118530273 running average of batch loss 4.186320722103119, time 0.5063347816467285\n",
      "#Epoch 146 with total epochs 300 at step 8 loss: 4.207422733306885 running average of batch loss 4.188665390014648, time 0.5233383178710938\n",
      "#Epoch 146 with total epochs 300 at step 9 loss: 4.06889533996582 running average of batch loss 4.176688385009766, time 0.49632906913757324\n",
      "#Epoch 146 with total epochs 300 at step 10 loss: 4.511247634887695 running average of batch loss 4.2071028622713955, time 0.49034881591796875\n",
      "#Epoch 146 with total epochs 300 at step 11 loss: 3.924619197845459 running average of batch loss 4.183562556902568, time 0.5233719348907471\n",
      "#Epoch 146 with total epochs 300 at step 12 loss: 4.254730224609375 running average of batch loss 4.189036992880014, time 0.49034833908081055\n",
      "#Epoch 146 with total epochs 300 at step 13 loss: 4.417490482330322 running average of batch loss 4.205355099269322, time 0.5393822193145752\n",
      "#Epoch 146 with total epochs 300 at step 14 loss: 3.6958420276641846 running average of batch loss 4.171387561162313, time 0.487346887588501\n",
      "#Epoch 146 with total epochs 300 at step 15 loss: 4.081176280975342 running average of batch loss 4.165749356150627, time 0.5093395709991455\n",
      "#Epoch 146 with total epochs 300 at step 16 loss: 4.379260540008545 running average of batch loss 4.1783088375540345, time 0.4883272647857666\n",
      "#Epoch 146 with total epochs 300 at step 17 loss: 3.778264284133911 running average of batch loss 4.156084140141805, time 0.5243432521820068\n",
      "#Epoch 146 with total epochs 300 at step 18 loss: 3.8909738063812256 running average of batch loss 4.142130964680722, time 0.4863243103027344\n",
      "#Epoch 146 with total epochs 300 at step 19 loss: 4.009113311767578 running average of batch loss 4.135480082035064, time 0.5183649063110352\n",
      "#Epoch 146 with total epochs 300 at step 20 loss: 4.386050701141357 running average of batch loss 4.1474120162782215, time 0.521348237991333\n",
      "#Epoch 147 with total epochs 300 at step 0 loss: 4.300479888916016 running average of batch loss 4.300479888916016, time 0.4913489818572998\n",
      "#Epoch 147 with total epochs 300 at step 1 loss: 4.209526062011719 running average of batch loss 4.255002975463867, time 0.487321138381958\n",
      "#Epoch 147 with total epochs 300 at step 2 loss: 4.615604877471924 running average of batch loss 4.375203609466553, time 0.518364429473877\n",
      "#Epoch 147 with total epochs 300 at step 3 loss: 4.099136829376221 running average of batch loss 4.30618691444397, time 0.5253498554229736\n",
      "#Epoch 147 with total epochs 300 at step 4 loss: 4.297890663146973 running average of batch loss 4.304527664184571, time 0.48734545707702637\n",
      "#Epoch 147 with total epochs 300 at step 5 loss: 4.397504806518555 running average of batch loss 4.320023854573567, time 0.4883253574371338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 147 with total epochs 300 at step 6 loss: 4.45437479019165 running average of batch loss 4.339216845376151, time 0.48832201957702637\n",
      "#Epoch 147 with total epochs 300 at step 7 loss: 4.031759262084961 running average of batch loss 4.300784647464752, time 0.4883463382720947\n",
      "#Epoch 147 with total epochs 300 at step 8 loss: 4.79530668258667 running average of batch loss 4.355731540256077, time 0.4913480281829834\n",
      "#Epoch 147 with total epochs 300 at step 9 loss: 3.913308620452881 running average of batch loss 4.311489248275757, time 0.49034738540649414\n",
      "#Epoch 147 with total epochs 300 at step 10 loss: 4.147210121154785 running average of batch loss 4.296554782173851, time 0.4933509826660156\n",
      "#Epoch 147 with total epochs 300 at step 11 loss: 4.232832908630371 running average of batch loss 4.291244626045227, time 0.4873220920562744\n",
      "#Epoch 147 with total epochs 300 at step 12 loss: 4.664344310760498 running average of batch loss 4.319944601792556, time 0.48734617233276367\n",
      "#Epoch 147 with total epochs 300 at step 13 loss: 4.610236167907715 running average of batch loss 4.3406797136579245, time 0.4873230457305908\n",
      "#Epoch 147 with total epochs 300 at step 14 loss: 4.4403276443481445 running average of batch loss 4.347322909037272, time 0.4913489818572998\n",
      "#Epoch 147 with total epochs 300 at step 15 loss: 3.761955976486206 running average of batch loss 4.3107374757528305, time 0.5383830070495605\n",
      "#Epoch 147 with total epochs 300 at step 16 loss: 3.9812045097351074 running average of batch loss 4.291353183634141, time 0.48834657669067383\n",
      "#Epoch 147 with total epochs 300 at step 17 loss: 4.1765031814575195 running average of batch loss 4.284972627957662, time 0.4873466491699219\n",
      "#Epoch 147 with total epochs 300 at step 18 loss: 3.9877676963806152 running average of batch loss 4.269330263137817, time 0.4893491268157959\n",
      "#Epoch 147 with total epochs 300 at step 19 loss: 3.8469696044921875 running average of batch loss 4.248212230205536, time 0.5063562393188477\n",
      "#Epoch 147 with total epochs 300 at step 20 loss: 4.226140022277832 running average of batch loss 4.2471611726851695, time 0.523348331451416\n",
      "#Epoch 148 with total epochs 300 at step 0 loss: 4.309010982513428 running average of batch loss 4.309010982513428, time 0.501356840133667\n",
      "#Epoch 148 with total epochs 300 at step 1 loss: 4.1993088722229 running average of batch loss 4.254159927368164, time 0.5093355178833008\n",
      "#Epoch 148 with total epochs 300 at step 2 loss: 4.052735805511475 running average of batch loss 4.1870185534159345, time 0.526374101638794\n",
      "#Epoch 148 with total epochs 300 at step 3 loss: 4.5479044914245605 running average of batch loss 4.277240037918091, time 0.4883463382720947\n",
      "#Epoch 148 with total epochs 300 at step 4 loss: 3.9808287620544434 running average of batch loss 4.217957782745361, time 0.5223476886749268\n",
      "#Epoch 148 with total epochs 300 at step 5 loss: 4.1073994636535645 running average of batch loss 4.1995313962300616, time 0.496354341506958\n",
      "#Epoch 148 with total epochs 300 at step 6 loss: 3.7972521781921387 running average of batch loss 4.142062936510358, time 0.5003259181976318\n",
      "#Epoch 148 with total epochs 300 at step 7 loss: 4.4422926902771 running average of batch loss 4.179591655731201, time 0.48632097244262695\n",
      "#Epoch 148 with total epochs 300 at step 8 loss: 4.2180891036987305 running average of batch loss 4.183869149949816, time 0.48334312438964844\n",
      "#Epoch 148 with total epochs 300 at step 9 loss: 4.496417999267578 running average of batch loss 4.215124034881592, time 0.49034810066223145\n",
      "#Epoch 148 with total epochs 300 at step 10 loss: 4.15109395980835 running average of batch loss 4.209303118965843, time 0.4863460063934326\n",
      "#Epoch 148 with total epochs 300 at step 11 loss: 4.057783603668213 running average of batch loss 4.19667649269104, time 0.5213446617126465\n",
      "#Epoch 148 with total epochs 300 at step 12 loss: 3.8512258529663086 running average of batch loss 4.170103366558369, time 0.48734617233276367\n",
      "#Epoch 148 with total epochs 300 at step 13 loss: 4.031704902648926 running average of batch loss 4.160217761993408, time 0.4953279495239258\n",
      "#Epoch 148 with total epochs 300 at step 14 loss: 4.6868896484375 running average of batch loss 4.195329221089681, time 0.502356767654419\n",
      "#Epoch 148 with total epochs 300 at step 15 loss: 3.851640224456787 running average of batch loss 4.173848658800125, time 0.4893481731414795\n",
      "#Epoch 148 with total epochs 300 at step 16 loss: 4.213393688201904 running average of batch loss 4.17617483700023, time 0.48732757568359375\n",
      "#Epoch 148 with total epochs 300 at step 17 loss: 3.840545892715454 running average of batch loss 4.157528784539965, time 0.544358491897583\n",
      "#Epoch 148 with total epochs 300 at step 18 loss: 3.834059000015259 running average of batch loss 4.140504059038665, time 0.5213708877563477\n",
      "#Epoch 148 with total epochs 300 at step 19 loss: 4.089169025421143 running average of batch loss 4.137937307357788, time 0.48834848403930664\n",
      "#Epoch 148 with total epochs 300 at step 20 loss: 4.668349266052246 running average of batch loss 4.1631950196765715, time 0.4873216152191162\n",
      "#Epoch 149 with total epochs 300 at step 0 loss: 4.23671293258667 running average of batch loss 4.23671293258667, time 0.48832225799560547\n",
      "#Epoch 149 with total epochs 300 at step 1 loss: 4.034018516540527 running average of batch loss 4.135365724563599, time 0.5213704109191895\n",
      "#Epoch 149 with total epochs 300 at step 2 loss: 4.076664447784424 running average of batch loss 4.115798632303874, time 0.4893476963043213\n",
      "#Epoch 149 with total epochs 300 at step 3 loss: 4.028664588928223 running average of batch loss 4.094015121459961, time 0.521369457244873\n",
      "#Epoch 149 with total epochs 300 at step 4 loss: 3.9786410331726074 running average of batch loss 4.07094030380249, time 0.49132490158081055\n",
      "#Epoch 149 with total epochs 300 at step 5 loss: 4.1473164558410645 running average of batch loss 4.083669662475586, time 0.5223708152770996\n",
      "#Epoch 149 with total epochs 300 at step 6 loss: 3.764254093170166 running average of batch loss 4.038038866860526, time 0.4873218536376953\n",
      "#Epoch 149 with total epochs 300 at step 7 loss: 3.9942851066589355 running average of batch loss 4.032569646835327, time 0.4903249740600586\n",
      "#Epoch 149 with total epochs 300 at step 8 loss: 3.7522997856140137 running average of batch loss 4.00142855114407, time 0.5063328742980957\n",
      "#Epoch 149 with total epochs 300 at step 9 loss: 3.9882283210754395 running average of batch loss 4.000108528137207, time 0.5043306350708008\n",
      "#Epoch 149 with total epochs 300 at step 10 loss: 4.069363117218018 running average of batch loss 4.006404399871826, time 0.5243723392486572\n",
      "#Epoch 149 with total epochs 300 at step 11 loss: 4.276986122131348 running average of batch loss 4.028952876726787, time 0.486346960067749\n",
      "#Epoch 149 with total epochs 300 at step 12 loss: 4.088604927062988 running average of batch loss 4.0335414959834175, time 0.491349458694458\n",
      "#Epoch 149 with total epochs 300 at step 13 loss: 4.171395301818848 running average of batch loss 4.043388196400234, time 0.4893331527709961\n",
      "#Epoch 149 with total epochs 300 at step 14 loss: 4.179043292999268 running average of batch loss 4.052431869506836, time 0.5243725776672363\n",
      "#Epoch 149 with total epochs 300 at step 15 loss: 4.893102645874023 running average of batch loss 4.104973793029785, time 0.4913485050201416\n",
      "#Epoch 149 with total epochs 300 at step 16 loss: 4.145796775817871 running average of batch loss 4.107375144958496, time 0.5363800525665283\n",
      "#Epoch 149 with total epochs 300 at step 17 loss: 4.330198764801025 running average of batch loss 4.119754234949748, time 0.4873466491699219\n",
      "#Epoch 149 with total epochs 300 at step 18 loss: 4.55596923828125 running average of batch loss 4.142712919335616, time 0.48734498023986816\n",
      "#Epoch 149 with total epochs 300 at step 19 loss: 4.101596355438232 running average of batch loss 4.140657091140747, time 0.4873464107513428\n",
      "#Epoch 149 with total epochs 300 at step 20 loss: 3.9055216312408447 running average of batch loss 4.129460164478847, time 0.48834657669067383\n",
      "#Epoch 150 with total epochs 300 at step 0 loss: 4.1825385093688965 running average of batch loss 4.1825385093688965, time 0.4873476028442383\n",
      "#Epoch 150 with total epochs 300 at step 1 loss: 4.245229721069336 running average of batch loss 4.213884115219116, time 0.48834705352783203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 150 with total epochs 300 at step 2 loss: 4.213872909545898 running average of batch loss 4.21388037999471, time 0.4873480796813965\n",
      "#Epoch 150 with total epochs 300 at step 3 loss: 3.796973466873169 running average of batch loss 4.109653651714325, time 0.4893479347229004\n",
      "#Epoch 150 with total epochs 300 at step 4 loss: 4.656988143920898 running average of batch loss 4.2191205501556395, time 0.48834681510925293\n",
      "#Epoch 150 with total epochs 300 at step 5 loss: 4.477886199951172 running average of batch loss 4.262248158454895, time 0.4913492202758789\n",
      "#Epoch 150 with total epochs 300 at step 6 loss: 3.799759864807129 running average of batch loss 4.1961784022195, time 0.5203695297241211\n",
      "#Epoch 150 with total epochs 300 at step 7 loss: 4.209523677825928 running average of batch loss 4.197846561670303, time 0.4913489818572998\n",
      "#Epoch 150 with total epochs 300 at step 8 loss: 4.243951797485352 running average of batch loss 4.2029693656497535, time 0.4963521957397461\n",
      "#Epoch 150 with total epochs 300 at step 9 loss: 4.2291340827941895 running average of batch loss 4.205585837364197, time 0.48834848403930664\n",
      "#Epoch 150 with total epochs 300 at step 10 loss: 3.9874584674835205 running average of batch loss 4.185756076465953, time 0.5003554821014404\n",
      "#Epoch 150 with total epochs 300 at step 11 loss: 4.246732711791992 running average of batch loss 4.190837462743123, time 0.5253739356994629\n",
      "#Epoch 150 with total epochs 300 at step 12 loss: 4.181118965148926 running average of batch loss 4.190089886005108, time 0.49735450744628906\n",
      "#Epoch 150 with total epochs 300 at step 13 loss: 4.169171333312988 running average of batch loss 4.188595703669956, time 0.5123600959777832\n",
      "#Epoch 150 with total epochs 300 at step 14 loss: 4.314691543579102 running average of batch loss 4.197002092997233, time 0.49034953117370605\n",
      "#Epoch 150 with total epochs 300 at step 15 loss: 3.9694302082061768 running average of batch loss 4.182778850197792, time 0.49234771728515625\n",
      "#Epoch 150 with total epochs 300 at step 16 loss: 3.96897554397583 running average of batch loss 4.170202185125912, time 0.5273480415344238\n",
      "#Epoch 150 with total epochs 300 at step 17 loss: 4.069639205932617 running average of batch loss 4.164615352948506, time 0.49032020568847656\n",
      "#Epoch 150 with total epochs 300 at step 18 loss: 3.7985923290252686 running average of batch loss 4.145350983268337, time 0.4913489818572998\n",
      "#Epoch 150 with total epochs 300 at step 19 loss: 4.114614486694336 running average of batch loss 4.143814158439636, time 0.5233485698699951\n",
      "#Epoch 150 with total epochs 300 at step 20 loss: 4.191618919372559 running average of batch loss 4.146090575626919, time 0.48632264137268066\n",
      "#Epoch 151 with total epochs 300 at step 0 loss: 4.0734663009643555 running average of batch loss 4.0734663009643555, time 0.5233719348907471\n",
      "#Epoch 151 with total epochs 300 at step 1 loss: 4.541209697723389 running average of batch loss 4.307337999343872, time 0.5263731479644775\n",
      "#Epoch 151 with total epochs 300 at step 2 loss: 4.078379154205322 running average of batch loss 4.2310183842976885, time 0.48832082748413086\n",
      "#Epoch 151 with total epochs 300 at step 3 loss: 4.65339994430542 running average of batch loss 4.336613774299622, time 0.4943506717681885\n",
      "#Epoch 151 with total epochs 300 at step 4 loss: 4.131058216094971 running average of batch loss 4.295502662658691, time 0.4863474369049072\n",
      "#Epoch 151 with total epochs 300 at step 5 loss: 4.1206889152526855 running average of batch loss 4.2663670380910235, time 0.49832916259765625\n",
      "#Epoch 151 with total epochs 300 at step 6 loss: 4.2736430168151855 running average of batch loss 4.267406463623047, time 0.4873225688934326\n",
      "#Epoch 151 with total epochs 300 at step 7 loss: 3.8908514976501465 running average of batch loss 4.220337092876434, time 0.49532580375671387\n",
      "#Epoch 151 with total epochs 300 at step 8 loss: 4.07505989074707 running average of batch loss 4.2041951815287275, time 0.48734593391418457\n",
      "#Epoch 151 with total epochs 300 at step 9 loss: 4.228996753692627 running average of batch loss 4.206675338745117, time 0.4863460063934326\n",
      "#Epoch 151 with total epochs 300 at step 10 loss: 3.67600679397583 running average of batch loss 4.158432743766091, time 0.49735021591186523\n",
      "#Epoch 151 with total epochs 300 at step 11 loss: 3.945141077041626 running average of batch loss 4.140658438205719, time 0.49432945251464844\n",
      "#Epoch 151 with total epochs 300 at step 12 loss: 4.1642165184021 running average of batch loss 4.142470598220825, time 0.4883229732513428\n",
      "#Epoch 151 with total epochs 300 at step 13 loss: 4.178507328033447 running average of batch loss 4.1450446503502985, time 0.4893369674682617\n",
      "#Epoch 151 with total epochs 300 at step 14 loss: 4.044399261474609 running average of batch loss 4.138334957758586, time 0.4933500289916992\n",
      "#Epoch 151 with total epochs 300 at step 15 loss: 4.473928451538086 running average of batch loss 4.159309551119804, time 0.48832249641418457\n",
      "#Epoch 151 with total epochs 300 at step 16 loss: 3.9387269020080566 running average of batch loss 4.146334101172054, time 0.4883236885070801\n",
      "#Epoch 151 with total epochs 300 at step 17 loss: 3.934412956237793 running average of batch loss 4.134560704231262, time 0.48632073402404785\n",
      "#Epoch 151 with total epochs 300 at step 18 loss: 4.282843589782715 running average of batch loss 4.142365066628707, time 0.4883453845977783\n",
      "#Epoch 151 with total epochs 300 at step 19 loss: 4.527549743652344 running average of batch loss 4.161624300479889, time 0.4883246421813965\n",
      "#Epoch 151 with total epochs 300 at step 20 loss: 4.242435455322266 running average of batch loss 4.165472450710478, time 0.4873192310333252\n",
      "#Epoch 152 with total epochs 300 at step 0 loss: 4.603368282318115 running average of batch loss 4.603368282318115, time 0.48734378814697266\n",
      "#Epoch 152 with total epochs 300 at step 1 loss: 4.25195837020874 running average of batch loss 4.427663326263428, time 0.4873464107513428\n",
      "#Epoch 152 with total epochs 300 at step 2 loss: 4.234440803527832 running average of batch loss 4.3632558186848955, time 0.4843447208404541\n",
      "#Epoch 152 with total epochs 300 at step 3 loss: 3.6721973419189453 running average of batch loss 4.190491199493408, time 0.48932480812072754\n",
      "#Epoch 152 with total epochs 300 at step 4 loss: 4.05574369430542 running average of batch loss 4.163541698455811, time 0.4983549118041992\n",
      "#Epoch 152 with total epochs 300 at step 5 loss: 3.750133991241455 running average of batch loss 4.094640413920085, time 0.4883232116699219\n",
      "#Epoch 152 with total epochs 300 at step 6 loss: 4.047314167022705 running average of batch loss 4.087879521506173, time 0.491349458694458\n",
      "#Epoch 152 with total epochs 300 at step 7 loss: 4.160996437072754 running average of batch loss 4.097019135951996, time 0.4993274211883545\n",
      "#Epoch 152 with total epochs 300 at step 8 loss: 3.697237014770508 running average of batch loss 4.0525989002651635, time 0.4883251190185547\n",
      "#Epoch 152 with total epochs 300 at step 9 loss: 4.6604132652282715 running average of batch loss 4.113380336761475, time 0.5243496894836426\n",
      "#Epoch 152 with total epochs 300 at step 10 loss: 4.626949787139893 running average of batch loss 4.160068468614058, time 0.48632287979125977\n",
      "#Epoch 152 with total epochs 300 at step 11 loss: 4.875229835510254 running average of batch loss 4.219665249188741, time 0.5133378505706787\n",
      "#Epoch 152 with total epochs 300 at step 12 loss: 4.320838928222656 running average of batch loss 4.2274478398836575, time 0.526374101638794\n",
      "#Epoch 152 with total epochs 300 at step 13 loss: 4.288388252258301 running average of batch loss 4.231800726481846, time 0.48734426498413086\n",
      "#Epoch 152 with total epochs 300 at step 14 loss: 4.110020160675049 running average of batch loss 4.223682022094726, time 0.4873473644256592\n",
      "#Epoch 152 with total epochs 300 at step 15 loss: 4.2405314445495605 running average of batch loss 4.224735110998154, time 0.5013546943664551\n",
      "#Epoch 152 with total epochs 300 at step 16 loss: 3.9240500926971436 running average of batch loss 4.207047756980447, time 0.4873228073120117\n",
      "#Epoch 152 with total epochs 300 at step 17 loss: 3.7705371379852295 running average of batch loss 4.182797167036268, time 0.4903256893157959\n",
      "#Epoch 152 with total epochs 300 at step 18 loss: 3.9539108276367188 running average of batch loss 4.170750517594187, time 0.5263736248016357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 152 with total epochs 300 at step 19 loss: 4.710096836090088 running average of batch loss 4.197717833518982, time 0.48734617233276367\n",
      "#Epoch 152 with total epochs 300 at step 20 loss: 4.462690830230713 running average of batch loss 4.21033559526716, time 0.4883239269256592\n",
      "#Epoch 153 with total epochs 300 at step 0 loss: 3.7658369541168213 running average of batch loss 3.7658369541168213, time 0.5083324909210205\n",
      "#Epoch 153 with total epochs 300 at step 1 loss: 4.231779098510742 running average of batch loss 3.9988080263137817, time 0.5233726501464844\n",
      "#Epoch 153 with total epochs 300 at step 2 loss: 3.9408748149871826 running average of batch loss 3.979496955871582, time 0.4913492202758789\n",
      "#Epoch 153 with total epochs 300 at step 3 loss: 4.267094612121582 running average of batch loss 4.051396369934082, time 0.4893481731414795\n",
      "#Epoch 153 with total epochs 300 at step 4 loss: 4.3699541091918945 running average of batch loss 4.115107917785645, time 0.489346981048584\n",
      "#Epoch 153 with total epochs 300 at step 5 loss: 3.6909706592559814 running average of batch loss 4.044418374697368, time 0.48734617233276367\n",
      "#Epoch 153 with total epochs 300 at step 6 loss: 4.390199184417725 running average of batch loss 4.093815633228847, time 0.4893486499786377\n",
      "#Epoch 153 with total epochs 300 at step 7 loss: 3.9981892108917236 running average of batch loss 4.0818623304367065, time 0.48932313919067383\n",
      "#Epoch 153 with total epochs 300 at step 8 loss: 3.908766508102417 running average of batch loss 4.062629461288452, time 0.48734617233276367\n",
      "#Epoch 153 with total epochs 300 at step 9 loss: 4.0014753341674805 running average of batch loss 4.056514048576355, time 0.49034786224365234\n",
      "#Epoch 153 with total epochs 300 at step 10 loss: 3.8760268688201904 running average of batch loss 4.0401061231439765, time 0.48734593391418457\n",
      "#Epoch 153 with total epochs 300 at step 11 loss: 4.068065166473389 running average of batch loss 4.042436043421428, time 0.48834824562072754\n",
      "#Epoch 153 with total epochs 300 at step 12 loss: 4.1671037673950195 running average of batch loss 4.052025868342473, time 0.49034786224365234\n",
      "#Epoch 153 with total epochs 300 at step 13 loss: 3.7734062671661377 running average of batch loss 4.032124468258449, time 0.49034786224365234\n",
      "#Epoch 153 with total epochs 300 at step 14 loss: 4.155325889587402 running average of batch loss 4.0403378963470455, time 0.4863455295562744\n",
      "#Epoch 153 with total epochs 300 at step 15 loss: 4.136956691741943 running average of batch loss 4.046376571059227, time 0.5213704109191895\n",
      "#Epoch 153 with total epochs 300 at step 16 loss: 4.262698173522949 running average of batch loss 4.059101371204152, time 0.49234890937805176\n",
      "#Epoch 153 with total epochs 300 at step 17 loss: 4.187593460083008 running average of batch loss 4.06623982058631, time 0.4883251190185547\n",
      "#Epoch 153 with total epochs 300 at step 18 loss: 4.2005743980407715 running average of batch loss 4.073310061504967, time 0.4943509101867676\n",
      "#Epoch 153 with total epochs 300 at step 19 loss: 4.0743255615234375 running average of batch loss 4.0733608365058895, time 0.5003564357757568\n",
      "#Epoch 153 with total epochs 300 at step 20 loss: 4.251260280609131 running average of batch loss 4.081832238606045, time 0.4873232841491699\n",
      "#Epoch 154 with total epochs 300 at step 0 loss: 3.9404897689819336 running average of batch loss 3.9404897689819336, time 0.4863464832305908\n",
      "#Epoch 154 with total epochs 300 at step 1 loss: 4.202180862426758 running average of batch loss 4.071335315704346, time 0.49535179138183594\n",
      "#Epoch 154 with total epochs 300 at step 2 loss: 4.347117900848389 running average of batch loss 4.163262844085693, time 0.5443873405456543\n",
      "#Epoch 154 with total epochs 300 at step 3 loss: 4.022422790527344 running average of batch loss 4.128052830696106, time 0.48632049560546875\n",
      "#Epoch 154 with total epochs 300 at step 4 loss: 4.489946365356445 running average of batch loss 4.200431537628174, time 0.4883253574371338\n",
      "#Epoch 154 with total epochs 300 at step 5 loss: 4.410253047943115 running average of batch loss 4.235401789347331, time 0.5233712196350098\n",
      "#Epoch 154 with total epochs 300 at step 6 loss: 3.975144624710083 running average of batch loss 4.198222194399152, time 0.4873466491699219\n",
      "#Epoch 154 with total epochs 300 at step 7 loss: 4.96174430847168 running average of batch loss 4.293662458658218, time 0.4873208999633789\n",
      "#Epoch 154 with total epochs 300 at step 8 loss: 3.968397855758667 running average of batch loss 4.257521947224935, time 0.4933295249938965\n",
      "#Epoch 154 with total epochs 300 at step 9 loss: 4.063386917114258 running average of batch loss 4.238108444213867, time 0.5003299713134766\n",
      "#Epoch 154 with total epochs 300 at step 10 loss: 3.9751060009002686 running average of batch loss 4.214199131185358, time 0.511336088180542\n",
      "#Epoch 154 with total epochs 300 at step 11 loss: 4.329861164093018 running average of batch loss 4.223837633927663, time 0.5203695297241211\n",
      "#Epoch 154 with total epochs 300 at step 12 loss: 4.642876148223877 running average of batch loss 4.256071365796602, time 0.4913492202758789\n",
      "#Epoch 154 with total epochs 300 at step 13 loss: 3.7146639823913574 running average of batch loss 4.217399409839085, time 0.4873466491699219\n",
      "#Epoch 154 with total epochs 300 at step 14 loss: 3.8037872314453125 running average of batch loss 4.189825264612834, time 0.48834657669067383\n",
      "#Epoch 154 with total epochs 300 at step 15 loss: 4.2569122314453125 running average of batch loss 4.194018200039864, time 0.48834657669067383\n",
      "#Epoch 154 with total epochs 300 at step 16 loss: 3.7395448684692383 running average of batch loss 4.167284474653356, time 0.4863462448120117\n",
      "#Epoch 154 with total epochs 300 at step 17 loss: 4.503527641296387 running average of batch loss 4.185964650577969, time 0.49234962463378906\n",
      "#Epoch 154 with total epochs 300 at step 18 loss: 3.9684665203094482 running average of batch loss 4.174517380563836, time 0.5233721733093262\n",
      "#Epoch 154 with total epochs 300 at step 19 loss: 4.253264904022217 running average of batch loss 4.178454756736755, time 0.48834705352783203\n",
      "#Epoch 154 with total epochs 300 at step 20 loss: 4.127840995788574 running average of batch loss 4.176044577643985, time 0.48932385444641113\n",
      "#Epoch 155 with total epochs 300 at step 0 loss: 4.150489330291748 running average of batch loss 4.150489330291748, time 0.48734617233276367\n",
      "#Epoch 155 with total epochs 300 at step 1 loss: 4.175323963165283 running average of batch loss 4.162906646728516, time 0.48834705352783203\n",
      "#Epoch 155 with total epochs 300 at step 2 loss: 4.120440483093262 running average of batch loss 4.148751258850098, time 0.5223708152770996\n",
      "#Epoch 155 with total epochs 300 at step 3 loss: 4.201889991760254 running average of batch loss 4.162035942077637, time 0.489349365234375\n",
      "#Epoch 155 with total epochs 300 at step 4 loss: 3.745140552520752 running average of batch loss 4.07865686416626, time 0.4873466491699219\n",
      "#Epoch 155 with total epochs 300 at step 5 loss: 4.036362171173096 running average of batch loss 4.071607748667399, time 0.4893465042114258\n",
      "#Epoch 155 with total epochs 300 at step 6 loss: 4.34448766708374 running average of batch loss 4.110590594155448, time 0.4873476028442383\n",
      "#Epoch 155 with total epochs 300 at step 7 loss: 3.969604969024658 running average of batch loss 4.092967391014099, time 0.512336254119873\n",
      "#Epoch 155 with total epochs 300 at step 8 loss: 3.7689006328582764 running average of batch loss 4.05695997344123, time 0.4863462448120117\n",
      "#Epoch 155 with total epochs 300 at step 9 loss: 3.9823174476623535 running average of batch loss 4.049495720863343, time 0.5023341178894043\n",
      "#Epoch 155 with total epochs 300 at step 10 loss: 4.1006083488464355 running average of batch loss 4.05414232340726, time 0.4873471260070801\n",
      "#Epoch 155 with total epochs 300 at step 11 loss: 4.111125946044922 running average of batch loss 4.058890958627065, time 0.4903266429901123\n",
      "#Epoch 155 with total epochs 300 at step 12 loss: 3.917966365814209 running average of batch loss 4.048050605333769, time 0.5463888645172119\n",
      "#Epoch 155 with total epochs 300 at step 13 loss: 4.130497455596924 running average of batch loss 4.053939666066851, time 0.4993305206298828\n",
      "#Epoch 155 with total epochs 300 at step 14 loss: 4.209710597991943 running average of batch loss 4.064324394861857, time 0.5203690528869629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 155 with total epochs 300 at step 15 loss: 4.129833221435547 running average of batch loss 4.068418696522713, time 0.4903237819671631\n",
      "#Epoch 155 with total epochs 300 at step 16 loss: 4.285874843597412 running average of batch loss 4.081210234585931, time 0.5093624591827393\n",
      "#Epoch 155 with total epochs 300 at step 17 loss: 4.00737190246582 running average of batch loss 4.077108105023702, time 0.48632144927978516\n",
      "#Epoch 155 with total epochs 300 at step 18 loss: 4.1463165283203125 running average of batch loss 4.08075065361826, time 0.49235033988952637\n",
      "#Epoch 155 with total epochs 300 at step 19 loss: 4.237865924835205 running average of batch loss 4.088606417179108, time 0.5083365440368652\n",
      "#Epoch 155 with total epochs 300 at step 20 loss: 3.8334953784942627 running average of batch loss 4.0764582724798295, time 0.5033583641052246\n",
      "#Epoch 156 with total epochs 300 at step 0 loss: 3.876187324523926 running average of batch loss 3.876187324523926, time 0.49535131454467773\n",
      "#Epoch 156 with total epochs 300 at step 1 loss: 4.115070819854736 running average of batch loss 3.995629072189331, time 0.49132370948791504\n",
      "#Epoch 156 with total epochs 300 at step 2 loss: 4.007126808166504 running average of batch loss 3.9994616508483887, time 0.521371603012085\n",
      "#Epoch 156 with total epochs 300 at step 3 loss: 4.321722507476807 running average of batch loss 4.080026865005493, time 0.5283761024475098\n",
      "#Epoch 156 with total epochs 300 at step 4 loss: 4.170080184936523 running average of batch loss 4.098037528991699, time 0.4893474578857422\n",
      "#Epoch 156 with total epochs 300 at step 5 loss: 4.32432746887207 running average of batch loss 4.135752518971761, time 0.4863467216491699\n",
      "#Epoch 156 with total epochs 300 at step 6 loss: 3.9814958572387695 running average of batch loss 4.113715853009905, time 0.48832273483276367\n",
      "#Epoch 156 with total epochs 300 at step 7 loss: 4.1616716384887695 running average of batch loss 4.119710326194763, time 0.4883463382720947\n",
      "#Epoch 156 with total epochs 300 at step 8 loss: 4.31437873840332 running average of batch loss 4.141340149773492, time 0.490325927734375\n",
      "#Epoch 156 with total epochs 300 at step 9 loss: 3.786709785461426 running average of batch loss 4.105877113342285, time 0.4873223304748535\n",
      "#Epoch 156 with total epochs 300 at step 10 loss: 4.226499557495117 running average of batch loss 4.116842790083452, time 0.4893486499786377\n",
      "#Epoch 156 with total epochs 300 at step 11 loss: 4.456691741943359 running average of batch loss 4.145163536071777, time 0.48834681510925293\n",
      "#Epoch 156 with total epochs 300 at step 12 loss: 3.9538519382476807 running average of batch loss 4.130447259316077, time 0.5243730545043945\n",
      "#Epoch 156 with total epochs 300 at step 13 loss: 3.797011375427246 running average of batch loss 4.106630410466876, time 0.4893484115600586\n",
      "#Epoch 156 with total epochs 300 at step 14 loss: 3.8736653327941895 running average of batch loss 4.091099405288697, time 0.5243487358093262\n",
      "#Epoch 156 with total epochs 300 at step 15 loss: 4.073308944702148 running average of batch loss 4.089987501502037, time 0.4863467216491699\n",
      "#Epoch 156 with total epochs 300 at step 16 loss: 4.601459503173828 running average of batch loss 4.120074089835672, time 0.4873471260070801\n",
      "#Epoch 156 with total epochs 300 at step 17 loss: 4.245798587799072 running average of batch loss 4.127058784166972, time 0.4863462448120117\n",
      "#Epoch 156 with total epochs 300 at step 18 loss: 4.228416442871094 running average of batch loss 4.1323933977829785, time 0.48834705352783203\n",
      "#Epoch 156 with total epochs 300 at step 19 loss: 3.9176406860351562 running average of batch loss 4.121655762195587, time 0.4943277835845947\n",
      "#Epoch 156 with total epochs 300 at step 20 loss: 4.382565021514893 running average of batch loss 4.134080012639363, time 0.5243730545043945\n",
      "#Epoch 157 with total epochs 300 at step 0 loss: 4.358959197998047 running average of batch loss 4.358959197998047, time 0.4943516254425049\n",
      "#Epoch 157 with total epochs 300 at step 1 loss: 3.587674140930176 running average of batch loss 3.9733166694641113, time 0.5113635063171387\n",
      "#Epoch 157 with total epochs 300 at step 2 loss: 3.9982404708862305 running average of batch loss 3.9816246032714844, time 0.4873466491699219\n",
      "#Epoch 157 with total epochs 300 at step 3 loss: 3.868656635284424 running average of batch loss 3.9533826112747192, time 0.493349552154541\n",
      "#Epoch 157 with total epochs 300 at step 4 loss: 4.055914402008057 running average of batch loss 3.973888969421387, time 0.49633097648620605\n",
      "#Epoch 157 with total epochs 300 at step 5 loss: 4.133471965789795 running average of batch loss 4.000486135482788, time 0.5003559589385986\n",
      "#Epoch 157 with total epochs 300 at step 6 loss: 4.234682083129883 running average of batch loss 4.033942699432373, time 0.490325927734375\n",
      "#Epoch 157 with total epochs 300 at step 7 loss: 3.911632537841797 running average of batch loss 4.018653929233551, time 0.49832701683044434\n",
      "#Epoch 157 with total epochs 300 at step 8 loss: 4.110569953918457 running average of batch loss 4.028866820865208, time 0.4933497905731201\n",
      "#Epoch 157 with total epochs 300 at step 9 loss: 4.365663051605225 running average of batch loss 4.062546443939209, time 0.5323777198791504\n",
      "#Epoch 157 with total epochs 300 at step 10 loss: 4.412106513977051 running average of batch loss 4.094324632124468, time 0.4883463382720947\n",
      "#Epoch 157 with total epochs 300 at step 11 loss: 4.095736026763916 running average of batch loss 4.094442248344421, time 0.48834872245788574\n",
      "#Epoch 157 with total epochs 300 at step 12 loss: 3.967388391494751 running average of batch loss 4.084668874740601, time 0.5223722457885742\n",
      "#Epoch 157 with total epochs 300 at step 13 loss: 4.195800304412842 running average of batch loss 4.092606834002903, time 0.49132490158081055\n",
      "#Epoch 157 with total epochs 300 at step 14 loss: 4.107185363769531 running average of batch loss 4.093578735987346, time 0.4933505058288574\n",
      "#Epoch 157 with total epochs 300 at step 15 loss: 4.141826152801514 running average of batch loss 4.096594199538231, time 0.49235033988952637\n",
      "#Epoch 157 with total epochs 300 at step 16 loss: 3.8688106536865234 running average of batch loss 4.083195167429307, time 0.5223720073699951\n",
      "#Epoch 157 with total epochs 300 at step 17 loss: 4.223990440368652 running average of batch loss 4.091017127037048, time 0.49034881591796875\n",
      "#Epoch 157 with total epochs 300 at step 18 loss: 4.048956871032715 running average of batch loss 4.08880342935261, time 0.4883236885070801\n",
      "#Epoch 157 with total epochs 300 at step 19 loss: 4.634401321411133 running average of batch loss 4.116083323955536, time 0.4883241653442383\n",
      "#Epoch 157 with total epochs 300 at step 20 loss: 4.27755069732666 running average of batch loss 4.123772246497018, time 0.4933505058288574\n",
      "#Epoch 158 with total epochs 300 at step 0 loss: 3.8417885303497314 running average of batch loss 3.8417885303497314, time 0.48832249641418457\n",
      "#Epoch 158 with total epochs 300 at step 1 loss: 3.818542242050171 running average of batch loss 3.830165386199951, time 0.4893472194671631\n",
      "#Epoch 158 with total epochs 300 at step 2 loss: 4.056923866271973 running average of batch loss 3.9057515462239585, time 0.48834705352783203\n",
      "#Epoch 158 with total epochs 300 at step 3 loss: 3.849477767944336 running average of batch loss 3.8916831016540527, time 0.49034810066223145\n",
      "#Epoch 158 with total epochs 300 at step 4 loss: 4.154040336608887 running average of batch loss 3.9441545486450194, time 0.523371696472168\n",
      "#Epoch 158 with total epochs 300 at step 5 loss: 4.155152320861816 running average of batch loss 3.979320844014486, time 0.49035072326660156\n",
      "#Epoch 158 with total epochs 300 at step 6 loss: 4.075636386871338 running average of batch loss 3.99308020727975, time 0.4883251190185547\n",
      "#Epoch 158 with total epochs 300 at step 7 loss: 3.811117172241211 running average of batch loss 3.970334827899933, time 0.48834657669067383\n",
      "#Epoch 158 with total epochs 300 at step 8 loss: 3.9669301509857178 running average of batch loss 3.96995653046502, time 0.4893460273742676\n",
      "#Epoch 158 with total epochs 300 at step 9 loss: 3.739840030670166 running average of batch loss 3.9469448804855345, time 0.48834729194641113\n",
      "#Epoch 158 with total epochs 300 at step 10 loss: 3.7336761951446533 running average of batch loss 3.9275568181818183, time 0.5233714580535889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 158 with total epochs 300 at step 11 loss: 3.9860706329345703 running average of batch loss 3.9324329694112143, time 0.48734617233276367\n",
      "#Epoch 158 with total epochs 300 at step 12 loss: 4.2152180671691895 running average of batch loss 3.954185669238751, time 0.4943532943725586\n",
      "#Epoch 158 with total epochs 300 at step 13 loss: 3.515545606613159 running average of batch loss 3.9228542361940657, time 0.4883248805999756\n",
      "#Epoch 158 with total epochs 300 at step 14 loss: 3.6518678665161133 running average of batch loss 3.9047884782155355, time 0.4883246421813965\n",
      "#Epoch 158 with total epochs 300 at step 15 loss: 3.9258005619049072 running average of batch loss 3.906101733446121, time 0.5063343048095703\n",
      "#Epoch 158 with total epochs 300 at step 16 loss: 4.224719524383545 running average of batch loss 3.9248439564424404, time 0.512333869934082\n",
      "#Epoch 158 with total epochs 300 at step 17 loss: 4.305826187133789 running average of batch loss 3.946009635925293, time 0.489346981048584\n",
      "#Epoch 158 with total epochs 300 at step 18 loss: 4.319808006286621 running average of batch loss 3.965683234365363, time 0.5113377571105957\n",
      "#Epoch 158 with total epochs 300 at step 19 loss: 4.068018913269043 running average of batch loss 3.970800018310547, time 0.5013549327850342\n",
      "#Epoch 158 with total epochs 300 at step 20 loss: 3.785193681716919 running average of batch loss 3.961961621329898, time 0.49632906913757324\n",
      "#Epoch 159 with total epochs 300 at step 0 loss: 4.042219161987305 running average of batch loss 4.042219161987305, time 0.5243701934814453\n",
      "#Epoch 159 with total epochs 300 at step 1 loss: 4.368952751159668 running average of batch loss 4.205585956573486, time 0.4893488883972168\n",
      "#Epoch 159 with total epochs 300 at step 2 loss: 3.917771100997925 running average of batch loss 4.109647671381633, time 0.497326135635376\n",
      "#Epoch 159 with total epochs 300 at step 3 loss: 3.8925600051879883 running average of batch loss 4.055375754833221, time 0.48734593391418457\n",
      "#Epoch 159 with total epochs 300 at step 4 loss: 3.9962334632873535 running average of batch loss 4.043547296524048, time 0.48834872245788574\n",
      "#Epoch 159 with total epochs 300 at step 5 loss: 4.146072864532471 running average of batch loss 4.060634891192119, time 0.5253727436065674\n",
      "#Epoch 159 with total epochs 300 at step 6 loss: 3.805284261703491 running average of batch loss 4.0241562298366, time 0.4913487434387207\n",
      "#Epoch 159 with total epochs 300 at step 7 loss: 4.266780853271484 running average of batch loss 4.054484307765961, time 0.5263738632202148\n",
      "#Epoch 159 with total epochs 300 at step 8 loss: 3.8170056343078613 running average of batch loss 4.028097788492839, time 0.48834729194641113\n",
      "#Epoch 159 with total epochs 300 at step 9 loss: 3.7995564937591553 running average of batch loss 4.00524365901947, time 0.48834705352783203\n",
      "#Epoch 159 with total epochs 300 at step 10 loss: 4.045082092285156 running average of batch loss 4.0088653347708965, time 0.4893510341644287\n",
      "#Epoch 159 with total epochs 300 at step 11 loss: 4.102976322174072 running average of batch loss 4.016707917054494, time 0.48932433128356934\n",
      "#Epoch 159 with total epochs 300 at step 12 loss: 3.6254961490631104 running average of batch loss 3.98661470413208, time 0.4883244037628174\n",
      "#Epoch 159 with total epochs 300 at step 13 loss: 4.068593502044678 running average of batch loss 3.9924703325544084, time 0.4903240203857422\n",
      "#Epoch 159 with total epochs 300 at step 14 loss: 4.154736042022705 running average of batch loss 4.0032880465189615, time 0.48632097244262695\n",
      "#Epoch 159 with total epochs 300 at step 15 loss: 4.283015727996826 running average of batch loss 4.020771026611328, time 0.48834705352783203\n",
      "#Epoch 159 with total epochs 300 at step 16 loss: 3.906186819076538 running average of batch loss 4.014030779109282, time 0.4883463382720947\n",
      "#Epoch 159 with total epochs 300 at step 17 loss: 3.7603869438171387 running average of batch loss 3.999939454926385, time 0.48832130432128906\n",
      "#Epoch 159 with total epochs 300 at step 18 loss: 3.6811864376068115 running average of batch loss 3.9831629803306177, time 0.48834729194641113\n",
      "#Epoch 159 with total epochs 300 at step 19 loss: 3.9323129653930664 running average of batch loss 3.9806204795837403, time 0.4903523921966553\n",
      "#Epoch 159 with total epochs 300 at step 20 loss: 3.9743337631225586 running average of batch loss 3.9803211121332076, time 0.520369291305542\n",
      "#Epoch 160 with total epochs 300 at step 0 loss: 3.9695661067962646 running average of batch loss 3.9695661067962646, time 0.4893488883972168\n",
      "#Epoch 160 with total epochs 300 at step 1 loss: 3.9295835494995117 running average of batch loss 3.949574828147888, time 0.4973289966583252\n",
      "#Epoch 160 with total epochs 300 at step 2 loss: 4.079593658447266 running average of batch loss 3.9929144382476807, time 0.4873225688934326\n",
      "#Epoch 160 with total epochs 300 at step 3 loss: 4.111074924468994 running average of batch loss 4.022454559803009, time 0.48932433128356934\n",
      "#Epoch 160 with total epochs 300 at step 4 loss: 4.088235855102539 running average of batch loss 4.035610818862915, time 0.48832011222839355\n",
      "#Epoch 160 with total epochs 300 at step 5 loss: 4.224686145782471 running average of batch loss 4.067123373349507, time 0.528374433517456\n",
      "#Epoch 160 with total epochs 300 at step 6 loss: 4.15427827835083 running average of batch loss 4.0795740740639825, time 0.4893498420715332\n",
      "#Epoch 160 with total epochs 300 at step 7 loss: 4.1673994064331055 running average of batch loss 4.090552240610123, time 0.5023305416107178\n",
      "#Epoch 160 with total epochs 300 at step 8 loss: 4.350694179534912 running average of batch loss 4.119456900490655, time 0.5293388366699219\n",
      "#Epoch 160 with total epochs 300 at step 9 loss: 4.080056190490723 running average of batch loss 4.115516829490661, time 0.4923515319824219\n",
      "#Epoch 160 with total epochs 300 at step 10 loss: 3.6280570030212402 running average of batch loss 4.071202299811623, time 0.4963493347167969\n",
      "#Epoch 160 with total epochs 300 at step 11 loss: 3.7151529788970947 running average of batch loss 4.041531523068746, time 0.4993288516998291\n",
      "#Epoch 160 with total epochs 300 at step 12 loss: 3.9890899658203125 running average of batch loss 4.037497557126558, time 0.4863240718841553\n",
      "#Epoch 160 with total epochs 300 at step 13 loss: 3.6405506134033203 running average of batch loss 4.00914420400347, time 0.4883248805999756\n",
      "#Epoch 160 with total epochs 300 at step 14 loss: 3.9962422847747803 running average of batch loss 4.008284076054891, time 0.5053341388702393\n",
      "#Epoch 160 with total epochs 300 at step 15 loss: 3.915367364883423 running average of batch loss 4.002476781606674, time 0.5263745784759521\n",
      "#Epoch 160 with total epochs 300 at step 16 loss: 4.036928653717041 running average of batch loss 4.004503362319049, time 0.4883706569671631\n",
      "#Epoch 160 with total epochs 300 at step 17 loss: 3.663756847381592 running average of batch loss 3.985573000378079, time 0.4883232116699219\n",
      "#Epoch 160 with total epochs 300 at step 18 loss: 4.086465835571289 running average of batch loss 3.990883149598774, time 0.4883251190185547\n",
      "#Epoch 160 with total epochs 300 at step 19 loss: 4.270163536071777 running average of batch loss 4.004847168922424, time 0.48932337760925293\n",
      "#Epoch 160 with total epochs 300 at step 20 loss: 4.2910261154174805 running average of batch loss 4.018474737803142, time 0.5403854846954346\n",
      "avg difference between predicted and ground truth batch wise 5.947717191611018\n",
      "#Epoch 161 with total epochs 300 at step 0 loss: 3.9311182498931885 running average of batch loss 3.9311182498931885, time 0.49735331535339355\n",
      "#Epoch 161 with total epochs 300 at step 1 loss: 3.9608376026153564 running average of batch loss 3.9459779262542725, time 0.5233724117279053\n",
      "#Epoch 161 with total epochs 300 at step 2 loss: 3.6146202087402344 running average of batch loss 3.8355253537495932, time 0.4943506717681885\n",
      "#Epoch 161 with total epochs 300 at step 3 loss: 3.9399285316467285 running average of batch loss 3.861626148223877, time 0.5313780307769775\n",
      "#Epoch 161 with total epochs 300 at step 4 loss: 3.8081607818603516 running average of batch loss 3.850933074951172, time 0.4893462657928467\n",
      "#Epoch 161 with total epochs 300 at step 5 loss: 4.290387153625488 running average of batch loss 3.924175421396891, time 0.5303759574890137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 161 with total epochs 300 at step 6 loss: 3.7776846885681152 running average of batch loss 3.9032481738499234, time 0.4863450527191162\n",
      "#Epoch 161 with total epochs 300 at step 7 loss: 3.5959253311157227 running average of batch loss 3.864832818508148, time 0.48734545707702637\n",
      "#Epoch 161 with total epochs 300 at step 8 loss: 4.015394687652588 running average of batch loss 3.8815619150797525, time 0.49035000801086426\n",
      "#Epoch 161 with total epochs 300 at step 9 loss: 3.8213841915130615 running average of batch loss 3.8755441427230837, time 0.5203433036804199\n",
      "#Epoch 161 with total epochs 300 at step 10 loss: 3.9070770740509033 running average of batch loss 3.8784107728437944, time 0.487323522567749\n",
      "#Epoch 161 with total epochs 300 at step 11 loss: 4.304548740386963 running average of batch loss 3.9139222701390586, time 0.5383825302124023\n",
      "#Epoch 161 with total epochs 300 at step 12 loss: 3.9250595569610596 running average of batch loss 3.9147789845099816, time 0.5033586025238037\n",
      "#Epoch 161 with total epochs 300 at step 13 loss: 3.84255051612854 running average of batch loss 3.9096198081970215, time 0.5373585224151611\n",
      "#Epoch 161 with total epochs 300 at step 14 loss: 4.063359260559082 running average of batch loss 3.9198691050211587, time 0.4873223304748535\n",
      "#Epoch 161 with total epochs 300 at step 15 loss: 4.015811920166016 running average of batch loss 3.9258655309677124, time 0.48734545707702637\n",
      "#Epoch 161 with total epochs 300 at step 16 loss: 3.893676996231079 running average of batch loss 3.9239720877479103, time 0.49034905433654785\n",
      "#Epoch 161 with total epochs 300 at step 17 loss: 4.188479423522949 running average of batch loss 3.9386669397354126, time 0.5023572444915771\n",
      "#Epoch 161 with total epochs 300 at step 18 loss: 3.7631382942199707 running average of batch loss 3.929428589971442, time 0.48834753036499023\n",
      "#Epoch 161 with total epochs 300 at step 19 loss: 4.483339309692383 running average of batch loss 3.957124125957489, time 0.4963393211364746\n",
      "#Epoch 161 with total epochs 300 at step 20 loss: 3.973325252532959 running average of batch loss 3.9578956081753685, time 0.4993276596069336\n",
      "#Epoch 162 with total epochs 300 at step 0 loss: 4.167017459869385 running average of batch loss 4.167017459869385, time 0.4873473644256592\n",
      "#Epoch 162 with total epochs 300 at step 1 loss: 4.548933982849121 running average of batch loss 4.357975721359253, time 0.48734450340270996\n",
      "#Epoch 162 with total epochs 300 at step 2 loss: 3.840855360031128 running average of batch loss 4.185602267583211, time 0.4933505058288574\n",
      "#Epoch 162 with total epochs 300 at step 3 loss: 4.26975679397583 running average of batch loss 4.206640899181366, time 0.4933502674102783\n",
      "#Epoch 162 with total epochs 300 at step 4 loss: 3.919066905975342 running average of batch loss 4.149126100540161, time 0.5253691673278809\n",
      "#Epoch 162 with total epochs 300 at step 5 loss: 3.960132122039795 running average of batch loss 4.117627104123433, time 0.4913487434387207\n",
      "#Epoch 162 with total epochs 300 at step 6 loss: 4.105957984924316 running average of batch loss 4.115960087094988, time 0.4903252124786377\n",
      "#Epoch 162 with total epochs 300 at step 7 loss: 4.252971649169922 running average of batch loss 4.133086532354355, time 0.4893467426300049\n",
      "#Epoch 162 with total epochs 300 at step 8 loss: 3.8206965923309326 running average of batch loss 4.098376539018419, time 0.4993305206298828\n",
      "#Epoch 162 with total epochs 300 at step 9 loss: 4.020075798034668 running average of batch loss 4.090546464920044, time 0.4893481731414795\n",
      "#Epoch 162 with total epochs 300 at step 10 loss: 4.0156569480896 running average of batch loss 4.083738327026367, time 0.48734474182128906\n",
      "#Epoch 162 with total epochs 300 at step 11 loss: 3.9591217041015625 running average of batch loss 4.0733536084493, time 0.48834848403930664\n",
      "#Epoch 162 with total epochs 300 at step 12 loss: 3.8733925819396973 running average of batch loss 4.057971991025484, time 0.4873232841491699\n",
      "#Epoch 162 with total epochs 300 at step 13 loss: 3.7881789207458496 running average of batch loss 4.038701057434082, time 0.48834729194641113\n",
      "#Epoch 162 with total epochs 300 at step 14 loss: 4.244886875152588 running average of batch loss 4.052446778615316, time 0.4923274517059326\n",
      "#Epoch 162 with total epochs 300 at step 15 loss: 3.972780704498291 running average of batch loss 4.047467648983002, time 0.4873464107513428\n",
      "#Epoch 162 with total epochs 300 at step 16 loss: 4.216613292694092 running average of batch loss 4.057417392730713, time 0.48834776878356934\n",
      "#Epoch 162 with total epochs 300 at step 17 loss: 4.770022392272949 running average of batch loss 4.097006559371948, time 0.4893219470977783\n",
      "#Epoch 162 with total epochs 300 at step 18 loss: 3.95544171333313 running average of batch loss 4.089555778001484, time 0.48834729194641113\n",
      "#Epoch 162 with total epochs 300 at step 19 loss: 4.170338153839111 running average of batch loss 4.093594896793365, time 0.48832249641418457\n",
      "#Epoch 162 with total epochs 300 at step 20 loss: 3.589204788208008 running average of batch loss 4.069576320194063, time 0.48932552337646484\n",
      "#Epoch 163 with total epochs 300 at step 0 loss: 4.05858039855957 running average of batch loss 4.05858039855957, time 0.48832273483276367\n",
      "#Epoch 163 with total epochs 300 at step 1 loss: 4.01882266998291 running average of batch loss 4.03870153427124, time 0.49034929275512695\n",
      "#Epoch 163 with total epochs 300 at step 2 loss: 3.7775206565856934 running average of batch loss 3.951641241709391, time 0.487346887588501\n",
      "#Epoch 163 with total epochs 300 at step 3 loss: 4.123061180114746 running average of batch loss 3.99449622631073, time 0.4883229732513428\n",
      "#Epoch 163 with total epochs 300 at step 4 loss: 4.319784164428711 running average of batch loss 4.059553813934326, time 0.5363805294036865\n",
      "#Epoch 163 with total epochs 300 at step 5 loss: 3.8536529541015625 running average of batch loss 4.025237003962199, time 0.48834657669067383\n",
      "#Epoch 163 with total epochs 300 at step 6 loss: 4.175627708435059 running average of batch loss 4.046721390315464, time 0.48832249641418457\n",
      "#Epoch 163 with total epochs 300 at step 7 loss: 4.0218825340271 running average of batch loss 4.043616533279419, time 0.489346981048584\n",
      "#Epoch 163 with total epochs 300 at step 8 loss: 3.7239198684692383 running average of batch loss 4.008094681633843, time 0.4873239994049072\n",
      "#Epoch 163 with total epochs 300 at step 9 loss: 4.162893295288086 running average of batch loss 4.023574542999268, time 0.48834753036499023\n",
      "#Epoch 163 with total epochs 300 at step 10 loss: 3.7394704818725586 running average of batch loss 3.9977469010786577, time 0.48732471466064453\n",
      "#Epoch 163 with total epochs 300 at step 11 loss: 3.916029930114746 running average of batch loss 3.9909371534983316, time 0.49332666397094727\n",
      "#Epoch 163 with total epochs 300 at step 12 loss: 3.8838729858398438 running average of batch loss 3.9827014482938328, time 0.5233712196350098\n",
      "#Epoch 163 with total epochs 300 at step 13 loss: 3.8268840312957764 running average of batch loss 3.9715716327939714, time 0.49034810066223145\n",
      "#Epoch 163 with total epochs 300 at step 14 loss: 3.9278416633605957 running average of batch loss 3.968656301498413, time 0.4883248805999756\n",
      "#Epoch 163 with total epochs 300 at step 15 loss: 4.252841472625732 running average of batch loss 3.9864178746938705, time 0.4883251190185547\n",
      "#Epoch 163 with total epochs 300 at step 16 loss: 4.102563381195068 running average of batch loss 3.993249963311588, time 0.48832011222839355\n",
      "#Epoch 163 with total epochs 300 at step 17 loss: 4.000612735748291 running average of batch loss 3.993659006224738, time 0.4903256893157959\n",
      "#Epoch 163 with total epochs 300 at step 18 loss: 4.078289031982422 running average of batch loss 3.9981132181067216, time 0.48734593391418457\n",
      "#Epoch 163 with total epochs 300 at step 19 loss: 4.018041610717773 running average of batch loss 3.9991096377372743, time 0.48734593391418457\n",
      "#Epoch 163 with total epochs 300 at step 20 loss: 3.914447784423828 running average of batch loss 3.9950781209128245, time 0.4873466491699219\n",
      "#Epoch 164 with total epochs 300 at step 0 loss: 3.592989683151245 running average of batch loss 3.592989683151245, time 0.535376787185669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 164 with total epochs 300 at step 1 loss: 3.9241132736206055 running average of batch loss 3.7585514783859253, time 0.48834681510925293\n",
      "#Epoch 164 with total epochs 300 at step 2 loss: 3.6731672286987305 running average of batch loss 3.730090061823527, time 0.48834824562072754\n",
      "#Epoch 164 with total epochs 300 at step 3 loss: 3.868191719055176 running average of batch loss 3.764615476131439, time 0.497326135635376\n",
      "#Epoch 164 with total epochs 300 at step 4 loss: 4.029480934143066 running average of batch loss 3.8175885677337646, time 0.4903247356414795\n",
      "#Epoch 164 with total epochs 300 at step 5 loss: 4.08699893951416 running average of batch loss 3.8624902963638306, time 0.4913480281829834\n",
      "#Epoch 164 with total epochs 300 at step 6 loss: 4.139346122741699 running average of batch loss 3.902041128703526, time 0.4873213768005371\n",
      "#Epoch 164 with total epochs 300 at step 7 loss: 4.280026912689209 running average of batch loss 3.9492893517017365, time 0.48834657669067383\n",
      "#Epoch 164 with total epochs 300 at step 8 loss: 4.151730537414551 running average of batch loss 3.971782816780938, time 0.4893467426300049\n",
      "#Epoch 164 with total epochs 300 at step 9 loss: 3.9021155834198 running average of batch loss 3.964816093444824, time 0.48932480812072754\n",
      "#Epoch 164 with total epochs 300 at step 10 loss: 3.9243452548980713 running average of batch loss 3.9611369263042104, time 0.49032068252563477\n",
      "#Epoch 164 with total epochs 300 at step 11 loss: 4.017112731933594 running average of batch loss 3.9658015767733255, time 0.5233712196350098\n",
      "#Epoch 164 with total epochs 300 at step 12 loss: 4.0365400314331055 running average of batch loss 3.9712429963625393, time 0.49034833908081055\n",
      "#Epoch 164 with total epochs 300 at step 13 loss: 3.7059106826782227 running average of batch loss 3.9522906882422313, time 0.4883246421813965\n",
      "#Epoch 164 with total epochs 300 at step 14 loss: 4.067045211791992 running average of batch loss 3.9599409898122153, time 0.4873473644256592\n",
      "#Epoch 164 with total epochs 300 at step 15 loss: 3.9669189453125 running average of batch loss 3.960377112030983, time 0.4873464107513428\n",
      "#Epoch 164 with total epochs 300 at step 16 loss: 3.753389835357666 running average of batch loss 3.948201389873729, time 0.4913487434387207\n",
      "#Epoch 164 with total epochs 300 at step 17 loss: 4.165290832519531 running average of batch loss 3.9602619144651623, time 0.48834729194641113\n",
      "#Epoch 164 with total epochs 300 at step 18 loss: 4.158992767333984 running average of batch loss 3.970721433037206, time 0.48834824562072754\n",
      "#Epoch 164 with total epochs 300 at step 19 loss: 4.19943380355835 running average of batch loss 3.982157051563263, time 0.49332523345947266\n",
      "#Epoch 164 with total epochs 300 at step 20 loss: 4.144961833953857 running average of batch loss 3.9899096602485296, time 0.5213420391082764\n",
      "#Epoch 165 with total epochs 300 at step 0 loss: 4.136296272277832 running average of batch loss 4.136296272277832, time 0.5263702869415283\n",
      "#Epoch 165 with total epochs 300 at step 1 loss: 4.197116374969482 running average of batch loss 4.166706323623657, time 0.49034929275512695\n",
      "#Epoch 165 with total epochs 300 at step 2 loss: 3.7875518798828125 running average of batch loss 4.040321509043376, time 0.49632978439331055\n",
      "#Epoch 165 with total epochs 300 at step 3 loss: 3.744945526123047 running average of batch loss 3.9664775133132935, time 0.4873197078704834\n",
      "#Epoch 165 with total epochs 300 at step 4 loss: 3.8773303031921387 running average of batch loss 3.9486480712890626, time 0.4893524646759033\n",
      "#Epoch 165 with total epochs 300 at step 5 loss: 4.2459492683410645 running average of batch loss 3.9981982707977295, time 0.5053315162658691\n",
      "#Epoch 165 with total epochs 300 at step 6 loss: 4.149227142333984 running average of batch loss 4.0197738238743375, time 0.49232912063598633\n",
      "#Epoch 165 with total epochs 300 at step 7 loss: 4.0941925048828125 running average of batch loss 4.029076159000397, time 0.5223486423492432\n",
      "#Epoch 165 with total epochs 300 at step 8 loss: 3.4992194175720215 running average of batch loss 3.9702031877305775, time 0.49034857749938965\n",
      "#Epoch 165 with total epochs 300 at step 9 loss: 4.269895076751709 running average of batch loss 4.00017237663269, time 0.48734569549560547\n",
      "#Epoch 165 with total epochs 300 at step 10 loss: 3.617560863494873 running average of batch loss 3.96538951180198, time 0.5023319721221924\n",
      "#Epoch 165 with total epochs 300 at step 11 loss: 4.058929920196533 running average of batch loss 3.9731845458348594, time 0.5053558349609375\n",
      "#Epoch 165 with total epochs 300 at step 12 loss: 3.949711322784424 running average of batch loss 3.971378913292518, time 0.48834681510925293\n",
      "#Epoch 165 with total epochs 300 at step 13 loss: 3.8237085342407227 running average of batch loss 3.9608310290745328, time 0.522369384765625\n",
      "#Epoch 165 with total epochs 300 at step 14 loss: 3.95584774017334 running average of batch loss 3.960498809814453, time 0.49235057830810547\n",
      "#Epoch 165 with total epochs 300 at step 15 loss: 4.53446102142334 running average of batch loss 3.9963714480400085, time 0.4903252124786377\n",
      "#Epoch 165 with total epochs 300 at step 16 loss: 3.9259369373321533 running average of batch loss 3.9922282415277817, time 0.5253727436065674\n",
      "#Epoch 165 with total epochs 300 at step 17 loss: 4.01607608795166 running average of batch loss 3.993553121884664, time 0.4893465042114258\n",
      "#Epoch 165 with total epochs 300 at step 18 loss: 4.152010440826416 running average of batch loss 4.0018929807763355, time 0.48834681510925293\n",
      "#Epoch 165 with total epochs 300 at step 19 loss: 4.198101997375488 running average of batch loss 4.011703431606293, time 0.487323522567749\n",
      "#Epoch 165 with total epochs 300 at step 20 loss: 3.776721954345703 running average of batch loss 4.0005138374510265, time 0.4863450527191162\n",
      "#Epoch 166 with total epochs 300 at step 0 loss: 3.674940586090088 running average of batch loss 3.674940586090088, time 0.4913501739501953\n",
      "#Epoch 166 with total epochs 300 at step 1 loss: 4.0995330810546875 running average of batch loss 3.8872368335723877, time 0.5273783206939697\n",
      "#Epoch 166 with total epochs 300 at step 2 loss: 3.7239365577697754 running average of batch loss 3.83280340830485, time 0.4893486499786377\n",
      "#Epoch 166 with total epochs 300 at step 3 loss: 4.272947311401367 running average of batch loss 3.9428393840789795, time 0.48834681510925293\n",
      "#Epoch 166 with total epochs 300 at step 4 loss: 4.214035511016846 running average of batch loss 3.997078609466553, time 0.48834800720214844\n",
      "#Epoch 166 with total epochs 300 at step 5 loss: 4.212620735168457 running average of batch loss 4.033002297083537, time 0.49234938621520996\n",
      "#Epoch 166 with total epochs 300 at step 6 loss: 4.140010833740234 running average of batch loss 4.048289230891636, time 0.4913487434387207\n",
      "#Epoch 166 with total epochs 300 at step 7 loss: 3.775313138961792 running average of batch loss 4.014167219400406, time 0.5253696441650391\n",
      "#Epoch 166 with total epochs 300 at step 8 loss: 3.9679203033447266 running average of batch loss 4.009028673171997, time 0.49235033988952637\n",
      "#Epoch 166 with total epochs 300 at step 9 loss: 4.01162576675415 running average of batch loss 4.009288382530213, time 0.497326135635376\n",
      "#Epoch 166 with total epochs 300 at step 10 loss: 3.8746120929718018 running average of batch loss 3.9970450834794478, time 0.4883451461791992\n",
      "#Epoch 166 with total epochs 300 at step 11 loss: 3.7717912197113037 running average of batch loss 3.978273928165436, time 0.5253732204437256\n",
      "#Epoch 166 with total epochs 300 at step 12 loss: 3.71694016456604 running average of batch loss 3.9581713309654822, time 0.4893479347229004\n",
      "#Epoch 166 with total epochs 300 at step 13 loss: 3.8005950450897217 running average of batch loss 3.9469158819743564, time 0.5073599815368652\n",
      "#Epoch 166 with total epochs 300 at step 14 loss: 4.314454555511475 running average of batch loss 3.9714184602101645, time 0.4933502674102783\n",
      "#Epoch 166 with total epochs 300 at step 15 loss: 3.8936798572540283 running average of batch loss 3.966559797525406, time 0.521367073059082\n",
      "#Epoch 166 with total epochs 300 at step 16 loss: 4.367856025695801 running average of batch loss 3.9901654580060173, time 0.49034833908081055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 166 with total epochs 300 at step 17 loss: 4.522083759307861 running average of batch loss 4.0197164747450085, time 0.48534536361694336\n",
      "#Epoch 166 with total epochs 300 at step 18 loss: 4.02239465713501 running average of batch loss 4.019857431712904, time 0.48834729194641113\n",
      "#Epoch 166 with total epochs 300 at step 19 loss: 3.8845808506011963 running average of batch loss 4.013093602657318, time 0.5343794822692871\n",
      "#Epoch 166 with total epochs 300 at step 20 loss: 3.646202564239502 running average of batch loss 3.995622600827898, time 0.4883582592010498\n",
      "#Epoch 167 with total epochs 300 at step 0 loss: 3.9915740489959717 running average of batch loss 3.9915740489959717, time 0.5083389282226562\n",
      "#Epoch 167 with total epochs 300 at step 1 loss: 3.637258291244507 running average of batch loss 3.8144161701202393, time 0.5073332786560059\n",
      "#Epoch 167 with total epochs 300 at step 2 loss: 3.898566246032715 running average of batch loss 3.842466195424398, time 0.5203702449798584\n",
      "#Epoch 167 with total epochs 300 at step 3 loss: 3.837613582611084 running average of batch loss 3.8412530422210693, time 0.49337029457092285\n",
      "#Epoch 167 with total epochs 300 at step 4 loss: 4.309042930603027 running average of batch loss 3.934811019897461, time 0.5023312568664551\n",
      "#Epoch 167 with total epochs 300 at step 5 loss: 4.354412078857422 running average of batch loss 4.004744529724121, time 0.4993295669555664\n",
      "#Epoch 167 with total epochs 300 at step 6 loss: 4.503245830535889 running average of batch loss 4.075959001268659, time 0.5323774814605713\n",
      "#Epoch 167 with total epochs 300 at step 7 loss: 4.047213554382324 running average of batch loss 4.072365820407867, time 0.48734593391418457\n",
      "#Epoch 167 with total epochs 300 at step 8 loss: 4.0946044921875 running average of batch loss 4.074836783938938, time 0.49335145950317383\n",
      "#Epoch 167 with total epochs 300 at step 9 loss: 4.1900458335876465 running average of batch loss 4.086357688903808, time 0.4893226623535156\n",
      "#Epoch 167 with total epochs 300 at step 10 loss: 3.603466033935547 running average of batch loss 4.042458447543058, time 0.48932409286499023\n",
      "#Epoch 167 with total epochs 300 at step 11 loss: 3.91896915435791 running average of batch loss 4.032167673110962, time 0.5203697681427002\n",
      "#Epoch 167 with total epochs 300 at step 12 loss: 3.586857318878174 running average of batch loss 3.9979130304776707, time 0.4913501739501953\n",
      "#Epoch 167 with total epochs 300 at step 13 loss: 4.187016010284424 running average of batch loss 4.011420386178153, time 0.4863407611846924\n",
      "#Epoch 167 with total epochs 300 at step 14 loss: 4.057982444763184 running average of batch loss 4.014524523417155, time 0.4923222064971924\n",
      "#Epoch 167 with total epochs 300 at step 15 loss: 4.18890380859375 running average of batch loss 4.025423228740692, time 0.4903256893157959\n",
      "#Epoch 167 with total epochs 300 at step 16 loss: 3.8442654609680176 running average of batch loss 4.014766889459946, time 0.538381814956665\n",
      "#Epoch 167 with total epochs 300 at step 17 loss: 3.7769432067871094 running average of batch loss 4.001554462644789, time 0.49535179138183594\n",
      "#Epoch 167 with total epochs 300 at step 18 loss: 4.381319046020508 running average of batch loss 4.021542072296143, time 0.5120739936828613\n",
      "#Epoch 167 with total epochs 300 at step 19 loss: 3.987086296081543 running average of batch loss 4.019819283485413, time 0.5204277038574219\n",
      "#Epoch 167 with total epochs 300 at step 20 loss: 4.101289749145508 running average of batch loss 4.023698829469227, time 0.5219161510467529\n",
      "#Epoch 168 with total epochs 300 at step 0 loss: 3.7155041694641113 running average of batch loss 3.7155041694641113, time 0.49286627769470215\n",
      "#Epoch 168 with total epochs 300 at step 1 loss: 3.5257740020751953 running average of batch loss 3.6206390857696533, time 0.4888455867767334\n",
      "#Epoch 168 with total epochs 300 at step 2 loss: 4.0019965171813965 running average of batch loss 3.747758229573568, time 0.4919106960296631\n",
      "#Epoch 168 with total epochs 300 at step 3 loss: 3.860994338989258 running average of batch loss 3.7760672569274902, time 0.5245325565338135\n",
      "#Epoch 168 with total epochs 300 at step 4 loss: 4.127129554748535 running average of batch loss 3.8462797164916993, time 0.49736475944519043\n",
      "#Epoch 168 with total epochs 300 at step 5 loss: 4.216292381286621 running average of batch loss 3.9079484939575195, time 0.5013523101806641\n",
      "#Epoch 168 with total epochs 300 at step 6 loss: 3.8983399868011475 running average of batch loss 3.906575850078038, time 0.4903576374053955\n",
      "#Epoch 168 with total epochs 300 at step 7 loss: 3.4256787300109863 running average of batch loss 3.8464637100696564, time 0.5323002338409424\n",
      "#Epoch 168 with total epochs 300 at step 8 loss: 3.6854467391967773 running average of batch loss 3.8285729355282254, time 0.4883842468261719\n",
      "#Epoch 168 with total epochs 300 at step 9 loss: 3.994291305541992 running average of batch loss 3.845144772529602, time 0.4963414669036865\n",
      "#Epoch 168 with total epochs 300 at step 10 loss: 3.943504810333252 running average of batch loss 3.8540865941481157, time 0.5203425884246826\n",
      "#Epoch 168 with total epochs 300 at step 11 loss: 4.037370681762695 running average of batch loss 3.8693602681159973, time 0.48734593391418457\n",
      "#Epoch 168 with total epochs 300 at step 12 loss: 4.176731109619141 running average of batch loss 3.8930041790008545, time 0.5363771915435791\n",
      "#Epoch 168 with total epochs 300 at step 13 loss: 4.212100505828857 running average of batch loss 3.915796773774283, time 0.4893472194671631\n",
      "#Epoch 168 with total epochs 300 at step 14 loss: 4.762265205383301 running average of batch loss 3.972228002548218, time 0.5113630294799805\n",
      "#Epoch 168 with total epochs 300 at step 15 loss: 3.91398286819458 running average of batch loss 3.9685876816511154, time 0.5243725776672363\n",
      "#Epoch 168 with total epochs 300 at step 16 loss: 3.9897522926330566 running average of batch loss 3.9698326587677, time 0.487346887588501\n",
      "#Epoch 168 with total epochs 300 at step 17 loss: 4.200826644897461 running average of batch loss 3.9826656579971313, time 0.49234962463378906\n",
      "#Epoch 168 with total epochs 300 at step 18 loss: 4.030521869659424 running average of batch loss 3.985184405979357, time 0.48734617233276367\n",
      "#Epoch 168 with total epochs 300 at step 19 loss: 3.582730770111084 running average of batch loss 3.9650617241859436, time 0.48834681510925293\n",
      "#Epoch 168 with total epochs 300 at step 20 loss: 4.000990867614746 running average of batch loss 3.9667726357777915, time 0.5253729820251465\n",
      "#Epoch 169 with total epochs 300 at step 0 loss: 4.167649745941162 running average of batch loss 4.167649745941162, time 0.4873464107513428\n",
      "#Epoch 169 with total epochs 300 at step 1 loss: 4.2860894203186035 running average of batch loss 4.226869583129883, time 0.4893465042114258\n",
      "#Epoch 169 with total epochs 300 at step 2 loss: 4.022356033325195 running average of batch loss 4.158698399861653, time 0.48932361602783203\n",
      "#Epoch 169 with total epochs 300 at step 3 loss: 3.5283803939819336 running average of batch loss 4.001118898391724, time 0.4873232841491699\n",
      "#Epoch 169 with total epochs 300 at step 4 loss: 3.4626410007476807 running average of batch loss 3.893423318862915, time 0.5033328533172607\n",
      "#Epoch 169 with total epochs 300 at step 5 loss: 3.930997848510742 running average of batch loss 3.8996857404708862, time 0.48834800720214844\n",
      "#Epoch 169 with total epochs 300 at step 6 loss: 4.0290937423706055 running average of batch loss 3.918172597885132, time 0.5283751487731934\n",
      "#Epoch 169 with total epochs 300 at step 7 loss: 3.8594048023223877 running average of batch loss 3.910826623439789, time 0.49935460090637207\n",
      "#Epoch 169 with total epochs 300 at step 8 loss: 3.660599708557129 running average of batch loss 3.883023632897271, time 0.48734617233276367\n",
      "#Epoch 169 with total epochs 300 at step 9 loss: 3.962681293487549 running average of batch loss 3.890989398956299, time 0.48534512519836426\n",
      "#Epoch 169 with total epochs 300 at step 10 loss: 3.7842259407043457 running average of batch loss 3.881283630024303, time 0.4913489818572998\n",
      "#Epoch 169 with total epochs 300 at step 11 loss: 3.920754909515381 running average of batch loss 3.884572903315226, time 0.4893479347229004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 169 with total epochs 300 at step 12 loss: 4.011074542999268 running average of batch loss 3.894303798675537, time 0.5273749828338623\n",
      "#Epoch 169 with total epochs 300 at step 13 loss: 4.01668643951416 running average of batch loss 3.903045415878296, time 0.4863460063934326\n",
      "#Epoch 169 with total epochs 300 at step 14 loss: 3.9079525470733643 running average of batch loss 3.903372557957967, time 0.4883244037628174\n",
      "#Epoch 169 with total epochs 300 at step 15 loss: 3.820932626724243 running average of batch loss 3.8982200622558594, time 0.49532485008239746\n",
      "#Epoch 169 with total epochs 300 at step 16 loss: 3.3760533332824707 running average of batch loss 3.8675043723162483, time 0.48834729194641113\n",
      "#Epoch 169 with total epochs 300 at step 17 loss: 3.953968048095703 running average of batch loss 3.8723079098595514, time 0.5003535747528076\n",
      "#Epoch 169 with total epochs 300 at step 18 loss: 4.386114120483398 running average of batch loss 3.8993503419976485, time 0.49034905433654785\n",
      "#Epoch 169 with total epochs 300 at step 19 loss: 4.682036876678467 running average of batch loss 3.9384846687316895, time 0.5233461856842041\n",
      "#Epoch 169 with total epochs 300 at step 20 loss: 4.4447712898254395 running average of batch loss 3.9625935554504395, time 0.4903256893157959\n",
      "#Epoch 170 with total epochs 300 at step 0 loss: 4.301299571990967 running average of batch loss 4.301299571990967, time 0.48734569549560547\n",
      "#Epoch 170 with total epochs 300 at step 1 loss: 4.012742519378662 running average of batch loss 4.1570210456848145, time 0.4883260726928711\n",
      "#Epoch 170 with total epochs 300 at step 2 loss: 3.9694671630859375 running average of batch loss 4.094503084818522, time 0.5013554096221924\n",
      "#Epoch 170 with total epochs 300 at step 3 loss: 3.4170544147491455 running average of batch loss 3.925140917301178, time 0.5223708152770996\n",
      "#Epoch 170 with total epochs 300 at step 4 loss: 3.762235403060913 running average of batch loss 3.892559814453125, time 0.49034953117370605\n",
      "#Epoch 170 with total epochs 300 at step 5 loss: 3.7476277351379395 running average of batch loss 3.8684044679005942, time 0.49735426902770996\n",
      "#Epoch 170 with total epochs 300 at step 6 loss: 3.88778018951416 running average of batch loss 3.8711724281311035, time 0.49335145950317383\n",
      "#Epoch 170 with total epochs 300 at step 7 loss: 4.290564060211182 running average of batch loss 3.9235963821411133, time 0.4883463382720947\n",
      "#Epoch 170 with total epochs 300 at step 8 loss: 4.485254287719727 running average of batch loss 3.9860028160942926, time 0.48734593391418457\n",
      "#Epoch 170 with total epochs 300 at step 9 loss: 3.8281288146972656 running average of batch loss 3.97021541595459, time 0.5383815765380859\n",
      "#Epoch 170 with total epochs 300 at step 10 loss: 4.007126331329346 running average of batch loss 3.973570953715931, time 0.4883458614349365\n",
      "#Epoch 170 with total epochs 300 at step 11 loss: 4.411818504333496 running average of batch loss 4.010091582934062, time 0.49235081672668457\n",
      "#Epoch 170 with total epochs 300 at step 12 loss: 3.7827279567718506 running average of batch loss 3.992602073229276, time 0.48734569549560547\n",
      "#Epoch 170 with total epochs 300 at step 13 loss: 3.8746395111083984 running average of batch loss 3.9841761759349277, time 0.5013556480407715\n",
      "#Epoch 170 with total epochs 300 at step 14 loss: 3.41767954826355 running average of batch loss 3.946409734090169, time 0.49034786224365234\n",
      "#Epoch 170 with total epochs 300 at step 15 loss: 4.610642433166504 running average of batch loss 3.98792427778244, time 0.48734450340270996\n",
      "#Epoch 170 with total epochs 300 at step 16 loss: 3.9324803352355957 running average of batch loss 3.9846628693973316, time 0.5273737907409668\n",
      "#Epoch 170 with total epochs 300 at step 17 loss: 3.6371617317199707 running average of batch loss 3.9653572506374783, time 0.4913485050201416\n",
      "#Epoch 170 with total epochs 300 at step 18 loss: 3.8960089683532715 running average of batch loss 3.9617073410435726, time 0.48734569549560547\n",
      "#Epoch 170 with total epochs 300 at step 19 loss: 3.886106014251709 running average of batch loss 3.9579272747039793, time 0.4883463382720947\n",
      "#Epoch 170 with total epochs 300 at step 20 loss: 3.950997829437256 running average of batch loss 3.9575973011198498, time 0.4893479347229004\n",
      "#Epoch 171 with total epochs 300 at step 0 loss: 3.7475786209106445 running average of batch loss 3.7475786209106445, time 0.5193686485290527\n",
      "#Epoch 171 with total epochs 300 at step 1 loss: 3.936298370361328 running average of batch loss 3.8419384956359863, time 0.5223722457885742\n",
      "#Epoch 171 with total epochs 300 at step 2 loss: 4.124423980712891 running average of batch loss 3.9361003239949546, time 0.502356767654419\n",
      "#Epoch 171 with total epochs 300 at step 3 loss: 3.9583513736724854 running average of batch loss 3.941663086414337, time 0.5223708152770996\n",
      "#Epoch 171 with total epochs 300 at step 4 loss: 3.7615318298339844 running average of batch loss 3.9056368350982664, time 0.4873464107513428\n",
      "#Epoch 171 with total epochs 300 at step 5 loss: 3.9364726543426514 running average of batch loss 3.910776138305664, time 0.507361888885498\n",
      "#Epoch 171 with total epochs 300 at step 6 loss: 4.567653179168701 running average of batch loss 4.004615715571812, time 0.5113344192504883\n",
      "#Epoch 171 with total epochs 300 at step 7 loss: 3.8281683921813965 running average of batch loss 3.9825598001480103, time 0.49932861328125\n",
      "#Epoch 171 with total epochs 300 at step 8 loss: 3.690941333770752 running average of batch loss 3.950157748328315, time 0.5093369483947754\n",
      "#Epoch 171 with total epochs 300 at step 9 loss: 4.516172409057617 running average of batch loss 4.006759214401245, time 0.5103399753570557\n",
      "#Epoch 171 with total epochs 300 at step 10 loss: 3.971698522567749 running average of batch loss 4.0035718787800185, time 0.5153665542602539\n",
      "#Epoch 171 with total epochs 300 at step 11 loss: 3.886974334716797 running average of batch loss 3.9938554167747498, time 0.4883453845977783\n",
      "#Epoch 171 with total epochs 300 at step 12 loss: 3.8388915061950684 running average of batch loss 3.981935115960928, time 0.517341136932373\n",
      "#Epoch 171 with total epochs 300 at step 13 loss: 4.171133995056152 running average of batch loss 3.995449321610587, time 0.48932433128356934\n",
      "#Epoch 171 with total epochs 300 at step 14 loss: 3.722691535949707 running average of batch loss 3.977265469233195, time 0.524371862411499\n",
      "#Epoch 171 with total epochs 300 at step 15 loss: 3.8124372959136963 running average of batch loss 3.9669637084007263, time 0.49132513999938965\n",
      "#Epoch 171 with total epochs 300 at step 16 loss: 3.9697539806365967 running average of batch loss 3.96712784206166, time 0.48932385444641113\n",
      "#Epoch 171 with total epochs 300 at step 17 loss: 3.806576728820801 running average of batch loss 3.958208335770501, time 0.4873201847076416\n",
      "#Epoch 171 with total epochs 300 at step 18 loss: 4.054083347320557 running average of batch loss 3.9632543890099776, time 0.4883451461791992\n",
      "#Epoch 171 with total epochs 300 at step 19 loss: 3.5054492950439453 running average of batch loss 3.940364134311676, time 0.4893486499786377\n",
      "#Epoch 171 with total epochs 300 at step 20 loss: 4.090297222137451 running average of batch loss 3.9475038051605225, time 0.4883456230163574\n",
      "#Epoch 172 with total epochs 300 at step 0 loss: 3.8203203678131104 running average of batch loss 3.8203203678131104, time 0.48834729194641113\n",
      "#Epoch 172 with total epochs 300 at step 1 loss: 3.866427183151245 running average of batch loss 3.8433737754821777, time 0.5323784351348877\n",
      "#Epoch 172 with total epochs 300 at step 2 loss: 3.9601330757141113 running average of batch loss 3.8822935422261557, time 0.49034857749938965\n",
      "#Epoch 172 with total epochs 300 at step 3 loss: 3.6721816062927246 running average of batch loss 3.829765558242798, time 0.49132680892944336\n",
      "#Epoch 172 with total epochs 300 at step 4 loss: 4.181774616241455 running average of batch loss 3.900167369842529, time 0.48734474182128906\n",
      "#Epoch 172 with total epochs 300 at step 5 loss: 4.184855937957764 running average of batch loss 3.947615464528402, time 0.5063354969024658\n",
      "#Epoch 172 with total epochs 300 at step 6 loss: 3.9646294116973877 running average of batch loss 3.950046028409685, time 0.5223720073699951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 172 with total epochs 300 at step 7 loss: 4.062686443328857 running average of batch loss 3.964126080274582, time 0.4933512210845947\n",
      "#Epoch 172 with total epochs 300 at step 8 loss: 3.639009475708008 running average of batch loss 3.928002013100518, time 0.4883229732513428\n",
      "#Epoch 172 with total epochs 300 at step 9 loss: 3.833916187286377 running average of batch loss 3.918593430519104, time 0.4863462448120117\n",
      "#Epoch 172 with total epochs 300 at step 10 loss: 3.9206573963165283 running average of batch loss 3.9187810637734155, time 0.4873483180999756\n",
      "#Epoch 172 with total epochs 300 at step 11 loss: 3.3939592838287354 running average of batch loss 3.875045915444692, time 0.49234938621520996\n",
      "#Epoch 172 with total epochs 300 at step 12 loss: 3.760594129562378 running average of batch loss 3.866241931915283, time 0.48834776878356934\n",
      "#Epoch 172 with total epochs 300 at step 13 loss: 3.820646286010742 running average of batch loss 3.8629851000649587, time 0.49233126640319824\n",
      "#Epoch 172 with total epochs 300 at step 14 loss: 4.030038356781006 running average of batch loss 3.874121983846029, time 0.5113351345062256\n",
      "#Epoch 172 with total epochs 300 at step 15 loss: 4.063777446746826 running average of batch loss 3.8859754502773285, time 0.5213696956634521\n",
      "#Epoch 172 with total epochs 300 at step 16 loss: 3.7656912803649902 running average of batch loss 3.8788999108707203, time 0.49235033988952637\n",
      "#Epoch 172 with total epochs 300 at step 17 loss: 3.737166404724121 running average of batch loss 3.8710258271959095, time 0.48834729194641113\n",
      "#Epoch 172 with total epochs 300 at step 18 loss: 3.946962594985962 running average of batch loss 3.8750224991848596, time 0.48632311820983887\n",
      "#Epoch 172 with total epochs 300 at step 19 loss: 4.000670433044434 running average of batch loss 3.8813048958778382, time 0.4893484115600586\n",
      "#Epoch 172 with total epochs 300 at step 20 loss: 3.7543087005615234 running average of batch loss 3.8752574580056325, time 0.48932552337646484\n",
      "#Epoch 173 with total epochs 300 at step 0 loss: 3.6973791122436523 running average of batch loss 3.6973791122436523, time 0.501356840133667\n",
      "#Epoch 173 with total epochs 300 at step 1 loss: 3.818986415863037 running average of batch loss 3.7581827640533447, time 0.5293748378753662\n",
      "#Epoch 173 with total epochs 300 at step 2 loss: 3.598015069961548 running average of batch loss 3.7047935326894126, time 0.49034595489501953\n",
      "#Epoch 173 with total epochs 300 at step 3 loss: 3.695617198944092 running average of batch loss 3.7024994492530823, time 0.4863450527191162\n",
      "#Epoch 173 with total epochs 300 at step 4 loss: 3.877819299697876 running average of batch loss 3.737563419342041, time 0.4893460273742676\n",
      "#Epoch 173 with total epochs 300 at step 5 loss: 3.735572338104248 running average of batch loss 3.7372315724690757, time 0.5243723392486572\n",
      "#Epoch 173 with total epochs 300 at step 6 loss: 3.884216785430908 running average of batch loss 3.7582294600350514, time 0.49234938621520996\n",
      "#Epoch 173 with total epochs 300 at step 7 loss: 3.7192018032073975 running average of batch loss 3.753351002931595, time 0.4863450527191162\n",
      "#Epoch 173 with total epochs 300 at step 8 loss: 3.9547290802001953 running average of batch loss 3.7757263448503284, time 0.489346981048584\n",
      "#Epoch 173 with total epochs 300 at step 9 loss: 3.7186765670776367 running average of batch loss 3.770021367073059, time 0.5233719348907471\n",
      "#Epoch 173 with total epochs 300 at step 10 loss: 4.008188247680664 running average of batch loss 3.7916729016737505, time 0.48834800720214844\n",
      "#Epoch 173 with total epochs 300 at step 11 loss: 3.5784597396850586 running average of batch loss 3.7739051381746926, time 0.489346981048584\n",
      "#Epoch 173 with total epochs 300 at step 12 loss: 4.298272132873535 running average of batch loss 3.8142410608438344, time 0.5193688869476318\n",
      "#Epoch 173 with total epochs 300 at step 13 loss: 3.6936235427856445 running average of batch loss 3.805625523839678, time 0.49034833908081055\n",
      "#Epoch 173 with total epochs 300 at step 14 loss: 4.0465006828308105 running average of batch loss 3.8216838677724203, time 0.4913480281829834\n",
      "#Epoch 173 with total epochs 300 at step 15 loss: 3.6834566593170166 running average of batch loss 3.8130446672439575, time 0.5243721008300781\n",
      "#Epoch 173 with total epochs 300 at step 16 loss: 3.7952418327331543 running average of batch loss 3.8119974416844986, time 0.4913489818572998\n",
      "#Epoch 173 with total epochs 300 at step 17 loss: 4.3362016677856445 running average of batch loss 3.841119898690118, time 0.5023577213287354\n",
      "#Epoch 173 with total epochs 300 at step 18 loss: 4.166497230529785 running average of batch loss 3.8582450214185213, time 0.5233719348907471\n",
      "#Epoch 173 with total epochs 300 at step 19 loss: 3.989285707473755 running average of batch loss 3.864797055721283, time 0.49735236167907715\n",
      "#Epoch 173 with total epochs 300 at step 20 loss: 3.6822943687438965 running average of batch loss 3.8561064515795027, time 0.5283758640289307\n",
      "#Epoch 174 with total epochs 300 at step 0 loss: 3.6551434993743896 running average of batch loss 3.6551434993743896, time 0.4943504333496094\n",
      "#Epoch 174 with total epochs 300 at step 1 loss: 3.84141206741333 running average of batch loss 3.74827778339386, time 0.4893476963043213\n",
      "#Epoch 174 with total epochs 300 at step 2 loss: 3.745718240737915 running average of batch loss 3.747424602508545, time 0.5203695297241211\n",
      "#Epoch 174 with total epochs 300 at step 3 loss: 4.145714282989502 running average of batch loss 3.846997022628784, time 0.4893474578857422\n",
      "#Epoch 174 with total epochs 300 at step 4 loss: 4.029287815093994 running average of batch loss 3.883455181121826, time 0.49035048484802246\n",
      "#Epoch 174 with total epochs 300 at step 5 loss: 4.528146743774414 running average of batch loss 3.9909037748972573, time 0.5223708152770996\n",
      "#Epoch 174 with total epochs 300 at step 6 loss: 4.128733158111572 running average of batch loss 4.0105936867850165, time 0.49034881591796875\n",
      "#Epoch 174 with total epochs 300 at step 7 loss: 3.7429862022399902 running average of batch loss 3.9771427512168884, time 0.4873464107513428\n",
      "#Epoch 174 with total epochs 300 at step 8 loss: 4.141525745391846 running average of batch loss 3.9954075283474393, time 0.4913504123687744\n",
      "#Epoch 174 with total epochs 300 at step 9 loss: 3.8976802825927734 running average of batch loss 3.9856348037719727, time 0.5303771495819092\n",
      "#Epoch 174 with total epochs 300 at step 10 loss: 3.609891414642334 running average of batch loss 3.951476313851096, time 0.49234843254089355\n",
      "#Epoch 174 with total epochs 300 at step 11 loss: 4.315554618835449 running average of batch loss 3.9818161725997925, time 0.4893476963043213\n",
      "#Epoch 174 with total epochs 300 at step 12 loss: 3.8374414443969727 running average of batch loss 3.970710424276499, time 0.5674030780792236\n",
      "#Epoch 174 with total epochs 300 at step 13 loss: 3.7292089462280273 running average of batch loss 3.953460318701608, time 0.49034833908081055\n",
      "#Epoch 174 with total epochs 300 at step 14 loss: 3.882983922958374 running average of batch loss 3.9487618923187258, time 0.5562043190002441\n",
      "#Epoch 174 with total epochs 300 at step 15 loss: 4.110516548156738 running average of batch loss 3.9588715583086014, time 0.5014693737030029\n",
      "#Epoch 174 with total epochs 300 at step 16 loss: 3.7958521842956543 running average of batch loss 3.9492821833666634, time 0.5283703804016113\n",
      "#Epoch 174 with total epochs 300 at step 17 loss: 3.8145127296447754 running average of batch loss 3.941794991493225, time 0.4949219226837158\n",
      "#Epoch 174 with total epochs 300 at step 18 loss: 3.5040509700775146 running average of batch loss 3.9187558324713456, time 0.5269322395324707\n",
      "#Epoch 174 with total epochs 300 at step 19 loss: 3.5116219520568848 running average of batch loss 3.8983991384506225, time 0.4929788112640381\n",
      "#Epoch 174 with total epochs 300 at step 20 loss: 3.8938469886779785 running average of batch loss 3.89818236941383, time 0.5279970169067383\n",
      "#Epoch 175 with total epochs 300 at step 0 loss: 3.5562620162963867 running average of batch loss 3.5562620162963867, time 0.49133801460266113\n",
      "#Epoch 175 with total epochs 300 at step 1 loss: 3.662703514099121 running average of batch loss 3.609482765197754, time 0.49036192893981934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 175 with total epochs 300 at step 2 loss: 3.597799062728882 running average of batch loss 3.60558819770813, time 0.5267307758331299\n",
      "#Epoch 175 with total epochs 300 at step 3 loss: 3.7310538291931152 running average of batch loss 3.636954605579376, time 0.49084925651550293\n",
      "#Epoch 175 with total epochs 300 at step 4 loss: 3.8985228538513184 running average of batch loss 3.6892682552337646, time 0.49133825302124023\n",
      "#Epoch 175 with total epochs 300 at step 5 loss: 3.828591823577881 running average of batch loss 3.712488849957784, time 0.4898524284362793\n",
      "#Epoch 175 with total epochs 300 at step 6 loss: 3.9813570976257324 running average of batch loss 3.750898599624634, time 0.4893486499786377\n",
      "#Epoch 175 with total epochs 300 at step 7 loss: 3.730936050415039 running average of batch loss 3.7484032809734344, time 0.5393617153167725\n",
      "#Epoch 175 with total epochs 300 at step 8 loss: 4.018409729003906 running average of batch loss 3.7784039974212646, time 0.49832987785339355\n",
      "#Epoch 175 with total epochs 300 at step 9 loss: 3.5883822441101074 running average of batch loss 3.759401822090149, time 0.4873216152191162\n",
      "#Epoch 175 with total epochs 300 at step 10 loss: 3.9557418823242188 running average of batch loss 3.7772509184750644, time 0.4873232841491699\n",
      "#Epoch 175 with total epochs 300 at step 11 loss: 3.6730575561523438 running average of batch loss 3.768568138281504, time 0.49733424186706543\n",
      "#Epoch 175 with total epochs 300 at step 12 loss: 3.8968653678894043 running average of batch loss 3.7784371559436503, time 0.48832273483276367\n",
      "#Epoch 175 with total epochs 300 at step 13 loss: 3.9030630588531494 running average of batch loss 3.787339006151472, time 0.487346887588501\n",
      "#Epoch 175 with total epochs 300 at step 14 loss: 3.9621059894561768 running average of batch loss 3.7989901383717855, time 0.48734402656555176\n",
      "#Epoch 175 with total epochs 300 at step 15 loss: 4.027223587036133 running average of batch loss 3.813254728913307, time 0.4923231601715088\n",
      "#Epoch 175 with total epochs 300 at step 16 loss: 4.103178977966309 running average of batch loss 3.83030909650466, time 0.5283761024475098\n",
      "#Epoch 175 with total epochs 300 at step 17 loss: 3.8430888652801514 running average of batch loss 3.831019083658854, time 0.49034929275512695\n",
      "#Epoch 175 with total epochs 300 at step 18 loss: 3.889470100402832 running average of batch loss 3.8340954529611686, time 0.5073587894439697\n",
      "#Epoch 175 with total epochs 300 at step 19 loss: 3.6559109687805176 running average of batch loss 3.8251862287521363, time 0.48932528495788574\n",
      "#Epoch 175 with total epochs 300 at step 20 loss: 3.4965968132019043 running average of batch loss 3.809539113725935, time 0.48932385444641113\n",
      "#Epoch 176 with total epochs 300 at step 0 loss: 3.5567009449005127 running average of batch loss 3.5567009449005127, time 0.5213701725006104\n",
      "#Epoch 176 with total epochs 300 at step 1 loss: 4.1147141456604 running average of batch loss 3.8357075452804565, time 0.5003561973571777\n",
      "#Epoch 176 with total epochs 300 at step 2 loss: 3.7026712894439697 running average of batch loss 3.7913621266682944, time 0.4863462448120117\n",
      "#Epoch 176 with total epochs 300 at step 3 loss: 3.952239513397217 running average of batch loss 3.831581473350525, time 0.487346887588501\n",
      "#Epoch 176 with total epochs 300 at step 4 loss: 3.6109890937805176 running average of batch loss 3.7874629974365233, time 0.49034738540649414\n",
      "#Epoch 176 with total epochs 300 at step 5 loss: 3.7274250984191895 running average of batch loss 3.7774566809336343, time 0.5003552436828613\n",
      "#Epoch 176 with total epochs 300 at step 6 loss: 3.9553561210632324 running average of batch loss 3.802870886666434, time 0.48734617233276367\n",
      "#Epoch 176 with total epochs 300 at step 7 loss: 3.8861541748046875 running average of batch loss 3.813281297683716, time 0.5253725051879883\n",
      "#Epoch 176 with total epochs 300 at step 8 loss: 4.209018230438232 running average of batch loss 3.8572520679897733, time 0.4893491268157959\n",
      "#Epoch 176 with total epochs 300 at step 9 loss: 3.6623423099517822 running average of batch loss 3.837761092185974, time 0.4873471260070801\n",
      "#Epoch 176 with total epochs 300 at step 10 loss: 3.7500882148742676 running average of batch loss 3.8297908306121826, time 0.4893221855163574\n",
      "#Epoch 176 with total epochs 300 at step 11 loss: 3.6129071712493896 running average of batch loss 3.8117171923319497, time 0.4883241653442383\n",
      "#Epoch 176 with total epochs 300 at step 12 loss: 3.8252360820770264 running average of batch loss 3.812757106927725, time 0.48534369468688965\n",
      "#Epoch 176 with total epochs 300 at step 13 loss: 4.301024913787842 running average of batch loss 3.8476333788463046, time 0.5253736972808838\n",
      "#Epoch 176 with total epochs 300 at step 14 loss: 3.850522041320801 running average of batch loss 3.8478259563446047, time 0.4943511486053467\n",
      "#Epoch 176 with total epochs 300 at step 15 loss: 3.8247733116149902 running average of batch loss 3.8463851660490036, time 0.48834776878356934\n",
      "#Epoch 176 with total epochs 300 at step 16 loss: 3.70562481880188 running average of batch loss 3.838105145622702, time 0.4883460998535156\n",
      "#Epoch 176 with total epochs 300 at step 17 loss: 4.0823540687561035 running average of batch loss 3.8516745302412243, time 0.49235010147094727\n",
      "#Epoch 176 with total epochs 300 at step 18 loss: 3.6069869995117188 running average of batch loss 3.8387962391501977, time 0.530376672744751\n",
      "#Epoch 176 with total epochs 300 at step 19 loss: 3.598414182662964 running average of batch loss 3.8267771363258363, time 0.4983537197113037\n",
      "#Epoch 176 with total epochs 300 at step 20 loss: 3.337785005569458 running average of batch loss 3.8034917967660085, time 0.49032092094421387\n",
      "#Epoch 177 with total epochs 300 at step 0 loss: 3.939218521118164 running average of batch loss 3.939218521118164, time 0.48734569549560547\n",
      "#Epoch 177 with total epochs 300 at step 1 loss: 4.009668350219727 running average of batch loss 3.9744434356689453, time 0.5223720073699951\n",
      "#Epoch 177 with total epochs 300 at step 2 loss: 3.7162742614746094 running average of batch loss 3.8883870442708335, time 0.4963521957397461\n",
      "#Epoch 177 with total epochs 300 at step 3 loss: 3.885824680328369 running average of batch loss 3.8877464532852173, time 0.4883460998535156\n",
      "#Epoch 177 with total epochs 300 at step 4 loss: 3.490722894668579 running average of batch loss 3.8083417415618896, time 0.49535155296325684\n",
      "#Epoch 177 with total epochs 300 at step 5 loss: 3.6109371185302734 running average of batch loss 3.77544097105662, time 0.4893474578857422\n",
      "#Epoch 177 with total epochs 300 at step 6 loss: 3.7225918769836426 running average of batch loss 3.7678911004747664, time 0.5283749103546143\n",
      "#Epoch 177 with total epochs 300 at step 7 loss: 3.783632278442383 running average of batch loss 3.7698587477207184, time 0.4893479347229004\n",
      "#Epoch 177 with total epochs 300 at step 8 loss: 4.0168633460998535 running average of batch loss 3.797303703096178, time 0.48734474182128906\n",
      "#Epoch 177 with total epochs 300 at step 9 loss: 4.014198303222656 running average of batch loss 3.818993163108826, time 0.48734426498413086\n",
      "#Epoch 177 with total epochs 300 at step 10 loss: 3.6778135299682617 running average of batch loss 3.806158651005138, time 0.530376672744751\n",
      "#Epoch 177 with total epochs 300 at step 11 loss: 3.4505250453948975 running average of batch loss 3.7765225172042847, time 0.49234938621520996\n",
      "#Epoch 177 with total epochs 300 at step 12 loss: 3.4703714847564697 running average of batch loss 3.752972437785222, time 0.4993562698364258\n",
      "#Epoch 177 with total epochs 300 at step 13 loss: 3.9834325313568115 running average of batch loss 3.7694338730403354, time 0.5263745784759521\n",
      "#Epoch 177 with total epochs 300 at step 14 loss: 4.044580459594727 running average of batch loss 3.787776978810628, time 0.49434995651245117\n",
      "#Epoch 177 with total epochs 300 at step 15 loss: 3.7591552734375 running average of batch loss 3.7859881222248077, time 0.4873471260070801\n",
      "#Epoch 177 with total epochs 300 at step 16 loss: 3.845740556716919 running average of batch loss 3.789502971312579, time 0.530376672744751\n",
      "#Epoch 177 with total epochs 300 at step 17 loss: 4.020767688751221 running average of batch loss 3.8023510111702814, time 0.49234890937805176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 177 with total epochs 300 at step 18 loss: 3.595489501953125 running average of batch loss 3.791463563316747, time 0.5323786735534668\n",
      "#Epoch 177 with total epochs 300 at step 19 loss: 3.4507391452789307 running average of batch loss 3.774427342414856, time 0.48834705352783203\n",
      "#Epoch 177 with total epochs 300 at step 20 loss: 4.025386333465576 running average of batch loss 3.7863777705601285, time 0.49034857749938965\n",
      "#Epoch 178 with total epochs 300 at step 0 loss: 3.509780168533325 running average of batch loss 3.509780168533325, time 0.4863455295562744\n",
      "#Epoch 178 with total epochs 300 at step 1 loss: 3.7045583724975586 running average of batch loss 3.607169270515442, time 0.4903237819671631\n",
      "#Epoch 178 with total epochs 300 at step 2 loss: 3.576019763946533 running average of batch loss 3.596786101659139, time 0.5203702449798584\n",
      "#Epoch 178 with total epochs 300 at step 3 loss: 3.922991991043091 running average of batch loss 3.678337574005127, time 0.4943511486053467\n",
      "#Epoch 178 with total epochs 300 at step 4 loss: 3.765174388885498 running average of batch loss 3.695704936981201, time 0.48833465576171875\n",
      "#Epoch 178 with total epochs 300 at step 5 loss: 3.953023672103882 running average of batch loss 3.7385913928349814, time 0.5273754596710205\n",
      "#Epoch 178 with total epochs 300 at step 6 loss: 3.9576337337493896 running average of batch loss 3.769883155822754, time 0.49034833908081055\n",
      "#Epoch 178 with total epochs 300 at step 7 loss: 3.852165699005127 running average of batch loss 3.7801684737205505, time 0.48834657669067383\n",
      "#Epoch 178 with total epochs 300 at step 8 loss: 3.8264870643615723 running average of batch loss 3.7853149837917752, time 0.4863462448120117\n",
      "#Epoch 178 with total epochs 300 at step 9 loss: 3.4230172634124756 running average of batch loss 3.749085211753845, time 0.4903252124786377\n",
      "#Epoch 178 with total epochs 300 at step 10 loss: 3.7457380294799805 running average of batch loss 3.748780922456221, time 0.5233480930328369\n",
      "#Epoch 178 with total epochs 300 at step 11 loss: 3.567321538925171 running average of batch loss 3.733659307161967, time 0.49535036087036133\n",
      "#Epoch 178 with total epochs 300 at step 12 loss: 3.4832143783569336 running average of batch loss 3.714394312638503, time 0.4943516254425049\n",
      "#Epoch 178 with total epochs 300 at step 13 loss: 3.8413681983947754 running average of batch loss 3.723463875906808, time 0.4893229007720947\n",
      "#Epoch 178 with total epochs 300 at step 14 loss: 3.851166009902954 running average of batch loss 3.731977351506551, time 0.4893462657928467\n",
      "#Epoch 178 with total epochs 300 at step 15 loss: 3.750988483428955 running average of batch loss 3.7331655472517014, time 0.526374101638794\n",
      "#Epoch 178 with total epochs 300 at step 16 loss: 4.39270544052124 running average of batch loss 3.771962011561674, time 0.4893481731414795\n",
      "#Epoch 178 with total epochs 300 at step 17 loss: 3.413090229034424 running average of batch loss 3.75202469031016, time 0.48932337760925293\n",
      "#Epoch 178 with total epochs 300 at step 18 loss: 3.9477391242980957 running average of batch loss 3.7623254499937357, time 0.489346981048584\n",
      "#Epoch 178 with total epochs 300 at step 19 loss: 3.780850648880005 running average of batch loss 3.763251709938049, time 0.4943516254425049\n",
      "#Epoch 178 with total epochs 300 at step 20 loss: 3.5252468585968018 running average of batch loss 3.751918145588466, time 0.4873230457305908\n",
      "#Epoch 179 with total epochs 300 at step 0 loss: 3.7839198112487793 running average of batch loss 3.7839198112487793, time 0.48932528495788574\n",
      "#Epoch 179 with total epochs 300 at step 1 loss: 4.103600025177002 running average of batch loss 3.9437599182128906, time 0.4883239269256592\n",
      "#Epoch 179 with total epochs 300 at step 2 loss: 3.687979221343994 running average of batch loss 3.8584996859232583, time 0.5243725776672363\n",
      "#Epoch 179 with total epochs 300 at step 3 loss: 3.760848045349121 running average of batch loss 3.834086775779724, time 0.5023584365844727\n",
      "#Epoch 179 with total epochs 300 at step 4 loss: 4.031924724578857 running average of batch loss 3.873654365539551, time 0.4883456230163574\n",
      "#Epoch 179 with total epochs 300 at step 5 loss: 3.903669834136963 running average of batch loss 3.8786569436391196, time 0.4883463382720947\n",
      "#Epoch 179 with total epochs 300 at step 6 loss: 4.042957782745361 running average of batch loss 3.9021284920828685, time 0.5263738632202148\n",
      "#Epoch 179 with total epochs 300 at step 7 loss: 3.712007999420166 running average of batch loss 3.8783634305000305, time 0.4943525791168213\n",
      "#Epoch 179 with total epochs 300 at step 8 loss: 4.169602394104004 running average of batch loss 3.9107233153449164, time 0.4873478412628174\n",
      "#Epoch 179 with total epochs 300 at step 9 loss: 3.546907424926758 running average of batch loss 3.8743417263031006, time 0.48734593391418457\n",
      "#Epoch 179 with total epochs 300 at step 10 loss: 3.3417277336120605 running average of batch loss 3.825922272422097, time 0.4893491268157959\n",
      "#Epoch 179 with total epochs 300 at step 11 loss: 4.119668960571289 running average of batch loss 3.8504011631011963, time 0.4873483180999756\n",
      "#Epoch 179 with total epochs 300 at step 12 loss: 3.713879108428955 running average of batch loss 3.839899466587947, time 0.4883453845977783\n",
      "#Epoch 179 with total epochs 300 at step 13 loss: 3.9083354473114014 running average of batch loss 3.8447877509253368, time 0.4893229007720947\n",
      "#Epoch 179 with total epochs 300 at step 14 loss: 4.214181423187256 running average of batch loss 3.8694139957427978, time 0.4883229732513428\n",
      "#Epoch 179 with total epochs 300 at step 15 loss: 4.285684585571289 running average of batch loss 3.8954309076070786, time 0.5233731269836426\n",
      "#Epoch 179 with total epochs 300 at step 16 loss: 3.783047676086426 running average of batch loss 3.888820129282334, time 0.49235010147094727\n",
      "#Epoch 179 with total epochs 300 at step 17 loss: 3.980048418045044 running average of batch loss 3.8938883675469294, time 0.48832273483276367\n",
      "#Epoch 179 with total epochs 300 at step 18 loss: 3.5952563285827637 running average of batch loss 3.878170891811973, time 0.4893476963043213\n",
      "#Epoch 179 with total epochs 300 at step 19 loss: 3.7666890621185303 running average of batch loss 3.872596800327301, time 0.4913489818572998\n",
      "#Epoch 179 with total epochs 300 at step 20 loss: 4.2889909744262695 running average of batch loss 3.892425094332014, time 0.4863457679748535\n",
      "#Epoch 180 with total epochs 300 at step 0 loss: 3.381915330886841 running average of batch loss 3.381915330886841, time 0.48832273483276367\n",
      "#Epoch 180 with total epochs 300 at step 1 loss: 4.453157901763916 running average of batch loss 3.9175366163253784, time 0.5063600540161133\n",
      "#Epoch 180 with total epochs 300 at step 2 loss: 3.513282060623169 running average of batch loss 3.782785097757975, time 0.4933505058288574\n",
      "#Epoch 180 with total epochs 300 at step 3 loss: 3.595907211303711 running average of batch loss 3.736065626144409, time 0.5333783626556396\n",
      "#Epoch 180 with total epochs 300 at step 4 loss: 3.816037654876709 running average of batch loss 3.7520600318908692, time 0.49234986305236816\n",
      "#Epoch 180 with total epochs 300 at step 5 loss: 3.7267212867736816 running average of batch loss 3.7478369077046714, time 0.4903247356414795\n",
      "#Epoch 180 with total epochs 300 at step 6 loss: 3.9793989658355713 running average of batch loss 3.7809172017233714, time 0.49034643173217773\n",
      "#Epoch 180 with total epochs 300 at step 7 loss: 3.703580141067505 running average of batch loss 3.771250069141388, time 0.49235033988952637\n",
      "#Epoch 180 with total epochs 300 at step 8 loss: 3.8777289390563965 running average of batch loss 3.7830810546875, time 0.48932433128356934\n",
      "#Epoch 180 with total epochs 300 at step 9 loss: 3.7650747299194336 running average of batch loss 3.7812804222106933, time 0.4903237819671631\n",
      "#Epoch 180 with total epochs 300 at step 10 loss: 3.9818713665008545 running average of batch loss 3.799515962600708, time 0.5233719348907471\n",
      "#Epoch 180 with total epochs 300 at step 11 loss: 3.557316303253174 running average of batch loss 3.7793326576550803, time 0.49735403060913086\n",
      "#Epoch 180 with total epochs 300 at step 12 loss: 3.7912423610687256 running average of batch loss 3.780248788686899, time 0.4873478412628174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 180 with total epochs 300 at step 13 loss: 3.8504250049591064 running average of batch loss 3.7852613755634854, time 0.48932361602783203\n",
      "#Epoch 180 with total epochs 300 at step 14 loss: 3.8120319843292236 running average of batch loss 3.7870460828145345, time 0.48834681510925293\n",
      "#Epoch 180 with total epochs 300 at step 15 loss: 3.779810905456543 running average of batch loss 3.78659388422966, time 0.4893224239349365\n",
      "#Epoch 180 with total epochs 300 at step 16 loss: 4.023987770080566 running average of batch loss 3.800558230456184, time 0.48834872245788574\n",
      "#Epoch 180 with total epochs 300 at step 17 loss: 3.365825653076172 running average of batch loss 3.776406420601739, time 0.525371789932251\n",
      "#Epoch 180 with total epochs 300 at step 18 loss: 3.5057826042175293 running average of batch loss 3.7621630618446753, time 0.49735260009765625\n",
      "#Epoch 180 with total epochs 300 at step 19 loss: 3.803018093109131 running average of batch loss 3.764205813407898, time 0.49035143852233887\n",
      "#Epoch 180 with total epochs 300 at step 20 loss: 3.613762617111206 running average of batch loss 3.757041851679484, time 0.5263733863830566\n",
      "avg difference between predicted and ground truth batch wise 5.649860871246882\n",
      "#Epoch 181 with total epochs 300 at step 0 loss: 3.943976879119873 running average of batch loss 3.943976879119873, time 0.4893486499786377\n",
      "#Epoch 181 with total epochs 300 at step 1 loss: 3.754849433898926 running average of batch loss 3.8494131565093994, time 0.5273537635803223\n",
      "#Epoch 181 with total epochs 300 at step 2 loss: 3.407961845397949 running average of batch loss 3.7022627194722495, time 0.4913496971130371\n",
      "#Epoch 181 with total epochs 300 at step 3 loss: 3.1681034564971924 running average of batch loss 3.568722903728485, time 0.4883463382720947\n",
      "#Epoch 181 with total epochs 300 at step 4 loss: 3.986337184906006 running average of batch loss 3.6522457599639893, time 0.4953296184539795\n",
      "#Epoch 181 with total epochs 300 at step 5 loss: 3.636353015899658 running average of batch loss 3.6495969692866006, time 0.48832249641418457\n",
      "#Epoch 181 with total epochs 300 at step 6 loss: 4.41847038269043 running average of batch loss 3.7594360283442905, time 0.4933493137359619\n",
      "#Epoch 181 with total epochs 300 at step 7 loss: 3.4845287799835205 running average of batch loss 3.7250726222991943, time 0.4893481731414795\n",
      "#Epoch 181 with total epochs 300 at step 8 loss: 3.7633376121520996 running average of batch loss 3.729324287838406, time 0.4913511276245117\n",
      "#Epoch 181 with total epochs 300 at step 9 loss: 4.280184268951416 running average of batch loss 3.784410285949707, time 0.48932433128356934\n",
      "#Epoch 181 with total epochs 300 at step 10 loss: 3.356947898864746 running average of batch loss 3.7455500689419834, time 0.48932433128356934\n",
      "#Epoch 181 with total epochs 300 at step 11 loss: 3.7161641120910645 running average of batch loss 3.7431012392044067, time 0.4873464107513428\n",
      "#Epoch 181 with total epochs 300 at step 12 loss: 4.477433204650879 running average of batch loss 3.79958831346952, time 0.48932504653930664\n",
      "#Epoch 181 with total epochs 300 at step 13 loss: 3.939675807952881 running average of batch loss 3.8095945630754744, time 0.49032020568847656\n",
      "#Epoch 181 with total epochs 300 at step 14 loss: 3.8925304412841797 running average of batch loss 3.8151236216227216, time 0.4973292350769043\n",
      "#Epoch 181 with total epochs 300 at step 15 loss: 3.7197628021240234 running average of batch loss 3.8091635704040527, time 0.4923224449157715\n",
      "#Epoch 181 with total epochs 300 at step 16 loss: 4.460287094116211 running average of batch loss 3.847464954151827, time 0.5153672695159912\n",
      "#Epoch 181 with total epochs 300 at step 17 loss: 4.07957124710083 running average of batch loss 3.8603597482045493, time 0.5083327293395996\n",
      "#Epoch 181 with total epochs 300 at step 18 loss: 3.9939465522766113 running average of batch loss 3.8673906326293945, time 0.5033557415008545\n",
      "#Epoch 181 with total epochs 300 at step 19 loss: 4.072089672088623 running average of batch loss 3.877625584602356, time 0.497330904006958\n",
      "#Epoch 181 with total epochs 300 at step 20 loss: 3.645326852798462 running average of batch loss 3.866563740230742, time 0.4883449077606201\n",
      "#Epoch 182 with total epochs 300 at step 0 loss: 3.670431137084961 running average of batch loss 3.670431137084961, time 0.49335193634033203\n",
      "#Epoch 182 with total epochs 300 at step 1 loss: 3.526873826980591 running average of batch loss 3.598652482032776, time 0.49034881591796875\n",
      "#Epoch 182 with total epochs 300 at step 2 loss: 3.8657188415527344 running average of batch loss 3.687674601872762, time 0.4863457679748535\n",
      "#Epoch 182 with total epochs 300 at step 3 loss: 3.562819719314575 running average of batch loss 3.6564608812332153, time 0.48834705352783203\n",
      "#Epoch 182 with total epochs 300 at step 4 loss: 3.8128445148468018 running average of batch loss 3.6877376079559325, time 0.48734617233276367\n",
      "#Epoch 182 with total epochs 300 at step 5 loss: 3.626438617706299 running average of batch loss 3.6775211095809937, time 0.49535059928894043\n",
      "#Epoch 182 with total epochs 300 at step 6 loss: 4.2144575119018555 running average of batch loss 3.7542263099125455, time 0.4863460063934326\n",
      "#Epoch 182 with total epochs 300 at step 7 loss: 3.6289401054382324 running average of batch loss 3.7385655343532562, time 0.4873478412628174\n",
      "#Epoch 182 with total epochs 300 at step 8 loss: 4.172397613525391 running average of batch loss 3.7867690987057157, time 0.48932480812072754\n",
      "#Epoch 182 with total epochs 300 at step 9 loss: 4.006557941436768 running average of batch loss 3.808747982978821, time 0.48932313919067383\n",
      "#Epoch 182 with total epochs 300 at step 10 loss: 3.7711849212646484 running average of batch loss 3.8053331591866235, time 0.48734545707702637\n",
      "#Epoch 182 with total epochs 300 at step 11 loss: 4.073443412780762 running average of batch loss 3.827675680319468, time 0.48932504653930664\n",
      "#Epoch 182 with total epochs 300 at step 12 loss: 3.698727607727051 running average of batch loss 3.8177565978123593, time 0.4873192310333252\n",
      "#Epoch 182 with total epochs 300 at step 13 loss: 3.632511854171753 running average of batch loss 3.8045248304094588, time 0.4883463382720947\n",
      "#Epoch 182 with total epochs 300 at step 14 loss: 3.803668737411499 running average of batch loss 3.804467757542928, time 0.48834681510925293\n",
      "#Epoch 182 with total epochs 300 at step 15 loss: 3.637860059738159 running average of batch loss 3.79405477643013, time 0.48534536361694336\n",
      "#Epoch 182 with total epochs 300 at step 16 loss: 3.832289695739746 running average of batch loss 3.7963038893306957, time 0.4873218536376953\n",
      "#Epoch 182 with total epochs 300 at step 17 loss: 3.644516944885254 running average of batch loss 3.7878712813059487, time 0.506333589553833\n",
      "#Epoch 182 with total epochs 300 at step 18 loss: 3.8413584232330322 running average of batch loss 3.7906863940389535, time 0.5173399448394775\n",
      "#Epoch 182 with total epochs 300 at step 19 loss: 3.7967264652252197 running average of batch loss 3.790988397598267, time 0.4893479347229004\n",
      "#Epoch 182 with total epochs 300 at step 20 loss: 3.8126378059387207 running average of batch loss 3.792019321804955, time 0.48734617233276367\n",
      "#Epoch 183 with total epochs 300 at step 0 loss: 3.829258680343628 running average of batch loss 3.829258680343628, time 0.4903249740600586\n",
      "#Epoch 183 with total epochs 300 at step 1 loss: 3.711015224456787 running average of batch loss 3.7701369524002075, time 0.49234771728515625\n",
      "#Epoch 183 with total epochs 300 at step 2 loss: 4.227160453796387 running average of batch loss 3.922478119532267, time 0.4873464107513428\n",
      "#Epoch 183 with total epochs 300 at step 3 loss: 3.4469597339630127 running average of batch loss 3.8035985231399536, time 0.48832225799560547\n",
      "#Epoch 183 with total epochs 300 at step 4 loss: 3.7086122035980225 running average of batch loss 3.784601259231567, time 0.488323450088501\n",
      "#Epoch 183 with total epochs 300 at step 5 loss: 3.4085466861724854 running average of batch loss 3.7219254970550537, time 0.4883239269256592\n",
      "#Epoch 183 with total epochs 300 at step 6 loss: 3.7665951251983643 running average of batch loss 3.728306872504098, time 0.48834681510925293\n",
      "#Epoch 183 with total epochs 300 at step 7 loss: 4.048423767089844 running average of batch loss 3.7683214843273163, time 0.487346887588501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 183 with total epochs 300 at step 8 loss: 3.480440616607666 running average of batch loss 3.736334721247355, time 0.4873471260070801\n",
      "#Epoch 183 with total epochs 300 at step 9 loss: 3.968271255493164 running average of batch loss 3.759528374671936, time 0.4883246421813965\n",
      "#Epoch 183 with total epochs 300 at step 10 loss: 3.654745101928711 running average of batch loss 3.75000262260437, time 0.4863464832305908\n",
      "#Epoch 183 with total epochs 300 at step 11 loss: 3.714439630508423 running average of batch loss 3.747039039929708, time 0.4883453845977783\n",
      "#Epoch 183 with total epochs 300 at step 12 loss: 3.802356004714966 running average of batch loss 3.751294191067035, time 0.4893472194671631\n",
      "#Epoch 183 with total epochs 300 at step 13 loss: 3.6781461238861084 running average of batch loss 3.7460693291255405, time 0.48534655570983887\n",
      "#Epoch 183 with total epochs 300 at step 14 loss: 3.6284849643707275 running average of batch loss 3.7382303714752196, time 0.48834776878356934\n",
      "#Epoch 183 with total epochs 300 at step 15 loss: 4.131185531616211 running average of batch loss 3.7627900689840317, time 0.49535393714904785\n",
      "#Epoch 183 with total epochs 300 at step 16 loss: 3.663632392883301 running average of batch loss 3.756957264507518, time 0.506333589553833\n",
      "#Epoch 183 with total epochs 300 at step 17 loss: 3.6628260612487793 running average of batch loss 3.751727753215366, time 0.49833035469055176\n",
      "#Epoch 183 with total epochs 300 at step 18 loss: 3.8082988262176514 running average of batch loss 3.754705178110223, time 0.4883241653442383\n",
      "#Epoch 183 with total epochs 300 at step 19 loss: 3.8887393474578857 running average of batch loss 3.761406886577606, time 0.48734474182128906\n",
      "#Epoch 183 with total epochs 300 at step 20 loss: 3.830014705657959 running average of batch loss 3.7646739255814325, time 0.48832154273986816\n",
      "#Epoch 184 with total epochs 300 at step 0 loss: 4.124015808105469 running average of batch loss 4.124015808105469, time 0.485321044921875\n",
      "#Epoch 184 with total epochs 300 at step 1 loss: 3.9153060913085938 running average of batch loss 4.019660949707031, time 0.4883232116699219\n",
      "#Epoch 184 with total epochs 300 at step 2 loss: 4.091255187988281 running average of batch loss 4.043525695800781, time 0.49235033988952637\n",
      "#Epoch 184 with total epochs 300 at step 3 loss: 3.5557281970977783 running average of batch loss 3.9215763211250305, time 0.4873225688934326\n",
      "#Epoch 184 with total epochs 300 at step 4 loss: 3.587517023086548 running average of batch loss 3.854764461517334, time 0.4923272132873535\n",
      "#Epoch 184 with total epochs 300 at step 5 loss: 4.058919906616211 running average of batch loss 3.8887903690338135, time 0.4913480281829834\n",
      "#Epoch 184 with total epochs 300 at step 6 loss: 3.942838668823242 running average of batch loss 3.8965115547180176, time 0.4883241653442383\n",
      "#Epoch 184 with total epochs 300 at step 7 loss: 3.774439811706543 running average of batch loss 3.8812525868415833, time 0.4883460998535156\n",
      "#Epoch 184 with total epochs 300 at step 8 loss: 3.937222719192505 running average of batch loss 3.88747149043613, time 0.4893476963043213\n",
      "#Epoch 184 with total epochs 300 at step 9 loss: 3.73230242729187 running average of batch loss 3.871954584121704, time 0.48932385444641113\n",
      "#Epoch 184 with total epochs 300 at step 10 loss: 3.7554707527160645 running average of batch loss 3.8613651449030097, time 0.4903247356414795\n",
      "#Epoch 184 with total epochs 300 at step 11 loss: 3.8256633281707764 running average of batch loss 3.858389993508657, time 0.4933497905731201\n",
      "#Epoch 184 with total epochs 300 at step 12 loss: 4.126296043395996 running average of batch loss 3.8789981511922984, time 0.48834705352783203\n",
      "#Epoch 184 with total epochs 300 at step 13 loss: 4.052215576171875 running average of batch loss 3.8913708244051253, time 0.49034857749938965\n",
      "#Epoch 184 with total epochs 300 at step 14 loss: 3.8623416423797607 running average of batch loss 3.889435545603434, time 0.5243728160858154\n",
      "#Epoch 184 with total epochs 300 at step 15 loss: 3.507864236831665 running average of batch loss 3.8655873388051987, time 0.4913489818572998\n",
      "#Epoch 184 with total epochs 300 at step 16 loss: 3.9930930137634277 running average of batch loss 3.873087672626271, time 0.48834729194641113\n",
      "#Epoch 184 with total epochs 300 at step 17 loss: 3.957160711288452 running average of batch loss 3.8777583969963922, time 0.5073587894439697\n",
      "#Epoch 184 with total epochs 300 at step 18 loss: 4.108769416809082 running average of batch loss 3.8899168717233756, time 0.5313842296600342\n",
      "#Epoch 184 with total epochs 300 at step 19 loss: 4.403830051422119 running average of batch loss 3.915612530708313, time 0.49234962463378906\n",
      "#Epoch 184 with total epochs 300 at step 20 loss: 3.828423023223877 running average of batch loss 3.9114606493995305, time 0.5253715515136719\n",
      "#Epoch 185 with total epochs 300 at step 0 loss: 3.6989762783050537 running average of batch loss 3.6989762783050537, time 0.496354341506958\n",
      "#Epoch 185 with total epochs 300 at step 1 loss: 4.288569450378418 running average of batch loss 3.993772864341736, time 0.4943516254425049\n",
      "#Epoch 185 with total epochs 300 at step 2 loss: 3.9711031913757324 running average of batch loss 3.9862163066864014, time 0.48734593391418457\n",
      "#Epoch 185 with total epochs 300 at step 3 loss: 3.40673565864563 running average of batch loss 3.8413461446762085, time 0.5303773880004883\n",
      "#Epoch 185 with total epochs 300 at step 4 loss: 4.063210487365723 running average of batch loss 3.8857190132141115, time 0.49535274505615234\n",
      "#Epoch 185 with total epochs 300 at step 5 loss: 3.659116268157959 running average of batch loss 3.847951889038086, time 0.4893472194671631\n",
      "#Epoch 185 with total epochs 300 at step 6 loss: 3.690471649169922 running average of batch loss 3.8254547119140625, time 0.48834776878356934\n",
      "#Epoch 185 with total epochs 300 at step 7 loss: 3.7464776039123535 running average of batch loss 3.815582573413849, time 0.5784099102020264\n",
      "#Epoch 185 with total epochs 300 at step 8 loss: 3.744553804397583 running average of batch loss 3.807690487967597, time 0.507359504699707\n",
      "#Epoch 185 with total epochs 300 at step 9 loss: 3.9204046726226807 running average of batch loss 3.8189619064331053, time 0.4873464107513428\n",
      "#Epoch 185 with total epochs 300 at step 10 loss: 4.1067304611206055 running average of batch loss 3.8451226841319692, time 0.48932433128356934\n",
      "#Epoch 185 with total epochs 300 at step 11 loss: 3.937116861343384 running average of batch loss 3.8527888655662537, time 0.48834776878356934\n",
      "#Epoch 185 with total epochs 300 at step 12 loss: 3.6993613243103027 running average of batch loss 3.8409867470081034, time 0.4883458614349365\n",
      "#Epoch 185 with total epochs 300 at step 13 loss: 3.591575860977173 running average of batch loss 3.82317168372018, time 0.4873228073120117\n",
      "#Epoch 185 with total epochs 300 at step 14 loss: 4.00422477722168 running average of batch loss 3.8352418899536134, time 0.517345666885376\n",
      "#Epoch 185 with total epochs 300 at step 15 loss: 3.86163330078125 running average of batch loss 3.8368913531303406, time 0.5073323249816895\n",
      "#Epoch 185 with total epochs 300 at step 16 loss: 3.245295286178589 running average of batch loss 3.80209158448612, time 0.4873223304748535\n",
      "#Epoch 185 with total epochs 300 at step 17 loss: 3.576303720474243 running average of batch loss 3.789547814263238, time 0.4863452911376953\n",
      "#Epoch 185 with total epochs 300 at step 18 loss: 3.597230911254883 running average of batch loss 3.7794258719996403, time 0.48932337760925293\n",
      "#Epoch 185 with total epochs 300 at step 19 loss: 3.223942279815674 running average of batch loss 3.7516516923904417, time 0.4883463382720947\n",
      "#Epoch 185 with total epochs 300 at step 20 loss: 3.965935230255127 running average of batch loss 3.7618556703839983, time 0.4893472194671631\n",
      "#Epoch 186 with total epochs 300 at step 0 loss: 3.8473548889160156 running average of batch loss 3.8473548889160156, time 0.48834705352783203\n",
      "#Epoch 186 with total epochs 300 at step 1 loss: 3.9193758964538574 running average of batch loss 3.8833653926849365, time 0.4883246421813965\n",
      "#Epoch 186 with total epochs 300 at step 2 loss: 3.9343152046203613 running average of batch loss 3.900348663330078, time 0.48734617233276367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 186 with total epochs 300 at step 3 loss: 3.7067339420318604 running average of batch loss 3.8519449830055237, time 0.4883451461791992\n",
      "#Epoch 186 with total epochs 300 at step 4 loss: 3.876906156539917 running average of batch loss 3.856937217712402, time 0.491349458694458\n",
      "#Epoch 186 with total epochs 300 at step 5 loss: 4.123679161071777 running average of batch loss 3.9013942082722983, time 0.4863460063934326\n",
      "#Epoch 186 with total epochs 300 at step 6 loss: 3.647575855255127 running average of batch loss 3.8651344435555592, time 0.489346981048584\n",
      "#Epoch 186 with total epochs 300 at step 7 loss: 3.6158485412597656 running average of batch loss 3.833973705768585, time 0.4863452911376953\n",
      "#Epoch 186 with total epochs 300 at step 8 loss: 3.6806206703186035 running average of batch loss 3.8169344796074762, time 0.4863448143005371\n",
      "#Epoch 186 with total epochs 300 at step 9 loss: 3.6837892532348633 running average of batch loss 3.803619956970215, time 0.49132537841796875\n",
      "#Epoch 186 with total epochs 300 at step 10 loss: 3.770901918411255 running average of batch loss 3.800645589828491, time 0.4863452911376953\n",
      "#Epoch 186 with total epochs 300 at step 11 loss: 3.99696683883667 running average of batch loss 3.817005693912506, time 0.4883449077606201\n",
      "#Epoch 186 with total epochs 300 at step 12 loss: 3.5490283966064453 running average of batch loss 3.7963920556581936, time 0.48834753036499023\n",
      "#Epoch 186 with total epochs 300 at step 13 loss: 3.7548606395721436 running average of batch loss 3.7934255259377614, time 0.4883236885070801\n",
      "#Epoch 186 with total epochs 300 at step 14 loss: 3.331737995147705 running average of batch loss 3.7626463572184243, time 0.49034786224365234\n",
      "#Epoch 186 with total epochs 300 at step 15 loss: 3.6246395111083984 running average of batch loss 3.754020929336548, time 0.4883236885070801\n",
      "#Epoch 186 with total epochs 300 at step 16 loss: 3.802431106567383 running average of batch loss 3.7568685868207146, time 0.486344575881958\n",
      "#Epoch 186 with total epochs 300 at step 17 loss: 3.962594509124756 running average of batch loss 3.768297804726495, time 0.5063347816467285\n",
      "#Epoch 186 with total epochs 300 at step 18 loss: 3.7542929649353027 running average of batch loss 3.7675607078953792, time 0.49632692337036133\n",
      "#Epoch 186 with total epochs 300 at step 19 loss: 3.696345567703247 running average of batch loss 3.763999950885773, time 0.4883241653442383\n",
      "#Epoch 186 with total epochs 300 at step 20 loss: 3.6431431770324707 running average of batch loss 3.7582448664165677, time 0.5003316402435303\n",
      "#Epoch 187 with total epochs 300 at step 0 loss: 4.041776180267334 running average of batch loss 4.041776180267334, time 0.48834681510925293\n",
      "#Epoch 187 with total epochs 300 at step 1 loss: 3.4514217376708984 running average of batch loss 3.746598958969116, time 0.4893474578857422\n",
      "#Epoch 187 with total epochs 300 at step 2 loss: 3.769045829772949 running average of batch loss 3.7540812492370605, time 0.4883456230163574\n",
      "#Epoch 187 with total epochs 300 at step 3 loss: 3.664834499359131 running average of batch loss 3.731769561767578, time 0.4863455295562744\n",
      "#Epoch 187 with total epochs 300 at step 4 loss: 3.668083429336548 running average of batch loss 3.719032335281372, time 0.4893472194671631\n",
      "#Epoch 187 with total epochs 300 at step 5 loss: 4.015507698059082 running average of batch loss 3.7684448957443237, time 0.4923264980316162\n",
      "#Epoch 187 with total epochs 300 at step 6 loss: 3.678300619125366 running average of batch loss 3.7555671419416154, time 0.4893479347229004\n",
      "#Epoch 187 with total epochs 300 at step 7 loss: 3.647688150405884 running average of batch loss 3.742082267999649, time 0.48832201957702637\n",
      "#Epoch 187 with total epochs 300 at step 8 loss: 3.9023892879486084 running average of batch loss 3.759894159105089, time 0.4893474578857422\n",
      "#Epoch 187 with total epochs 300 at step 9 loss: 4.192157745361328 running average of batch loss 3.803120517730713, time 0.49034762382507324\n",
      "#Epoch 187 with total epochs 300 at step 10 loss: 4.159459590911865 running average of batch loss 3.8355149789289995, time 0.4893462657928467\n",
      "#Epoch 187 with total epochs 300 at step 11 loss: 3.6383187770843506 running average of batch loss 3.819081962108612, time 0.4923264980316162\n",
      "#Epoch 187 with total epochs 300 at step 12 loss: 3.7563765048980713 running average of batch loss 3.814258465400109, time 0.48834705352783203\n",
      "#Epoch 187 with total epochs 300 at step 13 loss: 3.7755911350250244 running average of batch loss 3.81149651323046, time 0.4893465042114258\n",
      "#Epoch 187 with total epochs 300 at step 14 loss: 3.8283238410949707 running average of batch loss 3.8126183350880942, time 0.48734521865844727\n",
      "#Epoch 187 with total epochs 300 at step 15 loss: 3.3768725395202637 running average of batch loss 3.7853842228651047, time 0.511340856552124\n",
      "#Epoch 187 with total epochs 300 at step 16 loss: 3.558931827545166 running average of batch loss 3.7720634937286377, time 0.4873228073120117\n",
      "#Epoch 187 with total epochs 300 at step 17 loss: 3.776235342025757 running average of batch loss 3.772295263078478, time 0.48733043670654297\n",
      "#Epoch 187 with total epochs 300 at step 18 loss: 4.086795806884766 running average of batch loss 3.7888479232788086, time 0.48932337760925293\n",
      "#Epoch 187 with total epochs 300 at step 19 loss: 3.835580587387085 running average of batch loss 3.7911845564842226, time 0.4873223304748535\n",
      "#Epoch 187 with total epochs 300 at step 20 loss: 3.5916748046875 running average of batch loss 3.78168409211295, time 0.4943511486053467\n",
      "#Epoch 188 with total epochs 300 at step 0 loss: 3.721806287765503 running average of batch loss 3.721806287765503, time 0.49535250663757324\n",
      "#Epoch 188 with total epochs 300 at step 1 loss: 3.511751651763916 running average of batch loss 3.6167789697647095, time 0.49034881591796875\n",
      "#Epoch 188 with total epochs 300 at step 2 loss: 3.917386293411255 running average of batch loss 3.7169814109802246, time 0.49034810066223145\n",
      "#Epoch 188 with total epochs 300 at step 3 loss: 3.773977518081665 running average of batch loss 3.7312304377555847, time 0.4883458614349365\n",
      "#Epoch 188 with total epochs 300 at step 4 loss: 3.6040518283843994 running average of batch loss 3.7057947158813476, time 0.48834681510925293\n",
      "#Epoch 188 with total epochs 300 at step 5 loss: 3.426682233810425 running average of batch loss 3.6592759688695273, time 0.487346887588501\n",
      "#Epoch 188 with total epochs 300 at step 6 loss: 4.269362926483154 running average of batch loss 3.7464312485286166, time 0.49234795570373535\n",
      "#Epoch 188 with total epochs 300 at step 7 loss: 3.9195728302001953 running average of batch loss 3.768073946237564, time 0.4893462657928467\n",
      "#Epoch 188 with total epochs 300 at step 8 loss: 4.283568859100342 running average of batch loss 3.8253511587778726, time 0.4913485050201416\n",
      "#Epoch 188 with total epochs 300 at step 9 loss: 3.6157491207122803 running average of batch loss 3.8043909549713133, time 0.523371696472168\n",
      "#Epoch 188 with total epochs 300 at step 10 loss: 3.5519728660583496 running average of batch loss 3.781443855979226, time 0.513364315032959\n",
      "#Epoch 188 with total epochs 300 at step 11 loss: 3.9114224910736084 running average of batch loss 3.7922754089037576, time 0.4913489818572998\n",
      "#Epoch 188 with total epochs 300 at step 12 loss: 3.870861053466797 running average of batch loss 3.79832045848553, time 0.4913516044616699\n",
      "#Epoch 188 with total epochs 300 at step 13 loss: 3.362464666366577 running average of batch loss 3.7671879019056047, time 0.5323774814605713\n",
      "#Epoch 188 with total epochs 300 at step 14 loss: 4.034997940063477 running average of batch loss 3.785041904449463, time 0.5053596496582031\n",
      "#Epoch 188 with total epochs 300 at step 15 loss: 3.722029447555542 running average of batch loss 3.781103625893593, time 0.4883248805999756\n",
      "#Epoch 188 with total epochs 300 at step 16 loss: 3.148146629333496 running average of batch loss 3.7438708613900578, time 0.4893455505371094\n",
      "#Epoch 188 with total epochs 300 at step 17 loss: 3.8140571117401123 running average of batch loss 3.7477700975206165, time 0.4863457679748535\n",
      "#Epoch 188 with total epochs 300 at step 18 loss: 3.4591856002807617 running average of batch loss 3.7325814397711503, time 0.49034881591796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 188 with total epochs 300 at step 19 loss: 3.694408893585205 running average of batch loss 3.730672812461853, time 0.48832178115844727\n",
      "#Epoch 188 with total epochs 300 at step 20 loss: 4.138871192932129 running average of batch loss 3.750110830579485, time 0.48932600021362305\n",
      "#Epoch 189 with total epochs 300 at step 0 loss: 3.9274299144744873 running average of batch loss 3.9274299144744873, time 0.5333786010742188\n",
      "#Epoch 189 with total epochs 300 at step 1 loss: 4.191352844238281 running average of batch loss 4.059391379356384, time 0.4963521957397461\n",
      "#Epoch 189 with total epochs 300 at step 2 loss: 3.6878108978271484 running average of batch loss 3.935531218846639, time 0.49034881591796875\n",
      "#Epoch 189 with total epochs 300 at step 3 loss: 3.3863115310668945 running average of batch loss 3.798226296901703, time 0.4873359203338623\n",
      "#Epoch 189 with total epochs 300 at step 4 loss: 3.5377259254455566 running average of batch loss 3.7461262226104735, time 0.48732447624206543\n",
      "#Epoch 189 with total epochs 300 at step 5 loss: 3.5885772705078125 running average of batch loss 3.7198680639266968, time 0.4903244972229004\n",
      "#Epoch 189 with total epochs 300 at step 6 loss: 3.290363073348999 running average of batch loss 3.658510208129883, time 0.4893481731414795\n",
      "#Epoch 189 with total epochs 300 at step 7 loss: 3.7648391723632812 running average of batch loss 3.6718013286590576, time 0.4943506717681885\n",
      "#Epoch 189 with total epochs 300 at step 8 loss: 3.896383285522461 running average of batch loss 3.696754879421658, time 0.523371696472168\n",
      "#Epoch 189 with total epochs 300 at step 9 loss: 3.4462952613830566 running average of batch loss 3.671708917617798, time 0.4983539581298828\n",
      "#Epoch 189 with total epochs 300 at step 10 loss: 3.585711717605591 running average of batch loss 3.663890990343961, time 0.48834681510925293\n",
      "#Epoch 189 with total epochs 300 at step 11 loss: 3.8721323013305664 running average of batch loss 3.681244432926178, time 0.48932385444641113\n",
      "#Epoch 189 with total epochs 300 at step 12 loss: 3.4651713371276855 running average of batch loss 3.664623425557063, time 0.4883244037628174\n",
      "#Epoch 189 with total epochs 300 at step 13 loss: 3.793227195739746 running average of batch loss 3.6738094091415405, time 0.5243744850158691\n",
      "#Epoch 189 with total epochs 300 at step 14 loss: 3.4422712326049805 running average of batch loss 3.6583735307057696, time 0.4963521957397461\n",
      "#Epoch 189 with total epochs 300 at step 15 loss: 3.7185165882110596 running average of batch loss 3.6621324717998505, time 0.4883255958557129\n",
      "#Epoch 189 with total epochs 300 at step 16 loss: 4.047754764556885 running average of batch loss 3.684816136079676, time 0.48833727836608887\n",
      "#Epoch 189 with total epochs 300 at step 17 loss: 3.596141815185547 running average of batch loss 3.679889784918891, time 0.48834753036499023\n",
      "#Epoch 189 with total epochs 300 at step 18 loss: 3.625493288040161 running average of batch loss 3.677026811398958, time 0.4873194694519043\n",
      "#Epoch 189 with total epochs 300 at step 19 loss: 3.5277414321899414 running average of batch loss 3.669562542438507, time 0.488323450088501\n",
      "#Epoch 189 with total epochs 300 at step 20 loss: 3.9403128623962402 running average of batch loss 3.6824554148174466, time 0.5263495445251465\n",
      "#Epoch 190 with total epochs 300 at step 0 loss: 3.893845558166504 running average of batch loss 3.893845558166504, time 0.4913487434387207\n",
      "#Epoch 190 with total epochs 300 at step 1 loss: 3.887101650238037 running average of batch loss 3.8904736042022705, time 0.49234962463378906\n",
      "#Epoch 190 with total epochs 300 at step 2 loss: 3.8335654735565186 running average of batch loss 3.871504227320353, time 0.4883460998535156\n",
      "#Epoch 190 with total epochs 300 at step 3 loss: 3.9184322357177734 running average of batch loss 3.8832362294197083, time 0.4863455295562744\n",
      "#Epoch 190 with total epochs 300 at step 4 loss: 3.5872817039489746 running average of batch loss 3.8240453243255614, time 0.526374340057373\n",
      "#Epoch 190 with total epochs 300 at step 5 loss: 4.066822052001953 running average of batch loss 3.864508112271627, time 0.49535250663757324\n",
      "#Epoch 190 with total epochs 300 at step 6 loss: 3.824333906173706 running average of batch loss 3.858768939971924, time 0.4893479347229004\n",
      "#Epoch 190 with total epochs 300 at step 7 loss: 3.2300314903259277 running average of batch loss 3.7801767587661743, time 0.48932433128356934\n",
      "#Epoch 190 with total epochs 300 at step 8 loss: 3.349104404449463 running average of batch loss 3.732279830508762, time 0.49432873725891113\n",
      "#Epoch 190 with total epochs 300 at step 9 loss: 3.8780431747436523 running average of batch loss 3.746856164932251, time 0.4863455295562744\n",
      "#Epoch 190 with total epochs 300 at step 10 loss: 3.8768746852874756 running average of batch loss 3.7586760304190894, time 0.49034857749938965\n",
      "#Epoch 190 with total epochs 300 at step 11 loss: 3.918220281600952 running average of batch loss 3.7719713846842446, time 0.4863460063934326\n",
      "#Epoch 190 with total epochs 300 at step 12 loss: 3.316497564315796 running average of batch loss 3.736934936963595, time 0.4903240203857422\n",
      "#Epoch 190 with total epochs 300 at step 13 loss: 3.712223529815674 running average of batch loss 3.735169836453029, time 0.4863436222076416\n",
      "#Epoch 190 with total epochs 300 at step 14 loss: 3.8717849254608154 running average of batch loss 3.744277509053548, time 0.48734617233276367\n",
      "#Epoch 190 with total epochs 300 at step 15 loss: 3.6564016342163086 running average of batch loss 3.7387852668762207, time 0.4873464107513428\n",
      "#Epoch 190 with total epochs 300 at step 16 loss: 3.463653564453125 running average of batch loss 3.722601049086627, time 0.48834753036499023\n",
      "#Epoch 190 with total epochs 300 at step 17 loss: 3.575272560119629 running average of batch loss 3.7144161330329046, time 0.4883456230163574\n",
      "#Epoch 190 with total epochs 300 at step 18 loss: 4.311107635498047 running average of batch loss 3.745820948952123, time 0.4893476963043213\n",
      "#Epoch 190 with total epochs 300 at step 19 loss: 3.4358887672424316 running average of batch loss 3.7303243398666384, time 0.4873466491699219\n",
      "#Epoch 190 with total epochs 300 at step 20 loss: 3.5979809761047363 running average of batch loss 3.7240222749255953, time 0.4873487949371338\n",
      "#Epoch 191 with total epochs 300 at step 0 loss: 3.5439226627349854 running average of batch loss 3.5439226627349854, time 0.49735450744628906\n",
      "#Epoch 191 with total epochs 300 at step 1 loss: 3.7053539752960205 running average of batch loss 3.624638319015503, time 0.526374340057373\n",
      "#Epoch 191 with total epochs 300 at step 2 loss: 4.3374433517456055 running average of batch loss 3.8622399965922036, time 0.4943516254425049\n",
      "#Epoch 191 with total epochs 300 at step 3 loss: 3.746446371078491 running average of batch loss 3.8332915902137756, time 0.48831605911254883\n",
      "#Epoch 191 with total epochs 300 at step 4 loss: 4.2921624183654785 running average of batch loss 3.925065755844116, time 0.4893465042114258\n",
      "#Epoch 191 with total epochs 300 at step 5 loss: 4.0604448318481445 running average of batch loss 3.947628935178121, time 0.4883229732513428\n",
      "#Epoch 191 with total epochs 300 at step 6 loss: 3.936936855316162 running average of batch loss 3.946101495197841, time 0.4893465042114258\n",
      "#Epoch 191 with total epochs 300 at step 7 loss: 3.5955255031585693 running average of batch loss 3.902279496192932, time 0.4893500804901123\n",
      "#Epoch 191 with total epochs 300 at step 8 loss: 3.2364120483398438 running average of batch loss 3.8282942242092557, time 0.4883236885070801\n",
      "#Epoch 191 with total epochs 300 at step 9 loss: 3.997697353363037 running average of batch loss 3.8452345371246337, time 0.4933505058288574\n",
      "#Epoch 191 with total epochs 300 at step 10 loss: 3.8068289756774902 running average of batch loss 3.8417431224476206, time 0.5243735313415527\n",
      "#Epoch 191 with total epochs 300 at step 11 loss: 3.6211700439453125 running average of batch loss 3.8233620325724282, time 0.4963524341583252\n",
      "#Epoch 191 with total epochs 300 at step 12 loss: 3.809352397918701 running average of batch loss 3.8222843683682957, time 0.6474599838256836\n",
      "#Epoch 191 with total epochs 300 at step 13 loss: 3.432805061340332 running average of batch loss 3.794464417866298, time 0.6354513168334961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 191 with total epochs 300 at step 14 loss: 3.4628143310546875 running average of batch loss 3.7723544120788572, time 0.49034857749938965\n",
      "#Epoch 191 with total epochs 300 at step 15 loss: 3.5597875118255615 running average of batch loss 3.7590689808130264, time 0.4863460063934326\n",
      "#Epoch 191 with total epochs 300 at step 16 loss: 3.737567186355591 running average of batch loss 3.757804169374354, time 0.4873464107513428\n",
      "#Epoch 191 with total epochs 300 at step 17 loss: 3.8214144706726074 running average of batch loss 3.7613380750020347, time 0.4943506717681885\n",
      "#Epoch 191 with total epochs 300 at step 18 loss: 3.490535259246826 running average of batch loss 3.7470852952254448, time 0.5103621482849121\n",
      "#Epoch 191 with total epochs 300 at step 19 loss: 3.8090758323669434 running average of batch loss 3.7501848220825194, time 0.4903252124786377\n",
      "#Epoch 191 with total epochs 300 at step 20 loss: 3.4143030643463135 running average of batch loss 3.7341904526665095, time 0.4863450527191162\n",
      "#Epoch 192 with total epochs 300 at step 0 loss: 3.710221290588379 running average of batch loss 3.710221290588379, time 0.5053284168243408\n",
      "#Epoch 192 with total epochs 300 at step 1 loss: 3.9177777767181396 running average of batch loss 3.8139995336532593, time 0.5063595771789551\n",
      "#Epoch 192 with total epochs 300 at step 2 loss: 3.0317533016204834 running average of batch loss 3.553250789642334, time 0.4823415279388428\n",
      "#Epoch 192 with total epochs 300 at step 3 loss: 3.5578339099884033 running average of batch loss 3.5543965697288513, time 0.5063602924346924\n",
      "#Epoch 192 with total epochs 300 at step 4 loss: 3.5144267082214355 running average of batch loss 3.546402597427368, time 0.48534703254699707\n",
      "#Epoch 192 with total epochs 300 at step 5 loss: 3.5431675910949707 running average of batch loss 3.5458634297053018, time 0.5093328952789307\n",
      "#Epoch 192 with total epochs 300 at step 6 loss: 3.268787145614624 running average of batch loss 3.5062811034066335, time 0.5103332996368408\n",
      "#Epoch 192 with total epochs 300 at step 7 loss: 3.8259034156799316 running average of batch loss 3.546233892440796, time 0.5423848628997803\n",
      "#Epoch 192 with total epochs 300 at step 8 loss: 3.429558277130127 running average of batch loss 3.533269935184055, time 0.518345832824707\n",
      "#Epoch 192 with total epochs 300 at step 9 loss: 3.762155055999756 running average of batch loss 3.556158447265625, time 0.5193417072296143\n",
      "#Epoch 192 with total epochs 300 at step 10 loss: 3.921224594116211 running average of batch loss 3.5893462787974966, time 0.49332618713378906\n",
      "#Epoch 192 with total epochs 300 at step 11 loss: 3.456990957260132 running average of batch loss 3.5783166686693826, time 0.49335479736328125\n",
      "#Epoch 192 with total epochs 300 at step 12 loss: 4.127626895904541 running average of batch loss 3.6205713015336256, time 0.502331018447876\n",
      "#Epoch 192 with total epochs 300 at step 13 loss: 3.373382329940796 running average of batch loss 3.602914946419852, time 0.5063381195068359\n",
      "#Epoch 192 with total epochs 300 at step 14 loss: 3.9175302982330322 running average of batch loss 3.6238893032073975, time 0.5113630294799805\n",
      "#Epoch 192 with total epochs 300 at step 15 loss: 3.6441521644592285 running average of batch loss 3.625155732035637, time 0.520371675491333\n",
      "#Epoch 192 with total epochs 300 at step 16 loss: 3.5987462997436523 running average of batch loss 3.623602236018461, time 0.5033290386199951\n",
      "#Epoch 192 with total epochs 300 at step 17 loss: 3.8524727821350098 running average of batch loss 3.6363172663582697, time 0.5313503742218018\n",
      "#Epoch 192 with total epochs 300 at step 18 loss: 3.48024845123291 running average of batch loss 3.628103118193777, time 0.49735260009765625\n",
      "#Epoch 192 with total epochs 300 at step 19 loss: 3.670177698135376 running average of batch loss 3.630206847190857, time 0.5143649578094482\n",
      "#Epoch 192 with total epochs 300 at step 20 loss: 3.687711238861084 running average of batch loss 3.6329451515561058, time 0.4963521957397461\n",
      "#Epoch 193 with total epochs 300 at step 0 loss: 3.6885766983032227 running average of batch loss 3.6885766983032227, time 0.48935556411743164\n",
      "#Epoch 193 with total epochs 300 at step 1 loss: 3.778717517852783 running average of batch loss 3.733647108078003, time 0.5133647918701172\n",
      "#Epoch 193 with total epochs 300 at step 2 loss: 3.7950096130371094 running average of batch loss 3.754101276397705, time 0.5053565502166748\n",
      "#Epoch 193 with total epochs 300 at step 3 loss: 3.4300904273986816 running average of batch loss 3.673098564147949, time 0.5013265609741211\n",
      "#Epoch 193 with total epochs 300 at step 4 loss: 3.520352840423584 running average of batch loss 3.642549419403076, time 0.5403802394866943\n",
      "#Epoch 193 with total epochs 300 at step 5 loss: 3.7658777236938477 running average of batch loss 3.6631041367848716, time 0.49234628677368164\n",
      "#Epoch 193 with total epochs 300 at step 6 loss: 3.9354617595672607 running average of batch loss 3.702012368610927, time 0.5223438739776611\n",
      "#Epoch 193 with total epochs 300 at step 7 loss: 3.3014228343963623 running average of batch loss 3.6519386768341064, time 0.5053310394287109\n",
      "#Epoch 193 with total epochs 300 at step 8 loss: 3.396181106567383 running average of batch loss 3.623521169026693, time 0.5663735866546631\n",
      "#Epoch 193 with total epochs 300 at step 9 loss: 4.141601085662842 running average of batch loss 3.675329160690308, time 0.4983510971069336\n",
      "#Epoch 193 with total epochs 300 at step 10 loss: 3.7730839252471924 running average of batch loss 3.684215957468206, time 0.5013561248779297\n",
      "#Epoch 193 with total epochs 300 at step 11 loss: 3.559434413909912 running average of batch loss 3.673817495505015, time 0.5073566436767578\n",
      "#Epoch 193 with total epochs 300 at step 12 loss: 3.6508231163024902 running average of batch loss 3.6720486971048207, time 0.49632883071899414\n",
      "#Epoch 193 with total epochs 300 at step 13 loss: 3.2550926208496094 running average of batch loss 3.6422661202294484, time 0.49932432174682617\n",
      "#Epoch 193 with total epochs 300 at step 14 loss: 3.62980580329895 running average of batch loss 3.641435432434082, time 0.5213711261749268\n",
      "#Epoch 193 with total epochs 300 at step 15 loss: 3.6274867057800293 running average of batch loss 3.6405636370182037, time 0.48734545707702637\n",
      "#Epoch 193 with total epochs 300 at step 16 loss: 3.665783405303955 running average of batch loss 3.6420471527997185, time 0.5253763198852539\n",
      "#Epoch 193 with total epochs 300 at step 17 loss: 3.965484142303467 running average of batch loss 3.6600158744388156, time 0.5263636112213135\n",
      "#Epoch 193 with total epochs 300 at step 18 loss: 3.9007959365844727 running average of batch loss 3.6726885092885873, time 0.5093631744384766\n",
      "#Epoch 193 with total epochs 300 at step 19 loss: 3.948021411895752 running average of batch loss 3.6864551544189452, time 0.505357027053833\n",
      "#Epoch 193 with total epochs 300 at step 20 loss: 3.248185873031616 running average of batch loss 3.6655851886385964, time 0.5143353939056396\n",
      "#Epoch 194 with total epochs 300 at step 0 loss: 4.045930862426758 running average of batch loss 4.045930862426758, time 0.5433573722839355\n",
      "#Epoch 194 with total epochs 300 at step 1 loss: 4.057465553283691 running average of batch loss 4.051698207855225, time 0.4983541965484619\n",
      "#Epoch 194 with total epochs 300 at step 2 loss: 3.5902626514434814 running average of batch loss 3.897886355717977, time 0.5323781967163086\n",
      "#Epoch 194 with total epochs 300 at step 3 loss: 3.4038355350494385 running average of batch loss 3.7743736505508423, time 0.5063595771789551\n",
      "#Epoch 194 with total epochs 300 at step 4 loss: 4.083286285400391 running average of batch loss 3.8361561775207518, time 0.5113496780395508\n",
      "#Epoch 194 with total epochs 300 at step 5 loss: 3.5640721321105957 running average of batch loss 3.790808836619059, time 0.5123646259307861\n",
      "#Epoch 194 with total epochs 300 at step 6 loss: 3.806185007095337 running average of batch loss 3.7930054324013844, time 0.5033566951751709\n",
      "#Epoch 194 with total epochs 300 at step 7 loss: 3.6824262142181396 running average of batch loss 3.779183030128479, time 0.49034810066223145\n",
      "#Epoch 194 with total epochs 300 at step 8 loss: 3.3668458461761475 running average of batch loss 3.7333677874671087, time 0.4913492202758789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 194 with total epochs 300 at step 9 loss: 3.399343729019165 running average of batch loss 3.6999653816223144, time 0.49087977409362793\n",
      "#Epoch 194 with total epochs 300 at step 10 loss: 3.7371151447296143 running average of batch loss 3.703342632813887, time 0.4928293228149414\n",
      "#Epoch 194 with total epochs 300 at step 11 loss: 3.6557059288024902 running average of batch loss 3.6993729074796042, time 0.49935483932495117\n",
      "#Epoch 194 with total epochs 300 at step 12 loss: 3.8348214626312256 running average of batch loss 3.709792027106652, time 0.4943521022796631\n",
      "#Epoch 194 with total epochs 300 at step 13 loss: 3.526852607727051 running average of batch loss 3.696724925722395, time 0.4953289031982422\n",
      "#Epoch 194 with total epochs 300 at step 14 loss: 3.8015146255493164 running average of batch loss 3.703710905710856, time 0.5373837947845459\n",
      "#Epoch 194 with total epochs 300 at step 15 loss: 3.774249315261841 running average of batch loss 3.7081195563077927, time 0.5233438014984131\n",
      "#Epoch 194 with total epochs 300 at step 16 loss: 3.8988378047943115 running average of batch loss 3.7193382768069996, time 0.5813860893249512\n",
      "#Epoch 194 with total epochs 300 at step 17 loss: 3.7420895099639893 running average of batch loss 3.7206022342046103, time 0.4913206100463867\n",
      "#Epoch 194 with total epochs 300 at step 18 loss: 3.7299609184265137 running average of batch loss 3.721094796532079, time 0.49434781074523926\n",
      "#Epoch 194 with total epochs 300 at step 19 loss: 3.4557037353515625 running average of batch loss 3.707825243473053, time 0.49132513999938965\n",
      "#Epoch 194 with total epochs 300 at step 20 loss: 3.4399561882019043 running average of batch loss 3.695069574174427, time 0.5203521251678467\n",
      "#Epoch 195 with total epochs 300 at step 0 loss: 3.924149990081787 running average of batch loss 3.924149990081787, time 0.5003523826599121\n",
      "#Epoch 195 with total epochs 300 at step 1 loss: 3.7967631816864014 running average of batch loss 3.8604565858840942, time 0.5043294429779053\n",
      "#Epoch 195 with total epochs 300 at step 2 loss: 3.986879348754883 running average of batch loss 3.902597506841024, time 0.5003523826599121\n",
      "#Epoch 195 with total epochs 300 at step 3 loss: 3.772723436355591 running average of batch loss 3.8701289892196655, time 0.5053544044494629\n",
      "#Epoch 195 with total epochs 300 at step 4 loss: 3.5486059188842773 running average of batch loss 3.805824375152588, time 0.4893207550048828\n",
      "#Epoch 195 with total epochs 300 at step 5 loss: 3.5322887897491455 running average of batch loss 3.7602351109186807, time 0.5123641490936279\n",
      "#Epoch 195 with total epochs 300 at step 6 loss: 3.2818055152893066 running average of batch loss 3.6918880258287703, time 0.502326250076294\n",
      "#Epoch 195 with total epochs 300 at step 7 loss: 3.3783719539642334 running average of batch loss 3.652698516845703, time 0.49235033988952637\n",
      "#Epoch 195 with total epochs 300 at step 8 loss: 3.626783847808838 running average of batch loss 3.64981910917494, time 0.5403616428375244\n",
      "#Epoch 195 with total epochs 300 at step 9 loss: 3.5491161346435547 running average of batch loss 3.6397488117218018, time 0.49532389640808105\n",
      "#Epoch 195 with total epochs 300 at step 10 loss: 3.421448230743408 running average of batch loss 3.6199033043601294, time 0.5483658313751221\n",
      "#Epoch 195 with total epochs 300 at step 11 loss: 3.9292166233062744 running average of batch loss 3.6456794142723083, time 0.5243704319000244\n",
      "#Epoch 195 with total epochs 300 at step 12 loss: 3.6149537563323975 running average of batch loss 3.6433159021230845, time 0.511336088180542\n",
      "#Epoch 195 with total epochs 300 at step 13 loss: 3.783257246017456 running average of batch loss 3.653311712401254, time 0.5073599815368652\n",
      "#Epoch 195 with total epochs 300 at step 14 loss: 3.616612195968628 running average of batch loss 3.650865077972412, time 0.4983546733856201\n",
      "#Epoch 195 with total epochs 300 at step 15 loss: 4.173463344573975 running average of batch loss 3.6835274696350098, time 0.5083625316619873\n",
      "#Epoch 195 with total epochs 300 at step 16 loss: 3.9122066497802734 running average of batch loss 3.696979186114143, time 0.514336347579956\n",
      "#Epoch 195 with total epochs 300 at step 17 loss: 3.5764172077178955 running average of batch loss 3.6902812984254627, time 0.4883460998535156\n",
      "#Epoch 195 with total epochs 300 at step 18 loss: 3.6337761878967285 running average of batch loss 3.6873073452397396, time 0.5043470859527588\n",
      "#Epoch 195 with total epochs 300 at step 19 loss: 3.5819592475891113 running average of batch loss 3.682039940357208, time 0.5053589344024658\n",
      "#Epoch 195 with total epochs 300 at step 20 loss: 3.742074728012085 running average of batch loss 3.6848987397693453, time 0.5043594837188721\n",
      "#Epoch 196 with total epochs 300 at step 0 loss: 3.6940667629241943 running average of batch loss 3.6940667629241943, time 0.5173673629760742\n",
      "#Epoch 196 with total epochs 300 at step 1 loss: 3.849946975708008 running average of batch loss 3.772006869316101, time 0.5543928146362305\n",
      "#Epoch 196 with total epochs 300 at step 2 loss: 3.8523199558258057 running average of batch loss 3.7987778981526694, time 0.5163683891296387\n",
      "#Epoch 196 with total epochs 300 at step 3 loss: 3.6036858558654785 running average of batch loss 3.7500048875808716, time 0.5063343048095703\n",
      "#Epoch 196 with total epochs 300 at step 4 loss: 3.3113903999328613 running average of batch loss 3.6622819900512695, time 0.5153384208679199\n",
      "#Epoch 196 with total epochs 300 at step 5 loss: 3.1415798664093018 running average of batch loss 3.5754983027776084, time 0.493349552154541\n",
      "#Epoch 196 with total epochs 300 at step 6 loss: 3.3544178009033203 running average of batch loss 3.5439153739384244, time 0.48534560203552246\n",
      "#Epoch 196 with total epochs 300 at step 7 loss: 3.320760488510132 running average of batch loss 3.5160210132598877, time 0.5293550491333008\n",
      "#Epoch 196 with total epochs 300 at step 8 loss: 3.584200859069824 running average of batch loss 3.523596551683214, time 0.49332189559936523\n",
      "#Epoch 196 with total epochs 300 at step 9 loss: 4.048354148864746 running average of batch loss 3.5760723114013673, time 0.5403833389282227\n",
      "#Epoch 196 with total epochs 300 at step 10 loss: 3.8156540393829346 running average of batch loss 3.5978524684906006, time 0.5313725471496582\n",
      "#Epoch 196 with total epochs 300 at step 11 loss: 4.115865707397461 running average of batch loss 3.6410202383995056, time 0.4843463897705078\n",
      "#Epoch 196 with total epochs 300 at step 12 loss: 3.746903896331787 running average of batch loss 3.6491651351635275, time 0.5163381099700928\n",
      "#Epoch 196 with total epochs 300 at step 13 loss: 3.687037229537964 running average of batch loss 3.6518702847617015, time 0.4893200397491455\n",
      "#Epoch 196 with total epochs 300 at step 14 loss: 3.481194496154785 running average of batch loss 3.6404918988545734, time 0.5973978042602539\n",
      "#Epoch 196 with total epochs 300 at step 15 loss: 3.2408287525177 running average of batch loss 3.615512952208519, time 0.5393569469451904\n",
      "#Epoch 196 with total epochs 300 at step 16 loss: 4.171253681182861 running average of batch loss 3.6482035833246567, time 0.505354642868042\n",
      "#Epoch 196 with total epochs 300 at step 17 loss: 3.567469596862793 running average of batch loss 3.6437183618545532, time 0.4843461513519287\n",
      "#Epoch 196 with total epochs 300 at step 18 loss: 3.7771832942962646 running average of batch loss 3.6507428319830644, time 0.5863895416259766\n",
      "#Epoch 196 with total epochs 300 at step 19 loss: 3.7422802448272705 running average of batch loss 3.655319702625275, time 0.49234461784362793\n",
      "#Epoch 196 with total epochs 300 at step 20 loss: 3.462651252746582 running average of batch loss 3.646145014535813, time 0.5323784351348877\n",
      "#Epoch 197 with total epochs 300 at step 0 loss: 3.6093623638153076 running average of batch loss 3.6093623638153076, time 0.4823434352874756\n",
      "#Epoch 197 with total epochs 300 at step 1 loss: 3.4079270362854004 running average of batch loss 3.508644700050354, time 0.52437424659729\n",
      "#Epoch 197 with total epochs 300 at step 2 loss: 3.887465000152588 running average of batch loss 3.634918133417765, time 0.49432373046875\n",
      "#Epoch 197 with total epochs 300 at step 3 loss: 3.544248104095459 running average of batch loss 3.6122506260871887, time 0.4993572235107422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 197 with total epochs 300 at step 4 loss: 3.47723388671875 running average of batch loss 3.585247278213501, time 0.4983246326446533\n",
      "#Epoch 197 with total epochs 300 at step 5 loss: 3.725722312927246 running average of batch loss 3.608659783999125, time 0.48331475257873535\n",
      "#Epoch 197 with total epochs 300 at step 6 loss: 3.5989034175872803 running average of batch loss 3.6072660173688615, time 0.5183687210083008\n",
      "#Epoch 197 with total epochs 300 at step 7 loss: 3.533886432647705 running average of batch loss 3.598093569278717, time 0.5063552856445312\n",
      "#Epoch 197 with total epochs 300 at step 8 loss: 3.7347605228424072 running average of batch loss 3.613278786341349, time 0.48334503173828125\n",
      "#Epoch 197 with total epochs 300 at step 9 loss: 3.539919376373291 running average of batch loss 3.6059428453445435, time 0.49735307693481445\n",
      "#Epoch 197 with total epochs 300 at step 10 loss: 3.6430931091308594 running average of batch loss 3.60932014205239, time 0.49934983253479004\n",
      "#Epoch 197 with total epochs 300 at step 11 loss: 3.3772706985473633 running average of batch loss 3.5899826884269714, time 0.4893472194671631\n",
      "#Epoch 197 with total epochs 300 at step 12 loss: 4.175401210784912 running average of batch loss 3.6350148824545054, time 0.4903252124786377\n",
      "#Epoch 197 with total epochs 300 at step 13 loss: 3.518106460571289 running average of batch loss 3.6266642808914185, time 0.5303788185119629\n",
      "#Epoch 197 with total epochs 300 at step 14 loss: 3.5177454948425293 running average of batch loss 3.619403028488159, time 0.5343551635742188\n",
      "#Epoch 197 with total epochs 300 at step 15 loss: 3.7190794944763184 running average of batch loss 3.625632807612419, time 0.4983229637145996\n",
      "#Epoch 197 with total epochs 300 at step 16 loss: 3.6756536960601807 running average of batch loss 3.6285752128152287, time 0.5193402767181396\n",
      "#Epoch 197 with total epochs 300 at step 17 loss: 3.4580299854278564 running average of batch loss 3.619100477960375, time 0.5013313293457031\n",
      "#Epoch 197 with total epochs 300 at step 18 loss: 3.6522634029388428 running average of batch loss 3.6208458950645044, time 0.5033581256866455\n",
      "#Epoch 197 with total epochs 300 at step 19 loss: 3.7983829975128174 running average of batch loss 3.6297227501869203, time 0.5043330192565918\n",
      "#Epoch 197 with total epochs 300 at step 20 loss: 3.7316651344299316 running average of batch loss 3.6345771494365873, time 0.5003325939178467\n",
      "#Epoch 198 with total epochs 300 at step 0 loss: 3.527348279953003 running average of batch loss 3.527348279953003, time 0.5043535232543945\n",
      "#Epoch 198 with total epochs 300 at step 1 loss: 3.757885217666626 running average of batch loss 3.6426167488098145, time 0.4973301887512207\n",
      "#Epoch 198 with total epochs 300 at step 2 loss: 3.3195807933807373 running average of batch loss 3.534938097000122, time 0.49935388565063477\n",
      "#Epoch 198 with total epochs 300 at step 3 loss: 3.7250280380249023 running average of batch loss 3.582460582256317, time 0.5183424949645996\n",
      "#Epoch 198 with total epochs 300 at step 4 loss: 4.102386474609375 running average of batch loss 3.6864457607269285, time 0.4943258762359619\n",
      "#Epoch 198 with total epochs 300 at step 5 loss: 3.636481285095215 running average of batch loss 3.678118348121643, time 0.5133373737335205\n",
      "#Epoch 198 with total epochs 300 at step 6 loss: 3.471477508544922 running average of batch loss 3.6485982281821117, time 0.5063614845275879\n",
      "#Epoch 198 with total epochs 300 at step 7 loss: 3.758105516433716 running average of batch loss 3.662286639213562, time 0.5213699340820312\n",
      "#Epoch 198 with total epochs 300 at step 8 loss: 3.416889190673828 running average of batch loss 3.6350202560424805, time 0.5003552436828613\n",
      "#Epoch 198 with total epochs 300 at step 9 loss: 3.4619851112365723 running average of batch loss 3.61771674156189, time 0.5393579006195068\n",
      "#Epoch 198 with total epochs 300 at step 10 loss: 3.5668656826019287 running average of batch loss 3.613093918020075, time 0.4963536262512207\n",
      "#Epoch 198 with total epochs 300 at step 11 loss: 3.8590471744537354 running average of batch loss 3.63359002272288, time 0.49735069274902344\n",
      "#Epoch 198 with total epochs 300 at step 12 loss: 3.6704776287078857 running average of batch loss 3.6364275308755727, time 0.4953494071960449\n",
      "#Epoch 198 with total epochs 300 at step 13 loss: 3.6898114681243896 running average of batch loss 3.6402406692504883, time 0.49434781074523926\n",
      "#Epoch 198 with total epochs 300 at step 14 loss: 3.512695789337158 running average of batch loss 3.6317376772562664, time 0.5003588199615479\n",
      "#Epoch 198 with total epochs 300 at step 15 loss: 3.6026787757873535 running average of batch loss 3.6299214959144592, time 0.5053353309631348\n",
      "#Epoch 198 with total epochs 300 at step 16 loss: 3.622636079788208 running average of batch loss 3.6294929420246795, time 0.5083584785461426\n",
      "#Epoch 198 with total epochs 300 at step 17 loss: 3.526671886444092 running average of batch loss 3.6237806611590915, time 0.5433862209320068\n",
      "#Epoch 198 with total epochs 300 at step 18 loss: 3.5403902530670166 running average of batch loss 3.6193916923121403, time 0.507331371307373\n",
      "#Epoch 198 with total epochs 300 at step 19 loss: 3.632464647293091 running average of batch loss 3.620045340061188, time 0.511359691619873\n",
      "#Epoch 198 with total epochs 300 at step 20 loss: 3.695554256439209 running average of batch loss 3.623641002745855, time 0.5023555755615234\n",
      "#Epoch 199 with total epochs 300 at step 0 loss: 3.755922794342041 running average of batch loss 3.755922794342041, time 0.5383806228637695\n",
      "#Epoch 199 with total epochs 300 at step 1 loss: 3.6740238666534424 running average of batch loss 3.7149733304977417, time 0.49332451820373535\n",
      "#Epoch 199 with total epochs 300 at step 2 loss: 3.2204713821411133 running average of batch loss 3.5501393477121987, time 0.4863436222076416\n",
      "#Epoch 199 with total epochs 300 at step 3 loss: 3.357186794281006 running average of batch loss 3.5019012093544006, time 0.5203454494476318\n",
      "#Epoch 199 with total epochs 300 at step 4 loss: 3.7982096672058105 running average of batch loss 3.561162900924683, time 0.500328540802002\n",
      "#Epoch 199 with total epochs 300 at step 5 loss: 3.655656099319458 running average of batch loss 3.576911767323812, time 0.5233440399169922\n",
      "#Epoch 199 with total epochs 300 at step 6 loss: 3.4813547134399414 running average of batch loss 3.563260759626116, time 0.494351863861084\n",
      "#Epoch 199 with total epochs 300 at step 7 loss: 3.8708574771881104 running average of batch loss 3.6017103493213654, time 0.5113646984100342\n",
      "#Epoch 199 with total epochs 300 at step 8 loss: 4.133426666259766 running average of batch loss 3.6607899400922985, time 0.5053286552429199\n",
      "#Epoch 199 with total epochs 300 at step 9 loss: 3.723912000656128 running average of batch loss 3.6671021461486815, time 0.5053300857543945\n",
      "#Epoch 199 with total epochs 300 at step 10 loss: 3.6625964641571045 running average of batch loss 3.666692538694902, time 0.5063610076904297\n",
      "#Epoch 199 with total epochs 300 at step 11 loss: 3.795943260192871 running average of batch loss 3.677463432153066, time 0.5043325424194336\n",
      "#Epoch 199 with total epochs 300 at step 12 loss: 3.343895196914673 running average of batch loss 3.651804337134728, time 0.4943256378173828\n",
      "#Epoch 199 with total epochs 300 at step 13 loss: 3.411170721054077 running average of batch loss 3.6346162217003957, time 0.5073380470275879\n",
      "#Epoch 199 with total epochs 300 at step 14 loss: 3.6801702976226807 running average of batch loss 3.6376531600952147, time 0.5043575763702393\n",
      "#Epoch 199 with total epochs 300 at step 15 loss: 3.5676698684692383 running average of batch loss 3.6332792043685913, time 0.5103330612182617\n",
      "#Epoch 199 with total epochs 300 at step 16 loss: 3.6645519733428955 running average of batch loss 3.635118779014139, time 0.49835658073425293\n",
      "#Epoch 199 with total epochs 300 at step 17 loss: 3.6876959800720215 running average of batch loss 3.6380397346284656, time 0.5183396339416504\n",
      "#Epoch 199 with total epochs 300 at step 18 loss: 3.813307523727417 running average of batch loss 3.6472643551073576, time 0.4983224868774414\n",
      "#Epoch 199 with total epochs 300 at step 19 loss: 3.9056830406188965 running average of batch loss 3.6601852893829347, time 0.5053591728210449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 199 with total epochs 300 at step 20 loss: 3.365781545639038 running average of batch loss 3.646166063490368, time 0.5163693428039551\n",
      "#Epoch 200 with total epochs 300 at step 0 loss: 3.920546054840088 running average of batch loss 3.920546054840088, time 0.5023269653320312\n",
      "#Epoch 200 with total epochs 300 at step 1 loss: 3.6920461654663086 running average of batch loss 3.8062961101531982, time 0.4983255863189697\n",
      "#Epoch 200 with total epochs 300 at step 2 loss: 3.3477563858032227 running average of batch loss 3.653449535369873, time 0.5904178619384766\n",
      "#Epoch 200 with total epochs 300 at step 3 loss: 3.6081433296203613 running average of batch loss 3.642122983932495, time 0.5053317546844482\n",
      "#Epoch 200 with total epochs 300 at step 4 loss: 3.2996835708618164 running average of batch loss 3.5736351013183594, time 0.502361536026001\n",
      "#Epoch 200 with total epochs 300 at step 5 loss: 3.6964828968048096 running average of batch loss 3.5941097338994346, time 0.4943242073059082\n",
      "#Epoch 200 with total epochs 300 at step 6 loss: 3.5434296131134033 running average of batch loss 3.586869716644287, time 0.5013270378112793\n",
      "#Epoch 200 with total epochs 300 at step 7 loss: 3.4177675247192383 running average of batch loss 3.565731942653656, time 0.5023312568664551\n",
      "#Epoch 200 with total epochs 300 at step 8 loss: 3.8656649589538574 running average of batch loss 3.5990578333536782, time 0.4933280944824219\n",
      "#Epoch 200 with total epochs 300 at step 9 loss: 3.7583813667297363 running average of batch loss 3.6149901866912844, time 0.5113611221313477\n",
      "#Epoch 200 with total epochs 300 at step 10 loss: 3.4618141651153564 running average of batch loss 3.601065093820745, time 0.505357027053833\n",
      "#Epoch 200 with total epochs 300 at step 11 loss: 3.862248659133911 running average of batch loss 3.622830390930176, time 0.48734569549560547\n",
      "#Epoch 200 with total epochs 300 at step 12 loss: 3.816624641418457 running average of batch loss 3.6377376409677358, time 0.5183680057525635\n",
      "#Epoch 200 with total epochs 300 at step 13 loss: 3.5194339752197266 running average of batch loss 3.6292873791285922, time 0.548365592956543\n",
      "#Epoch 200 with total epochs 300 at step 14 loss: 3.0910086631774902 running average of batch loss 3.593402131398519, time 0.4973282814025879\n",
      "#Epoch 200 with total epochs 300 at step 15 loss: 3.6989471912384033 running average of batch loss 3.5999986976385117, time 0.511364221572876\n",
      "#Epoch 200 with total epochs 300 at step 16 loss: 3.805567741394043 running average of batch loss 3.6120909943300137, time 0.5063340663909912\n",
      "#Epoch 200 with total epochs 300 at step 17 loss: 3.347109317779541 running average of batch loss 3.5973697900772095, time 0.529346227645874\n",
      "#Epoch 200 with total epochs 300 at step 18 loss: 4.016417026519775 running average of batch loss 3.619424907784713, time 0.5173678398132324\n",
      "#Epoch 200 with total epochs 300 at step 19 loss: 3.7228810787200928 running average of batch loss 3.6245977163314818, time 0.4913506507873535\n",
      "#Epoch 200 with total epochs 300 at step 20 loss: 3.4489145278930664 running average of batch loss 3.616231850215367, time 0.5363800525665283\n",
      "avg difference between predicted and ground truth batch wise 5.595650276729039\n",
      "#Epoch 201 with total epochs 300 at step 0 loss: 3.374786138534546 running average of batch loss 3.374786138534546, time 0.49035096168518066\n",
      "#Epoch 201 with total epochs 300 at step 1 loss: 3.610247850418091 running average of batch loss 3.4925169944763184, time 0.5213663578033447\n",
      "#Epoch 201 with total epochs 300 at step 2 loss: 3.663872003555298 running average of batch loss 3.549635330835978, time 0.5043566226959229\n",
      "#Epoch 201 with total epochs 300 at step 3 loss: 3.929306745529175 running average of batch loss 3.6445531845092773, time 0.5193660259246826\n",
      "#Epoch 201 with total epochs 300 at step 4 loss: 3.4385697841644287 running average of batch loss 3.6033565044403075, time 0.5183701515197754\n",
      "#Epoch 201 with total epochs 300 at step 5 loss: 4.013677597045898 running average of batch loss 3.6717433532079062, time 0.519340991973877\n",
      "#Epoch 201 with total epochs 300 at step 6 loss: 3.688883066177368 running average of batch loss 3.674191883632115, time 0.4833219051361084\n",
      "#Epoch 201 with total epochs 300 at step 7 loss: 3.648686408996582 running average of batch loss 3.6710036993026733, time 0.5033283233642578\n",
      "#Epoch 201 with total epochs 300 at step 8 loss: 3.103713035583496 running average of batch loss 3.6079714033338757, time 0.5063297748565674\n",
      "#Epoch 201 with total epochs 300 at step 9 loss: 4.020983695983887 running average of batch loss 3.649272632598877, time 0.4813413619995117\n",
      "#Epoch 201 with total epochs 300 at step 10 loss: 3.387141704559326 running average of batch loss 3.625442548231645, time 0.5373845100402832\n",
      "#Epoch 201 with total epochs 300 at step 11 loss: 4.167393684387207 running average of batch loss 3.6706051429112754, time 0.5083589553833008\n",
      "#Epoch 201 with total epochs 300 at step 12 loss: 3.70399808883667 running average of batch loss 3.6731738310593824, time 0.5023362636566162\n",
      "#Epoch 201 with total epochs 300 at step 13 loss: 3.685792922973633 running average of batch loss 3.674075194767543, time 0.5083305835723877\n",
      "#Epoch 201 with total epochs 300 at step 14 loss: 3.513390064239502 running average of batch loss 3.6633628527323405, time 0.49935460090637207\n",
      "#Epoch 201 with total epochs 300 at step 15 loss: 3.461336612701416 running average of batch loss 3.6507362127304077, time 0.5003557205200195\n",
      "#Epoch 201 with total epochs 300 at step 16 loss: 3.552319049835205 running average of batch loss 3.6449469678542195, time 0.4943509101867676\n",
      "#Epoch 201 with total epochs 300 at step 17 loss: 3.9379994869232178 running average of batch loss 3.6612276633580527, time 0.4943513870239258\n",
      "#Epoch 201 with total epochs 300 at step 18 loss: 3.903533458709717 running average of batch loss 3.6739805999555086, time 0.4983561038970947\n",
      "#Epoch 201 with total epochs 300 at step 19 loss: 3.315023899078369 running average of batch loss 3.6560327649116515, time 0.5073339939117432\n",
      "#Epoch 201 with total epochs 300 at step 20 loss: 3.429941415786743 running average of batch loss 3.645266510191418, time 0.5213696956634521\n",
      "#Epoch 202 with total epochs 300 at step 0 loss: 3.835357427597046 running average of batch loss 3.835357427597046, time 0.4893472194671631\n",
      "#Epoch 202 with total epochs 300 at step 1 loss: 3.5100526809692383 running average of batch loss 3.672705054283142, time 0.5033597946166992\n",
      "#Epoch 202 with total epochs 300 at step 2 loss: 4.075621128082275 running average of batch loss 3.8070104122161865, time 0.4993271827697754\n",
      "#Epoch 202 with total epochs 300 at step 3 loss: 3.6607000827789307 running average of batch loss 3.7704328298568726, time 0.5573675632476807\n",
      "#Epoch 202 with total epochs 300 at step 4 loss: 3.2256815433502197 running average of batch loss 3.661482572555542, time 0.49535131454467773\n",
      "#Epoch 202 with total epochs 300 at step 5 loss: 3.6158199310302734 running average of batch loss 3.6538721323013306, time 0.4913496971130371\n",
      "#Epoch 202 with total epochs 300 at step 6 loss: 3.404167890548706 running average of batch loss 3.6182000977652415, time 0.5133640766143799\n",
      "#Epoch 202 with total epochs 300 at step 7 loss: 3.4619975090026855 running average of batch loss 3.598674774169922, time 0.5644011497497559\n",
      "#Epoch 202 with total epochs 300 at step 8 loss: 3.398265838623047 running average of batch loss 3.5764071146647134, time 0.5023572444915771\n",
      "#Epoch 202 with total epochs 300 at step 9 loss: 3.4926352500915527 running average of batch loss 3.5680299282073973, time 0.4863450527191162\n",
      "#Epoch 202 with total epochs 300 at step 10 loss: 3.2701103687286377 running average of batch loss 3.5409463318911465, time 0.5223729610443115\n",
      "#Epoch 202 with total epochs 300 at step 11 loss: 3.4325056076049805 running average of batch loss 3.5319096048672995, time 0.5003254413604736\n",
      "#Epoch 202 with total epochs 300 at step 12 loss: 3.6546454429626465 running average of batch loss 3.5413508231823263, time 0.5033547878265381\n",
      "#Epoch 202 with total epochs 300 at step 13 loss: 3.7496118545532227 running average of batch loss 3.55622661113739, time 0.5493621826171875\n",
      "#Epoch 202 with total epochs 300 at step 14 loss: 3.8837356567382812 running average of batch loss 3.5780605475107827, time 0.5253705978393555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 202 with total epochs 300 at step 15 loss: 3.4936275482177734 running average of batch loss 3.57278348505497, time 0.5133645534515381\n",
      "#Epoch 202 with total epochs 300 at step 16 loss: 3.5624606609344482 running average of batch loss 3.572176260106704, time 0.538353681564331\n",
      "#Epoch 202 with total epochs 300 at step 17 loss: 3.25551176071167 running average of batch loss 3.554583787918091, time 0.49832582473754883\n",
      "#Epoch 202 with total epochs 300 at step 18 loss: 3.8272807598114014 running average of batch loss 3.5689362601230017, time 0.49732327461242676\n",
      "#Epoch 202 with total epochs 300 at step 19 loss: 3.7042956352233887 running average of batch loss 3.5757042288780214, time 0.481342077255249\n",
      "#Epoch 202 with total epochs 300 at step 20 loss: 3.828281879425049 running average of batch loss 3.587731736046927, time 0.526371955871582\n",
      "#Epoch 203 with total epochs 300 at step 0 loss: 3.5543339252471924 running average of batch loss 3.5543339252471924, time 0.4953291416168213\n",
      "#Epoch 203 with total epochs 300 at step 1 loss: 3.6061177253723145 running average of batch loss 3.5802258253097534, time 0.5373773574829102\n",
      "#Epoch 203 with total epochs 300 at step 2 loss: 3.9313278198242188 running average of batch loss 3.6972598234812417, time 0.48834824562072754\n",
      "#Epoch 203 with total epochs 300 at step 3 loss: 3.5020229816436768 running average of batch loss 3.6484506130218506, time 0.5053305625915527\n",
      "#Epoch 203 with total epochs 300 at step 4 loss: 3.6263930797576904 running average of batch loss 3.6440391063690187, time 0.502354621887207\n",
      "#Epoch 203 with total epochs 300 at step 5 loss: 3.467078447341919 running average of batch loss 3.6145456631978354, time 0.547389030456543\n",
      "#Epoch 203 with total epochs 300 at step 6 loss: 3.6722545623779297 running average of batch loss 3.6227897916521346, time 0.5103635787963867\n",
      "#Epoch 203 with total epochs 300 at step 7 loss: 3.7529704570770264 running average of batch loss 3.639062374830246, time 0.5323545932769775\n",
      "#Epoch 203 with total epochs 300 at step 8 loss: 3.513026475906372 running average of batch loss 3.6250583860609265, time 0.5123653411865234\n",
      "#Epoch 203 with total epochs 300 at step 9 loss: 3.9726362228393555 running average of batch loss 3.6598161697387694, time 0.5493636131286621\n",
      "#Epoch 203 with total epochs 300 at step 10 loss: 3.267723560333252 running average of batch loss 3.6241713870655405, time 0.5173676013946533\n",
      "#Epoch 203 with total epochs 300 at step 11 loss: 4.070377349853516 running average of batch loss 3.661355217297872, time 0.5173447132110596\n",
      "#Epoch 203 with total epochs 300 at step 12 loss: 3.293154239654541 running average of batch loss 3.633032065171462, time 0.4953501224517822\n",
      "#Epoch 203 with total epochs 300 at step 13 loss: 3.673142433166504 running average of batch loss 3.635897091456822, time 0.5013284683227539\n",
      "#Epoch 203 with total epochs 300 at step 14 loss: 3.424363374710083 running average of batch loss 3.621794843673706, time 0.5033292770385742\n",
      "#Epoch 203 with total epochs 300 at step 15 loss: 3.3654778003692627 running average of batch loss 3.6057750284671783, time 0.50335693359375\n",
      "#Epoch 203 with total epochs 300 at step 16 loss: 3.451923370361328 running average of batch loss 3.59672493093154, time 0.5023372173309326\n",
      "#Epoch 203 with total epochs 300 at step 17 loss: 3.605973482131958 running average of batch loss 3.5972387393315635, time 0.5003306865692139\n",
      "#Epoch 203 with total epochs 300 at step 18 loss: 3.7056875228881836 running average of batch loss 3.6029465700450696, time 0.49034953117370605\n",
      "#Epoch 203 with total epochs 300 at step 19 loss: 3.841871500015259 running average of batch loss 3.614892816543579, time 0.5103635787963867\n",
      "#Epoch 203 with total epochs 300 at step 20 loss: 3.408250331878662 running average of batch loss 3.605052698226202, time 0.49732518196105957\n",
      "#Epoch 204 with total epochs 300 at step 0 loss: 3.8196215629577637 running average of batch loss 3.8196215629577637, time 0.513364315032959\n",
      "#Epoch 204 with total epochs 300 at step 1 loss: 3.6860294342041016 running average of batch loss 3.7528254985809326, time 0.5293793678283691\n",
      "#Epoch 204 with total epochs 300 at step 2 loss: 3.8420166969299316 running average of batch loss 3.782555898030599, time 0.5003793239593506\n",
      "#Epoch 204 with total epochs 300 at step 3 loss: 3.558603286743164 running average of batch loss 3.7265677452087402, time 0.498321533203125\n",
      "#Epoch 204 with total epochs 300 at step 4 loss: 3.191434383392334 running average of batch loss 3.619541072845459, time 0.4983241558074951\n",
      "#Epoch 204 with total epochs 300 at step 5 loss: 3.523064136505127 running average of batch loss 3.603461583455404, time 0.5103652477264404\n",
      "#Epoch 204 with total epochs 300 at step 6 loss: 3.500498056411743 running average of batch loss 3.588752508163452, time 0.49732255935668945\n",
      "#Epoch 204 with total epochs 300 at step 7 loss: 3.4535515308380127 running average of batch loss 3.571852385997772, time 0.5654046535491943\n",
      "#Epoch 204 with total epochs 300 at step 8 loss: 3.5460355281829834 running average of batch loss 3.5689838462405734, time 0.4943230152130127\n",
      "#Epoch 204 with total epochs 300 at step 9 loss: 3.5860376358032227 running average of batch loss 3.5706892251968383, time 0.5643727779388428\n",
      "#Epoch 204 with total epochs 300 at step 10 loss: 3.652970552444458 running average of batch loss 3.578169345855713, time 0.5313806533813477\n",
      "#Epoch 204 with total epochs 300 at step 11 loss: 3.6401102542877197 running average of batch loss 3.5833310882250466, time 0.4963209629058838\n",
      "#Epoch 204 with total epochs 300 at step 12 loss: 3.381685733795166 running average of batch loss 3.567819907115056, time 0.49634885787963867\n",
      "#Epoch 204 with total epochs 300 at step 13 loss: 3.5650713443756104 running average of batch loss 3.5676235812050954, time 0.48534512519836426\n",
      "#Epoch 204 with total epochs 300 at step 14 loss: 3.7709155082702637 running average of batch loss 3.5811763763427735, time 0.5043327808380127\n",
      "#Epoch 204 with total epochs 300 at step 15 loss: 3.7890114784240723 running average of batch loss 3.5941660702228546, time 0.5033268928527832\n",
      "#Epoch 204 with total epochs 300 at step 16 loss: 3.2949771881103516 running average of batch loss 3.576566724216237, time 0.48834776878356934\n",
      "#Epoch 204 with total epochs 300 at step 17 loss: 4.202899932861328 running average of batch loss 3.6113630135854087, time 0.48734521865844727\n",
      "#Epoch 204 with total epochs 300 at step 18 loss: 3.881906032562256 running average of batch loss 3.625602119847348, time 0.4863448143005371\n",
      "#Epoch 204 with total epochs 300 at step 19 loss: 3.620936632156372 running average of batch loss 3.6253688454627992, time 0.4963521957397461\n",
      "#Epoch 204 with total epochs 300 at step 20 loss: 3.3276243209838867 running average of batch loss 3.611190534773327, time 0.48834729194641113\n",
      "#Epoch 205 with total epochs 300 at step 0 loss: 3.322873592376709 running average of batch loss 3.322873592376709, time 0.5423853397369385\n",
      "#Epoch 205 with total epochs 300 at step 1 loss: 3.6113665103912354 running average of batch loss 3.467120051383972, time 0.4913485050201416\n",
      "#Epoch 205 with total epochs 300 at step 2 loss: 3.5758657455444336 running average of batch loss 3.503368616104126, time 0.4893484115600586\n",
      "#Epoch 205 with total epochs 300 at step 3 loss: 3.251375913619995 running average of batch loss 3.4403704404830933, time 0.5153622627258301\n",
      "#Epoch 205 with total epochs 300 at step 4 loss: 3.4897618293762207 running average of batch loss 3.4502487182617188, time 0.5043580532073975\n",
      "#Epoch 205 with total epochs 300 at step 5 loss: 3.3210175037384033 running average of batch loss 3.428710182507833, time 0.5023558139801025\n",
      "#Epoch 205 with total epochs 300 at step 6 loss: 3.829296350479126 running average of batch loss 3.485936777932303, time 0.4913501739501953\n",
      "#Epoch 205 with total epochs 300 at step 7 loss: 3.6667943000793457 running average of batch loss 3.5085439682006836, time 0.49535202980041504\n",
      "#Epoch 205 with total epochs 300 at step 8 loss: 3.750509738922119 running average of batch loss 3.5354290538363986, time 0.520369291305542\n",
      "#Epoch 205 with total epochs 300 at step 9 loss: 3.5452523231506348 running average of batch loss 3.5364113807678224, time 0.5043582916259766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 205 with total epochs 300 at step 10 loss: 3.5375423431396484 running average of batch loss 3.5365141955288975, time 0.5003564357757568\n",
      "#Epoch 205 with total epochs 300 at step 11 loss: 3.1185073852539062 running average of batch loss 3.501680294672648, time 0.4933488368988037\n",
      "#Epoch 205 with total epochs 300 at step 12 loss: 3.615996837615967 running average of batch loss 3.5104738748990574, time 0.5083620548248291\n",
      "#Epoch 205 with total epochs 300 at step 13 loss: 3.5026071071624756 running average of batch loss 3.5099119629178728, time 0.48734188079833984\n",
      "#Epoch 205 with total epochs 300 at step 14 loss: 3.6722822189331055 running average of batch loss 3.520736646652222, time 0.49832653999328613\n",
      "#Epoch 205 with total epochs 300 at step 15 loss: 3.692333459854126 running average of batch loss 3.5314614474773407, time 0.523343563079834\n",
      "#Epoch 205 with total epochs 300 at step 16 loss: 3.6288037300109863 running average of batch loss 3.537187464096967, time 0.4883260726928711\n",
      "#Epoch 205 with total epochs 300 at step 17 loss: 3.5355708599090576 running average of batch loss 3.5370976527531943, time 0.5083329677581787\n",
      "#Epoch 205 with total epochs 300 at step 18 loss: 3.448523998260498 running average of batch loss 3.532435881464105, time 0.5373830795288086\n",
      "#Epoch 205 with total epochs 300 at step 19 loss: 3.653815269470215 running average of batch loss 3.5385048508644106, time 0.4993255138397217\n",
      "#Epoch 205 with total epochs 300 at step 20 loss: 3.3474578857421875 running average of batch loss 3.5294073763347806, time 0.5043580532073975\n",
      "#Epoch 206 with total epochs 300 at step 0 loss: 3.312359571456909 running average of batch loss 3.312359571456909, time 0.5393600463867188\n",
      "#Epoch 206 with total epochs 300 at step 1 loss: 3.954336166381836 running average of batch loss 3.6333478689193726, time 0.48631858825683594\n",
      "#Epoch 206 with total epochs 300 at step 2 loss: 3.6700289249420166 running average of batch loss 3.6455748875935874, time 0.5163640975952148\n",
      "#Epoch 206 with total epochs 300 at step 3 loss: 3.716947555541992 running average of batch loss 3.6634180545806885, time 0.5423557758331299\n",
      "#Epoch 206 with total epochs 300 at step 4 loss: 3.599346399307251 running average of batch loss 3.650603723526001, time 0.5223736763000488\n",
      "#Epoch 206 with total epochs 300 at step 5 loss: 3.592787504196167 running average of batch loss 3.640967686971029, time 0.49532198905944824\n",
      "#Epoch 206 with total epochs 300 at step 6 loss: 3.400587320327759 running average of batch loss 3.6066276345934187, time 0.4893476963043213\n",
      "#Epoch 206 with total epochs 300 at step 7 loss: 3.2005133628845215 running average of batch loss 3.5558633506298065, time 0.5023572444915771\n",
      "#Epoch 206 with total epochs 300 at step 8 loss: 3.5037009716033936 running average of batch loss 3.5500675307379828, time 0.5273747444152832\n",
      "#Epoch 206 with total epochs 300 at step 9 loss: 3.3770058155059814 running average of batch loss 3.5327613592147826, time 0.5033307075500488\n",
      "#Epoch 206 with total epochs 300 at step 10 loss: 3.4372196197509766 running average of batch loss 3.524075746536255, time 0.5053589344024658\n",
      "#Epoch 206 with total epochs 300 at step 11 loss: 3.4094743728637695 running average of batch loss 3.5145256320635476, time 0.48834681510925293\n",
      "#Epoch 206 with total epochs 300 at step 12 loss: 4.028820991516113 running average of batch loss 3.554086813559899, time 0.5153677463531494\n",
      "#Epoch 206 with total epochs 300 at step 13 loss: 3.670626401901245 running average of batch loss 3.562411069869995, time 0.5053322315216064\n",
      "#Epoch 206 with total epochs 300 at step 14 loss: 3.70119309425354 running average of batch loss 3.5716632048288983, time 0.5073320865631104\n",
      "#Epoch 206 with total epochs 300 at step 15 loss: 3.908425807952881 running average of batch loss 3.592710867524147, time 0.48932528495788574\n",
      "#Epoch 206 with total epochs 300 at step 16 loss: 3.5964882373809814 running average of batch loss 3.5929330657510197, time 0.5023314952850342\n",
      "#Epoch 206 with total epochs 300 at step 17 loss: 3.6402382850646973 running average of batch loss 3.5955611334906683, time 0.4913499355316162\n",
      "#Epoch 206 with total epochs 300 at step 18 loss: 3.5221927165985107 running average of batch loss 3.591699637864765, time 0.5083277225494385\n",
      "#Epoch 206 with total epochs 300 at step 19 loss: 3.686551094055176 running average of batch loss 3.5964422106742857, time 0.49035048484802246\n",
      "#Epoch 206 with total epochs 300 at step 20 loss: 3.821814775466919 running average of batch loss 3.6071742375691733, time 0.49434971809387207\n",
      "#Epoch 207 with total epochs 300 at step 0 loss: 3.8070058822631836 running average of batch loss 3.8070058822631836, time 0.5043337345123291\n",
      "#Epoch 207 with total epochs 300 at step 1 loss: 3.5559446811676025 running average of batch loss 3.681475281715393, time 0.4983513355255127\n",
      "#Epoch 207 with total epochs 300 at step 2 loss: 3.5267326831817627 running average of batch loss 3.629894415537516, time 0.48834800720214844\n",
      "#Epoch 207 with total epochs 300 at step 3 loss: 3.586325168609619 running average of batch loss 3.619002103805542, time 0.5043315887451172\n",
      "#Epoch 207 with total epochs 300 at step 4 loss: 3.3255791664123535 running average of batch loss 3.5603175163269043, time 0.5253720283508301\n",
      "#Epoch 207 with total epochs 300 at step 5 loss: 3.350252866744995 running average of batch loss 3.525306741396586, time 0.5083906650543213\n",
      "#Epoch 207 with total epochs 300 at step 6 loss: 3.3535633087158203 running average of batch loss 3.5007719652993337, time 0.49832677841186523\n",
      "#Epoch 207 with total epochs 300 at step 7 loss: 4.241443634033203 running average of batch loss 3.5933559238910675, time 0.49935126304626465\n",
      "#Epoch 207 with total epochs 300 at step 8 loss: 3.292423725128174 running average of batch loss 3.5599190129174128, time 0.5193698406219482\n",
      "#Epoch 207 with total epochs 300 at step 9 loss: 3.5298616886138916 running average of batch loss 3.5569132804870605, time 0.4833402633666992\n",
      "#Epoch 207 with total epochs 300 at step 10 loss: 3.8954403400421143 running average of batch loss 3.5876884677193384, time 0.48334574699401855\n",
      "#Epoch 207 with total epochs 300 at step 11 loss: 3.553213357925415 running average of batch loss 3.5848155419031777, time 0.5313737392425537\n",
      "#Epoch 207 with total epochs 300 at step 12 loss: 3.7160329818725586 running average of batch loss 3.594909191131592, time 0.49535465240478516\n",
      "#Epoch 207 with total epochs 300 at step 13 loss: 3.702770233154297 running average of batch loss 3.602613551276071, time 0.490342378616333\n",
      "#Epoch 207 with total epochs 300 at step 14 loss: 3.366664409637451 running average of batch loss 3.586883608500163, time 0.5293788909912109\n",
      "#Epoch 207 with total epochs 300 at step 15 loss: 3.469921827316284 running average of batch loss 3.5795734971761703, time 0.49834275245666504\n",
      "#Epoch 207 with total epochs 300 at step 16 loss: 3.360938549041748 running average of batch loss 3.5667126178741455, time 0.5503640174865723\n",
      "#Epoch 207 with total epochs 300 at step 17 loss: 3.6767663955688477 running average of batch loss 3.572826716634962, time 0.5133349895477295\n",
      "#Epoch 207 with total epochs 300 at step 18 loss: 3.411867141723633 running average of batch loss 3.564355160060682, time 0.5113358497619629\n",
      "#Epoch 207 with total epochs 300 at step 19 loss: 3.357475519180298 running average of batch loss 3.5540111780166628, time 0.49031972885131836\n",
      "#Epoch 207 with total epochs 300 at step 20 loss: 3.2457070350646973 running average of batch loss 3.5393300283522833, time 0.5333504676818848\n",
      "#Epoch 208 with total epochs 300 at step 0 loss: 3.5578365325927734 running average of batch loss 3.5578365325927734, time 0.5013563632965088\n",
      "#Epoch 208 with total epochs 300 at step 1 loss: 3.8141798973083496 running average of batch loss 3.6860082149505615, time 0.4893488883972168\n",
      "#Epoch 208 with total epochs 300 at step 2 loss: 3.0695717334747314 running average of batch loss 3.4805293877919516, time 0.5093362331390381\n",
      "#Epoch 208 with total epochs 300 at step 3 loss: 3.5618629455566406 running average of batch loss 3.500862777233124, time 0.488344669342041\n",
      "#Epoch 208 with total epochs 300 at step 4 loss: 3.340097427368164 running average of batch loss 3.468709707260132, time 0.5103623867034912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 208 with total epochs 300 at step 5 loss: 3.6500630378723145 running average of batch loss 3.498935262362162, time 0.49034833908081055\n",
      "#Epoch 208 with total epochs 300 at step 6 loss: 3.969975471496582 running average of batch loss 3.5662267208099365, time 0.5213727951049805\n",
      "#Epoch 208 with total epochs 300 at step 7 loss: 3.7191920280456543 running average of batch loss 3.5853473842144012, time 0.5053539276123047\n",
      "#Epoch 208 with total epochs 300 at step 8 loss: 3.3945798873901367 running average of batch loss 3.564150995678372, time 0.5043585300445557\n",
      "#Epoch 208 with total epochs 300 at step 9 loss: 3.560189962387085 running average of batch loss 3.5637548923492433, time 0.49735331535339355\n",
      "#Epoch 208 with total epochs 300 at step 10 loss: 3.4791321754455566 running average of batch loss 3.5560619180852715, time 0.4913489818572998\n",
      "#Epoch 208 with total epochs 300 at step 11 loss: 3.939279556274414 running average of batch loss 3.5879967212677, time 0.5233719348907471\n",
      "#Epoch 208 with total epochs 300 at step 12 loss: 3.691274404525757 running average of batch loss 3.5959411584413967, time 0.5103628635406494\n",
      "#Epoch 208 with total epochs 300 at step 13 loss: 3.4576761722564697 running average of batch loss 3.5860650879996165, time 0.5083367824554443\n",
      "#Epoch 208 with total epochs 300 at step 14 loss: 3.536419630050659 running average of batch loss 3.5827553908030194, time 0.5043537616729736\n",
      "#Epoch 208 with total epochs 300 at step 15 loss: 3.487203598022461 running average of batch loss 3.5767834037542343, time 0.5053591728210449\n",
      "#Epoch 208 with total epochs 300 at step 16 loss: 3.657386541366577 running average of batch loss 3.5815247647902546, time 0.5103628635406494\n",
      "#Epoch 208 with total epochs 300 at step 17 loss: 3.8055942058563232 running average of batch loss 3.593973067071703, time 0.5203633308410645\n",
      "#Epoch 208 with total epochs 300 at step 18 loss: 3.591765880584717 running average of batch loss 3.5938568993618616, time 0.5373818874359131\n",
      "#Epoch 208 with total epochs 300 at step 19 loss: 3.756110668182373 running average of batch loss 3.601969587802887, time 0.5173673629760742\n",
      "#Epoch 208 with total epochs 300 at step 20 loss: 3.3979105949401855 running average of batch loss 3.592252492904663, time 0.5083613395690918\n",
      "#Epoch 209 with total epochs 300 at step 0 loss: 3.423591375350952 running average of batch loss 3.423591375350952, time 0.49535250663757324\n",
      "#Epoch 209 with total epochs 300 at step 1 loss: 3.4529452323913574 running average of batch loss 3.438268303871155, time 0.4873483180999756\n",
      "#Epoch 209 with total epochs 300 at step 2 loss: 3.6570558547973633 running average of batch loss 3.511197487513224, time 0.5023305416107178\n",
      "#Epoch 209 with total epochs 300 at step 3 loss: 3.480757474899292 running average of batch loss 3.503587484359741, time 0.4983251094818115\n",
      "#Epoch 209 with total epochs 300 at step 4 loss: 3.8514819145202637 running average of batch loss 3.5731663703918457, time 0.48831725120544434\n",
      "#Epoch 209 with total epochs 300 at step 5 loss: 3.753390312194824 running average of batch loss 3.6032036940256753, time 0.526376485824585\n",
      "#Epoch 209 with total epochs 300 at step 6 loss: 3.4591240882873535 running average of batch loss 3.5826208932059154, time 0.5053303241729736\n",
      "#Epoch 209 with total epochs 300 at step 7 loss: 3.406073808670044 running average of batch loss 3.5605525076389313, time 0.5043423175811768\n",
      "#Epoch 209 with total epochs 300 at step 8 loss: 3.7947194576263428 running average of batch loss 3.5865710576375327, time 0.49931979179382324\n",
      "#Epoch 209 with total epochs 300 at step 9 loss: 3.9620039463043213 running average of batch loss 3.6241143465042116, time 0.48734521865844727\n",
      "#Epoch 209 with total epochs 300 at step 10 loss: 3.1713309288024902 running average of batch loss 3.582952217622237, time 0.4923238754272461\n",
      "#Epoch 209 with total epochs 300 at step 11 loss: 3.7413740158081055 running average of batch loss 3.596154034137726, time 0.5003235340118408\n",
      "#Epoch 209 with total epochs 300 at step 12 loss: 3.678086757659912 running average of batch loss 3.6024565513317404, time 0.4823453426361084\n",
      "#Epoch 209 with total epochs 300 at step 13 loss: 3.4966554641723633 running average of batch loss 3.5948993308203563, time 0.5203647613525391\n",
      "#Epoch 209 with total epochs 300 at step 14 loss: 3.627852201461792 running average of batch loss 3.5970961888631185, time 0.4873480796813965\n",
      "#Epoch 209 with total epochs 300 at step 15 loss: 3.7423598766326904 running average of batch loss 3.6061751693487167, time 0.5233473777770996\n",
      "#Epoch 209 with total epochs 300 at step 16 loss: 3.2051854133605957 running average of batch loss 3.5825875366435334, time 0.49332523345947266\n",
      "#Epoch 209 with total epochs 300 at step 17 loss: 3.5486621856689453 running average of batch loss 3.580702794922723, time 0.5233519077301025\n",
      "#Epoch 209 with total epochs 300 at step 18 loss: 4.19382381439209 running average of batch loss 3.6129723222632157, time 0.49835205078125\n",
      "#Epoch 209 with total epochs 300 at step 19 loss: 3.7107884883880615 running average of batch loss 3.617863130569458, time 0.5223422050476074\n",
      "#Epoch 209 with total epochs 300 at step 20 loss: 3.2655088901519775 running average of batch loss 3.6010843572162448, time 0.49235081672668457\n",
      "#Epoch 210 with total epochs 300 at step 0 loss: 3.216334104537964 running average of batch loss 3.216334104537964, time 0.5023303031921387\n",
      "#Epoch 210 with total epochs 300 at step 1 loss: 3.34313702583313 running average of batch loss 3.279735565185547, time 0.5033597946166992\n",
      "#Epoch 210 with total epochs 300 at step 2 loss: 4.004871845245361 running average of batch loss 3.5214476585388184, time 0.5203652381896973\n",
      "#Epoch 210 with total epochs 300 at step 3 loss: 3.375061273574829 running average of batch loss 3.484851062297821, time 0.5553689002990723\n",
      "#Epoch 210 with total epochs 300 at step 4 loss: 3.4559919834136963 running average of batch loss 3.479079246520996, time 0.5313522815704346\n",
      "#Epoch 210 with total epochs 300 at step 5 loss: 3.4180195331573486 running average of batch loss 3.4689026276270547, time 0.5033349990844727\n",
      "#Epoch 210 with total epochs 300 at step 6 loss: 3.821141242980957 running average of batch loss 3.5192224298204695, time 0.4933502674102783\n",
      "#Epoch 210 with total epochs 300 at step 7 loss: 3.7042901515960693 running average of batch loss 3.5423558950424194, time 0.4983561038970947\n",
      "#Epoch 210 with total epochs 300 at step 8 loss: 3.4600648880004883 running average of batch loss 3.5332124498155384, time 0.5293729305267334\n",
      "#Epoch 210 with total epochs 300 at step 9 loss: 3.455160140991211 running average of batch loss 3.5254072189331054, time 0.4913496971130371\n",
      "#Epoch 210 with total epochs 300 at step 10 loss: 3.6742172241210938 running average of batch loss 3.5389354012229224, time 0.4893474578857422\n",
      "#Epoch 210 with total epochs 300 at step 11 loss: 3.271866798400879 running average of batch loss 3.5166796843210855, time 0.5363514423370361\n",
      "#Epoch 210 with total epochs 300 at step 12 loss: 3.6711864471435547 running average of batch loss 3.528564819922814, time 0.5063574314117432\n",
      "#Epoch 210 with total epochs 300 at step 13 loss: 3.5477490425109863 running average of batch loss 3.529935121536255, time 0.4893496036529541\n",
      "#Epoch 210 with total epochs 300 at step 14 loss: 3.357966661453247 running average of batch loss 3.518470557530721, time 0.5203683376312256\n",
      "#Epoch 210 with total epochs 300 at step 15 loss: 3.6924924850463867 running average of batch loss 3.52934692800045, time 0.5093624591827393\n",
      "#Epoch 210 with total epochs 300 at step 16 loss: 3.5138144493103027 running average of batch loss 3.528433252783383, time 0.5113630294799805\n",
      "#Epoch 210 with total epochs 300 at step 17 loss: 3.675351142883301 running average of batch loss 3.5365953577889337, time 0.5233719348907471\n",
      "#Epoch 210 with total epochs 300 at step 18 loss: 3.6109626293182373 running average of batch loss 3.5405094247115287, time 0.5203478336334229\n",
      "#Epoch 210 with total epochs 300 at step 19 loss: 3.6551554203033447 running average of batch loss 3.5462417244911193, time 0.5423860549926758\n",
      "#Epoch 210 with total epochs 300 at step 20 loss: 3.5855159759521484 running average of batch loss 3.548111926941645, time 0.49235105514526367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 211 with total epochs 300 at step 0 loss: 3.4208297729492188 running average of batch loss 3.4208297729492188, time 0.5033571720123291\n",
      "#Epoch 211 with total epochs 300 at step 1 loss: 3.3862240314483643 running average of batch loss 3.4035269021987915, time 0.5423853397369385\n",
      "#Epoch 211 with total epochs 300 at step 2 loss: 3.212380886077881 running average of batch loss 3.3398115634918213, time 0.5323781967163086\n",
      "#Epoch 211 with total epochs 300 at step 3 loss: 3.389054536819458 running average of batch loss 3.3521223068237305, time 0.502356767654419\n",
      "#Epoch 211 with total epochs 300 at step 4 loss: 3.5204949378967285 running average of batch loss 3.38579683303833, time 0.5003540515899658\n",
      "#Epoch 211 with total epochs 300 at step 5 loss: 3.330324172973633 running average of batch loss 3.376551389694214, time 0.5153665542602539\n",
      "#Epoch 211 with total epochs 300 at step 6 loss: 3.5362730026245117 running average of batch loss 3.3993687629699707, time 0.5093612670898438\n",
      "#Epoch 211 with total epochs 300 at step 7 loss: 3.8407039642333984 running average of batch loss 3.454535663127899, time 0.5143649578094482\n",
      "#Epoch 211 with total epochs 300 at step 8 loss: 3.627575159072876 running average of batch loss 3.473762273788452, time 0.5113630294799805\n",
      "#Epoch 211 with total epochs 300 at step 9 loss: 3.491382122039795 running average of batch loss 3.4755242586135866, time 0.48834705352783203\n",
      "#Epoch 211 with total epochs 300 at step 10 loss: 3.471015214920044 running average of batch loss 3.475114345550537, time 0.5093615055084229\n",
      "#Epoch 211 with total epochs 300 at step 11 loss: 3.4471018314361572 running average of batch loss 3.4727799693743386, time 0.5073609352111816\n",
      "#Epoch 211 with total epochs 300 at step 12 loss: 3.34200382232666 running average of batch loss 3.4627202657552867, time 0.5173704624176025\n",
      "#Epoch 211 with total epochs 300 at step 13 loss: 3.342716932296753 running average of batch loss 3.454148599079677, time 0.5263733863830566\n",
      "#Epoch 211 with total epochs 300 at step 14 loss: 3.6675310134887695 running average of batch loss 3.4683740933736167, time 0.49632811546325684\n",
      "#Epoch 211 with total epochs 300 at step 15 loss: 3.518362522125244 running average of batch loss 3.4714983701705933, time 0.4943521022796631\n",
      "#Epoch 211 with total epochs 300 at step 16 loss: 3.7113914489746094 running average of batch loss 3.4856097277473, time 0.49335193634033203\n",
      "#Epoch 211 with total epochs 300 at step 17 loss: 3.624680995941162 running average of batch loss 3.493335909313626, time 0.5023543834686279\n",
      "#Epoch 211 with total epochs 300 at step 18 loss: 3.339822292327881 running average of batch loss 3.4852562452617444, time 0.5203394889831543\n",
      "#Epoch 211 with total epochs 300 at step 19 loss: 3.698439598083496 running average of batch loss 3.495915412902832, time 0.5103316307067871\n",
      "#Epoch 211 with total epochs 300 at step 20 loss: 3.5450592041015625 running average of batch loss 3.498255593436105, time 0.522371768951416\n",
      "#Epoch 212 with total epochs 300 at step 0 loss: 3.5164637565612793 running average of batch loss 3.5164637565612793, time 0.4963228702545166\n",
      "#Epoch 212 with total epochs 300 at step 1 loss: 3.5920705795288086 running average of batch loss 3.554267168045044, time 0.5223667621612549\n",
      "#Epoch 212 with total epochs 300 at step 2 loss: 3.5759835243225098 running average of batch loss 3.5615059534708657, time 0.5313801765441895\n",
      "#Epoch 212 with total epochs 300 at step 3 loss: 3.561955213546753 running average of batch loss 3.5616182684898376, time 0.515364408493042\n",
      "#Epoch 212 with total epochs 300 at step 4 loss: 3.7447991371154785 running average of batch loss 3.598254442214966, time 0.5043318271636963\n",
      "#Epoch 212 with total epochs 300 at step 5 loss: 3.666247844696045 running average of batch loss 3.6095866759618125, time 0.5133395195007324\n",
      "#Epoch 212 with total epochs 300 at step 6 loss: 3.6143269538879395 running average of batch loss 3.610263858522688, time 0.49632835388183594\n",
      "#Epoch 212 with total epochs 300 at step 7 loss: 3.5788381099700928 running average of batch loss 3.6063356399536133, time 0.5393826961517334\n",
      "#Epoch 212 with total epochs 300 at step 8 loss: 3.6175780296325684 running average of batch loss 3.607584794362386, time 0.5243687629699707\n",
      "#Epoch 212 with total epochs 300 at step 9 loss: 3.4891271591186523 running average of batch loss 3.5957390308380126, time 0.5263731479644775\n",
      "#Epoch 212 with total epochs 300 at step 10 loss: 3.0786778926849365 running average of batch loss 3.5487334728240967, time 0.49034976959228516\n",
      "#Epoch 212 with total epochs 300 at step 11 loss: 3.3390231132507324 running average of batch loss 3.531257609526316, time 0.4983541965484619\n",
      "#Epoch 212 with total epochs 300 at step 12 loss: 3.4941742420196533 running average of batch loss 3.5284050427950344, time 0.500328540802002\n",
      "#Epoch 212 with total epochs 300 at step 13 loss: 3.132338285446167 running average of batch loss 3.5001145601272583, time 0.5003244876861572\n",
      "#Epoch 212 with total epochs 300 at step 14 loss: 3.586190700531006 running average of batch loss 3.505852969487508, time 0.49235057830810547\n",
      "#Epoch 212 with total epochs 300 at step 15 loss: 3.5872373580932617 running average of batch loss 3.5109394937753677, time 0.4943501949310303\n",
      "#Epoch 212 with total epochs 300 at step 16 loss: 3.5255463123321533 running average of batch loss 3.511798718396355, time 0.48832130432128906\n",
      "#Epoch 212 with total epochs 300 at step 17 loss: 3.637984275817871 running average of batch loss 3.518809027141995, time 0.5183405876159668\n",
      "#Epoch 212 with total epochs 300 at step 18 loss: 3.4593310356140137 running average of batch loss 3.515678606535259, time 0.49132418632507324\n",
      "#Epoch 212 with total epochs 300 at step 19 loss: 3.574998378753662 running average of batch loss 3.518644595146179, time 0.4913499355316162\n",
      "#Epoch 212 with total epochs 300 at step 20 loss: 3.393052101135254 running average of batch loss 3.512664000193278, time 0.5193443298339844\n",
      "#Epoch 213 with total epochs 300 at step 0 loss: 3.368445634841919 running average of batch loss 3.368445634841919, time 0.49732160568237305\n",
      "#Epoch 213 with total epochs 300 at step 1 loss: 3.1854054927825928 running average of batch loss 3.276925563812256, time 0.5293726921081543\n",
      "#Epoch 213 with total epochs 300 at step 2 loss: 3.379690170288086 running average of batch loss 3.3111804326375327, time 0.5233714580535889\n",
      "#Epoch 213 with total epochs 300 at step 3 loss: 3.60617733001709 running average of batch loss 3.384929656982422, time 0.61043381690979\n",
      "#Epoch 213 with total epochs 300 at step 4 loss: 3.5177831649780273 running average of batch loss 3.411500358581543, time 0.5353808403015137\n",
      "#Epoch 213 with total epochs 300 at step 5 loss: 3.5302793979644775 running average of batch loss 3.4312968651453652, time 0.5593752861022949\n",
      "#Epoch 213 with total epochs 300 at step 6 loss: 3.485008478164673 running average of batch loss 3.4389699527195523, time 0.5263752937316895\n",
      "#Epoch 213 with total epochs 300 at step 7 loss: 3.2876625061035156 running average of batch loss 3.4200565218925476, time 0.5083608627319336\n",
      "#Epoch 213 with total epochs 300 at step 8 loss: 3.585197687149048 running average of batch loss 3.438405540254381, time 0.4943540096282959\n",
      "#Epoch 213 with total epochs 300 at step 9 loss: 3.776843547821045 running average of batch loss 3.4722493410110475, time 0.5393517017364502\n",
      "#Epoch 213 with total epochs 300 at step 10 loss: 3.839306354522705 running average of batch loss 3.5056181604211982, time 0.4943532943725586\n",
      "#Epoch 213 with total epochs 300 at step 11 loss: 3.4010069370269775 running average of batch loss 3.4969005584716797, time 0.49935007095336914\n",
      "#Epoch 213 with total epochs 300 at step 12 loss: 3.549791097640991 running average of batch loss 3.5009690614847035, time 0.49132871627807617\n",
      "#Epoch 213 with total epochs 300 at step 13 loss: 3.485663414001465 running average of batch loss 3.4998758009501865, time 0.5273733139038086\n",
      "#Epoch 213 with total epochs 300 at step 14 loss: 3.543121337890625 running average of batch loss 3.502758836746216, time 0.512364387512207\n",
      "#Epoch 213 with total epochs 300 at step 15 loss: 3.7006092071533203 running average of batch loss 3.51512448489666, time 0.5413839817047119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 213 with total epochs 300 at step 16 loss: 3.9934635162353516 running average of batch loss 3.5432620749754062, time 0.5063595771789551\n",
      "#Epoch 213 with total epochs 300 at step 17 loss: 3.128857135772705 running average of batch loss 3.520239578353034, time 0.5013556480407715\n",
      "#Epoch 213 with total epochs 300 at step 18 loss: 3.299820899963379 running average of batch loss 3.508638595279894, time 0.49832868576049805\n",
      "#Epoch 213 with total epochs 300 at step 19 loss: 3.6093733310699463 running average of batch loss 3.513675332069397, time 0.4903225898742676\n",
      "#Epoch 213 with total epochs 300 at step 20 loss: 3.379208564758301 running average of batch loss 3.5072721526736306, time 0.5023586750030518\n",
      "#Epoch 214 with total epochs 300 at step 0 loss: 3.5215256214141846 running average of batch loss 3.5215256214141846, time 0.5383782386779785\n",
      "#Epoch 214 with total epochs 300 at step 1 loss: 3.6593432426452637 running average of batch loss 3.590434432029724, time 0.4933507442474365\n",
      "#Epoch 214 with total epochs 300 at step 2 loss: 3.010805368423462 running average of batch loss 3.39722474416097, time 0.5093526840209961\n",
      "#Epoch 214 with total epochs 300 at step 3 loss: 3.4387552738189697 running average of batch loss 3.40760737657547, time 0.4953269958496094\n",
      "#Epoch 214 with total epochs 300 at step 4 loss: 3.561281681060791 running average of batch loss 3.438342237472534, time 0.4933493137359619\n",
      "#Epoch 214 with total epochs 300 at step 5 loss: 3.283557891845703 running average of batch loss 3.412544846534729, time 0.5163671970367432\n",
      "#Epoch 214 with total epochs 300 at step 6 loss: 3.983259439468384 running average of batch loss 3.494075502668108, time 0.4973282814025879\n",
      "#Epoch 214 with total epochs 300 at step 7 loss: 3.633467674255371 running average of batch loss 3.511499524116516, time 0.487346887588501\n",
      "#Epoch 214 with total epochs 300 at step 8 loss: 3.9367029666900635 running average of batch loss 3.5587443510691323, time 0.4873230457305908\n",
      "#Epoch 214 with total epochs 300 at step 9 loss: 3.3972880840301514 running average of batch loss 3.5425987243652344, time 0.5413758754730225\n",
      "#Epoch 214 with total epochs 300 at step 10 loss: 3.613996982574463 running average of batch loss 3.549089475111528, time 0.5083603858947754\n",
      "#Epoch 214 with total epochs 300 at step 11 loss: 3.4888126850128174 running average of batch loss 3.5440664092699685, time 0.5013587474822998\n",
      "#Epoch 214 with total epochs 300 at step 12 loss: 3.400888204574585 running average of batch loss 3.5330527012164774, time 0.521338701248169\n",
      "#Epoch 214 with total epochs 300 at step 13 loss: 3.729487419128418 running average of batch loss 3.547083752495902, time 0.519371747970581\n",
      "#Epoch 214 with total epochs 300 at step 14 loss: 3.54902720451355 running average of batch loss 3.547213315963745, time 0.4973263740539551\n",
      "#Epoch 214 with total epochs 300 at step 15 loss: 4.299267292022705 running average of batch loss 3.59421668946743, time 0.5003297328948975\n",
      "#Epoch 214 with total epochs 300 at step 16 loss: 3.8042778968811035 running average of batch loss 3.606573231079999, time 0.5073602199554443\n",
      "#Epoch 214 with total epochs 300 at step 17 loss: 3.2159430980682373 running average of batch loss 3.5848715570237903, time 0.5113637447357178\n",
      "#Epoch 214 with total epochs 300 at step 18 loss: 3.9273972511291504 running average of batch loss 3.6028992251345984, time 0.48734188079833984\n",
      "#Epoch 214 with total epochs 300 at step 19 loss: 3.388458728790283 running average of batch loss 3.5921772003173826, time 0.5213453769683838\n",
      "#Epoch 214 with total epochs 300 at step 20 loss: 3.5639381408691406 running average of batch loss 3.5908324832008, time 0.5493617057800293\n",
      "#Epoch 215 with total epochs 300 at step 0 loss: 3.55728816986084 running average of batch loss 3.55728816986084, time 0.5253441333770752\n",
      "#Epoch 215 with total epochs 300 at step 1 loss: 3.726863145828247 running average of batch loss 3.6420756578445435, time 0.5293467044830322\n",
      "#Epoch 215 with total epochs 300 at step 2 loss: 3.774864673614502 running average of batch loss 3.6863386631011963, time 0.4943501949310303\n",
      "#Epoch 215 with total epochs 300 at step 3 loss: 3.6287364959716797 running average of batch loss 3.671938121318817, time 0.5113344192504883\n",
      "#Epoch 215 with total epochs 300 at step 4 loss: 3.2724263668060303 running average of batch loss 3.5920357704162598, time 0.5033316612243652\n",
      "#Epoch 215 with total epochs 300 at step 5 loss: 3.392958164215088 running average of batch loss 3.558856169382731, time 0.48932433128356934\n",
      "#Epoch 215 with total epochs 300 at step 6 loss: 3.4555258750915527 running average of batch loss 3.5440946987697055, time 0.49035048484802246\n",
      "#Epoch 215 with total epochs 300 at step 7 loss: 3.358231782913208 running average of batch loss 3.5208618342876434, time 0.5083305835723877\n",
      "#Epoch 215 with total epochs 300 at step 8 loss: 3.6344149112701416 running average of batch loss 3.5334788428412542, time 0.48834776878356934\n",
      "#Epoch 215 with total epochs 300 at step 9 loss: 3.6679656505584717 running average of batch loss 3.5469275236129763, time 0.496326208114624\n",
      "#Epoch 215 with total epochs 300 at step 10 loss: 3.3479251861572266 running average of batch loss 3.52883640202609, time 0.48734593391418457\n",
      "#Epoch 215 with total epochs 300 at step 11 loss: 3.1068196296691895 running average of batch loss 3.493668337663015, time 0.5073597431182861\n",
      "#Epoch 215 with total epochs 300 at step 12 loss: 3.808452606201172 running average of batch loss 3.51788251216595, time 0.4993321895599365\n",
      "#Epoch 215 with total epochs 300 at step 13 loss: 3.6400070190429688 running average of batch loss 3.526605691228594, time 0.49034762382507324\n",
      "#Epoch 215 with total epochs 300 at step 14 loss: 3.3601887226104736 running average of batch loss 3.515511226654053, time 0.4893472194671631\n",
      "#Epoch 215 with total epochs 300 at step 15 loss: 3.3985025882720947 running average of batch loss 3.5081981867551804, time 0.522374153137207\n",
      "#Epoch 215 with total epochs 300 at step 16 loss: 3.64235782623291 running average of batch loss 3.5160899302538704, time 0.5043232440948486\n",
      "#Epoch 215 with total epochs 300 at step 17 loss: 4.092218399047852 running average of batch loss 3.5480970674090915, time 0.4933509826660156\n",
      "#Epoch 215 with total epochs 300 at step 18 loss: 3.453329086303711 running average of batch loss 3.543109278929861, time 0.5053384304046631\n",
      "#Epoch 215 with total epochs 300 at step 19 loss: 3.148714542388916 running average of batch loss 3.5233895421028136, time 0.5143606662750244\n",
      "#Epoch 215 with total epochs 300 at step 20 loss: 3.7491259574890137 running average of batch loss 3.5341388952164423, time 0.501335620880127\n",
      "#Epoch 216 with total epochs 300 at step 0 loss: 3.603628158569336 running average of batch loss 3.603628158569336, time 0.5403585433959961\n",
      "#Epoch 216 with total epochs 300 at step 1 loss: 3.5223805904388428 running average of batch loss 3.5630043745040894, time 0.4923210144042969\n",
      "#Epoch 216 with total epochs 300 at step 2 loss: 3.3912620544433594 running average of batch loss 3.505756934483846, time 0.5103356838226318\n",
      "#Epoch 216 with total epochs 300 at step 3 loss: 3.595151424407959 running average of batch loss 3.5281055569648743, time 0.4943511486053467\n",
      "#Epoch 216 with total epochs 300 at step 4 loss: 3.4462010860443115 running average of batch loss 3.511724662780762, time 0.5063433647155762\n",
      "#Epoch 216 with total epochs 300 at step 5 loss: 3.581956624984741 running average of batch loss 3.5234299898147583, time 0.5213725566864014\n",
      "#Epoch 216 with total epochs 300 at step 6 loss: 3.3942205905914307 running average of batch loss 3.504971504211426, time 0.49932146072387695\n",
      "#Epoch 216 with total epochs 300 at step 7 loss: 3.5019869804382324 running average of batch loss 3.5045984387397766, time 0.5033578872680664\n",
      "#Epoch 216 with total epochs 300 at step 8 loss: 3.30271577835083 running average of batch loss 3.482167032029894, time 0.5453903675079346\n",
      "#Epoch 216 with total epochs 300 at step 9 loss: 3.490767002105713 running average of batch loss 3.4830270290374754, time 0.49832606315612793\n",
      "#Epoch 216 with total epochs 300 at step 10 loss: 3.4221529960632324 running average of batch loss 3.477493026039817, time 0.535377025604248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 216 with total epochs 300 at step 11 loss: 3.648674488067627 running average of batch loss 3.491758147875468, time 0.48232197761535645\n",
      "#Epoch 216 with total epochs 300 at step 12 loss: 3.2126457691192627 running average of batch loss 3.4702879648942213, time 0.5293445587158203\n",
      "#Epoch 216 with total epochs 300 at step 13 loss: 3.7511045932769775 running average of batch loss 3.49034629549299, time 0.5633988380432129\n",
      "#Epoch 216 with total epochs 300 at step 14 loss: 3.3399698734283447 running average of batch loss 3.48032120068868, time 0.4983246326446533\n",
      "#Epoch 216 with total epochs 300 at step 15 loss: 3.7138893604278564 running average of batch loss 3.4949192106723785, time 0.5013289451599121\n",
      "#Epoch 216 with total epochs 300 at step 16 loss: 3.524033308029175 running average of batch loss 3.496631804634543, time 0.48734593391418457\n",
      "#Epoch 216 with total epochs 300 at step 17 loss: 3.433838367462158 running average of batch loss 3.4931432803471885, time 0.5013537406921387\n",
      "#Epoch 216 with total epochs 300 at step 18 loss: 3.307967185974121 running average of batch loss 3.4833971701170268, time 0.5093610286712646\n",
      "#Epoch 216 with total epochs 300 at step 19 loss: 3.299055576324463 running average of batch loss 3.4741800904273985, time 0.5103352069854736\n",
      "#Epoch 216 with total epochs 300 at step 20 loss: 3.53070068359375 running average of batch loss 3.476871547244844, time 0.5223710536956787\n",
      "#Epoch 217 with total epochs 300 at step 0 loss: 3.2256393432617188 running average of batch loss 3.2256393432617188, time 0.5033590793609619\n",
      "#Epoch 217 with total epochs 300 at step 1 loss: 3.533205986022949 running average of batch loss 3.379422664642334, time 0.5253498554229736\n",
      "#Epoch 217 with total epochs 300 at step 2 loss: 3.7714662551879883 running average of batch loss 3.5101038614908853, time 0.5083625316619873\n",
      "#Epoch 217 with total epochs 300 at step 3 loss: 3.609212636947632 running average of batch loss 3.534881055355072, time 0.49935317039489746\n",
      "#Epoch 217 with total epochs 300 at step 4 loss: 3.4592413902282715 running average of batch loss 3.519753122329712, time 0.5423843860626221\n",
      "#Epoch 217 with total epochs 300 at step 5 loss: 3.4444282054901123 running average of batch loss 3.507198969523112, time 0.5063602924346924\n",
      "#Epoch 217 with total epochs 300 at step 6 loss: 3.1534550189971924 running average of batch loss 3.456664119447981, time 0.4903261661529541\n",
      "#Epoch 217 with total epochs 300 at step 7 loss: 3.5182712078094482 running average of batch loss 3.464365005493164, time 0.4883463382720947\n",
      "#Epoch 217 with total epochs 300 at step 8 loss: 3.134559154510498 running average of batch loss 3.4277199109395347, time 0.5393590927124023\n",
      "#Epoch 217 with total epochs 300 at step 9 loss: 3.4478812217712402 running average of batch loss 3.429736042022705, time 0.49832773208618164\n",
      "#Epoch 217 with total epochs 300 at step 10 loss: 3.3640663623809814 running average of batch loss 3.4237660711461846, time 0.49935078620910645\n",
      "#Epoch 217 with total epochs 300 at step 11 loss: 3.6098408699035645 running average of batch loss 3.4392723043759665, time 0.4883451461791992\n",
      "#Epoch 217 with total epochs 300 at step 12 loss: 3.927136182785034 running average of batch loss 3.4768002950228176, time 0.502356767654419\n",
      "#Epoch 217 with total epochs 300 at step 13 loss: 3.4354310035705566 running average of batch loss 3.4738453456333707, time 0.5103621482849121\n",
      "#Epoch 217 with total epochs 300 at step 14 loss: 3.51133131980896 running average of batch loss 3.47634441057841, time 0.4843769073486328\n",
      "#Epoch 217 with total epochs 300 at step 15 loss: 3.2963955402374268 running average of batch loss 3.4650976061820984, time 0.52734375\n",
      "#Epoch 217 with total epochs 300 at step 16 loss: 3.539729595184326 running average of batch loss 3.4694877231822296, time 0.5143651962280273\n",
      "#Epoch 217 with total epochs 300 at step 17 loss: 3.248734474182129 running average of batch loss 3.457223653793335, time 0.5373814105987549\n",
      "#Epoch 217 with total epochs 300 at step 18 loss: 3.516245126724243 running average of batch loss 3.460330047105488, time 0.5073637962341309\n",
      "#Epoch 217 with total epochs 300 at step 19 loss: 3.6849215030670166 running average of batch loss 3.4715596199035645, time 0.5343761444091797\n",
      "#Epoch 217 with total epochs 300 at step 20 loss: 3.4754271507263184 running average of batch loss 3.471743788037981, time 0.506359338760376\n",
      "#Epoch 218 with total epochs 300 at step 0 loss: 3.346803903579712 running average of batch loss 3.346803903579712, time 0.5043525695800781\n",
      "#Epoch 218 with total epochs 300 at step 1 loss: 3.5025923252105713 running average of batch loss 3.4246981143951416, time 0.5163698196411133\n",
      "#Epoch 218 with total epochs 300 at step 2 loss: 3.4554009437561035 running average of batch loss 3.4349323908487954, time 0.49735116958618164\n",
      "#Epoch 218 with total epochs 300 at step 3 loss: 3.2797012329101562 running average of batch loss 3.3961246013641357, time 0.5163676738739014\n",
      "#Epoch 218 with total epochs 300 at step 4 loss: 2.926875114440918 running average of batch loss 3.302274703979492, time 0.4823436737060547\n",
      "#Epoch 218 with total epochs 300 at step 5 loss: 3.3274340629577637 running average of batch loss 3.3064679304758706, time 0.49633121490478516\n",
      "#Epoch 218 with total epochs 300 at step 6 loss: 3.306992530822754 running average of batch loss 3.3065428733825684, time 0.4913191795349121\n",
      "#Epoch 218 with total epochs 300 at step 7 loss: 3.4539663791656494 running average of batch loss 3.3249708116054535, time 0.5023572444915771\n",
      "#Epoch 218 with total epochs 300 at step 8 loss: 4.024076461791992 running average of batch loss 3.4026492171817355, time 0.4993264675140381\n",
      "#Epoch 218 with total epochs 300 at step 9 loss: 3.4180307388305664 running average of batch loss 3.4041873693466185, time 0.5013532638549805\n",
      "#Epoch 218 with total epochs 300 at step 10 loss: 3.348723888397217 running average of batch loss 3.399145234714855, time 0.50032639503479\n",
      "#Epoch 218 with total epochs 300 at step 11 loss: 3.7197251319885254 running average of batch loss 3.4258602261543274, time 0.5073602199554443\n",
      "#Epoch 218 with total epochs 300 at step 12 loss: 3.373434543609619 running average of batch loss 3.421827481343196, time 0.4893498420715332\n",
      "#Epoch 218 with total epochs 300 at step 13 loss: 3.5212841033935547 running average of batch loss 3.4289315257753645, time 0.5103352069854736\n",
      "#Epoch 218 with total epochs 300 at step 14 loss: 3.407291889190674 running average of batch loss 3.4274888833363852, time 0.50935959815979\n",
      "#Epoch 218 with total epochs 300 at step 15 loss: 3.6790759563446045 running average of batch loss 3.443213075399399, time 0.5153665542602539\n",
      "#Epoch 218 with total epochs 300 at step 16 loss: 3.3841733932495117 running average of batch loss 3.4397401529199936, time 0.48834657669067383\n",
      "#Epoch 218 with total epochs 300 at step 17 loss: 3.246264934539795 running average of batch loss 3.428991529676649, time 0.5003557205200195\n",
      "#Epoch 218 with total epochs 300 at step 18 loss: 3.4973130226135254 running average of batch loss 3.4325873977259587, time 0.49034833908081055\n",
      "#Epoch 218 with total epochs 300 at step 19 loss: 3.4000706672668457 running average of batch loss 3.430961561203003, time 0.4983558654785156\n",
      "#Epoch 218 with total epochs 300 at step 20 loss: 3.3354506492614746 running average of batch loss 3.4264134225391207, time 0.5063314437866211\n",
      "#Epoch 219 with total epochs 300 at step 0 loss: 3.4406509399414062 running average of batch loss 3.4406509399414062, time 0.5413846969604492\n",
      "#Epoch 219 with total epochs 300 at step 1 loss: 3.7218034267425537 running average of batch loss 3.58122718334198, time 0.524345874786377\n",
      "#Epoch 219 with total epochs 300 at step 2 loss: 3.5559115409851074 running average of batch loss 3.572788635889689, time 0.5073337554931641\n",
      "#Epoch 219 with total epochs 300 at step 3 loss: 3.471235752105713 running average of batch loss 3.547400414943695, time 0.5233700275421143\n",
      "#Epoch 219 with total epochs 300 at step 4 loss: 3.269444704055786 running average of batch loss 3.491809272766113, time 0.512364387512207\n",
      "#Epoch 219 with total epochs 300 at step 5 loss: 3.258385181427002 running average of batch loss 3.452905257542928, time 0.5603642463684082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 219 with total epochs 300 at step 6 loss: 3.5726985931396484 running average of batch loss 3.470018591199602, time 0.489349365234375\n",
      "#Epoch 219 with total epochs 300 at step 7 loss: 3.1302261352539062 running average of batch loss 3.4275445342063904, time 0.5023298263549805\n",
      "#Epoch 219 with total epochs 300 at step 8 loss: 3.5053091049194336 running average of batch loss 3.436185042063395, time 0.5183706283569336\n",
      "#Epoch 219 with total epochs 300 at step 9 loss: 3.4302520751953125 running average of batch loss 3.4355917453765867, time 0.5323758125305176\n",
      "#Epoch 219 with total epochs 300 at step 10 loss: 3.246748924255371 running average of batch loss 3.418424216183749, time 0.5153684616088867\n",
      "#Epoch 219 with total epochs 300 at step 11 loss: 3.534646511077881 running average of batch loss 3.4281094074249268, time 0.5453557968139648\n",
      "#Epoch 219 with total epochs 300 at step 12 loss: 3.5707592964172363 running average of batch loss 3.4390824758089504, time 0.5363826751708984\n",
      "#Epoch 219 with total epochs 300 at step 13 loss: 3.7084386348724365 running average of batch loss 3.4583222014563426, time 0.5153353214263916\n",
      "#Epoch 219 with total epochs 300 at step 14 loss: 3.401625633239746 running average of batch loss 3.4545424302419026, time 0.4813711643218994\n",
      "#Epoch 219 with total epochs 300 at step 15 loss: 3.5394527912139893 running average of batch loss 3.459849327802658, time 0.5443587303161621\n",
      "#Epoch 219 with total epochs 300 at step 16 loss: 3.518228054046631 running average of batch loss 3.4632833705228916, time 0.49735045433044434\n",
      "#Epoch 219 with total epochs 300 at step 17 loss: 3.643733024597168 running average of batch loss 3.473308351304796, time 0.4993290901184082\n",
      "#Epoch 219 with total epochs 300 at step 18 loss: 3.0869412422180176 running average of batch loss 3.4529732403002287, time 0.5053262710571289\n",
      "#Epoch 219 with total epochs 300 at step 19 loss: 3.7065107822418213 running average of batch loss 3.4656501173973084, time 0.4983253479003906\n",
      "#Epoch 219 with total epochs 300 at step 20 loss: 3.4901814460754395 running average of batch loss 3.4668182759057906, time 0.4843440055847168\n",
      "#Epoch 220 with total epochs 300 at step 0 loss: 3.1030831336975098 running average of batch loss 3.1030831336975098, time 0.5243754386901855\n",
      "#Epoch 220 with total epochs 300 at step 1 loss: 3.713728904724121 running average of batch loss 3.4084060192108154, time 0.5293481349945068\n",
      "#Epoch 220 with total epochs 300 at step 2 loss: 3.4446942806243896 running average of batch loss 3.4205021063486734, time 0.4883456230163574\n",
      "#Epoch 220 with total epochs 300 at step 3 loss: 3.61742901802063 running average of batch loss 3.4697338342666626, time 0.5013558864593506\n",
      "#Epoch 220 with total epochs 300 at step 4 loss: 3.515845775604248 running average of batch loss 3.4789562225341797, time 0.49935483932495117\n",
      "#Epoch 220 with total epochs 300 at step 5 loss: 3.2360119819641113 running average of batch loss 3.4384655157725015, time 0.5003557205200195\n",
      "#Epoch 220 with total epochs 300 at step 6 loss: 2.9240713119506836 running average of batch loss 3.364980629512242, time 0.4883456230163574\n",
      "#Epoch 220 with total epochs 300 at step 7 loss: 3.561652898788452 running average of batch loss 3.389564663171768, time 0.4943242073059082\n",
      "#Epoch 220 with total epochs 300 at step 8 loss: 3.254762649536133 running average of batch loss 3.3745866616566977, time 0.496351957321167\n",
      "#Epoch 220 with total epochs 300 at step 9 loss: 3.2416770458221436 running average of batch loss 3.361295700073242, time 0.5033576488494873\n",
      "#Epoch 220 with total epochs 300 at step 10 loss: 3.4875741004943848 running average of batch loss 3.3727755546569824, time 0.4873480796813965\n",
      "#Epoch 220 with total epochs 300 at step 11 loss: 3.617673635482788 running average of batch loss 3.393183728059133, time 0.5003550052642822\n",
      "#Epoch 220 with total epochs 300 at step 12 loss: 3.484579086303711 running average of batch loss 3.400214140231793, time 0.4983553886413574\n",
      "#Epoch 220 with total epochs 300 at step 13 loss: 3.5279629230499268 running average of batch loss 3.409339053290231, time 0.5303506851196289\n",
      "#Epoch 220 with total epochs 300 at step 14 loss: 3.086604118347168 running average of batch loss 3.387823390960693, time 0.5093622207641602\n",
      "#Epoch 220 with total epochs 300 at step 15 loss: 3.416517734527588 running average of batch loss 3.3896167874336243, time 0.5283775329589844\n",
      "#Epoch 220 with total epochs 300 at step 16 loss: 3.656731605529785 running average of batch loss 3.405329423792222, time 0.5143377780914307\n",
      "#Epoch 220 with total epochs 300 at step 17 loss: 3.3400321006774902 running average of batch loss 3.4017017947302923, time 0.533379316329956\n",
      "#Epoch 220 with total epochs 300 at step 18 loss: 3.304291248321533 running average of batch loss 3.3965749238666736, time 0.4913218021392822\n",
      "#Epoch 220 with total epochs 300 at step 19 loss: 3.233846426010132 running average of batch loss 3.3884384989738465, time 0.48834753036499023\n",
      "#Epoch 220 with total epochs 300 at step 20 loss: 3.4680516719818115 running average of batch loss 3.392229602450416, time 0.48734593391418457\n",
      "avg difference between predicted and ground truth batch wise 5.4748762437105185\n",
      "#Epoch 221 with total epochs 300 at step 0 loss: 3.5449419021606445 running average of batch loss 3.5449419021606445, time 0.4813425540924072\n",
      "#Epoch 221 with total epochs 300 at step 1 loss: 3.41855788230896 running average of batch loss 3.4817498922348022, time 0.5143365859985352\n",
      "#Epoch 221 with total epochs 300 at step 2 loss: 3.744903564453125 running average of batch loss 3.569467782974243, time 0.4973306655883789\n",
      "#Epoch 221 with total epochs 300 at step 3 loss: 3.595676898956299 running average of batch loss 3.576020061969757, time 0.49031877517700195\n",
      "#Epoch 221 with total epochs 300 at step 4 loss: 3.0925958156585693 running average of batch loss 3.4793352127075194, time 0.5043628215789795\n",
      "#Epoch 221 with total epochs 300 at step 5 loss: 3.2637436389923096 running average of batch loss 3.4434032837549844, time 0.5023283958435059\n",
      "#Epoch 221 with total epochs 300 at step 6 loss: 3.4255619049072266 running average of batch loss 3.440854515348162, time 0.5053195953369141\n",
      "#Epoch 221 with total epochs 300 at step 7 loss: 3.4227356910705566 running average of batch loss 3.4385896623134613, time 0.5013275146484375\n",
      "#Epoch 221 with total epochs 300 at step 8 loss: 3.5404999256134033 running average of batch loss 3.4499130249023438, time 0.5113635063171387\n",
      "#Epoch 221 with total epochs 300 at step 9 loss: 3.460005760192871 running average of batch loss 3.4509222984313963, time 0.5023281574249268\n",
      "#Epoch 221 with total epochs 300 at step 10 loss: 3.522979497909546 running average of batch loss 3.45747295292941, time 0.5253689289093018\n",
      "#Epoch 221 with total epochs 300 at step 11 loss: 3.390667676925659 running average of batch loss 3.451905846595764, time 0.5153613090515137\n",
      "#Epoch 221 with total epochs 300 at step 12 loss: 3.4681379795074463 running average of batch loss 3.4531544722043552, time 0.5243725776672363\n",
      "#Epoch 221 with total epochs 300 at step 13 loss: 3.7690391540527344 running average of batch loss 3.4757176637649536, time 0.49132609367370605\n",
      "#Epoch 221 with total epochs 300 at step 14 loss: 3.4078681468963623 running average of batch loss 3.471194362640381, time 0.512364387512207\n",
      "#Epoch 221 with total epochs 300 at step 15 loss: 3.673740863800049 running average of batch loss 3.48385351896286, time 0.49034881591796875\n",
      "#Epoch 221 with total epochs 300 at step 16 loss: 3.7324705123901367 running average of batch loss 3.498478047987994, time 0.48932623863220215\n",
      "#Epoch 221 with total epochs 300 at step 17 loss: 3.5172119140625 running average of batch loss 3.4995188183254666, time 0.5053346157073975\n",
      "#Epoch 221 with total epochs 300 at step 18 loss: 3.9227235317230225 running average of batch loss 3.5217927506095483, time 0.5023303031921387\n",
      "#Epoch 221 with total epochs 300 at step 19 loss: 3.561264753341675 running average of batch loss 3.523766350746155, time 0.4873464107513428\n",
      "#Epoch 221 with total epochs 300 at step 20 loss: 3.236572504043579 running average of batch loss 3.5100904532841275, time 0.49034833908081055\n",
      "#Epoch 222 with total epochs 300 at step 0 loss: 4.021155834197998 running average of batch loss 4.021155834197998, time 0.4913496971130371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 222 with total epochs 300 at step 1 loss: 3.2813117504119873 running average of batch loss 3.6512337923049927, time 0.4913506507873535\n",
      "#Epoch 222 with total epochs 300 at step 2 loss: 3.24717378616333 running average of batch loss 3.516547123591105, time 0.511361837387085\n",
      "#Epoch 222 with total epochs 300 at step 3 loss: 3.245861530303955 running average of batch loss 3.4488757252693176, time 0.5033528804779053\n",
      "#Epoch 222 with total epochs 300 at step 4 loss: 3.5533010959625244 running average of batch loss 3.469760799407959, time 0.48834729194641113\n",
      "#Epoch 222 with total epochs 300 at step 5 loss: 3.134258508682251 running average of batch loss 3.4138437509536743, time 0.4963512420654297\n",
      "#Epoch 222 with total epochs 300 at step 6 loss: 3.7381410598754883 running average of batch loss 3.460171937942505, time 0.4893519878387451\n",
      "#Epoch 222 with total epochs 300 at step 7 loss: 3.387514352798462 running average of batch loss 3.4510897397994995, time 0.5193691253662109\n",
      "#Epoch 222 with total epochs 300 at step 8 loss: 3.4557137489318848 running average of batch loss 3.4516035185919867, time 0.5113346576690674\n",
      "#Epoch 222 with total epochs 300 at step 9 loss: 3.657118320465088 running average of batch loss 3.472154998779297, time 0.4893496036529541\n",
      "#Epoch 222 with total epochs 300 at step 10 loss: 3.3036725521087646 running average of batch loss 3.4568384127183394, time 0.49832725524902344\n",
      "#Epoch 222 with total epochs 300 at step 11 loss: 3.7532601356506348 running average of batch loss 3.4815402229626975, time 0.4923231601715088\n",
      "#Epoch 222 with total epochs 300 at step 12 loss: 3.380326271057129 running average of batch loss 3.4737545343545766, time 0.5083348751068115\n",
      "#Epoch 222 with total epochs 300 at step 13 loss: 3.160712480545044 running average of batch loss 3.4513943876538957, time 0.5513653755187988\n",
      "#Epoch 222 with total epochs 300 at step 14 loss: 3.313823938369751 running average of batch loss 3.4422230243682863, time 0.534376859664917\n",
      "#Epoch 222 with total epochs 300 at step 15 loss: 3.486736297607422 running average of batch loss 3.445005103945732, time 0.5353813171386719\n",
      "#Epoch 222 with total epochs 300 at step 16 loss: 3.7909340858459473 running average of batch loss 3.4653538675869213, time 0.5073306560516357\n",
      "#Epoch 222 with total epochs 300 at step 17 loss: 3.306462287902832 running average of batch loss 3.4565265576044717, time 0.5593996047973633\n",
      "#Epoch 222 with total epochs 300 at step 18 loss: 3.420581102371216 running average of batch loss 3.454634691539564, time 0.5173666477203369\n",
      "#Epoch 222 with total epochs 300 at step 19 loss: 3.1950531005859375 running average of batch loss 3.4416556119918824, time 0.534381628036499\n",
      "#Epoch 222 with total epochs 300 at step 20 loss: 3.498560905456543 running average of batch loss 3.444365387871152, time 0.5103371143341064\n",
      "#Epoch 223 with total epochs 300 at step 0 loss: 3.0452051162719727 running average of batch loss 3.0452051162719727, time 0.5323774814605713\n",
      "#Epoch 223 with total epochs 300 at step 1 loss: 3.5452628135681152 running average of batch loss 3.295233964920044, time 0.5273447036743164\n",
      "#Epoch 223 with total epochs 300 at step 2 loss: 3.36519718170166 running average of batch loss 3.3185550371805825, time 0.5213713645935059\n",
      "#Epoch 223 with total epochs 300 at step 3 loss: 3.236574649810791 running average of batch loss 3.2980599403381348, time 0.5063629150390625\n",
      "#Epoch 223 with total epochs 300 at step 4 loss: 3.412161111831665 running average of batch loss 3.320880174636841, time 0.5103623867034912\n",
      "#Epoch 223 with total epochs 300 at step 5 loss: 3.2231876850128174 running average of batch loss 3.304598093032837, time 0.5153408050537109\n",
      "#Epoch 223 with total epochs 300 at step 6 loss: 3.1905007362365723 running average of batch loss 3.2882984706333707, time 0.5083343982696533\n",
      "#Epoch 223 with total epochs 300 at step 7 loss: 3.471128225326538 running average of batch loss 3.3111521899700165, time 0.4923553466796875\n",
      "#Epoch 223 with total epochs 300 at step 8 loss: 3.3041911125183105 running average of batch loss 3.310378736919827, time 0.5243716239929199\n",
      "#Epoch 223 with total epochs 300 at step 9 loss: 3.1393089294433594 running average of batch loss 3.2932717561721803, time 0.5173676013946533\n",
      "#Epoch 223 with total epochs 300 at step 10 loss: 3.1491808891296387 running average of batch loss 3.28017258644104, time 0.5173678398132324\n",
      "#Epoch 223 with total epochs 300 at step 11 loss: 3.0261754989624023 running average of batch loss 3.259006162484487, time 0.503333568572998\n",
      "#Epoch 223 with total epochs 300 at step 12 loss: 3.375087261199951 running average of batch loss 3.267935477770292, time 0.48932337760925293\n",
      "#Epoch 223 with total epochs 300 at step 13 loss: 3.627152442932129 running average of batch loss 3.2935938324247087, time 0.5233714580535889\n",
      "#Epoch 223 with total epochs 300 at step 14 loss: 3.6484923362731934 running average of batch loss 3.3172537326812743, time 0.49236083030700684\n",
      "#Epoch 223 with total epochs 300 at step 15 loss: 3.2326698303222656 running average of batch loss 3.3119672387838364, time 0.5123350620269775\n",
      "#Epoch 223 with total epochs 300 at step 16 loss: 3.215120315551758 running average of batch loss 3.3062703609466553, time 0.4983549118041992\n",
      "#Epoch 223 with total epochs 300 at step 17 loss: 3.391397714614868 running average of batch loss 3.3109996583726673, time 0.5173642635345459\n",
      "#Epoch 223 with total epochs 300 at step 18 loss: 3.4519026279449463 running average of batch loss 3.3184156041396293, time 0.5063612461090088\n",
      "#Epoch 223 with total epochs 300 at step 19 loss: 3.2010278701782227 running average of batch loss 3.3125462174415587, time 0.5053582191467285\n",
      "#Epoch 223 with total epochs 300 at step 20 loss: 3.4988064765930176 running average of batch loss 3.321415753591628, time 0.5043578147888184\n",
      "#Epoch 224 with total epochs 300 at step 0 loss: 3.6562142372131348 running average of batch loss 3.6562142372131348, time 0.5123584270477295\n",
      "#Epoch 224 with total epochs 300 at step 1 loss: 3.458566188812256 running average of batch loss 3.5573902130126953, time 0.4933500289916992\n",
      "#Epoch 224 with total epochs 300 at step 2 loss: 3.5279839038848877 running average of batch loss 3.5475881099700928, time 0.503359317779541\n",
      "#Epoch 224 with total epochs 300 at step 3 loss: 3.1561176776885986 running average of batch loss 3.4497205018997192, time 0.5153415203094482\n",
      "#Epoch 224 with total epochs 300 at step 4 loss: 4.3053083419799805 running average of batch loss 3.6208380699157714, time 0.5373778343200684\n",
      "#Epoch 224 with total epochs 300 at step 5 loss: 3.577914237976074 running average of batch loss 3.613684097925822, time 0.4863467216491699\n",
      "#Epoch 224 with total epochs 300 at step 6 loss: 3.633226156234741 running average of batch loss 3.616475820541382, time 0.548363447189331\n",
      "#Epoch 224 with total epochs 300 at step 7 loss: 3.2671074867248535 running average of batch loss 3.572804778814316, time 0.48932433128356934\n",
      "#Epoch 224 with total epochs 300 at step 8 loss: 3.056591033935547 running average of batch loss 3.5154476960500083, time 0.4963250160217285\n",
      "#Epoch 224 with total epochs 300 at step 9 loss: 3.2686989307403564 running average of batch loss 3.490772819519043, time 0.49034833908081055\n",
      "#Epoch 224 with total epochs 300 at step 10 loss: 3.2553980350494385 running average of batch loss 3.469375111839988, time 0.518366813659668\n",
      "#Epoch 224 with total epochs 300 at step 11 loss: 3.2367308139801025 running average of batch loss 3.449988087018331, time 0.5063610076904297\n",
      "#Epoch 224 with total epochs 300 at step 12 loss: 3.5219886302948 running average of batch loss 3.45552659034729, time 0.5023295879364014\n",
      "#Epoch 224 with total epochs 300 at step 13 loss: 3.36989426612854 running average of batch loss 3.4494099957602367, time 0.514366865158081\n",
      "#Epoch 224 with total epochs 300 at step 14 loss: 3.374697685241699 running average of batch loss 3.4444291750590006, time 0.5283756256103516\n",
      "#Epoch 224 with total epochs 300 at step 15 loss: 3.3488717079162598 running average of batch loss 3.4384568333625793, time 0.5003533363342285\n",
      "#Epoch 224 with total epochs 300 at step 16 loss: 3.2862164974212646 running average of batch loss 3.4295015194836784, time 0.48834657669067383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 224 with total epochs 300 at step 17 loss: 3.29441237449646 running average of batch loss 3.4219965669843884, time 0.5153675079345703\n",
      "#Epoch 224 with total epochs 300 at step 18 loss: 3.5022761821746826 running average of batch loss 3.426221809889141, time 0.5533907413482666\n",
      "#Epoch 224 with total epochs 300 at step 19 loss: 3.5718274116516113 running average of batch loss 3.4335020899772646, time 0.5783860683441162\n",
      "#Epoch 224 with total epochs 300 at step 20 loss: 3.73172664642334 running average of batch loss 3.4477032593318393, time 0.5113627910614014\n",
      "#Epoch 225 with total epochs 300 at step 0 loss: 3.4320385456085205 running average of batch loss 3.4320385456085205, time 0.5063319206237793\n",
      "#Epoch 225 with total epochs 300 at step 1 loss: 3.4536890983581543 running average of batch loss 3.4428638219833374, time 0.5243725776672363\n",
      "#Epoch 225 with total epochs 300 at step 2 loss: 3.206688404083252 running average of batch loss 3.364138682683309, time 0.5013561248779297\n",
      "#Epoch 225 with total epochs 300 at step 3 loss: 3.7413856983184814 running average of batch loss 3.458450436592102, time 0.5113656520843506\n",
      "#Epoch 225 with total epochs 300 at step 4 loss: 3.452085018157959 running average of batch loss 3.4571773529052736, time 0.5323770046234131\n",
      "#Epoch 225 with total epochs 300 at step 5 loss: 3.5147294998168945 running average of batch loss 3.4667693773905435, time 0.4892110824584961\n",
      "#Epoch 225 with total epochs 300 at step 6 loss: 3.325350522994995 running average of batch loss 3.4465666839054654, time 0.5013563632965088\n",
      "#Epoch 225 with total epochs 300 at step 7 loss: 3.5082359313964844 running average of batch loss 3.4542753398418427, time 0.5003552436828613\n",
      "#Epoch 225 with total epochs 300 at step 8 loss: 3.460024833679199 running average of batch loss 3.454914172490438, time 0.48734593391418457\n",
      "#Epoch 225 with total epochs 300 at step 9 loss: 3.291105031967163 running average of batch loss 3.4385332584381105, time 0.5153660774230957\n",
      "#Epoch 225 with total epochs 300 at step 10 loss: 3.4952845573425293 running average of batch loss 3.4436924674294214, time 0.49735307693481445\n",
      "#Epoch 225 with total epochs 300 at step 11 loss: 3.0921835899353027 running average of batch loss 3.414400060971578, time 0.5023565292358398\n",
      "#Epoch 225 with total epochs 300 at step 12 loss: 3.277937173843384 running average of batch loss 3.403902915807871, time 0.4863457679748535\n",
      "#Epoch 225 with total epochs 300 at step 13 loss: 3.5983898639678955 running average of batch loss 3.417794840676444, time 0.4913506507873535\n",
      "#Epoch 225 with total epochs 300 at step 14 loss: 3.2373251914978027 running average of batch loss 3.405763530731201, time 0.5213377475738525\n",
      "#Epoch 225 with total epochs 300 at step 15 loss: 3.1875905990600586 running average of batch loss 3.3921277225017548, time 0.5133650302886963\n",
      "#Epoch 225 with total epochs 300 at step 16 loss: 3.3685286045074463 running average of batch loss 3.3907395390903248, time 0.49034881591796875\n",
      "#Epoch 225 with total epochs 300 at step 17 loss: 3.3512532711029053 running average of batch loss 3.388545857535468, time 0.4843463897705078\n",
      "#Epoch 225 with total epochs 300 at step 18 loss: 3.441775321960449 running average of batch loss 3.3913474082946777, time 0.5293428897857666\n",
      "#Epoch 225 with total epochs 300 at step 19 loss: 3.15667986869812 running average of batch loss 3.37961403131485, time 0.5023365020751953\n",
      "#Epoch 225 with total epochs 300 at step 20 loss: 3.305054187774658 running average of batch loss 3.3760635625748407, time 0.5093593597412109\n",
      "#Epoch 226 with total epochs 300 at step 0 loss: 3.0502467155456543 running average of batch loss 3.0502467155456543, time 0.5383844375610352\n",
      "#Epoch 226 with total epochs 300 at step 1 loss: 3.458942174911499 running average of batch loss 3.2545944452285767, time 0.521343469619751\n",
      "#Epoch 226 with total epochs 300 at step 2 loss: 3.5576276779174805 running average of batch loss 3.3556055227915444, time 0.5073568820953369\n",
      "#Epoch 226 with total epochs 300 at step 3 loss: 3.2609543800354004 running average of batch loss 3.3319427371025085, time 0.4843466281890869\n",
      "#Epoch 226 with total epochs 300 at step 4 loss: 3.0956406593322754 running average of batch loss 3.2846823215484617, time 0.49532198905944824\n",
      "#Epoch 226 with total epochs 300 at step 5 loss: 3.1064348220825195 running average of batch loss 3.2549744049708047, time 0.4863450527191162\n",
      "#Epoch 226 with total epochs 300 at step 6 loss: 3.148632764816284 running average of batch loss 3.2397827420915877, time 0.48334336280822754\n",
      "#Epoch 226 with total epochs 300 at step 7 loss: 3.312225103378296 running average of batch loss 3.248838037252426, time 0.515369176864624\n",
      "#Epoch 226 with total epochs 300 at step 8 loss: 3.536647081375122 running average of batch loss 3.280816819932726, time 0.5043275356292725\n",
      "#Epoch 226 with total epochs 300 at step 9 loss: 3.3268191814422607 running average of batch loss 3.2854170560836793, time 0.49034547805786133\n",
      "#Epoch 226 with total epochs 300 at step 10 loss: 3.338634490966797 running average of batch loss 3.290255004709417, time 0.489349365234375\n",
      "#Epoch 226 with total epochs 300 at step 11 loss: 3.5045976638793945 running average of batch loss 3.308116892973582, time 0.5153677463531494\n",
      "#Epoch 226 with total epochs 300 at step 12 loss: 3.5493385791778564 running average of batch loss 3.3266724072969875, time 0.5513648986816406\n",
      "#Epoch 226 with total epochs 300 at step 13 loss: 3.293301820755005 running average of batch loss 3.3242887939725603, time 0.4973263740539551\n",
      "#Epoch 226 with total epochs 300 at step 14 loss: 3.655475378036499 running average of batch loss 3.346367899576823, time 0.5113644599914551\n",
      "#Epoch 226 with total epochs 300 at step 15 loss: 3.282410144805908 running average of batch loss 3.3423705399036407, time 0.5223708152770996\n",
      "#Epoch 226 with total epochs 300 at step 16 loss: 3.353569507598877 running average of batch loss 3.343029302709243, time 0.5333502292633057\n",
      "#Epoch 226 with total epochs 300 at step 17 loss: 3.301908016204834 running average of batch loss 3.3407447867923312, time 0.5163412094116211\n",
      "#Epoch 226 with total epochs 300 at step 18 loss: 3.511465072631836 running average of batch loss 3.3497300649944104, time 0.5373783111572266\n",
      "#Epoch 226 with total epochs 300 at step 19 loss: 3.686556100845337 running average of batch loss 3.366571366786957, time 0.5063602924346924\n",
      "#Epoch 226 with total epochs 300 at step 20 loss: 3.5493788719177246 running average of batch loss 3.375276486078898, time 0.491349458694458\n",
      "#Epoch 227 with total epochs 300 at step 0 loss: 3.3321115970611572 running average of batch loss 3.3321115970611572, time 0.5093576908111572\n",
      "#Epoch 227 with total epochs 300 at step 1 loss: 3.718195915222168 running average of batch loss 3.5251537561416626, time 0.49034762382507324\n",
      "#Epoch 227 with total epochs 300 at step 2 loss: 3.833798885345459 running average of batch loss 3.6280354658762612, time 0.50335693359375\n",
      "#Epoch 227 with total epochs 300 at step 3 loss: 3.089722156524658 running average of batch loss 3.4934571385383606, time 0.4903254508972168\n",
      "#Epoch 227 with total epochs 300 at step 4 loss: 3.3969621658325195 running average of batch loss 3.4741581439971925, time 0.5053591728210449\n",
      "#Epoch 227 with total epochs 300 at step 5 loss: 3.798037052154541 running average of batch loss 3.528137962023417, time 0.5133640766143799\n",
      "#Epoch 227 with total epochs 300 at step 6 loss: 3.672776222229004 running average of batch loss 3.5488005706242154, time 0.5153665542602539\n",
      "#Epoch 227 with total epochs 300 at step 7 loss: 3.2470648288726807 running average of batch loss 3.5110836029052734, time 0.48534440994262695\n",
      "#Epoch 227 with total epochs 300 at step 8 loss: 3.2758593559265137 running average of batch loss 3.484947575463189, time 0.4843466281890869\n",
      "#Epoch 227 with total epochs 300 at step 9 loss: 3.385498285293579 running average of batch loss 3.475002646446228, time 0.49334716796875\n",
      "#Epoch 227 with total epochs 300 at step 10 loss: 3.5971906185150146 running average of batch loss 3.486110643907027, time 0.4973273277282715\n",
      "#Epoch 227 with total epochs 300 at step 11 loss: 3.58890962600708 running average of batch loss 3.4946772257486978, time 0.542384147644043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 227 with total epochs 300 at step 12 loss: 3.4761152267456055 running average of batch loss 3.493249379671537, time 0.5313804149627686\n",
      "#Epoch 227 with total epochs 300 at step 13 loss: 3.483003854751587 running average of batch loss 3.492517556462969, time 0.5053305625915527\n",
      "#Epoch 227 with total epochs 300 at step 14 loss: 3.683720111846924 running average of batch loss 3.505264393488566, time 0.5083339214324951\n",
      "#Epoch 227 with total epochs 300 at step 15 loss: 3.247915744781494 running average of batch loss 3.489180102944374, time 0.5073566436767578\n",
      "#Epoch 227 with total epochs 300 at step 16 loss: 3.7224903106689453 running average of batch loss 3.5029042328105255, time 0.5253481864929199\n",
      "#Epoch 227 with total epochs 300 at step 17 loss: 3.5981664657592773 running average of batch loss 3.508196579085456, time 0.5733795166015625\n",
      "#Epoch 227 with total epochs 300 at step 18 loss: 3.5857882499694824 running average of batch loss 3.512280351237247, time 0.5293478965759277\n",
      "#Epoch 227 with total epochs 300 at step 19 loss: 3.353886842727661 running average of batch loss 3.5043606758117676, time 0.5353519916534424\n",
      "#Epoch 227 with total epochs 300 at step 20 loss: 2.993685007095337 running average of batch loss 3.480042786825271, time 0.5103366374969482\n",
      "#Epoch 228 with total epochs 300 at step 0 loss: 3.598599672317505 running average of batch loss 3.598599672317505, time 0.5043308734893799\n",
      "#Epoch 228 with total epochs 300 at step 1 loss: 3.572840452194214 running average of batch loss 3.5857200622558594, time 0.5083334445953369\n",
      "#Epoch 228 with total epochs 300 at step 2 loss: 3.5664803981781006 running average of batch loss 3.5793068408966064, time 0.496335506439209\n",
      "#Epoch 228 with total epochs 300 at step 3 loss: 3.469402313232422 running average of batch loss 3.5518307089805603, time 0.5624027252197266\n",
      "#Epoch 228 with total epochs 300 at step 4 loss: 3.166562080383301 running average of batch loss 3.4747769832611084, time 0.5003261566162109\n",
      "#Epoch 228 with total epochs 300 at step 5 loss: 3.225649356842041 running average of batch loss 3.4332557121912637, time 0.5123636722564697\n",
      "#Epoch 228 with total epochs 300 at step 6 loss: 3.27097487449646 running average of batch loss 3.4100727353777205, time 0.5143642425537109\n",
      "#Epoch 228 with total epochs 300 at step 7 loss: 3.271260976791382 running average of batch loss 3.392721265554428, time 0.5283772945404053\n",
      "#Epoch 228 with total epochs 300 at step 8 loss: 3.7870492935180664 running average of batch loss 3.4365354908837213, time 0.4993276596069336\n",
      "#Epoch 228 with total epochs 300 at step 9 loss: 3.287799119949341 running average of batch loss 3.421661853790283, time 0.49735426902770996\n",
      "#Epoch 228 with total epochs 300 at step 10 loss: 3.398275852203369 running average of batch loss 3.419535853646018, time 0.48932528495788574\n",
      "#Epoch 228 with total epochs 300 at step 11 loss: 3.2077395915985107 running average of batch loss 3.4018861651420593, time 0.5093357563018799\n",
      "#Epoch 228 with total epochs 300 at step 12 loss: 3.4483866691589355 running average of batch loss 3.4054631269895115, time 0.5073337554931641\n",
      "#Epoch 228 with total epochs 300 at step 13 loss: 3.298527240753174 running average of batch loss 3.3978248494012013, time 0.5343766212463379\n",
      "#Epoch 228 with total epochs 300 at step 14 loss: 3.0511727333068848 running average of batch loss 3.374714708328247, time 0.4893486499786377\n",
      "#Epoch 228 with total epochs 300 at step 15 loss: 3.285463571548462 running average of batch loss 3.3691365122795105, time 0.5073559284210205\n",
      "#Epoch 228 with total epochs 300 at step 16 loss: 3.3720786571502686 running average of batch loss 3.3693095796248493, time 0.5053596496582031\n",
      "#Epoch 228 with total epochs 300 at step 17 loss: 3.1518850326538086 running average of batch loss 3.357230438126458, time 0.49034714698791504\n",
      "#Epoch 228 with total epochs 300 at step 18 loss: 3.2616465091705322 running average of batch loss 3.3521997050235144, time 0.5043585300445557\n",
      "#Epoch 228 with total epochs 300 at step 19 loss: 3.4551756381988525 running average of batch loss 3.3573485016822815, time 0.49535155296325684\n",
      "#Epoch 228 with total epochs 300 at step 20 loss: 3.20585298538208 running average of batch loss 3.35013442947751, time 0.510340690612793\n",
      "#Epoch 229 with total epochs 300 at step 0 loss: 3.751265525817871 running average of batch loss 3.751265525817871, time 0.4963247776031494\n",
      "#Epoch 229 with total epochs 300 at step 1 loss: 3.5091419219970703 running average of batch loss 3.6302037239074707, time 0.4873509407043457\n",
      "#Epoch 229 with total epochs 300 at step 2 loss: 3.595400333404541 running average of batch loss 3.6186025937398276, time 0.5493645668029785\n",
      "#Epoch 229 with total epochs 300 at step 3 loss: 3.632521390914917 running average of batch loss 3.6220822930336, time 0.511340856552124\n",
      "#Epoch 229 with total epochs 300 at step 4 loss: 3.1950318813323975 running average of batch loss 3.5366722106933595, time 0.5043549537658691\n",
      "#Epoch 229 with total epochs 300 at step 5 loss: 3.2335281372070312 running average of batch loss 3.486148198445638, time 0.5233659744262695\n",
      "#Epoch 229 with total epochs 300 at step 6 loss: 3.4356794357299805 running average of batch loss 3.4789383752005443, time 0.4833216667175293\n",
      "#Epoch 229 with total epochs 300 at step 7 loss: 3.411375045776367 running average of batch loss 3.470492959022522, time 0.5053315162658691\n",
      "#Epoch 229 with total epochs 300 at step 8 loss: 3.4247848987579346 running average of batch loss 3.46541428565979, time 0.5343763828277588\n",
      "#Epoch 229 with total epochs 300 at step 9 loss: 3.190704584121704 running average of batch loss 3.4379433155059815, time 0.5634019374847412\n",
      "#Epoch 229 with total epochs 300 at step 10 loss: 3.3216428756713867 running average of batch loss 3.427370548248291, time 0.5333757400512695\n",
      "#Epoch 229 with total epochs 300 at step 11 loss: 3.4779326915740967 running average of batch loss 3.431584060192108, time 0.5383853912353516\n",
      "#Epoch 229 with total epochs 300 at step 12 loss: 3.043433904647827 running average of batch loss 3.4017263559194713, time 0.5243716239929199\n",
      "#Epoch 229 with total epochs 300 at step 13 loss: 3.372847557067871 running average of batch loss 3.399663584572928, time 0.5303769111633301\n",
      "#Epoch 229 with total epochs 300 at step 14 loss: 2.928266763687134 running average of batch loss 3.3682371298472087, time 0.5293757915496826\n",
      "#Epoch 229 with total epochs 300 at step 15 loss: 3.7037336826324463 running average of batch loss 3.389205664396286, time 0.5943968296051025\n",
      "#Epoch 229 with total epochs 300 at step 16 loss: 3.555906295776367 running average of batch loss 3.399011583889232, time 0.5343542098999023\n",
      "#Epoch 229 with total epochs 300 at step 17 loss: 3.4097931385040283 running average of batch loss 3.3996105591456094, time 0.5243449211120605\n",
      "#Epoch 229 with total epochs 300 at step 18 loss: 3.488095283508301 running average of batch loss 3.4042676499015405, time 0.5303730964660645\n",
      "#Epoch 229 with total epochs 300 at step 19 loss: 3.5500328540802 running average of batch loss 3.4115559101104735, time 0.5083625316619873\n",
      "#Epoch 229 with total epochs 300 at step 20 loss: 3.2584476470947266 running average of batch loss 3.404265040443057, time 0.5103335380554199\n",
      "#Epoch 230 with total epochs 300 at step 0 loss: 3.4363465309143066 running average of batch loss 3.4363465309143066, time 0.48834919929504395\n",
      "#Epoch 230 with total epochs 300 at step 1 loss: 3.2674789428710938 running average of batch loss 3.3519127368927, time 0.49832797050476074\n",
      "#Epoch 230 with total epochs 300 at step 2 loss: 3.507737636566162 running average of batch loss 3.4038543701171875, time 0.48834919929504395\n",
      "#Epoch 230 with total epochs 300 at step 3 loss: 3.343456745147705 running average of batch loss 3.388754963874817, time 0.5143382549285889\n",
      "#Epoch 230 with total epochs 300 at step 4 loss: 3.3629753589630127 running average of batch loss 3.383599042892456, time 0.4883458614349365\n",
      "#Epoch 230 with total epochs 300 at step 5 loss: 3.2612979412078857 running average of batch loss 3.363215525945028, time 0.49335169792175293\n",
      "#Epoch 230 with total epochs 300 at step 6 loss: 3.0349042415618896 running average of batch loss 3.3163139138902937, time 0.5273480415344238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 230 with total epochs 300 at step 7 loss: 3.571779251098633 running average of batch loss 3.348247081041336, time 0.5283730030059814\n",
      "#Epoch 230 with total epochs 300 at step 8 loss: 3.357207775115967 running average of batch loss 3.3492427137162952, time 0.5063331127166748\n",
      "#Epoch 230 with total epochs 300 at step 9 loss: 3.575972557067871 running average of batch loss 3.3719156980514526, time 0.5313746929168701\n",
      "#Epoch 230 with total epochs 300 at step 10 loss: 3.5121397972106934 running average of batch loss 3.3846633434295654, time 0.4923288822174072\n",
      "#Epoch 230 with total epochs 300 at step 11 loss: 3.5007286071777344 running average of batch loss 3.394335448741913, time 0.5013282299041748\n",
      "#Epoch 230 with total epochs 300 at step 12 loss: 3.7684199810028076 running average of batch loss 3.423111181992751, time 0.5173680782318115\n",
      "#Epoch 230 with total epochs 300 at step 13 loss: 3.037686347961426 running average of batch loss 3.395580836704799, time 0.4933509826660156\n",
      "#Epoch 230 with total epochs 300 at step 14 loss: 3.2960665225982666 running average of batch loss 3.388946549097697, time 0.4903273582458496\n",
      "#Epoch 230 with total epochs 300 at step 15 loss: 3.580784797668457 running average of batch loss 3.4009364396333694, time 0.5243451595306396\n",
      "#Epoch 230 with total epochs 300 at step 16 loss: 3.5856590270996094 running average of batch loss 3.411802474190207, time 0.48834657669067383\n",
      "#Epoch 230 with total epochs 300 at step 17 loss: 3.238041877746582 running average of batch loss 3.402149107721117, time 0.5133645534515381\n",
      "#Epoch 230 with total epochs 300 at step 18 loss: 3.1263859272003174 running average of batch loss 3.387635256114759, time 0.51936936378479\n",
      "#Epoch 230 with total epochs 300 at step 19 loss: 3.084658622741699 running average of batch loss 3.372486424446106, time 0.5013594627380371\n",
      "#Epoch 230 with total epochs 300 at step 20 loss: 3.4709722995758057 running average of batch loss 3.3771762280237105, time 0.5013296604156494\n",
      "#Epoch 231 with total epochs 300 at step 0 loss: 3.608272075653076 running average of batch loss 3.608272075653076, time 0.48534345626831055\n",
      "#Epoch 231 with total epochs 300 at step 1 loss: 3.095594882965088 running average of batch loss 3.351933479309082, time 0.5053606033325195\n",
      "#Epoch 231 with total epochs 300 at step 2 loss: 3.767820119857788 running average of batch loss 3.490562359491984, time 0.5083355903625488\n",
      "#Epoch 231 with total epochs 300 at step 3 loss: 3.3055906295776367 running average of batch loss 3.444319427013397, time 0.5323507785797119\n",
      "#Epoch 231 with total epochs 300 at step 4 loss: 3.6391444206237793 running average of batch loss 3.483284425735474, time 0.49771642684936523\n",
      "#Epoch 231 with total epochs 300 at step 5 loss: 3.673959970474243 running average of batch loss 3.515063683191935, time 0.5148398876190186\n",
      "#Epoch 231 with total epochs 300 at step 6 loss: 3.5406723022460938 running average of batch loss 3.5187220573425293, time 0.5053322315216064\n",
      "#Epoch 231 with total epochs 300 at step 7 loss: 3.107842206954956 running average of batch loss 3.4673620760440826, time 0.5203685760498047\n",
      "#Epoch 231 with total epochs 300 at step 8 loss: 3.6723084449768066 running average of batch loss 3.4901338948143854, time 0.5033352375030518\n",
      "#Epoch 231 with total epochs 300 at step 9 loss: 3.466554880142212 running average of batch loss 3.487775993347168, time 0.49532437324523926\n",
      "#Epoch 231 with total epochs 300 at step 10 loss: 3.034726619720459 running average of batch loss 3.4465896866538306, time 0.4933502674102783\n",
      "#Epoch 231 with total epochs 300 at step 11 loss: 3.398831844329834 running average of batch loss 3.4426098664601645, time 0.48932552337646484\n",
      "#Epoch 231 with total epochs 300 at step 12 loss: 3.492095708847046 running average of batch loss 3.4464164697206936, time 0.5103616714477539\n",
      "#Epoch 231 with total epochs 300 at step 13 loss: 3.33685564994812 running average of batch loss 3.4385906968797957, time 0.5093352794647217\n",
      "#Epoch 231 with total epochs 300 at step 14 loss: 3.3783774375915527 running average of batch loss 3.434576479593913, time 0.5193700790405273\n",
      "#Epoch 231 with total epochs 300 at step 15 loss: 3.742713689804077 running average of batch loss 3.453835055232048, time 0.48932671546936035\n",
      "#Epoch 231 with total epochs 300 at step 16 loss: 3.2068822383880615 running average of batch loss 3.4393084189471077, time 0.5083606243133545\n",
      "#Epoch 231 with total epochs 300 at step 17 loss: 2.8835620880126953 running average of batch loss 3.408433622784085, time 0.5073602199554443\n",
      "#Epoch 231 with total epochs 300 at step 18 loss: 3.3788881301879883 running average of batch loss 3.4068785968579745, time 0.49735522270202637\n",
      "#Epoch 231 with total epochs 300 at step 19 loss: 3.2294921875 running average of batch loss 3.3980092763900758, time 0.49332618713378906\n",
      "#Epoch 231 with total epochs 300 at step 20 loss: 3.450277328491211 running average of batch loss 3.4004982312520347, time 0.5163407325744629\n",
      "#Epoch 232 with total epochs 300 at step 0 loss: 3.4212231636047363 running average of batch loss 3.4212231636047363, time 0.5083363056182861\n",
      "#Epoch 232 with total epochs 300 at step 1 loss: 3.10707950592041 running average of batch loss 3.2641513347625732, time 0.487318754196167\n",
      "#Epoch 232 with total epochs 300 at step 2 loss: 3.3275628089904785 running average of batch loss 3.2852884928385415, time 0.5753796100616455\n",
      "#Epoch 232 with total epochs 300 at step 3 loss: 3.6421921253204346 running average of batch loss 3.374514400959015, time 0.5473887920379639\n",
      "#Epoch 232 with total epochs 300 at step 4 loss: 3.2894487380981445 running average of batch loss 3.357501268386841, time 0.5875198841094971\n",
      "#Epoch 232 with total epochs 300 at step 5 loss: 3.035219430923462 running average of batch loss 3.303787628809611, time 0.5339155197143555\n",
      "#Epoch 232 with total epochs 300 at step 6 loss: 3.2103724479675293 running average of batch loss 3.2904426029750278, time 0.5075690746307373\n",
      "#Epoch 232 with total epochs 300 at step 7 loss: 3.3343665599823 running average of batch loss 3.295933097600937, time 0.5309996604919434\n",
      "#Epoch 232 with total epochs 300 at step 8 loss: 2.9558727741241455 running average of batch loss 3.258148617214627, time 0.491901159286499\n",
      "#Epoch 232 with total epochs 300 at step 9 loss: 3.5147533416748047 running average of batch loss 3.2838090896606444, time 0.5058355331420898\n",
      "#Epoch 232 with total epochs 300 at step 10 loss: 3.8854308128356934 running average of batch loss 3.338501973585649, time 0.49088168144226074\n",
      "#Epoch 232 with total epochs 300 at step 11 loss: 3.4726343154907227 running average of batch loss 3.3496796687444053, time 0.5054025650024414\n",
      "#Epoch 232 with total epochs 300 at step 12 loss: 3.4865262508392334 running average of batch loss 3.3602063289055457, time 0.506385326385498\n",
      "#Epoch 232 with total epochs 300 at step 13 loss: 3.1547837257385254 running average of batch loss 3.3455332858221873, time 0.49087047576904297\n",
      "#Epoch 232 with total epochs 300 at step 14 loss: 3.444700241088867 running average of batch loss 3.352144416173299, time 0.4893956184387207\n",
      "#Epoch 232 with total epochs 300 at step 15 loss: 3.4375855922698975 running average of batch loss 3.3574844896793365, time 0.4898216724395752\n",
      "#Epoch 232 with total epochs 300 at step 16 loss: 3.8511385917663574 running average of batch loss 3.3865229662726906, time 0.4894280433654785\n",
      "#Epoch 232 with total epochs 300 at step 17 loss: 3.237154483795166 running average of batch loss 3.3782247172461615, time 0.4863443374633789\n",
      "#Epoch 232 with total epochs 300 at step 18 loss: 3.567521333694458 running average of batch loss 3.3881876970592297, time 0.5013291835784912\n",
      "#Epoch 232 with total epochs 300 at step 19 loss: 3.085585594177246 running average of batch loss 3.3730575919151304, time 0.4883244037628174\n",
      "#Epoch 232 with total epochs 300 at step 20 loss: 3.4684884548187256 running average of batch loss 3.377601918720064, time 0.5123615264892578\n",
      "#Epoch 233 with total epochs 300 at step 0 loss: 3.675271987915039 running average of batch loss 3.675271987915039, time 0.49234914779663086\n",
      "#Epoch 233 with total epochs 300 at step 1 loss: 3.193734645843506 running average of batch loss 3.4345033168792725, time 0.5003535747528076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 233 with total epochs 300 at step 2 loss: 3.1250619888305664 running average of batch loss 3.3313562075297036, time 0.489346981048584\n",
      "#Epoch 233 with total epochs 300 at step 3 loss: 3.521718740463257 running average of batch loss 3.378946840763092, time 0.4883260726928711\n",
      "#Epoch 233 with total epochs 300 at step 4 loss: 3.4424004554748535 running average of batch loss 3.3916375637054443, time 0.49935126304626465\n",
      "#Epoch 233 with total epochs 300 at step 5 loss: 3.4749207496643066 running average of batch loss 3.405518094698588, time 0.49234962463378906\n",
      "#Epoch 233 with total epochs 300 at step 6 loss: 3.3824360370635986 running average of batch loss 3.4022206578935896, time 0.5133647918701172\n",
      "#Epoch 233 with total epochs 300 at step 7 loss: 3.433398485183716 running average of batch loss 3.4061178863048553, time 0.48834776878356934\n",
      "#Epoch 233 with total epochs 300 at step 8 loss: 3.1355159282684326 running average of batch loss 3.376051002078586, time 0.48932671546936035\n",
      "#Epoch 233 with total epochs 300 at step 9 loss: 3.0773210525512695 running average of batch loss 3.3461780071258547, time 0.5063598155975342\n",
      "#Epoch 233 with total epochs 300 at step 10 loss: 3.3652114868164062 running average of batch loss 3.3479083234613594, time 0.507331371307373\n",
      "#Epoch 233 with total epochs 300 at step 11 loss: 3.678668260574341 running average of batch loss 3.3754716515541077, time 0.5063316822052002\n",
      "#Epoch 233 with total epochs 300 at step 12 loss: 3.254669666290283 running average of batch loss 3.366179191149198, time 0.5183660984039307\n",
      "#Epoch 233 with total epochs 300 at step 13 loss: 3.2674007415771484 running average of batch loss 3.3591235876083374, time 0.5443863868713379\n",
      "#Epoch 233 with total epochs 300 at step 14 loss: 4.000949859619141 running average of batch loss 3.401912005742391, time 0.5253739356994629\n",
      "#Epoch 233 with total epochs 300 at step 15 loss: 3.4639220237731934 running average of batch loss 3.405787631869316, time 0.6494617462158203\n",
      "#Epoch 233 with total epochs 300 at step 16 loss: 3.6109797954559326 running average of batch loss 3.417857759139117, time 0.5063581466674805\n",
      "#Epoch 233 with total epochs 300 at step 17 loss: 3.5435502529144287 running average of batch loss 3.4248406754599676, time 0.49535393714904785\n",
      "#Epoch 233 with total epochs 300 at step 18 loss: 3.2004456520080566 running average of batch loss 3.413030411067762, time 0.49032044410705566\n",
      "#Epoch 233 with total epochs 300 at step 19 loss: 3.6486449241638184 running average of batch loss 3.424811136722565, time 0.5043284893035889\n",
      "#Epoch 233 with total epochs 300 at step 20 loss: 3.411471128463745 running average of batch loss 3.4241758982340493, time 0.531348466873169\n",
      "#Epoch 234 with total epochs 300 at step 0 loss: 3.170571804046631 running average of batch loss 3.170571804046631, time 0.5033321380615234\n",
      "#Epoch 234 with total epochs 300 at step 1 loss: 3.0831398963928223 running average of batch loss 3.1268558502197266, time 0.4833207130432129\n",
      "#Epoch 234 with total epochs 300 at step 2 loss: 3.3521037101745605 running average of batch loss 3.2019384702046714, time 0.5103592872619629\n",
      "#Epoch 234 with total epochs 300 at step 3 loss: 3.4860048294067383 running average of batch loss 3.272955060005188, time 0.5313475131988525\n",
      "#Epoch 234 with total epochs 300 at step 4 loss: 3.262092113494873 running average of batch loss 3.270782470703125, time 0.5153684616088867\n",
      "#Epoch 234 with total epochs 300 at step 5 loss: 3.2646358013153076 running average of batch loss 3.2697580258051553, time 0.5063538551330566\n",
      "#Epoch 234 with total epochs 300 at step 6 loss: 3.2602579593658447 running average of batch loss 3.2684008734566823, time 0.4843463897705078\n",
      "#Epoch 234 with total epochs 300 at step 7 loss: 3.5870466232299805 running average of batch loss 3.3082315921783447, time 0.5273714065551758\n",
      "#Epoch 234 with total epochs 300 at step 8 loss: 3.305182456970215 running average of batch loss 3.3078927993774414, time 0.5033535957336426\n",
      "#Epoch 234 with total epochs 300 at step 9 loss: 3.0042340755462646 running average of batch loss 3.277526926994324, time 0.5063602924346924\n",
      "#Epoch 234 with total epochs 300 at step 10 loss: 3.4544448852539062 running average of batch loss 3.293610377745195, time 0.4903249740600586\n",
      "#Epoch 234 with total epochs 300 at step 11 loss: 3.395796775817871 running average of batch loss 3.3021259109179177, time 0.49034881591796875\n",
      "#Epoch 234 with total epochs 300 at step 12 loss: 3.0008764266967773 running average of batch loss 3.278952873670138, time 0.48932313919067383\n",
      "#Epoch 234 with total epochs 300 at step 13 loss: 3.1705210208892822 running average of batch loss 3.271207741328648, time 0.4883456230163574\n",
      "#Epoch 234 with total epochs 300 at step 14 loss: 3.613981246948242 running average of batch loss 3.2940593083699543, time 0.5003311634063721\n",
      "#Epoch 234 with total epochs 300 at step 15 loss: 3.6458334922790527 running average of batch loss 3.316045194864273, time 0.651463508605957\n",
      "#Epoch 234 with total epochs 300 at step 16 loss: 3.4390859603881836 running average of batch loss 3.323282886953915, time 0.5343797206878662\n",
      "#Epoch 234 with total epochs 300 at step 17 loss: 3.0835976600646973 running average of batch loss 3.309967041015625, time 0.5123405456542969\n",
      "#Epoch 234 with total epochs 300 at step 18 loss: 3.1703553199768066 running average of batch loss 3.3026190556977926, time 0.4903233051300049\n",
      "#Epoch 234 with total epochs 300 at step 19 loss: 3.279541492462158 running average of batch loss 3.3014651775360107, time 0.5103397369384766\n",
      "#Epoch 234 with total epochs 300 at step 20 loss: 3.3424928188323975 running average of batch loss 3.3034188747406006, time 0.5183653831481934\n",
      "#Epoch 235 with total epochs 300 at step 0 loss: 3.387300729751587 running average of batch loss 3.387300729751587, time 0.5253753662109375\n",
      "#Epoch 235 with total epochs 300 at step 1 loss: 3.2749874591827393 running average of batch loss 3.331144094467163, time 0.5453619956970215\n",
      "#Epoch 235 with total epochs 300 at step 2 loss: 3.2369332313537598 running average of batch loss 3.299740473429362, time 0.5203666687011719\n",
      "#Epoch 235 with total epochs 300 at step 3 loss: 3.595872402191162 running average of batch loss 3.373773455619812, time 0.5153672695159912\n",
      "#Epoch 235 with total epochs 300 at step 4 loss: 3.491507053375244 running average of batch loss 3.3973201751708983, time 0.5433604717254639\n",
      "#Epoch 235 with total epochs 300 at step 5 loss: 3.4855082035064697 running average of batch loss 3.4120181798934937, time 0.49232983589172363\n",
      "#Epoch 235 with total epochs 300 at step 6 loss: 3.116271495819092 running average of batch loss 3.3697686535971507, time 0.5033268928527832\n",
      "#Epoch 235 with total epochs 300 at step 7 loss: 3.3661136627197266 running average of batch loss 3.3693117797374725, time 0.537381649017334\n",
      "#Epoch 235 with total epochs 300 at step 8 loss: 2.966296672821045 running average of batch loss 3.324532323413425, time 0.5013332366943359\n",
      "#Epoch 235 with total epochs 300 at step 9 loss: 3.0627291202545166 running average of batch loss 3.298352003097534, time 0.5003514289855957\n",
      "#Epoch 235 with total epochs 300 at step 10 loss: 3.4108309745788574 running average of batch loss 3.308577364141291, time 0.5403785705566406\n",
      "#Epoch 235 with total epochs 300 at step 11 loss: 4.051673889160156 running average of batch loss 3.3705020745595298, time 0.49732398986816406\n",
      "#Epoch 235 with total epochs 300 at step 12 loss: 3.6074557304382324 running average of batch loss 3.3887292788578915, time 0.5493898391723633\n",
      "#Epoch 235 with total epochs 300 at step 13 loss: 3.4572412967681885 running average of batch loss 3.3936229944229126, time 0.530376672744751\n",
      "#Epoch 235 with total epochs 300 at step 14 loss: 3.661642551422119 running average of batch loss 3.411490964889526, time 0.5223722457885742\n",
      "#Epoch 235 with total epochs 300 at step 15 loss: 3.5263845920562744 running average of batch loss 3.418671816587448, time 0.5904169082641602\n",
      "#Epoch 235 with total epochs 300 at step 16 loss: 3.444215774536133 running average of batch loss 3.4201744023491356, time 0.5563952922821045\n",
      "#Epoch 235 with total epochs 300 at step 17 loss: 2.8088769912719727 running average of batch loss 3.386213435067071, time 0.5473897457122803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 235 with total epochs 300 at step 18 loss: 3.2100276947021484 running average of batch loss 3.376940501363654, time 0.521369218826294\n",
      "#Epoch 235 with total epochs 300 at step 19 loss: 3.459969997406006 running average of batch loss 3.3810919761657714, time 0.5023353099822998\n",
      "#Epoch 235 with total epochs 300 at step 20 loss: 3.7007665634155273 running average of batch loss 3.396314575558617, time 0.5083358287811279\n",
      "#Epoch 236 with total epochs 300 at step 0 loss: 3.270944118499756 running average of batch loss 3.270944118499756, time 0.5193660259246826\n",
      "#Epoch 236 with total epochs 300 at step 1 loss: 3.3308119773864746 running average of batch loss 3.3008780479431152, time 0.5033364295959473\n",
      "#Epoch 236 with total epochs 300 at step 2 loss: 3.178858518600464 running average of batch loss 3.260204871495565, time 0.5103335380554199\n",
      "#Epoch 236 with total epochs 300 at step 3 loss: 3.1506505012512207 running average of batch loss 3.2328162789344788, time 0.49034833908081055\n",
      "#Epoch 236 with total epochs 300 at step 4 loss: 4.006430149078369 running average of batch loss 3.3875390529632567, time 0.4903285503387451\n",
      "#Epoch 236 with total epochs 300 at step 5 loss: 3.5414721965789795 running average of batch loss 3.4131945768992105, time 0.5073370933532715\n",
      "#Epoch 236 with total epochs 300 at step 6 loss: 3.4614295959472656 running average of batch loss 3.4200852939060757, time 0.49034953117370605\n",
      "#Epoch 236 with total epochs 300 at step 7 loss: 3.5133466720581055 running average of batch loss 3.4317429661750793, time 0.5353777408599854\n",
      "#Epoch 236 with total epochs 300 at step 8 loss: 3.0300145149230957 running average of batch loss 3.3871064715915256, time 0.507361650466919\n",
      "#Epoch 236 with total epochs 300 at step 9 loss: 3.200734853744507 running average of batch loss 3.368469309806824, time 0.5033309459686279\n",
      "#Epoch 236 with total epochs 300 at step 10 loss: 3.4227638244628906 running average of batch loss 3.373405174775557, time 0.49535107612609863\n",
      "#Epoch 236 with total epochs 300 at step 11 loss: 2.8429012298583984 running average of batch loss 3.329196512699127, time 0.5253438949584961\n",
      "#Epoch 236 with total epochs 300 at step 12 loss: 3.6918766498565674 running average of batch loss 3.3570949847881613, time 0.5123636722564697\n",
      "#Epoch 236 with total epochs 300 at step 13 loss: 3.17618989944458 running average of batch loss 3.3441731929779053, time 0.48834729194641113\n",
      "#Epoch 236 with total epochs 300 at step 14 loss: 3.319040298461914 running average of batch loss 3.3424976666768393, time 0.5243723392486572\n",
      "#Epoch 236 with total epochs 300 at step 15 loss: 3.6083366870880127 running average of batch loss 3.3591126054525375, time 0.5443615913391113\n",
      "#Epoch 236 with total epochs 300 at step 16 loss: 3.917503833770752 running average of batch loss 3.3919591482947853, time 0.5143392086029053\n",
      "#Epoch 236 with total epochs 300 at step 17 loss: 3.5430665016174316 running average of batch loss 3.4003540012571545, time 0.49434947967529297\n",
      "#Epoch 236 with total epochs 300 at step 18 loss: 3.566781997680664 running average of batch loss 3.409113369489971, time 0.5343515872955322\n",
      "#Epoch 236 with total epochs 300 at step 19 loss: 3.0434699058532715 running average of batch loss 3.390831196308136, time 0.5373485088348389\n",
      "#Epoch 236 with total epochs 300 at step 20 loss: 3.218451976776123 running average of batch loss 3.3826226620447066, time 0.5093615055084229\n",
      "#Epoch 237 with total epochs 300 at step 0 loss: 3.4847888946533203 running average of batch loss 3.4847888946533203, time 0.4883263111114502\n",
      "#Epoch 237 with total epochs 300 at step 1 loss: 3.5644757747650146 running average of batch loss 3.5246323347091675, time 0.5003292560577393\n",
      "#Epoch 237 with total epochs 300 at step 2 loss: 3.2609591484069824 running average of batch loss 3.436741272608439, time 0.5003252029418945\n",
      "#Epoch 237 with total epochs 300 at step 3 loss: 3.7426066398620605 running average of batch loss 3.5132076144218445, time 0.48834991455078125\n",
      "#Epoch 237 with total epochs 300 at step 4 loss: 3.5750021934509277 running average of batch loss 3.5255665302276613, time 0.4963524341583252\n",
      "#Epoch 237 with total epochs 300 at step 5 loss: 3.580359935760498 running average of batch loss 3.534698764483134, time 0.5313763618469238\n",
      "#Epoch 237 with total epochs 300 at step 6 loss: 3.535473108291626 running average of batch loss 3.5348093850272044, time 0.4923226833343506\n",
      "#Epoch 237 with total epochs 300 at step 7 loss: 3.137315273284912 running average of batch loss 3.4851226210594177, time 0.4983525276184082\n",
      "#Epoch 237 with total epochs 300 at step 8 loss: 2.9244720935821533 running average of batch loss 3.422828118006388, time 0.5063309669494629\n",
      "#Epoch 237 with total epochs 300 at step 9 loss: 3.309286594390869 running average of batch loss 3.4114739656448365, time 0.5009088516235352\n",
      "#Epoch 237 with total epochs 300 at step 10 loss: 3.493042469024658 running average of batch loss 3.418889284133911, time 0.540308952331543\n",
      "#Epoch 237 with total epochs 300 at step 11 loss: 3.273611545562744 running average of batch loss 3.406782805919647, time 0.49035048484802246\n",
      "#Epoch 237 with total epochs 300 at step 12 loss: 3.523350954055786 running average of batch loss 3.415749586545504, time 0.5263431072235107\n",
      "#Epoch 237 with total epochs 300 at step 13 loss: 3.5704503059387207 running average of batch loss 3.426799637930734, time 0.5043303966522217\n",
      "#Epoch 237 with total epochs 300 at step 14 loss: 3.4622080326080322 running average of batch loss 3.429160197575887, time 0.5323505401611328\n",
      "#Epoch 237 with total epochs 300 at step 15 loss: 3.1148018836975098 running average of batch loss 3.4095128029584885, time 0.49735403060913086\n",
      "#Epoch 237 with total epochs 300 at step 16 loss: 3.3129305839538574 running average of batch loss 3.403831495958216, time 0.5223681926727295\n",
      "#Epoch 237 with total epochs 300 at step 17 loss: 3.187572956085205 running average of batch loss 3.3918171326319375, time 0.49035072326660156\n",
      "#Epoch 237 with total epochs 300 at step 18 loss: 3.316833019256592 running average of batch loss 3.3878706003490247, time 0.5293686389923096\n",
      "#Epoch 237 with total epochs 300 at step 19 loss: 3.1190826892852783 running average of batch loss 3.3744312047958376, time 0.5403847694396973\n",
      "#Epoch 237 with total epochs 300 at step 20 loss: 3.3050360679626465 running average of batch loss 3.3711266744704473, time 0.5143387317657471\n",
      "#Epoch 238 with total epochs 300 at step 0 loss: 3.284092426300049 running average of batch loss 3.284092426300049, time 0.5413806438446045\n",
      "#Epoch 238 with total epochs 300 at step 1 loss: 3.212052822113037 running average of batch loss 3.248072624206543, time 0.509361982345581\n",
      "#Epoch 238 with total epochs 300 at step 2 loss: 3.461033821105957 running average of batch loss 3.319059689839681, time 0.5283722877502441\n",
      "#Epoch 238 with total epochs 300 at step 3 loss: 3.0677835941314697 running average of batch loss 3.256240665912628, time 0.5283842086791992\n",
      "#Epoch 238 with total epochs 300 at step 4 loss: 3.1629605293273926 running average of batch loss 3.237584638595581, time 0.5193417072296143\n",
      "#Epoch 238 with total epochs 300 at step 5 loss: 3.303255319595337 running average of batch loss 3.2485297520955405, time 0.505333662033081\n",
      "#Epoch 238 with total epochs 300 at step 6 loss: 3.363901376724243 running average of batch loss 3.2650114127567837, time 0.49035048484802246\n",
      "#Epoch 238 with total epochs 300 at step 7 loss: 2.9619193077087402 running average of batch loss 3.227124899625778, time 0.49932289123535156\n",
      "#Epoch 238 with total epochs 300 at step 8 loss: 3.2047457695007324 running average of batch loss 3.224638329611884, time 0.49034762382507324\n",
      "#Epoch 238 with total epochs 300 at step 9 loss: 3.33168888092041 running average of batch loss 3.2353433847427366, time 0.4833192825317383\n",
      "#Epoch 238 with total epochs 300 at step 10 loss: 3.4894449710845947 running average of batch loss 3.258443528955633, time 0.513364315032959\n",
      "#Epoch 238 with total epochs 300 at step 11 loss: 2.9874000549316406 running average of batch loss 3.235856572786967, time 0.5073583126068115\n",
      "#Epoch 238 with total epochs 300 at step 12 loss: 3.1925885677337646 running average of batch loss 3.2325282647059512, time 0.5013253688812256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 238 with total epochs 300 at step 13 loss: 3.1993398666381836 running average of batch loss 3.230157664843968, time 0.5033292770385742\n",
      "#Epoch 238 with total epochs 300 at step 14 loss: 3.083993434906006 running average of batch loss 3.2204133828481036, time 0.5403549671173096\n",
      "#Epoch 238 with total epochs 300 at step 15 loss: 3.2035608291625977 running average of batch loss 3.2193600982427597, time 0.49234652519226074\n",
      "#Epoch 238 with total epochs 300 at step 16 loss: 3.230801582336426 running average of batch loss 3.2200331267188576, time 0.5073549747467041\n",
      "#Epoch 238 with total epochs 300 at step 17 loss: 2.8741798400878906 running average of batch loss 3.2008190552393594, time 0.4883239269256592\n",
      "#Epoch 238 with total epochs 300 at step 18 loss: 3.3831980228424072 running average of batch loss 3.210417948271099, time 0.5043594837188721\n",
      "#Epoch 238 with total epochs 300 at step 19 loss: 3.1519384384155273 running average of batch loss 3.2074939727783205, time 0.5313777923583984\n",
      "#Epoch 238 with total epochs 300 at step 20 loss: 3.389726161956787 running average of batch loss 3.216171696072533, time 0.5113615989685059\n",
      "#Epoch 239 with total epochs 300 at step 0 loss: 3.0572421550750732 running average of batch loss 3.0572421550750732, time 0.49332737922668457\n",
      "#Epoch 239 with total epochs 300 at step 1 loss: 3.367382049560547 running average of batch loss 3.21231210231781, time 0.516369104385376\n",
      "#Epoch 239 with total epochs 300 at step 2 loss: 3.0461606979370117 running average of batch loss 3.156928300857544, time 0.5063564777374268\n",
      "#Epoch 239 with total epochs 300 at step 3 loss: 3.664198637008667 running average of batch loss 3.2837458848953247, time 0.5233724117279053\n",
      "#Epoch 239 with total epochs 300 at step 4 loss: 3.507039785385132 running average of batch loss 3.328404664993286, time 0.519343376159668\n",
      "#Epoch 239 with total epochs 300 at step 5 loss: 3.40801739692688 running average of batch loss 3.3416734536488852, time 0.4883248805999756\n",
      "#Epoch 239 with total epochs 300 at step 6 loss: 3.454136848449707 running average of batch loss 3.357739652906145, time 0.4943239688873291\n",
      "#Epoch 239 with total epochs 300 at step 7 loss: 3.4321396350860596 running average of batch loss 3.3670396506786346, time 0.49935388565063477\n",
      "#Epoch 239 with total epochs 300 at step 8 loss: 3.5327963829040527 running average of batch loss 3.385457065370348, time 0.5033292770385742\n",
      "#Epoch 239 with total epochs 300 at step 9 loss: 3.1645305156707764 running average of batch loss 3.363364410400391, time 0.501356840133667\n",
      "#Epoch 239 with total epochs 300 at step 10 loss: 3.341296672821045 running average of batch loss 3.361358252438632, time 0.5033268928527832\n",
      "#Epoch 239 with total epochs 300 at step 11 loss: 3.2467591762542725 running average of batch loss 3.351808329423269, time 0.5173676013946533\n",
      "#Epoch 239 with total epochs 300 at step 12 loss: 3.4755971431732178 running average of batch loss 3.3613305458655725, time 0.4883460998535156\n",
      "#Epoch 239 with total epochs 300 at step 13 loss: 3.2495310306549072 running average of batch loss 3.3533448662076677, time 0.51837158203125\n",
      "#Epoch 239 with total epochs 300 at step 14 loss: 3.2745208740234375 running average of batch loss 3.3480899333953857, time 0.49034547805786133\n",
      "#Epoch 239 with total epochs 300 at step 15 loss: 3.305860757827759 running average of batch loss 3.345450609922409, time 0.5003249645233154\n",
      "#Epoch 239 with total epochs 300 at step 16 loss: 3.4316225051879883 running average of batch loss 3.3505195449380314, time 0.5373849868774414\n",
      "#Epoch 239 with total epochs 300 at step 17 loss: 3.6886982917785645 running average of batch loss 3.3693072530958386, time 0.49532318115234375\n",
      "#Epoch 239 with total epochs 300 at step 18 loss: 3.824800968170166 running average of batch loss 3.393280606520803, time 0.49732518196105957\n",
      "#Epoch 239 with total epochs 300 at step 19 loss: 3.0367987155914307 running average of batch loss 3.3754565119743347, time 0.48534440994262695\n",
      "#Epoch 239 with total epochs 300 at step 20 loss: 3.3322229385375977 running average of batch loss 3.373397770382109, time 0.4923248291015625\n",
      "#Epoch 240 with total epochs 300 at step 0 loss: 3.287360191345215 running average of batch loss 3.287360191345215, time 0.4983487129211426\n",
      "#Epoch 240 with total epochs 300 at step 1 loss: 3.2792556285858154 running average of batch loss 3.283307909965515, time 0.526374340057373\n",
      "#Epoch 240 with total epochs 300 at step 2 loss: 3.638274669647217 running average of batch loss 3.401630163192749, time 0.5023350715637207\n",
      "#Epoch 240 with total epochs 300 at step 3 loss: 3.138115406036377 running average of batch loss 3.335751473903656, time 0.49434781074523926\n",
      "#Epoch 240 with total epochs 300 at step 4 loss: 3.3280835151672363 running average of batch loss 3.334217882156372, time 0.523369312286377\n",
      "#Epoch 240 with total epochs 300 at step 5 loss: 3.1751022338867188 running average of batch loss 3.307698607444763, time 0.5223715305328369\n",
      "#Epoch 240 with total epochs 300 at step 6 loss: 3.4149675369262695 running average of batch loss 3.3230227402278354, time 0.4903261661529541\n",
      "#Epoch 240 with total epochs 300 at step 7 loss: 3.588714122772217 running average of batch loss 3.356234163045883, time 0.4873199462890625\n",
      "#Epoch 240 with total epochs 300 at step 8 loss: 3.387126922607422 running average of batch loss 3.359666691886054, time 0.5233724117279053\n",
      "#Epoch 240 with total epochs 300 at step 9 loss: 3.4331552982330322 running average of batch loss 3.367015552520752, time 0.5403614044189453\n",
      "#Epoch 240 with total epochs 300 at step 10 loss: 3.161487102508545 running average of batch loss 3.3483311479741875, time 0.4913501739501953\n",
      "#Epoch 240 with total epochs 300 at step 11 loss: 3.2036516666412354 running average of batch loss 3.336274524529775, time 0.4993295669555664\n",
      "#Epoch 240 with total epochs 300 at step 12 loss: 3.4471774101257324 running average of batch loss 3.344805515729464, time 0.49132442474365234\n",
      "#Epoch 240 with total epochs 300 at step 13 loss: 3.176966905593872 running average of batch loss 3.3328170435769215, time 0.49235010147094727\n",
      "#Epoch 240 with total epochs 300 at step 14 loss: 2.9773635864257812 running average of batch loss 3.3091201464335125, time 0.5113654136657715\n",
      "#Epoch 240 with total epochs 300 at step 15 loss: 3.188924551010132 running average of batch loss 3.301607921719551, time 0.5113613605499268\n",
      "#Epoch 240 with total epochs 300 at step 16 loss: 3.2428536415100098 running average of batch loss 3.2981517875895783, time 0.4873480796813965\n",
      "#Epoch 240 with total epochs 300 at step 17 loss: 3.279524803161621 running average of batch loss 3.2971169551213584, time 0.5023324489593506\n",
      "#Epoch 240 with total epochs 300 at step 18 loss: 3.2227623462677 running average of batch loss 3.2932035546553764, time 0.48834800720214844\n",
      "#Epoch 240 with total epochs 300 at step 19 loss: 3.3312196731567383 running average of batch loss 3.2951043605804444, time 0.49433183670043945\n",
      "#Epoch 240 with total epochs 300 at step 20 loss: 3.278979778289795 running average of batch loss 3.2943365233285085, time 0.5083308219909668\n",
      "avg difference between predicted and ground truth batch wise 5.318948212061609\n",
      "#Epoch 241 with total epochs 300 at step 0 loss: 3.4616775512695312 running average of batch loss 3.4616775512695312, time 0.5363821983337402\n",
      "#Epoch 241 with total epochs 300 at step 1 loss: 3.0152554512023926 running average of batch loss 3.238466501235962, time 0.5033283233642578\n",
      "#Epoch 241 with total epochs 300 at step 2 loss: 3.3977229595184326 running average of batch loss 3.2915519873301187, time 0.496351957321167\n",
      "#Epoch 241 with total epochs 300 at step 3 loss: 3.228106737136841 running average of batch loss 3.2756906747817993, time 0.5143651962280273\n",
      "#Epoch 241 with total epochs 300 at step 4 loss: 3.468738317489624 running average of batch loss 3.314300203323364, time 0.5333812236785889\n",
      "#Epoch 241 with total epochs 300 at step 5 loss: 3.622169256210327 running average of batch loss 3.365611712137858, time 0.503328800201416\n",
      "#Epoch 241 with total epochs 300 at step 6 loss: 3.440192222595215 running average of batch loss 3.3762660707746233, time 0.4993271827697754\n",
      "#Epoch 241 with total epochs 300 at step 7 loss: 3.295816659927368 running average of batch loss 3.3662098944187164, time 0.5543980598449707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 241 with total epochs 300 at step 8 loss: 3.219334125518799 running average of batch loss 3.349890364540948, time 0.5093367099761963\n",
      "#Epoch 241 with total epochs 300 at step 9 loss: 3.4823949337005615 running average of batch loss 3.363140821456909, time 0.5143635272979736\n",
      "#Epoch 241 with total epochs 300 at step 10 loss: 3.389357089996338 running average of batch loss 3.3655241185968574, time 0.4973270893096924\n",
      "#Epoch 241 with total epochs 300 at step 11 loss: 3.315659523010254 running average of batch loss 3.361368735631307, time 0.5033316612243652\n",
      "#Epoch 241 with total epochs 300 at step 12 loss: 3.3680472373962402 running average of batch loss 3.3618824665363016, time 0.5153677463531494\n",
      "#Epoch 241 with total epochs 300 at step 13 loss: 3.3909695148468018 running average of batch loss 3.3639601128441945, time 0.4923210144042969\n",
      "#Epoch 241 with total epochs 300 at step 14 loss: 3.3101563453674316 running average of batch loss 3.3603731950124103, time 0.5103404521942139\n",
      "#Epoch 241 with total epochs 300 at step 15 loss: 3.081883192062378 running average of batch loss 3.3429675698280334, time 0.5123653411865234\n",
      "#Epoch 241 with total epochs 300 at step 16 loss: 3.1631200313568115 running average of batch loss 3.332388302859138, time 0.49632811546325684\n",
      "#Epoch 241 with total epochs 300 at step 17 loss: 2.932593584060669 running average of batch loss 3.310177485148112, time 0.4893474578857422\n",
      "#Epoch 241 with total epochs 300 at step 18 loss: 3.188485860824585 running average of batch loss 3.3037726628152946, time 0.498354434967041\n",
      "#Epoch 241 with total epochs 300 at step 19 loss: 3.2552154064178467 running average of batch loss 3.301344799995422, time 0.4873220920562744\n",
      "#Epoch 241 with total epochs 300 at step 20 loss: 3.345970630645752 running average of batch loss 3.3034698395502, time 0.5053563117980957\n",
      "#Epoch 242 with total epochs 300 at step 0 loss: 3.2034966945648193 running average of batch loss 3.2034966945648193, time 0.5093374252319336\n",
      "#Epoch 242 with total epochs 300 at step 1 loss: 3.226430654525757 running average of batch loss 3.214963674545288, time 0.5113651752471924\n",
      "#Epoch 242 with total epochs 300 at step 2 loss: 3.26115083694458 running average of batch loss 3.2303593953450522, time 0.5023281574249268\n",
      "#Epoch 242 with total epochs 300 at step 3 loss: 3.0404767990112305 running average of batch loss 3.1828887462615967, time 0.4913485050201416\n",
      "#Epoch 242 with total epochs 300 at step 4 loss: 3.4045588970184326 running average of batch loss 3.227222776412964, time 0.5403835773468018\n",
      "#Epoch 242 with total epochs 300 at step 5 loss: 3.7813663482666016 running average of batch loss 3.3195800383885703, time 0.49135422706604004\n",
      "#Epoch 242 with total epochs 300 at step 6 loss: 3.3868508338928223 running average of batch loss 3.3291901520320346, time 0.5613701343536377\n",
      "#Epoch 242 with total epochs 300 at step 7 loss: 3.254422664642334 running average of batch loss 3.319844216108322, time 0.48834824562072754\n",
      "#Epoch 242 with total epochs 300 at step 8 loss: 3.427231788635254 running average of batch loss 3.3317761686113148, time 0.5073349475860596\n",
      "#Epoch 242 with total epochs 300 at step 9 loss: 3.3901073932647705 running average of batch loss 3.33760929107666, time 0.5063352584838867\n",
      "#Epoch 242 with total epochs 300 at step 10 loss: 3.493800163269043 running average of batch loss 3.3518084612759678, time 0.5053350925445557\n",
      "#Epoch 242 with total epochs 300 at step 11 loss: 2.9123806953430176 running average of batch loss 3.315189480781555, time 0.5043299198150635\n",
      "#Epoch 242 with total epochs 300 at step 12 loss: 3.362738609313965 running average of batch loss 3.318847106053279, time 0.5093629360198975\n",
      "#Epoch 242 with total epochs 300 at step 13 loss: 3.5783743858337402 running average of batch loss 3.3373847688947404, time 0.517366886138916\n",
      "#Epoch 242 with total epochs 300 at step 14 loss: 3.1590993404388428 running average of batch loss 3.3254990736643473, time 0.5183699131011963\n",
      "#Epoch 242 with total epochs 300 at step 15 loss: 3.2703187465667725 running average of batch loss 3.322050303220749, time 0.4993259906768799\n",
      "#Epoch 242 with total epochs 300 at step 16 loss: 3.5254034996032715 running average of batch loss 3.3340122559491325, time 0.5293529033660889\n",
      "#Epoch 242 with total epochs 300 at step 17 loss: 3.6707334518432617 running average of batch loss 3.352718989054362, time 0.5043289661407471\n",
      "#Epoch 242 with total epochs 300 at step 18 loss: 3.417996883392334 running average of batch loss 3.356154667703729, time 0.49234986305236816\n",
      "#Epoch 242 with total epochs 300 at step 19 loss: 3.2629013061523438 running average of batch loss 3.35149199962616, time 0.5083630084991455\n",
      "#Epoch 242 with total epochs 300 at step 20 loss: 3.264981746673584 running average of batch loss 3.347372463771275, time 0.5023255348205566\n",
      "#Epoch 243 with total epochs 300 at step 0 loss: 3.619805097579956 running average of batch loss 3.619805097579956, time 0.48634767532348633\n",
      "#Epoch 243 with total epochs 300 at step 1 loss: 3.007607936859131 running average of batch loss 3.3137065172195435, time 0.4963254928588867\n",
      "#Epoch 243 with total epochs 300 at step 2 loss: 3.458944082260132 running average of batch loss 3.3621190388997397, time 0.535351037979126\n",
      "#Epoch 243 with total epochs 300 at step 3 loss: 3.0639426708221436 running average of batch loss 3.2875749468803406, time 0.5283782482147217\n",
      "#Epoch 243 with total epochs 300 at step 4 loss: 3.1182777881622314 running average of batch loss 3.2537155151367188, time 0.4993269443511963\n",
      "#Epoch 243 with total epochs 300 at step 5 loss: 3.4728267192840576 running average of batch loss 3.2902340491612754, time 0.526374340057373\n",
      "#Epoch 243 with total epochs 300 at step 6 loss: 3.3802928924560547 running average of batch loss 3.3030995982033864, time 0.506331205368042\n",
      "#Epoch 243 with total epochs 300 at step 7 loss: 3.0795445442199707 running average of batch loss 3.2751552164554596, time 0.5213711261749268\n",
      "#Epoch 243 with total epochs 300 at step 8 loss: 3.146040916442871 running average of batch loss 3.2608091831207275, time 0.48932313919067383\n",
      "#Epoch 243 with total epochs 300 at step 9 loss: 2.757877826690674 running average of batch loss 3.2105160474777223, time 0.5073349475860596\n",
      "#Epoch 243 with total epochs 300 at step 10 loss: 3.1567811965942383 running average of batch loss 3.205631061033769, time 0.5033559799194336\n",
      "#Epoch 243 with total epochs 300 at step 11 loss: 3.18115496635437 running average of batch loss 3.2035913864771524, time 0.5113632678985596\n",
      "#Epoch 243 with total epochs 300 at step 12 loss: 3.5456743240356445 running average of batch loss 3.2299054585970364, time 0.4883244037628174\n",
      "#Epoch 243 with total epochs 300 at step 13 loss: 3.2358546257019043 running average of batch loss 3.230330399104527, time 0.4883232116699219\n",
      "#Epoch 243 with total epochs 300 at step 14 loss: 3.484835386276245 running average of batch loss 3.2472973982493083, time 0.48832249641418457\n",
      "#Epoch 243 with total epochs 300 at step 15 loss: 3.416951894760132 running average of batch loss 3.2579008042812347, time 0.5023584365844727\n",
      "#Epoch 243 with total epochs 300 at step 16 loss: 3.2600224018096924 running average of batch loss 3.2580256041358497, time 0.5033276081085205\n",
      "#Epoch 243 with total epochs 300 at step 17 loss: 3.4026265144348145 running average of batch loss 3.266058988041348, time 0.520366907119751\n",
      "#Epoch 243 with total epochs 300 at step 18 loss: 3.3353168964385986 running average of batch loss 3.2697041411148873, time 0.5273752212524414\n",
      "#Epoch 243 with total epochs 300 at step 19 loss: 2.83687424659729 running average of batch loss 3.2480626463890077, time 0.4903299808502197\n",
      "#Epoch 243 with total epochs 300 at step 20 loss: 3.777568817138672 running average of batch loss 3.2732772259485152, time 0.5193431377410889\n",
      "#Epoch 244 with total epochs 300 at step 0 loss: 3.646381139755249 running average of batch loss 3.646381139755249, time 0.4923238754272461\n",
      "#Epoch 244 with total epochs 300 at step 1 loss: 3.2134780883789062 running average of batch loss 3.4299296140670776, time 0.5203704833984375\n",
      "#Epoch 244 with total epochs 300 at step 2 loss: 3.4143993854522705 running average of batch loss 3.424752871195475, time 0.486346960067749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 244 with total epochs 300 at step 3 loss: 3.4985110759735107 running average of batch loss 3.443192422389984, time 0.4953267574310303\n",
      "#Epoch 244 with total epochs 300 at step 4 loss: 3.360335111618042 running average of batch loss 3.4266209602355957, time 0.5003621578216553\n",
      "#Epoch 244 with total epochs 300 at step 5 loss: 3.244183301925659 running average of batch loss 3.3962146838506064, time 0.5093345642089844\n",
      "#Epoch 244 with total epochs 300 at step 6 loss: 3.253525495529175 running average of batch loss 3.375830514090402, time 0.49832701683044434\n",
      "#Epoch 244 with total epochs 300 at step 7 loss: 3.69817852973938 running average of batch loss 3.416124016046524, time 0.5153391361236572\n",
      "#Epoch 244 with total epochs 300 at step 8 loss: 3.500361919403076 running average of batch loss 3.425483783086141, time 0.49532532691955566\n",
      "#Epoch 244 with total epochs 300 at step 9 loss: 2.972088575363159 running average of batch loss 3.3801442623138427, time 0.512336015701294\n",
      "#Epoch 244 with total epochs 300 at step 10 loss: 3.1185178756713867 running average of batch loss 3.3563600453463467, time 0.49832868576049805\n",
      "#Epoch 244 with total epochs 300 at step 11 loss: 3.262744903564453 running average of batch loss 3.348558783531189, time 0.5013277530670166\n",
      "#Epoch 244 with total epochs 300 at step 12 loss: 3.2179033756256104 running average of batch loss 3.338508367538452, time 0.5023272037506104\n",
      "#Epoch 244 with total epochs 300 at step 13 loss: 3.5918869972229004 running average of batch loss 3.3566068410873413, time 0.49832797050476074\n",
      "#Epoch 244 with total epochs 300 at step 14 loss: 3.269482374191284 running average of batch loss 3.3507985432942706, time 0.5233745574951172\n",
      "#Epoch 244 with total epochs 300 at step 15 loss: 3.3463988304138184 running average of batch loss 3.3505235612392426, time 0.5423800945281982\n",
      "#Epoch 244 with total epochs 300 at step 16 loss: 3.069258451461792 running average of batch loss 3.3339785547817455, time 0.5143654346466064\n",
      "#Epoch 244 with total epochs 300 at step 17 loss: 3.264937400817871 running average of batch loss 3.330142935117086, time 0.54038405418396\n",
      "#Epoch 244 with total epochs 300 at step 18 loss: 3.381115674972534 running average of batch loss 3.3328257108989514, time 0.48331761360168457\n",
      "#Epoch 244 with total epochs 300 at step 19 loss: 3.1456358432769775 running average of batch loss 3.323466217517853, time 0.5213406085968018\n",
      "#Epoch 244 with total epochs 300 at step 20 loss: 3.4766881465911865 running average of batch loss 3.330762499854678, time 0.49034881591796875\n",
      "#Epoch 245 with total epochs 300 at step 0 loss: 3.2518749237060547 running average of batch loss 3.2518749237060547, time 0.4863455295562744\n",
      "#Epoch 245 with total epochs 300 at step 1 loss: 3.2380034923553467 running average of batch loss 3.2449392080307007, time 0.5073602199554443\n",
      "#Epoch 245 with total epochs 300 at step 2 loss: 3.413914680480957 running average of batch loss 3.3012643655141196, time 0.4893472194671631\n",
      "#Epoch 245 with total epochs 300 at step 3 loss: 3.0826256275177 running average of batch loss 3.2466046810150146, time 0.4893476963043213\n",
      "#Epoch 245 with total epochs 300 at step 4 loss: 3.6283206939697266 running average of batch loss 3.322947883605957, time 0.5083613395690918\n",
      "#Epoch 245 with total epochs 300 at step 5 loss: 3.119682788848877 running average of batch loss 3.2890703678131104, time 0.5133638381958008\n",
      "#Epoch 245 with total epochs 300 at step 6 loss: 3.1033403873443604 running average of batch loss 3.262537513460432, time 0.4983539581298828\n",
      "#Epoch 245 with total epochs 300 at step 7 loss: 3.409348487854004 running average of batch loss 3.2808888852596283, time 0.5073614120483398\n",
      "#Epoch 245 with total epochs 300 at step 8 loss: 3.017947196960449 running average of batch loss 3.251673142115275, time 0.5023295879364014\n",
      "#Epoch 245 with total epochs 300 at step 9 loss: 3.364859104156494 running average of batch loss 3.262991738319397, time 0.49935436248779297\n",
      "#Epoch 245 with total epochs 300 at step 10 loss: 3.312861442565918 running average of batch loss 3.2675253477963535, time 0.4863448143005371\n",
      "#Epoch 245 with total epochs 300 at step 11 loss: 3.1678662300109863 running average of batch loss 3.2592204213142395, time 0.4943506717681885\n",
      "#Epoch 245 with total epochs 300 at step 12 loss: 3.053748369216919 running average of batch loss 3.243414878845215, time 0.5023577213287354\n",
      "#Epoch 245 with total epochs 300 at step 13 loss: 3.129875421524048 running average of batch loss 3.2353049176079884, time 0.5043573379516602\n",
      "#Epoch 245 with total epochs 300 at step 14 loss: 3.709240198135376 running average of batch loss 3.2669006029764813, time 0.5043563842773438\n",
      "#Epoch 245 with total epochs 300 at step 15 loss: 3.662172555923462 running average of batch loss 3.2916051000356674, time 0.5113632678985596\n",
      "#Epoch 245 with total epochs 300 at step 16 loss: 3.4422428607940674 running average of batch loss 3.3004661447861614, time 0.49935460090637207\n",
      "#Epoch 245 with total epochs 300 at step 17 loss: 3.342562675476074 running average of batch loss 3.3028048409356012, time 0.504356861114502\n",
      "#Epoch 245 with total epochs 300 at step 18 loss: 3.3224196434020996 running average of batch loss 3.303837198960154, time 0.4983561038970947\n",
      "#Epoch 245 with total epochs 300 at step 19 loss: 3.1135199069976807 running average of batch loss 3.29432133436203, time 0.5123636722564697\n",
      "#Epoch 245 with total epochs 300 at step 20 loss: 3.1724917888641357 running average of batch loss 3.288519927433559, time 0.5243444442749023\n",
      "#Epoch 246 with total epochs 300 at step 0 loss: 3.232327938079834 running average of batch loss 3.232327938079834, time 0.5053303241729736\n",
      "#Epoch 246 with total epochs 300 at step 1 loss: 3.390028238296509 running average of batch loss 3.3111780881881714, time 0.48232293128967285\n",
      "#Epoch 246 with total epochs 300 at step 2 loss: 3.4144198894500732 running average of batch loss 3.3455920219421387, time 0.49832677841186523\n",
      "#Epoch 246 with total epochs 300 at step 3 loss: 3.1228764057159424 running average of batch loss 3.2899131178855896, time 0.5053319931030273\n",
      "#Epoch 246 with total epochs 300 at step 4 loss: 3.194126605987549 running average of batch loss 3.2707558155059813, time 0.501326322555542\n",
      "#Epoch 246 with total epochs 300 at step 5 loss: 3.1419053077697754 running average of batch loss 3.2492807308832803, time 0.4933488368988037\n",
      "#Epoch 246 with total epochs 300 at step 6 loss: 3.14635968208313 running average of batch loss 3.2345777239118303, time 0.528374433517456\n",
      "#Epoch 246 with total epochs 300 at step 7 loss: 3.1915409564971924 running average of batch loss 3.2291981279850006, time 0.48631930351257324\n",
      "#Epoch 246 with total epochs 300 at step 8 loss: 3.244819402694702 running average of batch loss 3.2309338251749673, time 0.48732852935791016\n",
      "#Epoch 246 with total epochs 300 at step 9 loss: 3.4295530319213867 running average of batch loss 3.2507957458496093, time 0.5093626976013184\n",
      "#Epoch 246 with total epochs 300 at step 10 loss: 3.0782132148742676 running average of batch loss 3.235106424851851, time 0.5283472537994385\n",
      "#Epoch 246 with total epochs 300 at step 11 loss: 3.2312889099121094 running average of batch loss 3.2347882986068726, time 0.5073602199554443\n",
      "#Epoch 246 with total epochs 300 at step 12 loss: 3.345324993133545 running average of batch loss 3.2432911212627706, time 0.5113351345062256\n",
      "#Epoch 246 with total epochs 300 at step 13 loss: 3.34745192527771 running average of batch loss 3.250731178692409, time 0.528374195098877\n",
      "#Epoch 246 with total epochs 300 at step 14 loss: 3.787999153137207 running average of batch loss 3.2865490436553957, time 0.5253739356994629\n",
      "#Epoch 246 with total epochs 300 at step 15 loss: 3.152783155441284 running average of batch loss 3.2781886756420135, time 0.4963526725769043\n",
      "#Epoch 246 with total epochs 300 at step 16 loss: 3.4239439964294434 running average of batch loss 3.2867625180412743, time 0.5183672904968262\n",
      "#Epoch 246 with total epochs 300 at step 17 loss: 3.573245048522949 running average of batch loss 3.302678214179145, time 0.4883460998535156\n",
      "#Epoch 246 with total epochs 300 at step 18 loss: 3.114903450012207 running average of batch loss 3.292795331854569, time 0.48632264137268066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 246 with total epochs 300 at step 19 loss: 3.202181339263916 running average of batch loss 3.2882646322250366, time 0.5083358287811279\n",
      "#Epoch 246 with total epochs 300 at step 20 loss: 3.057325601577759 running average of batch loss 3.2772675355275473, time 0.5033576488494873\n",
      "#Epoch 247 with total epochs 300 at step 0 loss: 2.9917666912078857 running average of batch loss 2.9917666912078857, time 0.4993276596069336\n",
      "#Epoch 247 with total epochs 300 at step 1 loss: 3.3651466369628906 running average of batch loss 3.178456664085388, time 0.48932385444641113\n",
      "#Epoch 247 with total epochs 300 at step 2 loss: 3.2076218128204346 running average of batch loss 3.188178380330404, time 0.4893486499786377\n",
      "#Epoch 247 with total epochs 300 at step 3 loss: 3.6539316177368164 running average of batch loss 3.304616689682007, time 0.5093350410461426\n",
      "#Epoch 247 with total epochs 300 at step 4 loss: 3.1281378269195557 running average of batch loss 3.269320917129517, time 0.4903218746185303\n",
      "#Epoch 247 with total epochs 300 at step 5 loss: 3.185917377471924 running average of batch loss 3.2554203271865845, time 0.5233721733093262\n",
      "#Epoch 247 with total epochs 300 at step 6 loss: 3.3282570838928223 running average of batch loss 3.2658255781446184, time 0.5023307800292969\n",
      "#Epoch 247 with total epochs 300 at step 7 loss: 3.251847743988037 running average of batch loss 3.2640783488750458, time 0.5283772945404053\n",
      "#Epoch 247 with total epochs 300 at step 8 loss: 2.842864990234375 running average of batch loss 3.217276864581638, time 0.49332547187805176\n",
      "#Epoch 247 with total epochs 300 at step 9 loss: 3.5282106399536133 running average of batch loss 3.2483702421188356, time 0.5393562316894531\n",
      "#Epoch 247 with total epochs 300 at step 10 loss: 3.2268481254577637 running average of batch loss 3.246413686058738, time 0.4863436222076416\n",
      "#Epoch 247 with total epochs 300 at step 11 loss: 3.0862278938293457 running average of batch loss 3.233064870039622, time 0.5063343048095703\n",
      "#Epoch 247 with total epochs 300 at step 12 loss: 3.344590425491333 running average of batch loss 3.2416437589205227, time 0.5103335380554199\n",
      "#Epoch 247 with total epochs 300 at step 13 loss: 3.6332297325134277 running average of batch loss 3.26961418560573, time 0.5153367519378662\n",
      "#Epoch 247 with total epochs 300 at step 14 loss: 3.1300129890441895 running average of batch loss 3.2603074391682942, time 0.49535369873046875\n",
      "#Epoch 247 with total epochs 300 at step 15 loss: 2.9103102684020996 running average of batch loss 3.238432615995407, time 0.5083351135253906\n",
      "#Epoch 247 with total epochs 300 at step 16 loss: 3.2475876808166504 running average of batch loss 3.2389711492201863, time 0.4883263111114502\n",
      "#Epoch 247 with total epochs 300 at step 17 loss: 3.0966854095458984 running average of batch loss 3.2310663859049478, time 0.5073375701904297\n",
      "#Epoch 247 with total epochs 300 at step 18 loss: 3.2076447010040283 running average of batch loss 3.229833665647005, time 0.48534321784973145\n",
      "#Epoch 247 with total epochs 300 at step 19 loss: 3.133363723754883 running average of batch loss 3.225010168552399, time 0.4873473644256592\n",
      "#Epoch 247 with total epochs 300 at step 20 loss: 3.129988670349121 running average of batch loss 3.2204853353046237, time 0.4983541965484619\n",
      "#Epoch 248 with total epochs 300 at step 0 loss: 3.140285015106201 running average of batch loss 3.140285015106201, time 0.4993293285369873\n",
      "#Epoch 248 with total epochs 300 at step 1 loss: 3.2798104286193848 running average of batch loss 3.210047721862793, time 0.501328706741333\n",
      "#Epoch 248 with total epochs 300 at step 2 loss: 3.1323490142822266 running average of batch loss 3.184148152669271, time 0.49034762382507324\n",
      "#Epoch 248 with total epochs 300 at step 3 loss: 3.2213096618652344 running average of batch loss 3.1934385299682617, time 0.5083634853363037\n",
      "#Epoch 248 with total epochs 300 at step 4 loss: 3.2446930408477783 running average of batch loss 3.203689432144165, time 0.5153384208679199\n",
      "#Epoch 248 with total epochs 300 at step 5 loss: 3.16965913772583 running average of batch loss 3.198017716407776, time 0.5023672580718994\n",
      "#Epoch 248 with total epochs 300 at step 6 loss: 3.483218193054199 running average of batch loss 3.2387606416429793, time 0.4963243007659912\n",
      "#Epoch 248 with total epochs 300 at step 7 loss: 3.2191643714904785 running average of batch loss 3.2363111078739166, time 0.5033550262451172\n",
      "#Epoch 248 with total epochs 300 at step 8 loss: 3.162172317504883 running average of batch loss 3.2280734644995794, time 0.4863450527191162\n",
      "#Epoch 248 with total epochs 300 at step 9 loss: 3.4447453022003174 running average of batch loss 3.249740648269653, time 0.5033607482910156\n",
      "#Epoch 248 with total epochs 300 at step 10 loss: 3.224332809448242 running average of batch loss 3.247430844740434, time 0.5293760299682617\n",
      "#Epoch 248 with total epochs 300 at step 11 loss: 3.0183193683624268 running average of batch loss 3.2283382217089334, time 0.49932360649108887\n",
      "#Epoch 248 with total epochs 300 at step 12 loss: 3.5303380489349365 running average of batch loss 3.2515689776493955, time 0.5203707218170166\n",
      "#Epoch 248 with total epochs 300 at step 13 loss: 3.499539852142334 running average of batch loss 3.2692811829703197, time 0.5153675079345703\n",
      "#Epoch 248 with total epochs 300 at step 14 loss: 2.9428486824035645 running average of batch loss 3.247519016265869, time 0.5063564777374268\n",
      "#Epoch 248 with total epochs 300 at step 15 loss: 3.2326762676239014 running average of batch loss 3.246591344475746, time 0.5203695297241211\n",
      "#Epoch 248 with total epochs 300 at step 16 loss: 2.9476118087768555 running average of batch loss 3.229004312964047, time 0.4943509101867676\n",
      "#Epoch 248 with total epochs 300 at step 17 loss: 3.1526741981506348 running average of batch loss 3.2247637510299683, time 0.5073609352111816\n",
      "#Epoch 248 with total epochs 300 at step 18 loss: 3.055851459503174 running average of batch loss 3.2158736304232947, time 0.5273745059967041\n",
      "#Epoch 248 with total epochs 300 at step 19 loss: 3.3403310775756836 running average of batch loss 3.2220965027809143, time 0.4933512210845947\n",
      "#Epoch 248 with total epochs 300 at step 20 loss: 3.234135627746582 running average of batch loss 3.222669794445946, time 0.4863424301147461\n",
      "#Epoch 249 with total epochs 300 at step 0 loss: 3.092909574508667 running average of batch loss 3.092909574508667, time 0.5183680057525635\n",
      "#Epoch 249 with total epochs 300 at step 1 loss: 3.3655800819396973 running average of batch loss 3.229244828224182, time 0.5123639106750488\n",
      "#Epoch 249 with total epochs 300 at step 2 loss: 3.105581760406494 running average of batch loss 3.188023805618286, time 0.5253746509552002\n",
      "#Epoch 249 with total epochs 300 at step 3 loss: 3.811107635498047 running average of batch loss 3.3437947630882263, time 0.5073635578155518\n",
      "#Epoch 249 with total epochs 300 at step 4 loss: 3.3691766262054443 running average of batch loss 3.34887113571167, time 0.5143642425537109\n",
      "#Epoch 249 with total epochs 300 at step 5 loss: 3.2646470069885254 running average of batch loss 3.334833780924479, time 0.502356767654419\n",
      "#Epoch 249 with total epochs 300 at step 6 loss: 3.456638813018799 running average of batch loss 3.352234499795096, time 0.4843454360961914\n",
      "#Epoch 249 with total epochs 300 at step 7 loss: 3.2335827350616455 running average of batch loss 3.337403029203415, time 0.5043578147888184\n",
      "#Epoch 249 with total epochs 300 at step 8 loss: 3.414351463317871 running average of batch loss 3.345952855216132, time 0.5073604583740234\n",
      "#Epoch 249 with total epochs 300 at step 9 loss: 3.271439552307129 running average of batch loss 3.338501524925232, time 0.5003550052642822\n",
      "#Epoch 249 with total epochs 300 at step 10 loss: 3.2037830352783203 running average of batch loss 3.3262543895027856, time 0.507361888885498\n",
      "#Epoch 249 with total epochs 300 at step 11 loss: 3.433603525161743 running average of batch loss 3.3352001508076987, time 0.4953267574310303\n",
      "#Epoch 249 with total epochs 300 at step 12 loss: 3.085237979888916 running average of batch loss 3.3159722915062537, time 0.5083637237548828\n",
      "#Epoch 249 with total epochs 300 at step 13 loss: 3.0769670009613037 running average of batch loss 3.2989004850387573, time 0.5403556823730469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 249 with total epochs 300 at step 14 loss: 3.3218390941619873 running average of batch loss 3.3004297256469726, time 0.53037428855896\n",
      "#Epoch 249 with total epochs 300 at step 15 loss: 3.168593645095825 running average of batch loss 3.292189970612526, time 0.4973282814025879\n",
      "#Epoch 249 with total epochs 300 at step 16 loss: 3.4344115257263184 running average of batch loss 3.300555944442749, time 0.5223472118377686\n",
      "#Epoch 249 with total epochs 300 at step 17 loss: 3.189607620239258 running average of batch loss 3.294392148653666, time 0.5183403491973877\n",
      "#Epoch 249 with total epochs 300 at step 18 loss: 3.0388665199279785 running average of batch loss 3.280943431352314, time 0.5483865737915039\n",
      "#Epoch 249 with total epochs 300 at step 19 loss: 3.457733392715454 running average of batch loss 3.289782929420471, time 0.5263500213623047\n",
      "#Epoch 249 with total epochs 300 at step 20 loss: 3.201864719390869 running average of batch loss 3.28559634799049, time 0.49234724044799805\n",
      "#Epoch 250 with total epochs 300 at step 0 loss: 3.3351752758026123 running average of batch loss 3.3351752758026123, time 0.4973266124725342\n",
      "#Epoch 250 with total epochs 300 at step 1 loss: 3.3545398712158203 running average of batch loss 3.3448575735092163, time 0.5023274421691895\n",
      "#Epoch 250 with total epochs 300 at step 2 loss: 3.3561179637908936 running average of batch loss 3.348611036936442, time 0.5273778438568115\n",
      "#Epoch 250 with total epochs 300 at step 3 loss: 3.5728516578674316 running average of batch loss 3.4046711921691895, time 0.4953458309173584\n",
      "#Epoch 250 with total epochs 300 at step 4 loss: 3.1568243503570557 running average of batch loss 3.3551018238067627, time 0.5013556480407715\n",
      "#Epoch 250 with total epochs 300 at step 5 loss: 3.2567713260650635 running average of batch loss 3.3387134075164795, time 0.4883413314819336\n",
      "#Epoch 250 with total epochs 300 at step 6 loss: 3.037548780441284 running average of batch loss 3.29568988936288, time 0.5013604164123535\n",
      "#Epoch 250 with total epochs 300 at step 7 loss: 3.5033884048461914 running average of batch loss 3.321652203798294, time 0.5003268718719482\n",
      "#Epoch 250 with total epochs 300 at step 8 loss: 3.126134157180786 running average of batch loss 3.299927976396349, time 0.5253744125366211\n",
      "#Epoch 250 with total epochs 300 at step 9 loss: 3.455261707305908 running average of batch loss 3.315461349487305, time 0.5063571929931641\n",
      "#Epoch 250 with total epochs 300 at step 10 loss: 2.889901876449585 running average of batch loss 3.276774124665694, time 0.5323522090911865\n",
      "#Epoch 250 with total epochs 300 at step 11 loss: 3.2743003368377686 running average of batch loss 3.276567975680033, time 0.5033555030822754\n",
      "#Epoch 250 with total epochs 300 at step 12 loss: 3.166576862335205 running average of batch loss 3.2681071208073544, time 0.502356767654419\n",
      "#Epoch 250 with total epochs 300 at step 13 loss: 3.168647050857544 running average of batch loss 3.2610028300966536, time 0.49935030937194824\n",
      "#Epoch 250 with total epochs 300 at step 14 loss: 3.3666610717773438 running average of batch loss 3.2680467128753663, time 0.5073564052581787\n",
      "#Epoch 250 with total epochs 300 at step 15 loss: 3.101015329360962 running average of batch loss 3.257607251405716, time 0.5143661499023438\n",
      "#Epoch 250 with total epochs 300 at step 16 loss: 3.3663387298583984 running average of batch loss 3.2640032207264618, time 0.5073602199554443\n",
      "#Epoch 250 with total epochs 300 at step 17 loss: 3.0497875213623047 running average of batch loss 3.252102348539564, time 0.4973301887512207\n",
      "#Epoch 250 with total epochs 300 at step 18 loss: 2.943676710128784 running average of batch loss 3.235869420202155, time 0.48632335662841797\n",
      "#Epoch 250 with total epochs 300 at step 19 loss: 2.920102119445801 running average of batch loss 3.220081055164337, time 0.5113606452941895\n",
      "#Epoch 250 with total epochs 300 at step 20 loss: 3.0470762252807617 running average of batch loss 3.211842729931786, time 0.5383830070495605\n",
      "#Epoch 251 with total epochs 300 at step 0 loss: 3.1569788455963135 running average of batch loss 3.1569788455963135, time 0.4893460273742676\n",
      "#Epoch 251 with total epochs 300 at step 1 loss: 3.098788261413574 running average of batch loss 3.127883553504944, time 0.5053586959838867\n",
      "#Epoch 251 with total epochs 300 at step 2 loss: 3.5104682445526123 running average of batch loss 3.2554117838541665, time 0.5123639106750488\n",
      "#Epoch 251 with total epochs 300 at step 3 loss: 3.551833152770996 running average of batch loss 3.329517126083374, time 0.4883255958557129\n",
      "#Epoch 251 with total epochs 300 at step 4 loss: 3.1976122856140137 running average of batch loss 3.3031361579895018, time 0.5023586750030518\n",
      "#Epoch 251 with total epochs 300 at step 5 loss: 3.07293701171875 running average of batch loss 3.2647696336110434, time 0.5103247165679932\n",
      "#Epoch 251 with total epochs 300 at step 6 loss: 3.2750492095947266 running average of batch loss 3.2662381444658553, time 0.5083348751068115\n",
      "#Epoch 251 with total epochs 300 at step 7 loss: 3.4700429439544678 running average of batch loss 3.2917137444019318, time 0.4993252754211426\n",
      "#Epoch 251 with total epochs 300 at step 8 loss: 3.3161911964416504 running average of batch loss 3.2944334612952337, time 0.4873480796813965\n",
      "#Epoch 251 with total epochs 300 at step 9 loss: 3.4438157081604004 running average of batch loss 3.3093716859817506, time 0.5373780727386475\n",
      "#Epoch 251 with total epochs 300 at step 10 loss: 3.6928367614746094 running average of batch loss 3.3442321473901924, time 0.505359411239624\n",
      "#Epoch 251 with total epochs 300 at step 11 loss: 3.1576125621795654 running average of batch loss 3.3286805152893066, time 0.49735331535339355\n",
      "#Epoch 251 with total epochs 300 at step 12 loss: 3.5381717681884766 running average of batch loss 3.3447952270507812, time 0.5023596286773682\n",
      "#Epoch 251 with total epochs 300 at step 13 loss: 3.204586982727051 running average of batch loss 3.334780352456229, time 0.5083374977111816\n",
      "#Epoch 251 with total epochs 300 at step 14 loss: 3.253126621246338 running average of batch loss 3.3293367703755696, time 0.5073578357696533\n",
      "#Epoch 251 with total epochs 300 at step 15 loss: 3.397878646850586 running average of batch loss 3.333620637655258, time 0.5073626041412354\n",
      "#Epoch 251 with total epochs 300 at step 16 loss: 3.6013760566711426 running average of batch loss 3.3493709564208984, time 0.5103318691253662\n",
      "#Epoch 251 with total epochs 300 at step 17 loss: 3.5356924533843994 running average of batch loss 3.3597221506966486, time 0.5143675804138184\n",
      "#Epoch 251 with total epochs 300 at step 18 loss: 3.1295461654663086 running average of batch loss 3.3476076251582096, time 0.5073585510253906\n",
      "#Epoch 251 with total epochs 300 at step 19 loss: 3.4548590183258057 running average of batch loss 3.3529701948165895, time 0.48834872245788574\n",
      "#Epoch 251 with total epochs 300 at step 20 loss: 3.2435131072998047 running average of batch loss 3.347757952553885, time 0.4993283748626709\n",
      "#Epoch 252 with total epochs 300 at step 0 loss: 3.592562437057495 running average of batch loss 3.592562437057495, time 0.4873464107513428\n",
      "#Epoch 252 with total epochs 300 at step 1 loss: 3.261420726776123 running average of batch loss 3.426991581916809, time 0.491351842880249\n",
      "#Epoch 252 with total epochs 300 at step 2 loss: 3.405123472213745 running average of batch loss 3.4197022120157876, time 0.5053293704986572\n",
      "#Epoch 252 with total epochs 300 at step 3 loss: 3.11576771736145 running average of batch loss 3.3437185883522034, time 0.5133647918701172\n",
      "#Epoch 252 with total epochs 300 at step 4 loss: 3.086834192276001 running average of batch loss 3.292341709136963, time 0.49632906913757324\n",
      "#Epoch 252 with total epochs 300 at step 5 loss: 3.752047300338745 running average of batch loss 3.3689593076705933, time 0.5003314018249512\n",
      "#Epoch 252 with total epochs 300 at step 6 loss: 3.347965955734253 running average of batch loss 3.365960257393973, time 0.5013298988342285\n",
      "#Epoch 252 with total epochs 300 at step 7 loss: 3.5401318073272705 running average of batch loss 3.3877317011356354, time 0.503331184387207\n",
      "#Epoch 252 with total epochs 300 at step 8 loss: 3.2287750244140625 running average of batch loss 3.3700698481665716, time 0.5043342113494873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 252 with total epochs 300 at step 9 loss: 2.873350143432617 running average of batch loss 3.320397877693176, time 0.5033555030822754\n",
      "#Epoch 252 with total epochs 300 at step 10 loss: 3.4152965545654297 running average of batch loss 3.3290250301361084, time 0.49735403060913086\n",
      "#Epoch 252 with total epochs 300 at step 11 loss: 3.5852653980255127 running average of batch loss 3.350378394126892, time 0.5073606967926025\n",
      "#Epoch 252 with total epochs 300 at step 12 loss: 3.024332046508789 running average of batch loss 3.3252979058485765, time 0.5173704624176025\n",
      "#Epoch 252 with total epochs 300 at step 13 loss: 3.4172821044921875 running average of batch loss 3.3318682057516917, time 0.4893183708190918\n",
      "#Epoch 252 with total epochs 300 at step 14 loss: 3.063896417617798 running average of batch loss 3.314003419876099, time 0.4993245601654053\n",
      "#Epoch 252 with total epochs 300 at step 15 loss: 3.422269344329834 running average of batch loss 3.320770040154457, time 0.515366792678833\n",
      "#Epoch 252 with total epochs 300 at step 16 loss: 3.261885643005371 running average of batch loss 3.3173062520868637, time 0.48932385444641113\n",
      "#Epoch 252 with total epochs 300 at step 17 loss: 3.327162027359009 running average of batch loss 3.3178537951575384, time 0.4783468246459961\n",
      "#Epoch 252 with total epochs 300 at step 18 loss: 2.9610366821289062 running average of batch loss 3.2990739471034, time 0.5473871231079102\n",
      "#Epoch 252 with total epochs 300 at step 19 loss: 3.440437078475952 running average of batch loss 3.3061421036720278, time 0.4923243522644043\n",
      "#Epoch 252 with total epochs 300 at step 20 loss: 3.3592374324798584 running average of batch loss 3.3086704526628767, time 0.5443580150604248\n",
      "#Epoch 253 with total epochs 300 at step 0 loss: 3.068153142929077 running average of batch loss 3.068153142929077, time 0.4903268814086914\n",
      "#Epoch 253 with total epochs 300 at step 1 loss: 3.1532373428344727 running average of batch loss 3.110695242881775, time 0.5023288726806641\n",
      "#Epoch 253 with total epochs 300 at step 2 loss: 3.313260078430176 running average of batch loss 3.1782168547312417, time 0.497328519821167\n",
      "#Epoch 253 with total epochs 300 at step 3 loss: 2.985520124435425 running average of batch loss 3.1300426721572876, time 0.4943246841430664\n",
      "#Epoch 253 with total epochs 300 at step 4 loss: 3.3814711570739746 running average of batch loss 3.180328369140625, time 0.499326229095459\n",
      "#Epoch 253 with total epochs 300 at step 5 loss: 2.8677756786346436 running average of batch loss 3.128236254056295, time 0.5663988590240479\n",
      "#Epoch 253 with total epochs 300 at step 6 loss: 3.2445578575134277 running average of batch loss 3.1448536259787425, time 0.5303785800933838\n",
      "#Epoch 253 with total epochs 300 at step 7 loss: 3.0647027492523193 running average of batch loss 3.1348347663879395, time 0.49532437324523926\n",
      "#Epoch 253 with total epochs 300 at step 8 loss: 3.2318100929260254 running average of batch loss 3.145609802669949, time 0.5343828201293945\n",
      "#Epoch 253 with total epochs 300 at step 9 loss: 3.245497465133667 running average of batch loss 3.1555985689163206, time 0.5033528804779053\n",
      "#Epoch 253 with total epochs 300 at step 10 loss: 3.553948163986206 running average of batch loss 3.1918121684681284, time 0.4863450527191162\n",
      "#Epoch 253 with total epochs 300 at step 11 loss: 3.3592710494995117 running average of batch loss 3.2057670752207437, time 0.5153656005859375\n",
      "#Epoch 253 with total epochs 300 at step 12 loss: 3.399543285369873 running average of batch loss 3.2206729375399075, time 0.5073606967926025\n",
      "#Epoch 253 with total epochs 300 at step 13 loss: 3.2004618644714355 running average of batch loss 3.219229289463588, time 0.500328779220581\n",
      "#Epoch 253 with total epochs 300 at step 14 loss: 3.5419793128967285 running average of batch loss 3.240745957692464, time 0.4913501739501953\n",
      "#Epoch 253 with total epochs 300 at step 15 loss: 2.9763736724853516 running average of batch loss 3.2242226898670197, time 0.5003554821014404\n",
      "#Epoch 253 with total epochs 300 at step 16 loss: 3.2753067016601562 running average of batch loss 3.227227631737204, time 0.5023574829101562\n",
      "#Epoch 253 with total epochs 300 at step 17 loss: 3.4155118465423584 running average of batch loss 3.237687865893046, time 0.4903256893157959\n",
      "#Epoch 253 with total epochs 300 at step 18 loss: 3.4741973876953125 running average of batch loss 3.2501357354615865, time 0.49434781074523926\n",
      "#Epoch 253 with total epochs 300 at step 19 loss: 3.189629077911377 running average of batch loss 3.247110402584076, time 0.48834919929504395\n",
      "#Epoch 253 with total epochs 300 at step 20 loss: 3.1798644065856934 running average of batch loss 3.2439082122984386, time 0.5063352584838867\n",
      "#Epoch 254 with total epochs 300 at step 0 loss: 3.373556613922119 running average of batch loss 3.373556613922119, time 0.5473597049713135\n",
      "#Epoch 254 with total epochs 300 at step 1 loss: 3.334907054901123 running average of batch loss 3.354231834411621, time 0.4883458614349365\n",
      "#Epoch 254 with total epochs 300 at step 2 loss: 3.1063754558563232 running average of batch loss 3.271613041559855, time 0.4883239269256592\n",
      "#Epoch 254 with total epochs 300 at step 3 loss: 3.1916372776031494 running average of batch loss 3.2516191005706787, time 0.5263757705688477\n",
      "#Epoch 254 with total epochs 300 at step 4 loss: 3.2663817405700684 running average of batch loss 3.254571628570557, time 0.49832916259765625\n",
      "#Epoch 254 with total epochs 300 at step 5 loss: 3.3177478313446045 running average of batch loss 3.2651009956995645, time 0.5083355903625488\n",
      "#Epoch 254 with total epochs 300 at step 6 loss: 3.2616398334503174 running average of batch loss 3.264606543949672, time 0.4983551502227783\n",
      "#Epoch 254 with total epochs 300 at step 7 loss: 3.5128729343414307 running average of batch loss 3.295639842748642, time 0.5063357353210449\n",
      "#Epoch 254 with total epochs 300 at step 8 loss: 2.9842705726623535 running average of batch loss 3.261043257183499, time 0.5063321590423584\n",
      "#Epoch 254 with total epochs 300 at step 9 loss: 3.6045165061950684 running average of batch loss 3.295390582084656, time 0.49034953117370605\n",
      "#Epoch 254 with total epochs 300 at step 10 loss: 3.450944423675537 running average of batch loss 3.3095318404110996, time 0.4973256587982178\n",
      "#Epoch 254 with total epochs 300 at step 11 loss: 3.665109634399414 running average of batch loss 3.339163323243459, time 0.5183703899383545\n",
      "#Epoch 254 with total epochs 300 at step 12 loss: 3.4307785034179688 running average of batch loss 3.3462106447953444, time 0.5073573589324951\n",
      "#Epoch 254 with total epochs 300 at step 13 loss: 3.0743372440338135 running average of batch loss 3.3267911161695207, time 0.4823124408721924\n",
      "#Epoch 254 with total epochs 300 at step 14 loss: 3.030923843383789 running average of batch loss 3.307066631317139, time 0.5313794612884521\n",
      "#Epoch 254 with total epochs 300 at step 15 loss: 2.8325023651123047 running average of batch loss 3.2774063646793365, time 0.5683748722076416\n",
      "#Epoch 254 with total epochs 300 at step 16 loss: 3.3489878177642822 running average of batch loss 3.2816170383902157, time 0.4963538646697998\n",
      "#Epoch 254 with total epochs 300 at step 17 loss: 3.152974843978882 running average of batch loss 3.274470249811808, time 0.5033338069915771\n",
      "#Epoch 254 with total epochs 300 at step 18 loss: 3.0794904232025146 running average of batch loss 3.264208153674477, time 0.5013210773468018\n",
      "#Epoch 254 with total epochs 300 at step 19 loss: 3.133791446685791 running average of batch loss 3.2576873183250425, time 0.5083608627319336\n",
      "#Epoch 254 with total epochs 300 at step 20 loss: 3.0744192600250244 running average of batch loss 3.248960267929804, time 0.5013265609741211\n",
      "#Epoch 255 with total epochs 300 at step 0 loss: 3.030303716659546 running average of batch loss 3.030303716659546, time 0.5053310394287109\n",
      "#Epoch 255 with total epochs 300 at step 1 loss: 3.1676619052886963 running average of batch loss 3.098982810974121, time 0.48432207107543945\n",
      "#Epoch 255 with total epochs 300 at step 2 loss: 3.3271396160125732 running average of batch loss 3.175035079320272, time 0.4963233470916748\n",
      "#Epoch 255 with total epochs 300 at step 3 loss: 3.4354701042175293 running average of batch loss 3.240143835544586, time 0.49034833908081055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 255 with total epochs 300 at step 4 loss: 3.3050336837768555 running average of batch loss 3.25312180519104, time 0.5143656730651855\n",
      "#Epoch 255 with total epochs 300 at step 5 loss: 2.9447684288024902 running average of batch loss 3.2017295757929483, time 0.48732447624206543\n",
      "#Epoch 255 with total epochs 300 at step 6 loss: 3.356863498687744 running average of batch loss 3.223891564777919, time 0.49335289001464844\n",
      "#Epoch 255 with total epochs 300 at step 7 loss: 3.429600715637207 running average of batch loss 3.24960520863533, time 0.5243442058563232\n",
      "#Epoch 255 with total epochs 300 at step 8 loss: 3.2883098125457764 running average of batch loss 3.2539057201809354, time 0.49035143852233887\n",
      "#Epoch 255 with total epochs 300 at step 9 loss: 3.3035480976104736 running average of batch loss 3.2588699579238893, time 0.5143682956695557\n",
      "#Epoch 255 with total epochs 300 at step 10 loss: 3.4041075706481934 running average of batch loss 3.2720733772624624, time 0.4963245391845703\n",
      "#Epoch 255 with total epochs 300 at step 11 loss: 3.2500109672546387 running average of batch loss 3.270234843095144, time 0.49832725524902344\n",
      "#Epoch 255 with total epochs 300 at step 12 loss: 3.4137394428253174 running average of batch loss 3.281273658459003, time 0.48834657669067383\n",
      "#Epoch 255 with total epochs 300 at step 13 loss: 3.4149019718170166 running average of batch loss 3.2908185379845754, time 0.5003557205200195\n",
      "#Epoch 255 with total epochs 300 at step 14 loss: 3.1351735591888428 running average of batch loss 3.28044220606486, time 0.48834705352783203\n",
      "#Epoch 255 with total epochs 300 at step 15 loss: 3.2027666568756104 running average of batch loss 3.275587484240532, time 0.49153947830200195\n",
      "#Epoch 255 with total epochs 300 at step 16 loss: 3.2838735580444336 running average of batch loss 3.276074900346644, time 0.5009129047393799\n",
      "#Epoch 255 with total epochs 300 at step 17 loss: 3.6172289848327637 running average of batch loss 3.295027905040317, time 0.49982762336730957\n",
      "#Epoch 255 with total epochs 300 at step 18 loss: 3.0748653411865234 running average of batch loss 3.283440401679591, time 0.509864330291748\n",
      "#Epoch 255 with total epochs 300 at step 19 loss: 3.1845803260803223 running average of batch loss 3.2784973978996277, time 0.4964632987976074\n",
      "#Epoch 255 with total epochs 300 at step 20 loss: 3.0614242553710938 running average of batch loss 3.268160581588745, time 0.5049221515655518\n",
      "#Epoch 256 with total epochs 300 at step 0 loss: 3.3997204303741455 running average of batch loss 3.3997204303741455, time 0.5023519992828369\n",
      "#Epoch 256 with total epochs 300 at step 1 loss: 3.292904853820801 running average of batch loss 3.346312642097473, time 0.505328893661499\n",
      "#Epoch 256 with total epochs 300 at step 2 loss: 3.0337767601013184 running average of batch loss 3.2421340147654214, time 0.49846315383911133\n",
      "#Epoch 256 with total epochs 300 at step 3 loss: 3.2381911277770996 running average of batch loss 3.241148293018341, time 0.5044078826904297\n",
      "#Epoch 256 with total epochs 300 at step 4 loss: 3.461468458175659 running average of batch loss 3.2852123260498045, time 0.5045056343078613\n",
      "#Epoch 256 with total epochs 300 at step 5 loss: 3.0716166496276855 running average of batch loss 3.249613046646118, time 0.5198724269866943\n",
      "#Epoch 256 with total epochs 300 at step 6 loss: 3.1455674171447754 running average of batch loss 3.2347493852887834, time 0.5233430862426758\n",
      "#Epoch 256 with total epochs 300 at step 7 loss: 2.866194248199463 running average of batch loss 3.1886799931526184, time 0.5253760814666748\n",
      "#Epoch 256 with total epochs 300 at step 8 loss: 3.148839235305786 running average of batch loss 3.1842532422807484, time 0.49832844734191895\n",
      "#Epoch 256 with total epochs 300 at step 9 loss: 3.4454376697540283 running average of batch loss 3.2103716850280763, time 0.5143373012542725\n",
      "#Epoch 256 with total epochs 300 at step 10 loss: 2.8875532150268555 running average of batch loss 3.1810245513916016, time 0.5313498973846436\n",
      "#Epoch 256 with total epochs 300 at step 11 loss: 3.6558423042297363 running average of batch loss 3.2205926974614463, time 0.49132227897644043\n",
      "#Epoch 256 with total epochs 300 at step 12 loss: 3.115734577178955 running average of batch loss 3.2125266882089467, time 0.5213403701782227\n",
      "#Epoch 256 with total epochs 300 at step 13 loss: 3.1441192626953125 running average of batch loss 3.2076404435294017, time 0.48734617233276367\n",
      "#Epoch 256 with total epochs 300 at step 14 loss: 3.098771810531616 running average of batch loss 3.2003825346628827, time 0.5453574657440186\n",
      "#Epoch 256 with total epochs 300 at step 15 loss: 3.076831340789795 running average of batch loss 3.1926605850458145, time 0.5043315887451172\n",
      "#Epoch 256 with total epochs 300 at step 16 loss: 3.254685163497925 running average of batch loss 3.1963090896606445, time 0.5063536167144775\n",
      "#Epoch 256 with total epochs 300 at step 17 loss: 3.283107042312622 running average of batch loss 3.2011311981413098, time 0.5373849868774414\n",
      "#Epoch 256 with total epochs 300 at step 18 loss: 3.1504268646240234 running average of batch loss 3.198462549008821, time 0.5393507480621338\n",
      "#Epoch 256 with total epochs 300 at step 19 loss: 3.0586447715759277 running average of batch loss 3.1914716601371764, time 0.5023317337036133\n",
      "#Epoch 256 with total epochs 300 at step 20 loss: 3.0169763565063477 running average of batch loss 3.18316235996428, time 0.5023560523986816\n",
      "#Epoch 257 with total epochs 300 at step 0 loss: 3.3645219802856445 running average of batch loss 3.3645219802856445, time 0.4883239269256592\n",
      "#Epoch 257 with total epochs 300 at step 1 loss: 3.215245485305786 running average of batch loss 3.2898837327957153, time 0.49532532691955566\n",
      "#Epoch 257 with total epochs 300 at step 2 loss: 3.1905136108398438 running average of batch loss 3.256760358810425, time 0.49034881591796875\n",
      "#Epoch 257 with total epochs 300 at step 3 loss: 3.414546012878418 running average of batch loss 3.296206772327423, time 0.5173687934875488\n",
      "#Epoch 257 with total epochs 300 at step 4 loss: 3.1675546169281006 running average of batch loss 3.2704763412475586, time 0.5063340663909912\n",
      "#Epoch 257 with total epochs 300 at step 5 loss: 2.833792209625244 running average of batch loss 3.1976956526438394, time 0.5023536682128906\n",
      "#Epoch 257 with total epochs 300 at step 6 loss: 3.2391788959503174 running average of batch loss 3.2036218302590505, time 0.5033326148986816\n",
      "#Epoch 257 with total epochs 300 at step 7 loss: 3.2048397064208984 running average of batch loss 3.2037740647792816, time 0.5053598880767822\n",
      "#Epoch 257 with total epochs 300 at step 8 loss: 3.1818230152130127 running average of batch loss 3.2013350592719183, time 0.5083367824554443\n",
      "#Epoch 257 with total epochs 300 at step 9 loss: 3.2099609375 running average of batch loss 3.2021976470947267, time 0.502326250076294\n",
      "#Epoch 257 with total epochs 300 at step 10 loss: 3.2366557121276855 running average of batch loss 3.2053301984613594, time 0.5023608207702637\n",
      "#Epoch 257 with total epochs 300 at step 11 loss: 3.4719083309173584 running average of batch loss 3.2275450428326926, time 0.505338191986084\n",
      "#Epoch 257 with total epochs 300 at step 12 loss: 3.1336965560913086 running average of batch loss 3.220325928467971, time 0.5073306560516357\n",
      "#Epoch 257 with total epochs 300 at step 13 loss: 3.483572483062744 running average of batch loss 3.2391292537961687, time 0.5033595561981201\n",
      "#Epoch 257 with total epochs 300 at step 14 loss: 3.2230224609375 running average of batch loss 3.238055467605591, time 0.5153646469116211\n",
      "#Epoch 257 with total epochs 300 at step 15 loss: 3.128697156906128 running average of batch loss 3.2312205731868744, time 0.49735331535339355\n",
      "#Epoch 257 with total epochs 300 at step 16 loss: 3.085872173309326 running average of batch loss 3.2226706673117245, time 0.5023312568664551\n",
      "#Epoch 257 with total epochs 300 at step 17 loss: 3.3286423683166504 running average of batch loss 3.2285579840342202, time 0.49035024642944336\n",
      "#Epoch 257 with total epochs 300 at step 18 loss: 3.367776870727539 running average of batch loss 3.2358852938601843, time 0.4973263740539551\n",
      "#Epoch 257 with total epochs 300 at step 19 loss: 3.0015292167663574 running average of batch loss 3.224167490005493, time 0.4993290901184082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 257 with total epochs 300 at step 20 loss: 3.525402545928955 running average of batch loss 3.238512016478039, time 0.5113604068756104\n",
      "#Epoch 258 with total epochs 300 at step 0 loss: 3.15378475189209 running average of batch loss 3.15378475189209, time 0.4913191795349121\n",
      "#Epoch 258 with total epochs 300 at step 1 loss: 3.0750010013580322 running average of batch loss 3.114392876625061, time 0.5083315372467041\n",
      "#Epoch 258 with total epochs 300 at step 2 loss: 2.8564038276672363 running average of batch loss 3.0283965269724527, time 0.511366605758667\n",
      "#Epoch 258 with total epochs 300 at step 3 loss: 3.0488858222961426 running average of batch loss 3.0335188508033752, time 0.549389123916626\n",
      "#Epoch 258 with total epochs 300 at step 4 loss: 3.4985604286193848 running average of batch loss 3.1265271663665772, time 0.4933280944824219\n",
      "#Epoch 258 with total epochs 300 at step 5 loss: 3.082632541656494 running average of batch loss 3.1192113955815635, time 0.5053329467773438\n",
      "#Epoch 258 with total epochs 300 at step 6 loss: 3.0196588039398193 running average of batch loss 3.1049895967756, time 0.508333683013916\n",
      "#Epoch 258 with total epochs 300 at step 7 loss: 3.417875289916992 running average of batch loss 3.144100308418274, time 0.5493621826171875\n",
      "#Epoch 258 with total epochs 300 at step 8 loss: 3.0602147579193115 running average of batch loss 3.134779691696167, time 0.506354570388794\n",
      "#Epoch 258 with total epochs 300 at step 9 loss: 3.3558778762817383 running average of batch loss 3.1568895101547243, time 0.5253505706787109\n",
      "#Epoch 258 with total epochs 300 at step 10 loss: 3.098372220993042 running average of batch loss 3.1515697565945713, time 0.4843466281890869\n",
      "#Epoch 258 with total epochs 300 at step 11 loss: 3.0985982418060303 running average of batch loss 3.147155463695526, time 0.5333771705627441\n",
      "#Epoch 258 with total epochs 300 at step 12 loss: 3.458165168762207 running average of batch loss 3.171079287162194, time 0.4893486499786377\n",
      "#Epoch 258 with total epochs 300 at step 13 loss: 3.342498540878296 running average of batch loss 3.1833235195704868, time 0.49532175064086914\n",
      "#Epoch 258 with total epochs 300 at step 14 loss: 2.9690370559692383 running average of batch loss 3.1690377553304034, time 0.4863474369049072\n",
      "#Epoch 258 with total epochs 300 at step 15 loss: 3.1939802169799805 running average of batch loss 3.170596659183502, time 0.5293452739715576\n",
      "#Epoch 258 with total epochs 300 at step 16 loss: 3.2473978996276855 running average of batch loss 3.1751143792096306, time 0.5143680572509766\n",
      "#Epoch 258 with total epochs 300 at step 17 loss: 3.3640637397766113 running average of batch loss 3.1856115659077964, time 0.49731922149658203\n",
      "#Epoch 258 with total epochs 300 at step 18 loss: 2.964423656463623 running average of batch loss 3.173970096989682, time 0.48932576179504395\n",
      "#Epoch 258 with total epochs 300 at step 19 loss: 2.76328706741333 running average of batch loss 3.1534359455108643, time 0.5053596496582031\n",
      "#Epoch 258 with total epochs 300 at step 20 loss: 3.2315123081207275 running average of batch loss 3.1571538675399053, time 0.5023303031921387\n",
      "#Epoch 259 with total epochs 300 at step 0 loss: 3.0920257568359375 running average of batch loss 3.0920257568359375, time 0.5033583641052246\n",
      "#Epoch 259 with total epochs 300 at step 1 loss: 3.1150026321411133 running average of batch loss 3.1035141944885254, time 0.4883239269256592\n",
      "#Epoch 259 with total epochs 300 at step 2 loss: 3.1912708282470703 running average of batch loss 3.1327664057413735, time 0.5323741436004639\n",
      "#Epoch 259 with total epochs 300 at step 3 loss: 3.1515402793884277 running average of batch loss 3.137459874153137, time 0.49732422828674316\n",
      "#Epoch 259 with total epochs 300 at step 4 loss: 3.2117457389831543 running average of batch loss 3.1523170471191406, time 0.5003557205200195\n",
      "#Epoch 259 with total epochs 300 at step 5 loss: 3.1639750003814697 running average of batch loss 3.154260039329529, time 0.4893465042114258\n",
      "#Epoch 259 with total epochs 300 at step 6 loss: 3.2358627319335938 running average of batch loss 3.1659175668443953, time 0.5003261566162109\n",
      "#Epoch 259 with total epochs 300 at step 7 loss: 3.1074612140655518 running average of batch loss 3.15861052274704, time 0.5113637447357178\n",
      "#Epoch 259 with total epochs 300 at step 8 loss: 3.3052594661712646 running average of batch loss 3.174904849794176, time 0.4893484115600586\n",
      "#Epoch 259 with total epochs 300 at step 9 loss: 3.1058995723724365 running average of batch loss 3.1680043220520018, time 0.5073602199554443\n",
      "#Epoch 259 with total epochs 300 at step 10 loss: 3.0327999591827393 running average of batch loss 3.1557130163366143, time 0.49132704734802246\n",
      "#Epoch 259 with total epochs 300 at step 11 loss: 3.0416336059570312 running average of batch loss 3.1462063988049827, time 0.5023589134216309\n",
      "#Epoch 259 with total epochs 300 at step 12 loss: 3.0351784229278564 running average of batch loss 3.137665785275973, time 0.49632906913757324\n",
      "#Epoch 259 with total epochs 300 at step 13 loss: 3.292471408843994 running average of batch loss 3.1487233298165456, time 0.4983251094818115\n",
      "#Epoch 259 with total epochs 300 at step 14 loss: 2.98862886428833 running average of batch loss 3.138050365447998, time 0.49131274223327637\n",
      "#Epoch 259 with total epochs 300 at step 15 loss: 3.367096424102783 running average of batch loss 3.152365744113922, time 0.5073330402374268\n",
      "#Epoch 259 with total epochs 300 at step 16 loss: 3.0278501510620117 running average of batch loss 3.1450412974638096, time 0.488325834274292\n",
      "#Epoch 259 with total epochs 300 at step 17 loss: 3.220153331756592 running average of batch loss 3.149214188257853, time 0.5013296604156494\n",
      "#Epoch 259 with total epochs 300 at step 18 loss: 3.3866007328033447 running average of batch loss 3.161708216918142, time 0.49234938621520996\n",
      "#Epoch 259 with total epochs 300 at step 19 loss: 3.373228073120117 running average of batch loss 3.172284209728241, time 0.5063388347625732\n",
      "#Epoch 259 with total epochs 300 at step 20 loss: 3.4641342163085938 running average of batch loss 3.18618182908921, time 0.5123355388641357\n",
      "#Epoch 260 with total epochs 300 at step 0 loss: 3.2987711429595947 running average of batch loss 3.2987711429595947, time 0.5233461856842041\n",
      "#Epoch 260 with total epochs 300 at step 1 loss: 2.935983419418335 running average of batch loss 3.117377281188965, time 0.4803152084350586\n",
      "#Epoch 260 with total epochs 300 at step 2 loss: 3.377340316772461 running average of batch loss 3.2040316263834634, time 0.51236891746521\n",
      "#Epoch 260 with total epochs 300 at step 3 loss: 3.020017623901367 running average of batch loss 3.1580281257629395, time 0.5523641109466553\n",
      "#Epoch 260 with total epochs 300 at step 4 loss: 3.150094509124756 running average of batch loss 3.156441402435303, time 0.5113427639007568\n",
      "#Epoch 260 with total epochs 300 at step 5 loss: 3.286336660385132 running average of batch loss 3.1780906120936074, time 0.5013546943664551\n",
      "#Epoch 260 with total epochs 300 at step 6 loss: 3.31305193901062 running average of batch loss 3.197370801653181, time 0.5293495655059814\n",
      "#Epoch 260 with total epochs 300 at step 7 loss: 3.3785388469696045 running average of batch loss 3.2200168073177338, time 0.5013315677642822\n",
      "#Epoch 260 with total epochs 300 at step 8 loss: 3.2703423500061035 running average of batch loss 3.2256085342831082, time 0.5383553504943848\n",
      "#Epoch 260 with total epochs 300 at step 9 loss: 3.4158589839935303 running average of batch loss 3.2446335792541503, time 0.494321346282959\n",
      "#Epoch 260 with total epochs 300 at step 10 loss: 3.255821466445923 running average of batch loss 3.2456506599079478, time 0.4843144416809082\n",
      "#Epoch 260 with total epochs 300 at step 11 loss: 3.672041177749634 running average of batch loss 3.281183203061422, time 0.4913513660430908\n",
      "#Epoch 260 with total epochs 300 at step 12 loss: 3.4218461513519287 running average of batch loss 3.292003429852999, time 0.5033309459686279\n",
      "#Epoch 260 with total epochs 300 at step 13 loss: 3.486696720123291 running average of batch loss 3.3059100934437344, time 0.4993274211883545\n",
      "#Epoch 260 with total epochs 300 at step 14 loss: 3.111464023590088 running average of batch loss 3.292947022120158, time 0.515366792678833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 260 with total epochs 300 at step 15 loss: 3.46217679977417 running average of batch loss 3.3035238832235336, time 0.49832963943481445\n",
      "#Epoch 260 with total epochs 300 at step 16 loss: 3.050173044204712 running average of batch loss 3.2886208926930145, time 0.49832916259765625\n",
      "#Epoch 260 with total epochs 300 at step 17 loss: 3.2849249839782715 running average of batch loss 3.2884155644310846, time 0.48833322525024414\n",
      "#Epoch 260 with total epochs 300 at step 18 loss: 3.17415714263916 running average of batch loss 3.282401963284141, time 0.48932433128356934\n",
      "#Epoch 260 with total epochs 300 at step 19 loss: 3.192631721496582 running average of batch loss 3.277913451194763, time 0.5103623867034912\n",
      "#Epoch 260 with total epochs 300 at step 20 loss: 3.2829556465148926 running average of batch loss 3.278153555733817, time 0.5053596496582031\n",
      "avg difference between predicted and ground truth batch wise 5.165745604310716\n",
      "#Epoch 261 with total epochs 300 at step 0 loss: 3.4600696563720703 running average of batch loss 3.4600696563720703, time 0.4943511486053467\n",
      "#Epoch 261 with total epochs 300 at step 1 loss: 3.0778350830078125 running average of batch loss 3.2689523696899414, time 0.5143661499023438\n",
      "#Epoch 261 with total epochs 300 at step 2 loss: 3.150848627090454 running average of batch loss 3.2295844554901123, time 0.489346981048584\n",
      "#Epoch 261 with total epochs 300 at step 3 loss: 2.922682285308838 running average of batch loss 3.1528589129447937, time 0.5183694362640381\n",
      "#Epoch 261 with total epochs 300 at step 4 loss: 3.514749050140381 running average of batch loss 3.225236940383911, time 0.5013508796691895\n",
      "#Epoch 261 with total epochs 300 at step 5 loss: 3.217175245285034 running average of batch loss 3.223893324534098, time 0.502331018447876\n",
      "#Epoch 261 with total epochs 300 at step 6 loss: 3.1174912452697754 running average of batch loss 3.208693027496338, time 0.5043578147888184\n",
      "#Epoch 261 with total epochs 300 at step 7 loss: 2.952784776687622 running average of batch loss 3.1767044961452484, time 0.49832582473754883\n",
      "#Epoch 261 with total epochs 300 at step 8 loss: 3.5121402740478516 running average of batch loss 3.2139751381344266, time 0.4893198013305664\n",
      "#Epoch 261 with total epochs 300 at step 9 loss: 3.2087655067443848 running average of batch loss 3.213454174995422, time 0.5083346366882324\n",
      "#Epoch 261 with total epochs 300 at step 10 loss: 3.1016972064971924 running average of batch loss 3.203294450586492, time 0.512336254119873\n",
      "#Epoch 261 with total epochs 300 at step 11 loss: 3.017146587371826 running average of batch loss 3.187782128651937, time 0.5063595771789551\n",
      "#Epoch 261 with total epochs 300 at step 12 loss: 2.991041660308838 running average of batch loss 3.1726482464716983, time 0.5363547801971436\n",
      "#Epoch 261 with total epochs 300 at step 13 loss: 2.8324642181396484 running average of batch loss 3.1483493873051236, time 0.5323486328125\n",
      "#Epoch 261 with total epochs 300 at step 14 loss: 3.4083006381988525 running average of batch loss 3.1656794706980387, time 0.49034786224365234\n",
      "#Epoch 261 with total epochs 300 at step 15 loss: 3.392592430114746 running average of batch loss 3.179861530661583, time 0.5103750228881836\n",
      "#Epoch 261 with total epochs 300 at step 16 loss: 3.1626176834106445 running average of batch loss 3.1788471867056454, time 0.4993281364440918\n",
      "#Epoch 261 with total epochs 300 at step 17 loss: 3.3825602531433105 running average of batch loss 3.1901645792855158, time 0.4873471260070801\n",
      "#Epoch 261 with total epochs 300 at step 18 loss: 3.0396900177001953 running average of batch loss 3.1822448655178674, time 0.4963264465332031\n",
      "#Epoch 261 with total epochs 300 at step 19 loss: 3.5516908168792725 running average of batch loss 3.2007171630859377, time 0.5193443298339844\n",
      "#Epoch 261 with total epochs 300 at step 20 loss: 3.5298357009887695 running average of batch loss 3.216389474414644, time 0.4893496036529541\n",
      "#Epoch 262 with total epochs 300 at step 0 loss: 3.285936117172241 running average of batch loss 3.285936117172241, time 0.5013282299041748\n",
      "#Epoch 262 with total epochs 300 at step 1 loss: 3.208218812942505 running average of batch loss 3.247077465057373, time 0.48835062980651855\n",
      "#Epoch 262 with total epochs 300 at step 2 loss: 3.2182326316833496 running average of batch loss 3.2374625205993652, time 0.5053560733795166\n",
      "#Epoch 262 with total epochs 300 at step 3 loss: 3.120677947998047 running average of batch loss 3.2082663774490356, time 0.4873471260070801\n",
      "#Epoch 262 with total epochs 300 at step 4 loss: 3.189448118209839 running average of batch loss 3.204502725601196, time 0.490325927734375\n",
      "#Epoch 262 with total epochs 300 at step 5 loss: 3.4282703399658203 running average of batch loss 3.2417973279953003, time 0.5323784351348877\n",
      "#Epoch 262 with total epochs 300 at step 6 loss: 3.1585543155670166 running average of batch loss 3.229905469076974, time 0.5153660774230957\n",
      "#Epoch 262 with total epochs 300 at step 7 loss: 3.295754909515381 running average of batch loss 3.238136649131775, time 0.5193684101104736\n",
      "#Epoch 262 with total epochs 300 at step 8 loss: 3.2473535537719727 running average of batch loss 3.2391607496473522, time 0.48834681510925293\n",
      "#Epoch 262 with total epochs 300 at step 9 loss: 3.2138478755950928 running average of batch loss 3.2366294622421266, time 0.5263738632202148\n",
      "#Epoch 262 with total epochs 300 at step 10 loss: 3.2820966243743896 running average of batch loss 3.2407628406177866, time 0.48834776878356934\n",
      "#Epoch 262 with total epochs 300 at step 11 loss: 3.1655399799346924 running average of batch loss 3.2344942688941956, time 0.505357027053833\n",
      "#Epoch 262 with total epochs 300 at step 12 loss: 2.9878718852996826 running average of batch loss 3.2155233163100023, time 0.5003261566162109\n",
      "#Epoch 262 with total epochs 300 at step 13 loss: 3.0030338764190674 running average of batch loss 3.2003454991749356, time 0.49132609367370605\n",
      "#Epoch 262 with total epochs 300 at step 14 loss: 2.81369686126709 running average of batch loss 3.1745689233144123, time 0.49535250663757324\n",
      "#Epoch 262 with total epochs 300 at step 15 loss: 2.837514638900757 running average of batch loss 3.153503030538559, time 0.5003540515899658\n",
      "#Epoch 262 with total epochs 300 at step 16 loss: 2.9245872497558594 running average of batch loss 3.1400373963748707, time 0.48334527015686035\n",
      "#Epoch 262 with total epochs 300 at step 17 loss: 3.258934497833252 running average of batch loss 3.1466427909003363, time 0.4923210144042969\n",
      "#Epoch 262 with total epochs 300 at step 18 loss: 3.0483760833740234 running average of batch loss 3.1414708589252673, time 0.5133645534515381\n",
      "#Epoch 262 with total epochs 300 at step 19 loss: 3.428868532180786 running average of batch loss 3.155840742588043, time 0.49634599685668945\n",
      "#Epoch 262 with total epochs 300 at step 20 loss: 3.1670310497283936 running average of batch loss 3.156373614356631, time 0.5213737487792969\n",
      "#Epoch 263 with total epochs 300 at step 0 loss: 3.3416714668273926 running average of batch loss 3.3416714668273926, time 0.5003259181976318\n",
      "#Epoch 263 with total epochs 300 at step 1 loss: 3.452383041381836 running average of batch loss 3.3970272541046143, time 0.49633026123046875\n",
      "#Epoch 263 with total epochs 300 at step 2 loss: 3.084959030151367 running average of batch loss 3.2930045127868652, time 0.4983532428741455\n",
      "#Epoch 263 with total epochs 300 at step 3 loss: 3.007659912109375 running average of batch loss 3.2216683626174927, time 0.5313479900360107\n",
      "#Epoch 263 with total epochs 300 at step 4 loss: 3.2553882598876953 running average of batch loss 3.2284123420715334, time 0.5143656730651855\n",
      "#Epoch 263 with total epochs 300 at step 5 loss: 2.9511494636535645 running average of batch loss 3.182201862335205, time 0.5333497524261475\n",
      "#Epoch 263 with total epochs 300 at step 6 loss: 3.136263608932495 running average of batch loss 3.1756392547062466, time 0.5213460922241211\n",
      "#Epoch 263 with total epochs 300 at step 7 loss: 3.131676435470581 running average of batch loss 3.1701439023017883, time 0.4933197498321533\n",
      "#Epoch 263 with total epochs 300 at step 8 loss: 3.0308847427368164 running average of batch loss 3.154670662350125, time 0.537358283996582\n",
      "#Epoch 263 with total epochs 300 at step 9 loss: 3.349726915359497 running average of batch loss 3.174176287651062, time 0.497316837310791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 263 with total epochs 300 at step 10 loss: 3.701932191848755 running average of batch loss 3.2221540971235796, time 0.5033273696899414\n",
      "#Epoch 263 with total epochs 300 at step 11 loss: 2.9892921447753906 running average of batch loss 3.202748934427897, time 0.4883270263671875\n",
      "#Epoch 263 with total epochs 300 at step 12 loss: 3.428478956222534 running average of batch loss 3.220112782258254, time 0.5193455219268799\n",
      "#Epoch 263 with total epochs 300 at step 13 loss: 3.3439884185791016 running average of batch loss 3.2289610419954573, time 0.5023279190063477\n",
      "#Epoch 263 with total epochs 300 at step 14 loss: 3.07254958152771 running average of batch loss 3.2185336112976075, time 0.5283722877502441\n",
      "#Epoch 263 with total epochs 300 at step 15 loss: 3.2594008445739746 running average of batch loss 3.2210878133773804, time 0.49833059310913086\n",
      "#Epoch 263 with total epochs 300 at step 16 loss: 3.226638078689575 running average of batch loss 3.2214142995722153, time 0.5253725051879883\n",
      "#Epoch 263 with total epochs 300 at step 17 loss: 3.1606526374816895 running average of batch loss 3.218038651678297, time 0.5033571720123291\n",
      "#Epoch 263 with total epochs 300 at step 18 loss: 3.4433460235595703 running average of batch loss 3.2298969344088904, time 0.5183701515197754\n",
      "#Epoch 263 with total epochs 300 at step 19 loss: 3.390739917755127 running average of batch loss 3.2379390835762023, time 0.5153625011444092\n",
      "#Epoch 263 with total epochs 300 at step 20 loss: 3.2564146518707275 running average of batch loss 3.238818872542608, time 0.515366792678833\n",
      "#Epoch 264 with total epochs 300 at step 0 loss: 2.907810926437378 running average of batch loss 2.907810926437378, time 0.48834729194641113\n",
      "#Epoch 264 with total epochs 300 at step 1 loss: 2.9909274578094482 running average of batch loss 2.949369192123413, time 0.48932600021362305\n",
      "#Epoch 264 with total epochs 300 at step 2 loss: 3.3972387313842773 running average of batch loss 3.098659038543701, time 0.49532651901245117\n",
      "#Epoch 264 with total epochs 300 at step 3 loss: 3.4064252376556396 running average of batch loss 3.175600588321686, time 0.5003283023834229\n",
      "#Epoch 264 with total epochs 300 at step 4 loss: 3.3626251220703125 running average of batch loss 3.2130054950714113, time 0.48834776878356934\n",
      "#Epoch 264 with total epochs 300 at step 5 loss: 3.089693069458008 running average of batch loss 3.1924534241358438, time 0.51336669921875\n",
      "#Epoch 264 with total epochs 300 at step 6 loss: 3.099349021911621 running average of batch loss 3.179152795246669, time 0.5083606243133545\n",
      "#Epoch 264 with total epochs 300 at step 7 loss: 3.1832165718078613 running average of batch loss 3.1796607673168182, time 0.5026853084564209\n",
      "#Epoch 264 with total epochs 300 at step 8 loss: 2.8745834827423096 running average of batch loss 3.145763291252984, time 0.48902082443237305\n",
      "#Epoch 264 with total epochs 300 at step 9 loss: 2.8316478729248047 running average of batch loss 3.114351749420166, time 0.49833226203918457\n",
      "#Epoch 264 with total epochs 300 at step 10 loss: 3.2444586753845215 running average of batch loss 3.126179651780562, time 0.5223443508148193\n",
      "#Epoch 264 with total epochs 300 at step 11 loss: 3.3403031826019287 running average of batch loss 3.144023279349009, time 0.5073578357696533\n",
      "#Epoch 264 with total epochs 300 at step 12 loss: 3.1262481212615967 running average of batch loss 3.1426559594961314, time 0.5023317337036133\n",
      "#Epoch 264 with total epochs 300 at step 13 loss: 3.2208621501922607 running average of batch loss 3.1482421159744263, time 0.5073397159576416\n",
      "#Epoch 264 with total epochs 300 at step 14 loss: 2.8696558475494385 running average of batch loss 3.129669698079427, time 0.5003304481506348\n",
      "#Epoch 264 with total epochs 300 at step 15 loss: 3.2485766410827637 running average of batch loss 3.1371013820171356, time 0.5053584575653076\n",
      "#Epoch 264 with total epochs 300 at step 16 loss: 3.1422617435455322 running average of batch loss 3.1374049326952766, time 0.5053327083587646\n",
      "#Epoch 264 with total epochs 300 at step 17 loss: 3.0616567134857178 running average of batch loss 3.1331966982947455, time 0.49832725524902344\n",
      "#Epoch 264 with total epochs 300 at step 18 loss: 3.0224907398223877 running average of batch loss 3.1273700689014636, time 0.5333490371704102\n",
      "#Epoch 264 with total epochs 300 at step 19 loss: 3.2442872524261475 running average of batch loss 3.1332159280776977, time 0.5413565635681152\n",
      "#Epoch 264 with total epochs 300 at step 20 loss: 2.8301877975463867 running average of batch loss 3.118786017100016, time 0.5373539924621582\n",
      "#Epoch 265 with total epochs 300 at step 0 loss: 3.3380746841430664 running average of batch loss 3.3380746841430664, time 0.539384126663208\n",
      "#Epoch 265 with total epochs 300 at step 1 loss: 3.033961772918701 running average of batch loss 3.186018228530884, time 0.5013325214385986\n",
      "#Epoch 265 with total epochs 300 at step 2 loss: 3.5510330200195312 running average of batch loss 3.307689825693766, time 0.5083334445953369\n",
      "#Epoch 265 with total epochs 300 at step 3 loss: 2.846895694732666 running average of batch loss 3.192491292953491, time 0.5213727951049805\n",
      "#Epoch 265 with total epochs 300 at step 4 loss: 3.2563047409057617 running average of batch loss 3.2052539825439452, time 0.5363540649414062\n",
      "#Epoch 265 with total epochs 300 at step 5 loss: 2.898362398147583 running average of batch loss 3.1541053851445517, time 0.5373497009277344\n",
      "#Epoch 265 with total epochs 300 at step 6 loss: 3.053701877593994 running average of batch loss 3.1397620269230435, time 0.48134374618530273\n",
      "#Epoch 265 with total epochs 300 at step 7 loss: 3.079413890838623 running average of batch loss 3.132218509912491, time 0.5173618793487549\n",
      "#Epoch 265 with total epochs 300 at step 8 loss: 3.138065814971924 running average of batch loss 3.13286821047465, time 0.5043575763702393\n",
      "#Epoch 265 with total epochs 300 at step 9 loss: 3.2617006301879883 running average of batch loss 3.145751452445984, time 0.5233712196350098\n",
      "#Epoch 265 with total epochs 300 at step 10 loss: 3.122349262237549 running average of batch loss 3.1436239806088535, time 0.5183682441711426\n",
      "#Epoch 265 with total epochs 300 at step 11 loss: 3.263305425643921 running average of batch loss 3.153597434361776, time 0.49034833908081055\n",
      "#Epoch 265 with total epochs 300 at step 12 loss: 3.0398998260498047 running average of batch loss 3.144851464491624, time 0.5233712196350098\n",
      "#Epoch 265 with total epochs 300 at step 13 loss: 3.282442092895508 running average of batch loss 3.154679366520473, time 0.5173678398132324\n",
      "#Epoch 265 with total epochs 300 at step 14 loss: 3.1060006618499756 running average of batch loss 3.1514341195424396, time 0.4933500289916992\n",
      "#Epoch 265 with total epochs 300 at step 15 loss: 3.028865337371826 running average of batch loss 3.1437735706567764, time 0.48834729194641113\n",
      "#Epoch 265 with total epochs 300 at step 16 loss: 3.454655170440674 running average of batch loss 3.162060723585241, time 0.5213706493377686\n",
      "#Epoch 265 with total epochs 300 at step 17 loss: 3.550389051437378 running average of batch loss 3.1836345195770264, time 0.5043575763702393\n",
      "#Epoch 265 with total epochs 300 at step 18 loss: 3.193300247192383 running average of batch loss 3.1841432420830977, time 0.48834681510925293\n",
      "#Epoch 265 with total epochs 300 at step 19 loss: 2.988790512084961 running average of batch loss 3.174375605583191, time 0.49735355377197266\n",
      "#Epoch 265 with total epochs 300 at step 20 loss: 3.273008108139038 running average of batch loss 3.179072391419184, time 0.4983537197113037\n",
      "#Epoch 266 with total epochs 300 at step 0 loss: 3.103846788406372 running average of batch loss 3.103846788406372, time 0.5053591728210449\n",
      "#Epoch 266 with total epochs 300 at step 1 loss: 3.2035727500915527 running average of batch loss 3.1537097692489624, time 0.48734617233276367\n",
      "#Epoch 266 with total epochs 300 at step 2 loss: 3.25726318359375 running average of batch loss 3.188227574030558, time 0.49535274505615234\n",
      "#Epoch 266 with total epochs 300 at step 3 loss: 2.8799684047698975 running average of batch loss 3.111162781715393, time 0.4893467426300049\n",
      "#Epoch 266 with total epochs 300 at step 4 loss: 3.307750701904297 running average of batch loss 3.150480365753174, time 0.5023565292358398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 266 with total epochs 300 at step 5 loss: 3.4256863594055176 running average of batch loss 3.196348031361898, time 0.4893496036529541\n",
      "#Epoch 266 with total epochs 300 at step 6 loss: 3.1365926265716553 running average of batch loss 3.1878115449632918, time 0.5193653106689453\n",
      "#Epoch 266 with total epochs 300 at step 7 loss: 3.248521327972412 running average of batch loss 3.1954002678394318, time 0.513364315032959\n",
      "#Epoch 266 with total epochs 300 at step 8 loss: 3.2593159675598145 running average of batch loss 3.2025020122528076, time 0.516366720199585\n",
      "#Epoch 266 with total epochs 300 at step 9 loss: 3.1532135009765625 running average of batch loss 3.197573161125183, time 0.5013558864593506\n",
      "#Epoch 266 with total epochs 300 at step 10 loss: 3.172658920288086 running average of batch loss 3.1953082301399927, time 0.486346960067749\n",
      "#Epoch 266 with total epochs 300 at step 11 loss: 3.1442224979400635 running average of batch loss 3.1910510857899985, time 0.5043604373931885\n",
      "#Epoch 266 with total epochs 300 at step 12 loss: 2.921257972717285 running average of batch loss 3.17029776939979, time 0.4973475933074951\n",
      "#Epoch 266 with total epochs 300 at step 13 loss: 3.075258731842041 running average of batch loss 3.163509266717093, time 0.5213711261749268\n",
      "#Epoch 266 with total epochs 300 at step 14 loss: 3.0690414905548096 running average of batch loss 3.157211414972941, time 0.4823453426361084\n",
      "#Epoch 266 with total epochs 300 at step 15 loss: 3.1099817752838135 running average of batch loss 3.1542595624923706, time 0.5303735733032227\n",
      "#Epoch 266 with total epochs 300 at step 16 loss: 3.3177292346954346 running average of batch loss 3.163875425563139, time 0.564403772354126\n",
      "#Epoch 266 with total epochs 300 at step 17 loss: 3.2068517208099365 running average of batch loss 3.1662629975212946, time 0.5443799495697021\n",
      "#Epoch 266 with total epochs 300 at step 18 loss: 3.1152443885803223 running average of batch loss 3.163577807577033, time 0.5473911762237549\n",
      "#Epoch 266 with total epochs 300 at step 19 loss: 2.7972640991210938 running average of batch loss 3.145262122154236, time 0.5263431072235107\n",
      "#Epoch 266 with total epochs 300 at step 20 loss: 3.1567203998565674 running average of batch loss 3.1458077544257756, time 0.48932409286499023\n",
      "#Epoch 267 with total epochs 300 at step 0 loss: 3.0937907695770264 running average of batch loss 3.0937907695770264, time 0.5113627910614014\n",
      "#Epoch 267 with total epochs 300 at step 1 loss: 2.9445838928222656 running average of batch loss 3.019187331199646, time 0.489346981048584\n",
      "#Epoch 267 with total epochs 300 at step 2 loss: 3.1872787475585938 running average of batch loss 3.0752178033192954, time 0.4913473129272461\n",
      "#Epoch 267 with total epochs 300 at step 3 loss: 3.1485595703125 running average of batch loss 3.0935532450675964, time 0.48834657669067383\n",
      "#Epoch 267 with total epochs 300 at step 4 loss: 2.8574464321136475 running average of batch loss 3.0463318824768066, time 0.4893503189086914\n",
      "#Epoch 267 with total epochs 300 at step 5 loss: 3.0198490619659424 running average of batch loss 3.041918079058329, time 0.5053553581237793\n",
      "#Epoch 267 with total epochs 300 at step 6 loss: 3.2515063285827637 running average of batch loss 3.0718592575618198, time 0.5423569679260254\n",
      "#Epoch 267 with total epochs 300 at step 7 loss: 3.1186068058013916 running average of batch loss 3.0777027010917664, time 0.49034905433654785\n",
      "#Epoch 267 with total epochs 300 at step 8 loss: 3.0037455558776855 running average of batch loss 3.069485240512424, time 0.49632740020751953\n",
      "#Epoch 267 with total epochs 300 at step 9 loss: 3.402212381362915 running average of batch loss 3.102757954597473, time 0.5073330402374268\n",
      "#Epoch 267 with total epochs 300 at step 10 loss: 3.4077227115631104 running average of batch loss 3.1304820234125312, time 0.5173676013946533\n",
      "#Epoch 267 with total epochs 300 at step 11 loss: 3.4074394702911377 running average of batch loss 3.153561810652415, time 0.5093626976013184\n",
      "#Epoch 267 with total epochs 300 at step 12 loss: 3.011744976043701 running average of batch loss 3.1426528233748217, time 0.49632835388183594\n",
      "#Epoch 267 with total epochs 300 at step 13 loss: 3.4206790924072266 running average of batch loss 3.162511842591422, time 0.5073297023773193\n",
      "#Epoch 267 with total epochs 300 at step 14 loss: 2.998507261276245 running average of batch loss 3.1515782038370768, time 0.488323450088501\n",
      "#Epoch 267 with total epochs 300 at step 15 loss: 3.1314992904663086 running average of batch loss 3.150323271751404, time 0.4873228073120117\n",
      "#Epoch 267 with total epochs 300 at step 16 loss: 3.154096841812134 running average of batch loss 3.1505452464608585, time 0.4863274097442627\n",
      "#Epoch 267 with total epochs 300 at step 17 loss: 3.135899782180786 running average of batch loss 3.14973160955641, time 0.5023326873779297\n",
      "#Epoch 267 with total epochs 300 at step 18 loss: 3.186821699142456 running average of batch loss 3.151683719534623, time 0.5043177604675293\n",
      "#Epoch 267 with total epochs 300 at step 19 loss: 3.3072032928466797 running average of batch loss 3.1594596982002257, time 0.4883244037628174\n",
      "#Epoch 267 with total epochs 300 at step 20 loss: 3.0118863582611084 running average of batch loss 3.152432396298363, time 0.4843447208404541\n",
      "#Epoch 268 with total epochs 300 at step 0 loss: 2.8970842361450195 running average of batch loss 2.8970842361450195, time 0.49132776260375977\n",
      "#Epoch 268 with total epochs 300 at step 1 loss: 2.987191915512085 running average of batch loss 2.9421380758285522, time 0.4963254928588867\n",
      "#Epoch 268 with total epochs 300 at step 2 loss: 3.4314377307891846 running average of batch loss 3.1052379608154297, time 0.48834705352783203\n",
      "#Epoch 268 with total epochs 300 at step 3 loss: 2.9523396492004395 running average of batch loss 3.067013382911682, time 0.4963412284851074\n",
      "#Epoch 268 with total epochs 300 at step 4 loss: 3.136963129043579 running average of batch loss 3.0810033321380614, time 0.4993250370025635\n",
      "#Epoch 268 with total epochs 300 at step 5 loss: 3.2754106521606445 running average of batch loss 3.113404552141825, time 0.49034881591796875\n",
      "#Epoch 268 with total epochs 300 at step 6 loss: 3.129526138305664 running average of batch loss 3.1157076358795166, time 0.5093395709991455\n",
      "#Epoch 268 with total epochs 300 at step 7 loss: 3.005690336227417 running average of batch loss 3.101955473423004, time 0.5333490371704102\n",
      "#Epoch 268 with total epochs 300 at step 8 loss: 3.462003469467163 running average of batch loss 3.1419608063167996, time 0.5213413238525391\n",
      "#Epoch 268 with total epochs 300 at step 9 loss: 3.3645381927490234 running average of batch loss 3.164218544960022, time 0.4823439121246338\n",
      "#Epoch 268 with total epochs 300 at step 10 loss: 2.9662423133850098 running average of batch loss 3.14622070572593, time 0.5003271102905273\n",
      "#Epoch 268 with total epochs 300 at step 11 loss: 3.0806164741516113 running average of batch loss 3.14075368642807, time 0.5093634128570557\n",
      "#Epoch 268 with total epochs 300 at step 12 loss: 2.9319775104522705 running average of batch loss 3.124693980583778, time 0.5293717384338379\n",
      "#Epoch 268 with total epochs 300 at step 13 loss: 2.978116035461426 running average of batch loss 3.1142241273607527, time 0.5083615779876709\n",
      "#Epoch 268 with total epochs 300 at step 14 loss: 3.591203451156616 running average of batch loss 3.1460227489471437, time 0.5073323249816895\n",
      "#Epoch 268 with total epochs 300 at step 15 loss: 3.047849416732788 running average of batch loss 3.1398869156837463, time 0.5043551921844482\n",
      "#Epoch 268 with total epochs 300 at step 16 loss: 3.2681808471679688 running average of batch loss 3.1474336175357593, time 0.5053620338439941\n",
      "#Epoch 268 with total epochs 300 at step 17 loss: 3.3251736164093018 running average of batch loss 3.157308061917623, time 0.48732423782348633\n",
      "#Epoch 268 with total epochs 300 at step 18 loss: 3.160672664642334 running average of batch loss 3.157485146271555, time 0.4803152084350586\n",
      "#Epoch 268 with total epochs 300 at step 19 loss: 3.0946991443634033 running average of batch loss 3.1543458461761475, time 0.5383799076080322\n",
      "#Epoch 268 with total epochs 300 at step 20 loss: 3.0517256259918213 running average of batch loss 3.149459169024513, time 0.5493903160095215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 269 with total epochs 300 at step 0 loss: 3.0698273181915283 running average of batch loss 3.0698273181915283, time 0.48534512519836426\n",
      "#Epoch 269 with total epochs 300 at step 1 loss: 3.3919970989227295 running average of batch loss 3.230912208557129, time 0.5043280124664307\n",
      "#Epoch 269 with total epochs 300 at step 2 loss: 3.3518528938293457 running average of batch loss 3.2712257703145347, time 0.48634839057922363\n",
      "#Epoch 269 with total epochs 300 at step 3 loss: 3.224911689758301 running average of batch loss 3.259647250175476, time 0.5283730030059814\n",
      "#Epoch 269 with total epochs 300 at step 4 loss: 2.9631361961364746 running average of batch loss 3.200345039367676, time 0.502328634262085\n",
      "#Epoch 269 with total epochs 300 at step 5 loss: 2.8865723609924316 running average of batch loss 3.1480495929718018, time 0.5003528594970703\n",
      "#Epoch 269 with total epochs 300 at step 6 loss: 3.134810209274292 running average of batch loss 3.1461582524435863, time 0.5033321380615234\n",
      "#Epoch 269 with total epochs 300 at step 7 loss: 2.875322103500366 running average of batch loss 3.1123037338256836, time 0.5053329467773438\n",
      "#Epoch 269 with total epochs 300 at step 8 loss: 3.2447667121887207 running average of batch loss 3.1270218425326877, time 0.49932312965393066\n",
      "#Epoch 269 with total epochs 300 at step 9 loss: 3.3809916973114014 running average of batch loss 3.152418828010559, time 0.5083625316619873\n",
      "#Epoch 269 with total epochs 300 at step 10 loss: 2.959010362625122 running average of batch loss 3.1348362402482466, time 0.502316951751709\n",
      "#Epoch 269 with total epochs 300 at step 11 loss: 3.270829677581787 running average of batch loss 3.1461690266927085, time 0.5173649787902832\n",
      "#Epoch 269 with total epochs 300 at step 12 loss: 3.3000874519348145 running average of batch loss 3.1580089055574856, time 0.5093634128570557\n",
      "#Epoch 269 with total epochs 300 at step 13 loss: 3.1620938777923584 running average of batch loss 3.158300689288548, time 0.51436448097229\n",
      "#Epoch 269 with total epochs 300 at step 14 loss: 3.771239757537842 running average of batch loss 3.199163293838501, time 0.4873232841491699\n",
      "#Epoch 269 with total epochs 300 at step 15 loss: 3.73429536819458 running average of batch loss 3.232609048485756, time 0.48932552337646484\n",
      "#Epoch 269 with total epochs 300 at step 16 loss: 3.0508761405944824 running average of batch loss 3.2219188774333283, time 0.5073337554931641\n",
      "#Epoch 269 with total epochs 300 at step 17 loss: 2.8933939933776855 running average of batch loss 3.203667494985792, time 0.5043327808380127\n",
      "#Epoch 269 with total epochs 300 at step 18 loss: 3.1634953022003174 running average of batch loss 3.2015531690497148, time 0.5313758850097656\n",
      "#Epoch 269 with total epochs 300 at step 19 loss: 3.016166925430298 running average of batch loss 3.1922838568687437, time 0.5093326568603516\n",
      "#Epoch 269 with total epochs 300 at step 20 loss: 3.439751625061035 running average of batch loss 3.204068036306472, time 0.48732471466064453\n",
      "#Epoch 270 with total epochs 300 at step 0 loss: 3.489104986190796 running average of batch loss 3.489104986190796, time 0.48734521865844727\n",
      "#Epoch 270 with total epochs 300 at step 1 loss: 3.064328670501709 running average of batch loss 3.2767168283462524, time 0.4883246421813965\n",
      "#Epoch 270 with total epochs 300 at step 2 loss: 3.0439929962158203 running average of batch loss 3.1991422176361084, time 0.4963247776031494\n",
      "#Epoch 270 with total epochs 300 at step 3 loss: 3.2024381160736084 running average of batch loss 3.1999661922454834, time 0.4903535842895508\n",
      "#Epoch 270 with total epochs 300 at step 4 loss: 3.1443681716918945 running average of batch loss 3.1888465881347656, time 0.494326114654541\n",
      "#Epoch 270 with total epochs 300 at step 5 loss: 2.8684661388397217 running average of batch loss 3.135449846585592, time 0.5053586959838867\n",
      "#Epoch 270 with total epochs 300 at step 6 loss: 3.056424140930176 running average of batch loss 3.1241604600633894, time 0.5243744850158691\n",
      "#Epoch 270 with total epochs 300 at step 7 loss: 3.7165918350219727 running average of batch loss 3.1982143819332123, time 0.49734973907470703\n",
      "#Epoch 270 with total epochs 300 at step 8 loss: 3.3552486896514893 running average of batch loss 3.215662638346354, time 0.5874147415161133\n",
      "#Epoch 270 with total epochs 300 at step 9 loss: 2.8118784427642822 running average of batch loss 3.175284218788147, time 0.4983561038970947\n",
      "#Epoch 270 with total epochs 300 at step 10 loss: 3.0720841884613037 running average of batch loss 3.1659023978493432, time 0.4903452396392822\n",
      "#Epoch 270 with total epochs 300 at step 11 loss: 2.87485408782959 running average of batch loss 3.1416483720143638, time 0.4823451042175293\n",
      "#Epoch 270 with total epochs 300 at step 12 loss: 3.256051540374756 running average of batch loss 3.1504486157343936, time 0.523343563079834\n",
      "#Epoch 270 with total epochs 300 at step 13 loss: 3.1132071018218994 running average of batch loss 3.147788507597787, time 0.48431944847106934\n",
      "#Epoch 270 with total epochs 300 at step 14 loss: 2.767155170440674 running average of batch loss 3.1224129517873127, time 0.4893479347229004\n",
      "#Epoch 270 with total epochs 300 at step 15 loss: 3.4669189453125 running average of batch loss 3.143944576382637, time 0.5053319931030273\n",
      "#Epoch 270 with total epochs 300 at step 16 loss: 3.00655198097229 running average of batch loss 3.1358626590055576, time 0.483323335647583\n",
      "#Epoch 270 with total epochs 300 at step 17 loss: 3.1671109199523926 running average of batch loss 3.137598673502604, time 0.4933199882507324\n",
      "#Epoch 270 with total epochs 300 at step 18 loss: 2.9090678691864014 running average of batch loss 3.1255707364333305, time 0.4859182834625244\n",
      "#Epoch 270 with total epochs 300 at step 19 loss: 2.990044593811035 running average of batch loss 3.1187944293022154, time 0.5038619041442871\n",
      "#Epoch 270 with total epochs 300 at step 20 loss: 2.8273682594299316 running average of batch loss 3.1049169926416305, time 0.4993271827697754\n",
      "#Epoch 271 with total epochs 300 at step 0 loss: 2.7803778648376465 running average of batch loss 2.7803778648376465, time 0.4893462657928467\n",
      "#Epoch 271 with total epochs 300 at step 1 loss: 2.8692338466644287 running average of batch loss 2.8248058557510376, time 0.5183696746826172\n",
      "#Epoch 271 with total epochs 300 at step 2 loss: 2.827831745147705 running average of batch loss 2.8258144855499268, time 0.5063550472259521\n",
      "#Epoch 271 with total epochs 300 at step 3 loss: 3.0782904624938965 running average of batch loss 2.888933479785919, time 0.49735426902770996\n",
      "#Epoch 271 with total epochs 300 at step 4 loss: 3.0702121257781982 running average of batch loss 2.925189208984375, time 0.4913487434387207\n",
      "#Epoch 271 with total epochs 300 at step 5 loss: 3.216552495956421 running average of batch loss 2.9737497568130493, time 0.4913482666015625\n",
      "#Epoch 271 with total epochs 300 at step 6 loss: 2.9364781379699707 running average of batch loss 2.9684252398354665, time 0.4993298053741455\n",
      "#Epoch 271 with total epochs 300 at step 7 loss: 3.357104778289795 running average of batch loss 3.0170101821422577, time 0.5213439464569092\n",
      "#Epoch 271 with total epochs 300 at step 8 loss: 3.312959671020508 running average of batch loss 3.0498934586842856, time 0.49234914779663086\n",
      "#Epoch 271 with total epochs 300 at step 9 loss: 3.387454032897949 running average of batch loss 3.083649516105652, time 0.4913513660430908\n",
      "#Epoch 271 with total epochs 300 at step 10 loss: 3.19887375831604 running average of batch loss 3.094124447215687, time 0.5033318996429443\n",
      "#Epoch 271 with total epochs 300 at step 11 loss: 3.1090750694274902 running average of batch loss 3.095370332400004, time 0.502357006072998\n",
      "#Epoch 271 with total epochs 300 at step 12 loss: 3.4439857006073 running average of batch loss 3.1221868991851807, time 0.5043582916259766\n",
      "#Epoch 271 with total epochs 300 at step 13 loss: 3.2025442123413086 running average of batch loss 3.1279267072677612, time 0.516340970993042\n",
      "#Epoch 271 with total epochs 300 at step 14 loss: 3.2500102519989014 running average of batch loss 3.136065610249837, time 0.5113377571105957\n",
      "#Epoch 271 with total epochs 300 at step 15 loss: 3.0799779891967773 running average of batch loss 3.132560133934021, time 0.509335994720459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 271 with total epochs 300 at step 16 loss: 3.0850517749786377 running average of batch loss 3.1297655245837044, time 0.5043544769287109\n",
      "#Epoch 271 with total epochs 300 at step 17 loss: 2.857248067855835 running average of batch loss 3.1146256658766003, time 0.5193405151367188\n",
      "#Epoch 271 with total epochs 300 at step 18 loss: 3.2272677421569824 running average of batch loss 3.120554196207147, time 0.5033574104309082\n",
      "#Epoch 271 with total epochs 300 at step 19 loss: 3.3423080444335938 running average of batch loss 3.131641888618469, time 0.5323801040649414\n",
      "#Epoch 271 with total epochs 300 at step 20 loss: 3.079684019088745 running average of batch loss 3.129167704355149, time 0.5093631744384766\n",
      "#Epoch 272 with total epochs 300 at step 0 loss: 2.927173137664795 running average of batch loss 2.927173137664795, time 0.4953293800354004\n",
      "#Epoch 272 with total epochs 300 at step 1 loss: 2.9448013305664062 running average of batch loss 2.9359872341156006, time 0.5323784351348877\n",
      "#Epoch 272 with total epochs 300 at step 2 loss: 3.136862277984619 running average of batch loss 3.00294558207194, time 0.5393860340118408\n",
      "#Epoch 272 with total epochs 300 at step 3 loss: 3.2241086959838867 running average of batch loss 3.0582363605499268, time 0.544360876083374\n",
      "#Epoch 272 with total epochs 300 at step 4 loss: 3.3173298835754395 running average of batch loss 3.1100550651550294, time 0.5113606452941895\n",
      "#Epoch 272 with total epochs 300 at step 5 loss: 3.206576108932495 running average of batch loss 3.126141905784607, time 0.5093638896942139\n",
      "#Epoch 272 with total epochs 300 at step 6 loss: 3.1718735694885254 running average of batch loss 3.1326750005994524, time 0.557368278503418\n",
      "#Epoch 272 with total epochs 300 at step 7 loss: 3.126103401184082 running average of batch loss 3.131853550672531, time 0.5013549327850342\n",
      "#Epoch 272 with total epochs 300 at step 8 loss: 2.7415435314178467 running average of batch loss 3.088485770755344, time 0.5223708152770996\n",
      "#Epoch 272 with total epochs 300 at step 9 loss: 3.0056118965148926 running average of batch loss 3.080198383331299, time 0.49535298347473145\n",
      "#Epoch 272 with total epochs 300 at step 10 loss: 3.2532312870025635 running average of batch loss 3.0959286473014136, time 0.48134374618530273\n",
      "#Epoch 272 with total epochs 300 at step 11 loss: 2.9686570167541504 running average of batch loss 3.085322678089142, time 0.5183682441711426\n",
      "#Epoch 272 with total epochs 300 at step 12 loss: 2.914994478225708 running average of batch loss 3.072220508868878, time 0.531374454498291\n",
      "#Epoch 272 with total epochs 300 at step 13 loss: 2.83941650390625 running average of batch loss 3.055591651371547, time 0.5503697395324707\n",
      "#Epoch 272 with total epochs 300 at step 14 loss: 2.939728260040283 running average of batch loss 3.047867425282796, time 0.4983537197113037\n",
      "#Epoch 272 with total epochs 300 at step 15 loss: 3.316838264465332 running average of batch loss 3.0646781027317047, time 0.5263767242431641\n",
      "#Epoch 272 with total epochs 300 at step 16 loss: 3.275993585586548 running average of batch loss 3.077108425252578, time 0.5043318271636963\n",
      "#Epoch 272 with total epochs 300 at step 17 loss: 3.3227992057800293 running average of batch loss 3.0907579130596585, time 0.5403566360473633\n",
      "#Epoch 272 with total epochs 300 at step 18 loss: 3.030470132827759 running average of batch loss 3.087584871994822, time 0.5143661499023438\n",
      "#Epoch 272 with total epochs 300 at step 19 loss: 3.080488681793213 running average of batch loss 3.0872300624847413, time 0.4913508892059326\n",
      "#Epoch 272 with total epochs 300 at step 20 loss: 2.7360124588012695 running average of batch loss 3.0705054146902904, time 0.49832749366760254\n",
      "#Epoch 273 with total epochs 300 at step 0 loss: 3.214881420135498 running average of batch loss 3.214881420135498, time 0.500333309173584\n",
      "#Epoch 273 with total epochs 300 at step 1 loss: 3.620213270187378 running average of batch loss 3.417547345161438, time 0.5163400173187256\n",
      "#Epoch 273 with total epochs 300 at step 2 loss: 3.302283763885498 running average of batch loss 3.3791261514027915, time 0.5273706912994385\n",
      "#Epoch 273 with total epochs 300 at step 3 loss: 3.4210641384124756 running average of batch loss 3.3896106481552124, time 0.49833106994628906\n",
      "#Epoch 273 with total epochs 300 at step 4 loss: 3.193950891494751 running average of batch loss 3.35047869682312, time 0.48732542991638184\n",
      "#Epoch 273 with total epochs 300 at step 5 loss: 3.4202306270599365 running average of batch loss 3.3621040185292563, time 0.5033330917358398\n",
      "#Epoch 273 with total epochs 300 at step 6 loss: 3.519835948944092 running average of batch loss 3.3846371514456615, time 0.5553665161132812\n",
      "#Epoch 273 with total epochs 300 at step 7 loss: 3.3040757179260254 running average of batch loss 3.374566972255707, time 0.48932385444641113\n",
      "#Epoch 273 with total epochs 300 at step 8 loss: 3.210184097290039 running average of batch loss 3.3563022083706326, time 0.508336067199707\n",
      "#Epoch 273 with total epochs 300 at step 9 loss: 3.275369644165039 running average of batch loss 3.348208951950073, time 0.5033295154571533\n",
      "#Epoch 273 with total epochs 300 at step 10 loss: 3.087918281555176 running average of batch loss 3.3245461637323555, time 0.4973306655883789\n",
      "#Epoch 273 with total epochs 300 at step 11 loss: 3.1297497749328613 running average of batch loss 3.3083131313323975, time 0.5333542823791504\n",
      "#Epoch 273 with total epochs 300 at step 12 loss: 3.3675196170806885 running average of batch loss 3.3128674763899584, time 0.5033323764801025\n",
      "#Epoch 273 with total epochs 300 at step 13 loss: 3.1967039108276367 running average of batch loss 3.3045700788497925, time 0.4993267059326172\n",
      "#Epoch 273 with total epochs 300 at step 14 loss: 3.367074489593506 running average of batch loss 3.30873703956604, time 0.5013291835784912\n",
      "#Epoch 273 with total epochs 300 at step 15 loss: 2.9855945110321045 running average of batch loss 3.288540631532669, time 0.5013296604156494\n",
      "#Epoch 273 with total epochs 300 at step 16 loss: 3.5109009742736816 running average of batch loss 3.3016206516939053, time 0.5173680782318115\n",
      "#Epoch 273 with total epochs 300 at step 17 loss: 3.268812656402588 running average of batch loss 3.2997979852888317, time 0.5253429412841797\n",
      "#Epoch 273 with total epochs 300 at step 18 loss: 3.158989429473877 running average of batch loss 3.292387008666992, time 0.5023307800292969\n",
      "#Epoch 273 with total epochs 300 at step 19 loss: 2.99227237701416 running average of batch loss 3.2773812770843507, time 0.49931859970092773\n",
      "#Epoch 273 with total epochs 300 at step 20 loss: 2.9569690227508545 running average of batch loss 3.2621235506875172, time 0.5233733654022217\n",
      "#Epoch 274 with total epochs 300 at step 0 loss: 3.0419137477874756 running average of batch loss 3.0419137477874756, time 0.49034619331359863\n",
      "#Epoch 274 with total epochs 300 at step 1 loss: 3.266507863998413 running average of batch loss 3.1542108058929443, time 0.5063586235046387\n",
      "#Epoch 274 with total epochs 300 at step 2 loss: 3.7031280994415283 running average of batch loss 3.3371832370758057, time 0.5053560733795166\n",
      "#Epoch 274 with total epochs 300 at step 3 loss: 3.2713053226470947 running average of batch loss 3.320713758468628, time 0.4803440570831299\n",
      "#Epoch 274 with total epochs 300 at step 4 loss: 3.273239850997925 running average of batch loss 3.3112189769744873, time 0.4913179874420166\n",
      "#Epoch 274 with total epochs 300 at step 5 loss: 2.8471992015838623 running average of batch loss 3.2338823477427163, time 0.5043611526489258\n",
      "#Epoch 274 with total epochs 300 at step 6 loss: 2.8118700981140137 running average of batch loss 3.1735948835100447, time 0.5033257007598877\n",
      "#Epoch 274 with total epochs 300 at step 7 loss: 3.2742486000061035 running average of batch loss 3.186176598072052, time 0.484344482421875\n",
      "#Epoch 274 with total epochs 300 at step 8 loss: 3.171220302581787 running average of batch loss 3.1845147874620228, time 0.5634005069732666\n",
      "#Epoch 274 with total epochs 300 at step 9 loss: 2.7820634841918945 running average of batch loss 3.14426965713501, time 0.502354621887207\n",
      "#Epoch 274 with total epochs 300 at step 10 loss: 3.125037670135498 running average of batch loss 3.142521294680509, time 0.5323784351348877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 274 with total epochs 300 at step 11 loss: 3.4135775566101074 running average of batch loss 3.165109316507975, time 0.4923570156097412\n",
      "#Epoch 274 with total epochs 300 at step 12 loss: 2.8891587257385254 running average of batch loss 3.1438823479872484, time 0.5263423919677734\n",
      "#Epoch 274 with total epochs 300 at step 13 loss: 2.8036110401153564 running average of batch loss 3.1195772545678273, time 0.4893474578857422\n",
      "#Epoch 274 with total epochs 300 at step 14 loss: 2.8657655715942383 running average of batch loss 3.1026564757029216, time 0.5373833179473877\n",
      "#Epoch 274 with total epochs 300 at step 15 loss: 3.4486992359161377 running average of batch loss 3.1242841482162476, time 0.5003283023834229\n",
      "#Epoch 274 with total epochs 300 at step 16 loss: 3.1837007999420166 running average of batch loss 3.127779245376587, time 0.530376672744751\n",
      "#Epoch 274 with total epochs 300 at step 17 loss: 3.0248825550079346 running average of batch loss 3.1220627625783286, time 0.4903264045715332\n",
      "#Epoch 274 with total epochs 300 at step 18 loss: 2.989109992980957 running average of batch loss 3.115065248388993, time 0.4963254928588867\n",
      "#Epoch 274 with total epochs 300 at step 19 loss: 3.0147194862365723 running average of batch loss 3.110047960281372, time 0.5033292770385742\n",
      "#Epoch 274 with total epochs 300 at step 20 loss: 3.2173264026641846 running average of batch loss 3.1151564575376964, time 0.489346981048584\n",
      "#Epoch 275 with total epochs 300 at step 0 loss: 3.2180018424987793 running average of batch loss 3.2180018424987793, time 0.4973318576812744\n",
      "#Epoch 275 with total epochs 300 at step 1 loss: 3.037717819213867 running average of batch loss 3.1278598308563232, time 0.500328779220581\n",
      "#Epoch 275 with total epochs 300 at step 2 loss: 3.025667667388916 running average of batch loss 3.0937957763671875, time 0.5023329257965088\n",
      "#Epoch 275 with total epochs 300 at step 3 loss: 3.3431668281555176 running average of batch loss 3.15613853931427, time 0.5073292255401611\n",
      "#Epoch 275 with total epochs 300 at step 4 loss: 2.9925501346588135 running average of batch loss 3.1234208583831786, time 0.4893496036529541\n",
      "#Epoch 275 with total epochs 300 at step 5 loss: 3.02239990234375 running average of batch loss 3.1065840323766074, time 0.5063333511352539\n",
      "#Epoch 275 with total epochs 300 at step 6 loss: 3.361114263534546 running average of batch loss 3.1429454939705983, time 0.49034976959228516\n",
      "#Epoch 275 with total epochs 300 at step 7 loss: 3.1791296005249023 running average of batch loss 3.1474685072898865, time 0.500324010848999\n",
      "#Epoch 275 with total epochs 300 at step 8 loss: 3.1963706016540527 running average of batch loss 3.1529020733303494, time 0.489349365234375\n",
      "#Epoch 275 with total epochs 300 at step 9 loss: 3.077688455581665 running average of batch loss 3.145380711555481, time 0.4963514804840088\n",
      "#Epoch 275 with total epochs 300 at step 10 loss: 2.9207053184509277 running average of batch loss 3.1249556758187036, time 0.5003256797790527\n",
      "#Epoch 275 with total epochs 300 at step 11 loss: 2.9225106239318848 running average of batch loss 3.108085254828135, time 0.4873464107513428\n",
      "#Epoch 275 with total epochs 300 at step 12 loss: 3.214846611022949 running average of batch loss 3.116297666843121, time 0.4893198013305664\n",
      "#Epoch 275 with total epochs 300 at step 13 loss: 3.0834758281707764 running average of batch loss 3.113953249795096, time 0.5043315887451172\n",
      "#Epoch 275 with total epochs 300 at step 14 loss: 3.0934836864471436 running average of batch loss 3.112588612238566, time 0.4943230152130127\n",
      "#Epoch 275 with total epochs 300 at step 15 loss: 3.1107823848724365 running average of batch loss 3.112475723028183, time 0.5383508205413818\n",
      "#Epoch 275 with total epochs 300 at step 16 loss: 3.057971239089966 running average of batch loss 3.10926957691417, time 0.5023596286773682\n",
      "#Epoch 275 with total epochs 300 at step 17 loss: 2.9414360523223877 running average of batch loss 3.099945492214627, time 0.5113358497619629\n",
      "#Epoch 275 with total epochs 300 at step 18 loss: 3.148679733276367 running average of batch loss 3.102510452270508, time 0.49932861328125\n",
      "#Epoch 275 with total epochs 300 at step 19 loss: 2.683741569519043 running average of batch loss 3.0815720081329347, time 0.50032639503479\n",
      "#Epoch 275 with total epochs 300 at step 20 loss: 2.775944232940674 running average of batch loss 3.067018304552351, time 0.48334360122680664\n",
      "#Epoch 276 with total epochs 300 at step 0 loss: 3.092578172683716 running average of batch loss 3.092578172683716, time 0.5403861999511719\n",
      "#Epoch 276 with total epochs 300 at step 1 loss: 3.1830437183380127 running average of batch loss 3.1378109455108643, time 0.487321138381958\n",
      "#Epoch 276 with total epochs 300 at step 2 loss: 3.656149387359619 running average of batch loss 3.3105904261271157, time 0.48432040214538574\n",
      "#Epoch 276 with total epochs 300 at step 3 loss: 3.163947582244873 running average of batch loss 3.273929715156555, time 0.4863250255584717\n",
      "#Epoch 276 with total epochs 300 at step 4 loss: 2.93595027923584 running average of batch loss 3.2063338279724123, time 0.49631237983703613\n",
      "#Epoch 276 with total epochs 300 at step 5 loss: 2.948425531387329 running average of batch loss 3.1633491118748984, time 0.5393843650817871\n",
      "#Epoch 276 with total epochs 300 at step 6 loss: 2.912680149078369 running average of batch loss 3.127539260046823, time 0.5333771705627441\n",
      "#Epoch 276 with total epochs 300 at step 7 loss: 3.1346325874328613 running average of batch loss 3.1284259259700775, time 0.5383825302124023\n",
      "#Epoch 276 with total epochs 300 at step 8 loss: 3.5656657218933105 running average of batch loss 3.177008125517103, time 0.4843463897705078\n",
      "#Epoch 276 with total epochs 300 at step 9 loss: 3.274104118347168 running average of batch loss 3.18671772480011, time 0.523343563079834\n",
      "#Epoch 276 with total epochs 300 at step 10 loss: 3.271077871322632 running average of batch loss 3.19438682902943, time 0.48834729194641113\n",
      "#Epoch 276 with total epochs 300 at step 11 loss: 3.1511731147766113 running average of batch loss 3.1907856861750283, time 0.5083613395690918\n",
      "#Epoch 276 with total epochs 300 at step 12 loss: 2.8978559970855713 running average of batch loss 3.168252633168147, time 0.5213713645935059\n",
      "#Epoch 276 with total epochs 300 at step 13 loss: 2.9356110095977783 running average of batch loss 3.151635374341692, time 0.523369312286377\n",
      "#Epoch 276 with total epochs 300 at step 14 loss: 3.025743007659912 running average of batch loss 3.1432425498962404, time 0.4983539581298828\n",
      "#Epoch 276 with total epochs 300 at step 15 loss: 3.0504379272460938 running average of batch loss 3.137442260980606, time 0.49034905433654785\n",
      "#Epoch 276 with total epochs 300 at step 16 loss: 2.9559247493743896 running average of batch loss 3.1267647602978874, time 0.5073575973510742\n",
      "#Epoch 276 with total epochs 300 at step 17 loss: 3.0954949855804443 running average of batch loss 3.125027550591363, time 0.49034810066223145\n",
      "#Epoch 276 with total epochs 300 at step 18 loss: 2.603086471557617 running average of batch loss 3.0975569674843237, time 0.5263738632202148\n",
      "#Epoch 276 with total epochs 300 at step 19 loss: 2.798288106918335 running average of batch loss 3.082593524456024, time 0.5103631019592285\n",
      "#Epoch 276 with total epochs 300 at step 20 loss: 3.2086665630340576 running average of batch loss 3.0885970024835494, time 0.49632692337036133\n",
      "#Epoch 277 with total epochs 300 at step 0 loss: 3.0012383460998535 running average of batch loss 3.0012383460998535, time 0.49735307693481445\n",
      "#Epoch 277 with total epochs 300 at step 1 loss: 2.8778433799743652 running average of batch loss 2.9395408630371094, time 0.4933500289916992\n",
      "#Epoch 277 with total epochs 300 at step 2 loss: 2.9577503204345703 running average of batch loss 2.945610682169596, time 0.5003552436828613\n",
      "#Epoch 277 with total epochs 300 at step 3 loss: 3.0042853355407715 running average of batch loss 2.96027934551239, time 0.5043582916259766\n",
      "#Epoch 277 with total epochs 300 at step 4 loss: 3.315241813659668 running average of batch loss 3.0312718391418456, time 0.5423853397369385\n",
      "#Epoch 277 with total epochs 300 at step 5 loss: 3.175084114074707 running average of batch loss 3.0552405516306558, time 0.523371696472168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 277 with total epochs 300 at step 6 loss: 3.5389556884765625 running average of batch loss 3.124342714037214, time 0.49935436248779297\n",
      "#Epoch 277 with total epochs 300 at step 7 loss: 3.189326763153076 running average of batch loss 3.1324657201766968, time 0.4893484115600586\n",
      "#Epoch 277 with total epochs 300 at step 8 loss: 3.0339813232421875 running average of batch loss 3.1215230094061956, time 0.5073368549346924\n",
      "#Epoch 277 with total epochs 300 at step 9 loss: 3.0885097980499268 running average of batch loss 3.1182216882705687, time 0.49034953117370605\n",
      "#Epoch 277 with total epochs 300 at step 10 loss: 2.93715238571167 running average of batch loss 3.101760842583396, time 0.5013551712036133\n",
      "#Epoch 277 with total epochs 300 at step 11 loss: 3.0620033740997314 running average of batch loss 3.0984477202097573, time 0.5283725261688232\n",
      "#Epoch 277 with total epochs 300 at step 12 loss: 2.9251208305358887 running average of batch loss 3.0851148825425367, time 0.5013558864593506\n",
      "#Epoch 277 with total epochs 300 at step 13 loss: 3.439131736755371 running average of batch loss 3.1104018007005965, time 0.5113644599914551\n",
      "#Epoch 277 with total epochs 300 at step 14 loss: 3.164311170578003 running average of batch loss 3.1139957586924236, time 0.5463883876800537\n",
      "#Epoch 277 with total epochs 300 at step 15 loss: 3.187647581100464 running average of batch loss 3.118598997592926, time 0.5063354969024658\n",
      "#Epoch 277 with total epochs 300 at step 16 loss: 3.0904502868652344 running average of batch loss 3.116943191079532, time 0.4923219680786133\n",
      "#Epoch 277 with total epochs 300 at step 17 loss: 3.1400680541992188 running average of batch loss 3.118227905697293, time 0.4963502883911133\n",
      "#Epoch 277 with total epochs 300 at step 18 loss: 3.013324499130249 running average of batch loss 3.1127066737727116, time 0.4983246326446533\n",
      "#Epoch 277 with total epochs 300 at step 19 loss: 2.9896671772003174 running average of batch loss 3.106554698944092, time 0.5023558139801025\n",
      "#Epoch 277 with total epochs 300 at step 20 loss: 3.443455457687378 running average of batch loss 3.1225975922175815, time 0.5053286552429199\n",
      "#Epoch 278 with total epochs 300 at step 0 loss: 3.2040672302246094 running average of batch loss 3.2040672302246094, time 0.5093648433685303\n",
      "#Epoch 278 with total epochs 300 at step 1 loss: 2.971029043197632 running average of batch loss 3.0875481367111206, time 0.5173685550689697\n",
      "#Epoch 278 with total epochs 300 at step 2 loss: 3.4397003650665283 running average of batch loss 3.20493221282959, time 0.5243442058563232\n",
      "#Epoch 278 with total epochs 300 at step 3 loss: 3.031625270843506 running average of batch loss 3.161605477333069, time 0.502333402633667\n",
      "#Epoch 278 with total epochs 300 at step 4 loss: 3.069422721862793 running average of batch loss 3.1431689262390137, time 0.4883403778076172\n",
      "#Epoch 278 with total epochs 300 at step 5 loss: 2.8251585960388184 running average of batch loss 3.090167204538981, time 0.5283751487731934\n",
      "#Epoch 278 with total epochs 300 at step 6 loss: 3.167457103729248 running average of batch loss 3.1012086187090193, time 0.5323793888092041\n",
      "#Epoch 278 with total epochs 300 at step 7 loss: 3.021982192993164 running average of batch loss 3.0913053154945374, time 0.5033574104309082\n",
      "#Epoch 278 with total epochs 300 at step 8 loss: 3.0262527465820312 running average of batch loss 3.0840772522820368, time 0.48834824562072754\n",
      "#Epoch 278 with total epochs 300 at step 9 loss: 3.07686710357666 running average of batch loss 3.083356237411499, time 0.5023322105407715\n",
      "#Epoch 278 with total epochs 300 at step 10 loss: 3.2465274333953857 running average of batch loss 3.0981899825009434, time 0.5063297748565674\n",
      "#Epoch 278 with total epochs 300 at step 11 loss: 3.2530741691589355 running average of batch loss 3.111096998055776, time 0.5093634128570557\n",
      "#Epoch 278 with total epochs 300 at step 12 loss: 3.139657974243164 running average of batch loss 3.1132939962240367, time 0.4973266124725342\n",
      "#Epoch 278 with total epochs 300 at step 13 loss: 3.5378682613372803 running average of batch loss 3.143620729446411, time 0.5223729610443115\n",
      "#Epoch 278 with total epochs 300 at step 14 loss: 3.003894567489624 running average of batch loss 3.134305651982625, time 0.5203661918640137\n",
      "#Epoch 278 with total epochs 300 at step 15 loss: 2.7706973552703857 running average of batch loss 3.1115801334381104, time 0.5173673629760742\n",
      "#Epoch 278 with total epochs 300 at step 16 loss: 2.9907028675079346 running average of batch loss 3.104469706030453, time 0.49132537841796875\n",
      "#Epoch 278 with total epochs 300 at step 17 loss: 3.2917206287384033 running average of batch loss 3.1148725350697837, time 0.5203711986541748\n",
      "#Epoch 278 with total epochs 300 at step 18 loss: 2.8730225563049316 running average of batch loss 3.102143588819002, time 0.5053305625915527\n",
      "#Epoch 278 with total epochs 300 at step 19 loss: 3.43485426902771 running average of batch loss 3.1187791228294373, time 0.4883236885070801\n",
      "#Epoch 278 with total epochs 300 at step 20 loss: 3.106870174407959 running average of batch loss 3.118212030047462, time 0.4863450527191162\n",
      "#Epoch 279 with total epochs 300 at step 0 loss: 3.232611656188965 running average of batch loss 3.232611656188965, time 0.4863467216491699\n",
      "#Epoch 279 with total epochs 300 at step 1 loss: 3.164158344268799 running average of batch loss 3.198385000228882, time 0.4883232116699219\n",
      "#Epoch 279 with total epochs 300 at step 2 loss: 2.919567108154297 running average of batch loss 3.105445702870687, time 0.48935651779174805\n",
      "#Epoch 279 with total epochs 300 at step 3 loss: 3.459418773651123 running average of batch loss 3.193938970565796, time 0.48887109756469727\n",
      "#Epoch 279 with total epochs 300 at step 4 loss: 3.1187102794647217 running average of batch loss 3.178893232345581, time 0.4873230457305908\n",
      "#Epoch 279 with total epochs 300 at step 5 loss: 2.8929736614227295 running average of batch loss 3.131239970525106, time 0.4973306655883789\n",
      "#Epoch 279 with total epochs 300 at step 6 loss: 3.2331037521362305 running average of batch loss 3.145791939326695, time 0.49535226821899414\n",
      "#Epoch 279 with total epochs 300 at step 7 loss: 3.178926467895508 running average of batch loss 3.1499337553977966, time 0.4903233051300049\n",
      "#Epoch 279 with total epochs 300 at step 8 loss: 3.2552852630615234 running average of batch loss 3.1616394784715443, time 0.5037477016448975\n",
      "#Epoch 279 with total epochs 300 at step 9 loss: 3.0231728553771973 running average of batch loss 3.1477928161621094, time 0.4918482303619385\n",
      "#Epoch 279 with total epochs 300 at step 10 loss: 3.138003349304199 running average of batch loss 3.1469028646295722, time 0.5104622840881348\n",
      "#Epoch 279 with total epochs 300 at step 11 loss: 3.1147117614746094 running average of batch loss 3.1442202726999917, time 0.49738287925720215\n",
      "#Epoch 279 with total epochs 300 at step 12 loss: 3.279902696609497 running average of batch loss 3.154657382231492, time 0.5104563236236572\n",
      "#Epoch 279 with total epochs 300 at step 13 loss: 2.874925136566162 running average of batch loss 3.1346765075411116, time 0.5028924942016602\n",
      "#Epoch 279 with total epochs 300 at step 14 loss: 2.827622652053833 running average of batch loss 3.114206250508626, time 0.5048584938049316\n",
      "#Epoch 279 with total epochs 300 at step 15 loss: 3.0889534950256348 running average of batch loss 3.1126279532909393, time 0.5090961456298828\n",
      "#Epoch 279 with total epochs 300 at step 16 loss: 3.7625179290771484 running average of batch loss 3.1508567753960106, time 0.5043299198150635\n",
      "#Epoch 279 with total epochs 300 at step 17 loss: 2.7840077877044678 running average of batch loss 3.1304762760798135, time 0.4993562698364258\n",
      "#Epoch 279 with total epochs 300 at step 18 loss: 3.076772451400757 running average of batch loss 3.127649758991442, time 0.49335265159606934\n",
      "#Epoch 279 with total epochs 300 at step 19 loss: 3.147763729095459 running average of batch loss 3.128655457496643, time 0.5148825645446777\n",
      "#Epoch 279 with total epochs 300 at step 20 loss: 3.0043997764587402 running average of batch loss 3.122738520304362, time 0.5264286994934082\n",
      "#Epoch 280 with total epochs 300 at step 0 loss: 3.0497775077819824 running average of batch loss 3.0497775077819824, time 0.5039117336273193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 280 with total epochs 300 at step 1 loss: 3.2752480506896973 running average of batch loss 3.16251277923584, time 0.49833178520202637\n",
      "#Epoch 280 with total epochs 300 at step 2 loss: 2.6393051147460938 running average of batch loss 2.9881102244059243, time 0.5013532638549805\n",
      "#Epoch 280 with total epochs 300 at step 3 loss: 3.2430245876312256 running average of batch loss 3.0518388152122498, time 0.5023322105407715\n",
      "#Epoch 280 with total epochs 300 at step 4 loss: 3.1718175411224365 running average of batch loss 3.075834560394287, time 0.50335693359375\n",
      "#Epoch 280 with total epochs 300 at step 5 loss: 3.139930009841919 running average of batch loss 3.0865171353022256, time 0.4863252639770508\n",
      "#Epoch 280 with total epochs 300 at step 6 loss: 3.000136375427246 running average of batch loss 3.0741770267486572, time 0.5123398303985596\n",
      "#Epoch 280 with total epochs 300 at step 7 loss: 3.029334783554077 running average of batch loss 3.0685717463493347, time 0.5203664302825928\n",
      "#Epoch 280 with total epochs 300 at step 8 loss: 3.0003108978271484 running average of batch loss 3.060987207624647, time 0.5083625316619873\n",
      "#Epoch 280 with total epochs 300 at step 9 loss: 2.891066074371338 running average of batch loss 3.0439950942993166, time 0.5043306350708008\n",
      "#Epoch 280 with total epochs 300 at step 10 loss: 3.1643424034118652 running average of batch loss 3.0549357587640937, time 0.4983561038970947\n",
      "#Epoch 280 with total epochs 300 at step 11 loss: 3.1935198307037354 running average of batch loss 3.0664844314257302, time 0.5253498554229736\n",
      "#Epoch 280 with total epochs 300 at step 12 loss: 3.1236462593078613 running average of batch loss 3.070881495108971, time 0.4993321895599365\n",
      "#Epoch 280 with total epochs 300 at step 13 loss: 3.4575867652893066 running average of batch loss 3.0985033001218523, time 0.5003573894500732\n",
      "#Epoch 280 with total epochs 300 at step 14 loss: 3.1098387241363525 running average of batch loss 3.0992589950561524, time 0.4993276596069336\n",
      "#Epoch 280 with total epochs 300 at step 15 loss: 3.1742608547210693 running average of batch loss 3.1039466112852097, time 0.5273466110229492\n",
      "#Epoch 280 with total epochs 300 at step 16 loss: 3.0047240257263184 running average of batch loss 3.098109988605275, time 0.5093345642089844\n",
      "#Epoch 280 with total epochs 300 at step 17 loss: 2.925016164779663 running average of batch loss 3.0884936650594077, time 0.5153391361236572\n",
      "#Epoch 280 with total epochs 300 at step 18 loss: 3.0378212928771973 running average of batch loss 3.085826698102449, time 0.4873471260070801\n",
      "#Epoch 280 with total epochs 300 at step 19 loss: 3.011902093887329 running average of batch loss 3.082130467891693, time 0.5003261566162109\n",
      "#Epoch 280 with total epochs 300 at step 20 loss: 3.038332939147949 running average of batch loss 3.0800448712848483, time 0.4893476963043213\n",
      "avg difference between predicted and ground truth batch wise 5.00396243257182\n",
      "#Epoch 281 with total epochs 300 at step 0 loss: 3.123502731323242 running average of batch loss 3.123502731323242, time 0.4893500804901123\n",
      "#Epoch 281 with total epochs 300 at step 1 loss: 2.943397283554077 running average of batch loss 3.0334500074386597, time 0.5203635692596436\n",
      "#Epoch 281 with total epochs 300 at step 2 loss: 2.9239888191223145 running average of batch loss 2.9969629446665444, time 0.5353825092315674\n",
      "#Epoch 281 with total epochs 300 at step 3 loss: 3.0761771202087402 running average of batch loss 3.0167664885520935, time 0.5183391571044922\n",
      "#Epoch 281 with total epochs 300 at step 4 loss: 2.9651057720184326 running average of batch loss 3.0064343452453612, time 0.49735355377197266\n",
      "#Epoch 281 with total epochs 300 at step 5 loss: 3.1843886375427246 running average of batch loss 3.0360933939615884, time 0.5143418312072754\n",
      "#Epoch 281 with total epochs 300 at step 6 loss: 2.927237033843994 running average of batch loss 3.020542485373361, time 0.505328893661499\n",
      "#Epoch 281 with total epochs 300 at step 7 loss: 3.195040702819824 running average of batch loss 3.0423547625541687, time 0.5463910102844238\n",
      "#Epoch 281 with total epochs 300 at step 8 loss: 3.1660032272338867 running average of batch loss 3.0560934808519153, time 0.48932385444641113\n",
      "#Epoch 281 with total epochs 300 at step 9 loss: 3.4509201049804688 running average of batch loss 3.0955761432647706, time 0.50935959815979\n",
      "#Epoch 281 with total epochs 300 at step 10 loss: 3.1975975036621094 running average of batch loss 3.1048508123918013, time 0.49532365798950195\n",
      "#Epoch 281 with total epochs 300 at step 11 loss: 3.0379841327667236 running average of batch loss 3.0992785890897117, time 0.5123369693756104\n",
      "#Epoch 281 with total epochs 300 at step 12 loss: 3.1367855072021484 running average of batch loss 3.102163736636822, time 0.48531246185302734\n",
      "#Epoch 281 with total epochs 300 at step 13 loss: 3.0355474948883057 running average of batch loss 3.097405433654785, time 0.5083394050598145\n",
      "#Epoch 281 with total epochs 300 at step 14 loss: 3.0853376388549805 running average of batch loss 3.0966009140014648, time 0.5023303031921387\n",
      "#Epoch 281 with total epochs 300 at step 15 loss: 3.1951003074645996 running average of batch loss 3.1027571260929108, time 0.49934935569763184\n",
      "#Epoch 281 with total epochs 300 at step 16 loss: 2.9597015380859375 running average of batch loss 3.094342091504265, time 0.5103628635406494\n",
      "#Epoch 281 with total epochs 300 at step 17 loss: 3.173867702484131 running average of batch loss 3.0987601810031467, time 0.4893488883972168\n",
      "#Epoch 281 with total epochs 300 at step 18 loss: 3.411092758178711 running average of batch loss 3.1151987376965975, time 0.5043282508850098\n",
      "#Epoch 281 with total epochs 300 at step 19 loss: 3.3036491870880127 running average of batch loss 3.124621260166168, time 0.48834753036499023\n",
      "#Epoch 281 with total epochs 300 at step 20 loss: 3.120584726333618 running average of batch loss 3.1244290442693803, time 0.49632906913757324\n",
      "#Epoch 282 with total epochs 300 at step 0 loss: 2.9585866928100586 running average of batch loss 2.9585866928100586, time 0.4993255138397217\n",
      "#Epoch 282 with total epochs 300 at step 1 loss: 3.077012777328491 running average of batch loss 3.017799735069275, time 0.520371675491333\n",
      "#Epoch 282 with total epochs 300 at step 2 loss: 3.054652690887451 running average of batch loss 3.0300840536753335, time 0.4943506717681885\n",
      "#Epoch 282 with total epochs 300 at step 3 loss: 3.2115254402160645 running average of batch loss 3.0754444003105164, time 0.5183627605438232\n",
      "#Epoch 282 with total epochs 300 at step 4 loss: 3.1512506008148193 running average of batch loss 3.090605640411377, time 0.5133650302886963\n",
      "#Epoch 282 with total epochs 300 at step 5 loss: 3.0642306804656982 running average of batch loss 3.0862098137537637, time 0.48834705352783203\n",
      "#Epoch 282 with total epochs 300 at step 6 loss: 3.507662534713745 running average of batch loss 3.1464173453194753, time 0.507333517074585\n",
      "#Epoch 282 with total epochs 300 at step 7 loss: 3.138073444366455 running average of batch loss 3.145374357700348, time 0.49234962463378906\n",
      "#Epoch 282 with total epochs 300 at step 8 loss: 3.4565067291259766 running average of batch loss 3.1799446211920843, time 0.48834681510925293\n",
      "#Epoch 282 with total epochs 300 at step 9 loss: 3.016110420227051 running average of batch loss 3.163561201095581, time 0.49126243591308594\n",
      "#Epoch 282 with total epochs 300 at step 10 loss: 3.167116403579712 running average of batch loss 3.163884401321411, time 0.4913647174835205\n",
      "#Epoch 282 with total epochs 300 at step 11 loss: 2.9466705322265625 running average of batch loss 3.145783245563507, time 0.4884681701660156\n",
      "#Epoch 282 with total epochs 300 at step 12 loss: 3.083296775817871 running average of batch loss 3.140976594044612, time 0.5049419403076172\n",
      "#Epoch 282 with total epochs 300 at step 13 loss: 2.837050676345825 running average of batch loss 3.11926759992327, time 0.49850964546203613\n",
      "#Epoch 282 with total epochs 300 at step 14 loss: 3.010462760925293 running average of batch loss 3.1120139439900716, time 0.49037837982177734\n",
      "#Epoch 282 with total epochs 300 at step 15 loss: 3.063307762145996 running average of batch loss 3.108969807624817, time 0.4908792972564697\n",
      "#Epoch 282 with total epochs 300 at step 16 loss: 3.034731388092041 running average of batch loss 3.104602841769948, time 0.5145535469055176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 282 with total epochs 300 at step 17 loss: 3.1926519870758057 running average of batch loss 3.1094944609536066, time 0.5038642883300781\n",
      "#Epoch 282 with total epochs 300 at step 18 loss: 2.8157615661621094 running average of batch loss 3.0940348349119486, time 0.5275795459747314\n",
      "#Epoch 282 with total epochs 300 at step 19 loss: 3.1109275817871094 running average of batch loss 3.0948794722557067, time 0.531348466873169\n",
      "#Epoch 282 with total epochs 300 at step 20 loss: 3.0556180477142334 running average of batch loss 3.093009880610875, time 0.4939091205596924\n",
      "#Epoch 283 with total epochs 300 at step 0 loss: 3.2293598651885986 running average of batch loss 3.2293598651885986, time 0.5130131244659424\n",
      "#Epoch 283 with total epochs 300 at step 1 loss: 3.2321019172668457 running average of batch loss 3.230730891227722, time 0.49832820892333984\n",
      "#Epoch 283 with total epochs 300 at step 2 loss: 3.1592857837677 running average of batch loss 3.206915855407715, time 0.5303761959075928\n",
      "#Epoch 283 with total epochs 300 at step 3 loss: 2.991464853286743 running average of batch loss 3.153053104877472, time 0.4983253479003906\n",
      "#Epoch 283 with total epochs 300 at step 4 loss: 3.0811960697174072 running average of batch loss 3.138681697845459, time 0.49832677841186523\n",
      "#Epoch 283 with total epochs 300 at step 5 loss: 3.0702102184295654 running average of batch loss 3.1272697846094766, time 0.5063543319702148\n",
      "#Epoch 283 with total epochs 300 at step 6 loss: 2.9558684825897217 running average of batch loss 3.10278388432094, time 0.5263528823852539\n",
      "#Epoch 283 with total epochs 300 at step 7 loss: 3.2790284156799316 running average of batch loss 3.124814450740814, time 0.491347074508667\n",
      "#Epoch 283 with total epochs 300 at step 8 loss: 3.293285846710205 running average of batch loss 3.1435334947374134, time 0.5073604583740234\n",
      "#Epoch 283 with total epochs 300 at step 9 loss: 3.2013115882873535 running average of batch loss 3.1493113040924072, time 0.4973275661468506\n",
      "#Epoch 283 with total epochs 300 at step 10 loss: 3.179908275604248 running average of batch loss 3.15209284695712, time 0.4973270893096924\n",
      "#Epoch 283 with total epochs 300 at step 11 loss: 3.236727237701416 running average of batch loss 3.159145712852478, time 0.5033540725708008\n",
      "#Epoch 283 with total epochs 300 at step 12 loss: 3.290504217147827 running average of batch loss 3.1692502131828895, time 0.49635910987854004\n",
      "#Epoch 283 with total epochs 300 at step 13 loss: 2.782973051071167 running average of batch loss 3.1416589873177663, time 0.506331205368042\n",
      "#Epoch 283 with total epochs 300 at step 14 loss: 3.138118028640747 running average of batch loss 3.141422923405965, time 0.5053298473358154\n",
      "#Epoch 283 with total epochs 300 at step 15 loss: 2.934345245361328 running average of batch loss 3.1284805685281754, time 0.5063316822052002\n",
      "#Epoch 283 with total epochs 300 at step 16 loss: 3.0920965671539307 running average of batch loss 3.1263403331532196, time 0.5053524971008301\n",
      "#Epoch 283 with total epochs 300 at step 17 loss: 2.6781153678894043 running average of batch loss 3.101438946194119, time 0.5293400287628174\n",
      "#Epoch 283 with total epochs 300 at step 18 loss: 3.2007038593292236 running average of batch loss 3.106663415306493, time 0.5033299922943115\n",
      "#Epoch 283 with total epochs 300 at step 19 loss: 3.5489728450775146 running average of batch loss 3.128778886795044, time 0.5203707218170166\n",
      "#Epoch 283 with total epochs 300 at step 20 loss: 3.2190518379211426 running average of batch loss 3.1330775987534296, time 0.51033616065979\n",
      "#Epoch 284 with total epochs 300 at step 0 loss: 2.8387768268585205 running average of batch loss 2.8387768268585205, time 0.5313522815704346\n",
      "#Epoch 284 with total epochs 300 at step 1 loss: 3.2130730152130127 running average of batch loss 3.0259249210357666, time 0.5123627185821533\n",
      "#Epoch 284 with total epochs 300 at step 2 loss: 2.9378252029418945 running average of batch loss 2.996558348337809, time 0.5063309669494629\n",
      "#Epoch 284 with total epochs 300 at step 3 loss: 2.9419305324554443 running average of batch loss 2.982901394367218, time 0.48932647705078125\n",
      "#Epoch 284 with total epochs 300 at step 4 loss: 2.9283087253570557 running average of batch loss 2.9719828605651855, time 0.5003340244293213\n",
      "#Epoch 284 with total epochs 300 at step 5 loss: 3.151092767715454 running average of batch loss 3.001834511756897, time 0.5003280639648438\n",
      "#Epoch 284 with total epochs 300 at step 6 loss: 3.4131369590759277 running average of batch loss 3.060592004231044, time 0.4873216152191162\n",
      "#Epoch 284 with total epochs 300 at step 7 loss: 3.348247528076172 running average of batch loss 3.096548944711685, time 0.4873471260070801\n",
      "#Epoch 284 with total epochs 300 at step 8 loss: 3.22721004486084 running average of batch loss 3.111066844728258, time 0.5073587894439697\n",
      "#Epoch 284 with total epochs 300 at step 9 loss: 3.0958731174468994 running average of batch loss 3.109547472000122, time 0.5093228816986084\n",
      "#Epoch 284 with total epochs 300 at step 10 loss: 3.1813743114471436 running average of batch loss 3.116077184677124, time 0.4963235855102539\n",
      "#Epoch 284 with total epochs 300 at step 11 loss: 3.386528253555298 running average of batch loss 3.138614773750305, time 0.5283770561218262\n",
      "#Epoch 284 with total epochs 300 at step 12 loss: 3.007249355316162 running average of batch loss 3.1285097415630636, time 0.5033321380615234\n",
      "#Epoch 284 with total epochs 300 at step 13 loss: 2.765676498413086 running average of batch loss 3.102593081338065, time 0.5103645324707031\n",
      "#Epoch 284 with total epochs 300 at step 14 loss: 3.220475912094116 running average of batch loss 3.1104519367218018, time 0.495328426361084\n",
      "#Epoch 284 with total epochs 300 at step 15 loss: 3.0487983226776123 running average of batch loss 3.10659858584404, time 0.520343542098999\n",
      "#Epoch 284 with total epochs 300 at step 16 loss: 3.2085025310516357 running average of batch loss 3.112592935562134, time 0.5043284893035889\n",
      "#Epoch 284 with total epochs 300 at step 17 loss: 3.317089557647705 running average of batch loss 3.123953859011332, time 0.4833214282989502\n",
      "#Epoch 284 with total epochs 300 at step 18 loss: 3.1321258544921875 running average of batch loss 3.12438396403664, time 0.4953482151031494\n",
      "#Epoch 284 with total epochs 300 at step 19 loss: 3.124627113342285 running average of batch loss 3.1243961215019227, time 0.486346960067749\n",
      "#Epoch 284 with total epochs 300 at step 20 loss: 3.176213264465332 running average of batch loss 3.1268636045001803, time 0.5053286552429199\n",
      "#Epoch 285 with total epochs 300 at step 0 loss: 2.808725357055664 running average of batch loss 2.808725357055664, time 0.5223731994628906\n",
      "#Epoch 285 with total epochs 300 at step 1 loss: 3.1634905338287354 running average of batch loss 2.9861079454421997, time 0.4943234920501709\n",
      "#Epoch 285 with total epochs 300 at step 2 loss: 3.2692008018493652 running average of batch loss 3.080472230911255, time 0.5043601989746094\n",
      "#Epoch 285 with total epochs 300 at step 3 loss: 3.059107780456543 running average of batch loss 3.075131118297577, time 0.518341064453125\n",
      "#Epoch 285 with total epochs 300 at step 4 loss: 3.1582260131835938 running average of batch loss 3.0917500972747805, time 0.48835253715515137\n",
      "#Epoch 285 with total epochs 300 at step 5 loss: 2.8790640830993652 running average of batch loss 3.0563024282455444, time 0.5363519191741943\n",
      "#Epoch 285 with total epochs 300 at step 6 loss: 3.0677449703216553 running average of batch loss 3.0579370771135603, time 0.492326021194458\n",
      "#Epoch 285 with total epochs 300 at step 7 loss: 3.556424140930176 running average of batch loss 3.120247960090637, time 0.5193634033203125\n",
      "#Epoch 285 with total epochs 300 at step 8 loss: 3.097119092941284 running average of batch loss 3.117678085962931, time 0.5383853912353516\n",
      "#Epoch 285 with total epochs 300 at step 9 loss: 2.693175792694092 running average of batch loss 3.0752278566360474, time 0.5333783626556396\n",
      "#Epoch 285 with total epochs 300 at step 10 loss: 3.062974452972412 running average of batch loss 3.0741139108484443, time 0.506328821182251\n",
      "#Epoch 285 with total epochs 300 at step 11 loss: 3.4765846729278564 running average of batch loss 3.1076531410217285, time 0.5063302516937256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 285 with total epochs 300 at step 12 loss: 3.099342107772827 running average of batch loss 3.107013830771813, time 0.5013329982757568\n",
      "#Epoch 285 with total epochs 300 at step 13 loss: 2.904613971710205 running average of batch loss 3.0925566979816983, time 0.5033566951751709\n",
      "#Epoch 285 with total epochs 300 at step 14 loss: 3.4590234756469727 running average of batch loss 3.1169878164927165, time 0.4913499355316162\n",
      "#Epoch 285 with total epochs 300 at step 15 loss: 3.3787949085235596 running average of batch loss 3.133350759744644, time 0.4913492202758789\n",
      "#Epoch 285 with total epochs 300 at step 16 loss: 3.17523193359375 running average of batch loss 3.1358143582063565, time 0.5023298263549805\n",
      "#Epoch 285 with total epochs 300 at step 17 loss: 3.1035828590393066 running average of batch loss 3.1340237193637424, time 0.48734498023986816\n",
      "#Epoch 285 with total epochs 300 at step 18 loss: 3.178293466567993 running average of batch loss 3.136353706058703, time 0.5023331642150879\n",
      "#Epoch 285 with total epochs 300 at step 19 loss: 3.1872057914733887 running average of batch loss 3.138896310329437, time 0.49034953117370605\n",
      "#Epoch 285 with total epochs 300 at step 20 loss: 2.909855365753174 running average of batch loss 3.1279895986829485, time 0.5043330192565918\n",
      "#Epoch 286 with total epochs 300 at step 0 loss: 2.8226444721221924 running average of batch loss 2.8226444721221924, time 0.5013563632965088\n",
      "#Epoch 286 with total epochs 300 at step 1 loss: 3.037407398223877 running average of batch loss 2.9300259351730347, time 0.5073351860046387\n",
      "#Epoch 286 with total epochs 300 at step 2 loss: 3.245303153991699 running average of batch loss 3.035118341445923, time 0.505333662033081\n",
      "#Epoch 286 with total epochs 300 at step 3 loss: 3.2752346992492676 running average of batch loss 3.095147430896759, time 0.5103371143341064\n",
      "#Epoch 286 with total epochs 300 at step 4 loss: 3.1521811485290527 running average of batch loss 3.1065541744232177, time 0.4993293285369873\n",
      "#Epoch 286 with total epochs 300 at step 5 loss: 3.1348202228546143 running average of batch loss 3.111265182495117, time 0.5223429203033447\n",
      "#Epoch 286 with total epochs 300 at step 6 loss: 3.0287604331970215 running average of batch loss 3.0994787897382463, time 0.5073316097259521\n",
      "#Epoch 286 with total epochs 300 at step 7 loss: 3.0260586738586426 running average of batch loss 3.090301275253296, time 0.49433064460754395\n",
      "#Epoch 286 with total epochs 300 at step 8 loss: 2.8397011756896973 running average of batch loss 3.062456819746229, time 0.492326021194458\n",
      "#Epoch 286 with total epochs 300 at step 9 loss: 3.2243261337280273 running average of batch loss 3.0786437511444094, time 0.5113356113433838\n",
      "#Epoch 286 with total epochs 300 at step 10 loss: 2.9465763568878174 running average of batch loss 3.06663762439381, time 0.4923210144042969\n",
      "#Epoch 286 with total epochs 300 at step 11 loss: 3.20157527923584 running average of batch loss 3.0778824289639792, time 0.5003547668457031\n",
      "#Epoch 286 with total epochs 300 at step 12 loss: 3.1179277896881104 running average of batch loss 3.080962841327374, time 0.490325927734375\n",
      "#Epoch 286 with total epochs 300 at step 13 loss: 2.827944755554199 running average of batch loss 3.062890120915004, time 0.5203418731689453\n",
      "#Epoch 286 with total epochs 300 at step 14 loss: 2.868509531021118 running average of batch loss 3.0499314149220784, time 0.502356767654419\n",
      "#Epoch 286 with total epochs 300 at step 15 loss: 3.0106754302978516 running average of batch loss 3.0474779158830643, time 0.4893476963043213\n",
      "#Epoch 286 with total epochs 300 at step 16 loss: 2.8298091888427734 running average of batch loss 3.034673873115988, time 0.506361722946167\n",
      "#Epoch 286 with total epochs 300 at step 17 loss: 2.8125107288360596 running average of batch loss 3.022331476211548, time 0.5653719902038574\n",
      "#Epoch 286 with total epochs 300 at step 18 loss: 2.9445390701293945 running average of batch loss 3.0182371390493294, time 0.538381814956665\n",
      "#Epoch 286 with total epochs 300 at step 19 loss: 2.9533872604370117 running average of batch loss 3.0149946451187133, time 0.504331111907959\n",
      "#Epoch 286 with total epochs 300 at step 20 loss: 3.11283016204834 running average of batch loss 3.0196534792582193, time 0.5013477802276611\n",
      "#Epoch 287 with total epochs 300 at step 0 loss: 2.8988261222839355 running average of batch loss 2.8988261222839355, time 0.5243690013885498\n",
      "#Epoch 287 with total epochs 300 at step 1 loss: 2.899723529815674 running average of batch loss 2.8992748260498047, time 0.5073320865631104\n",
      "#Epoch 287 with total epochs 300 at step 2 loss: 3.0114247798919678 running average of batch loss 2.9366581439971924, time 0.5083346366882324\n",
      "#Epoch 287 with total epochs 300 at step 3 loss: 2.830448865890503 running average of batch loss 2.91010582447052, time 0.5043303966522217\n",
      "#Epoch 287 with total epochs 300 at step 4 loss: 2.888292074203491 running average of batch loss 2.9057430744171144, time 0.49832701683044434\n",
      "#Epoch 287 with total epochs 300 at step 5 loss: 3.349597930908203 running average of batch loss 2.979718883832296, time 0.5053555965423584\n",
      "#Epoch 287 with total epochs 300 at step 6 loss: 3.062614917755127 running average of batch loss 2.9915611743927, time 0.4913520812988281\n",
      "#Epoch 287 with total epochs 300 at step 7 loss: 2.6998586654663086 running average of batch loss 2.9550983607769012, time 0.4893453121185303\n",
      "#Epoch 287 with total epochs 300 at step 8 loss: 3.304702043533325 running average of batch loss 2.993943214416504, time 0.5143399238586426\n",
      "#Epoch 287 with total epochs 300 at step 9 loss: 3.3099029064178467 running average of batch loss 3.025539183616638, time 0.49932432174682617\n",
      "#Epoch 287 with total epochs 300 at step 10 loss: 3.2468483448028564 running average of batch loss 3.0456581982699307, time 0.5543956756591797\n",
      "#Epoch 287 with total epochs 300 at step 11 loss: 3.2618865966796875 running average of batch loss 3.0636772314707437, time 0.5423805713653564\n",
      "#Epoch 287 with total epochs 300 at step 12 loss: 3.0305914878845215 running average of batch loss 3.061132174271804, time 0.5413863658905029\n",
      "#Epoch 287 with total epochs 300 at step 13 loss: 3.225041389465332 running average of batch loss 3.0728399753570557, time 0.5353553295135498\n",
      "#Epoch 287 with total epochs 300 at step 14 loss: 2.8447933197021484 running average of batch loss 3.057636864980062, time 0.5153381824493408\n",
      "#Epoch 287 with total epochs 300 at step 15 loss: 3.240182638168335 running average of batch loss 3.069045975804329, time 0.5083322525024414\n",
      "#Epoch 287 with total epochs 300 at step 16 loss: 2.993380546569824 running average of batch loss 3.064595068202299, time 0.5023565292358398\n",
      "#Epoch 287 with total epochs 300 at step 17 loss: 2.749887228012085 running average of batch loss 3.047111299302843, time 0.5013270378112793\n",
      "#Epoch 287 with total epochs 300 at step 18 loss: 2.8499910831451416 running average of batch loss 3.0367365510840165, time 0.489349365234375\n",
      "#Epoch 287 with total epochs 300 at step 19 loss: 3.243600845336914 running average of batch loss 3.0470797657966613, time 0.49532437324523926\n",
      "#Epoch 287 with total epochs 300 at step 20 loss: 2.6054940223693848 running average of batch loss 3.0260518732525052, time 0.5133671760559082\n",
      "#Epoch 288 with total epochs 300 at step 0 loss: 3.031187057495117 running average of batch loss 3.031187057495117, time 0.49732255935668945\n",
      "#Epoch 288 with total epochs 300 at step 1 loss: 2.973308801651001 running average of batch loss 3.002247929573059, time 0.5243613719940186\n",
      "#Epoch 288 with total epochs 300 at step 2 loss: 2.905515432357788 running average of batch loss 2.9700037638346353, time 0.5213420391082764\n",
      "#Epoch 288 with total epochs 300 at step 3 loss: 2.908081531524658 running average of batch loss 2.954523205757141, time 0.49234938621520996\n",
      "#Epoch 288 with total epochs 300 at step 4 loss: 2.8051531314849854 running average of batch loss 2.92464919090271, time 0.526374101638794\n",
      "#Epoch 288 with total epochs 300 at step 5 loss: 2.984088897705078 running average of batch loss 2.9345558087031045, time 0.5043582916259766\n",
      "#Epoch 288 with total epochs 300 at step 6 loss: 3.0957558155059814 running average of batch loss 2.9575843811035156, time 0.5073354244232178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 288 with total epochs 300 at step 7 loss: 3.3605456352233887 running average of batch loss 3.0079545378684998, time 0.49034881591796875\n",
      "#Epoch 288 with total epochs 300 at step 8 loss: 2.9628148078918457 running average of batch loss 3.0029390123155384, time 0.5073332786560059\n",
      "#Epoch 288 with total epochs 300 at step 9 loss: 3.143014907836914 running average of batch loss 3.0169466018676756, time 0.5123629570007324\n",
      "#Epoch 288 with total epochs 300 at step 10 loss: 2.967212438583374 running average of batch loss 3.0124253142963755, time 0.5233728885650635\n",
      "#Epoch 288 with total epochs 300 at step 11 loss: 2.862095594406128 running average of batch loss 2.999897837638855, time 0.4983501434326172\n",
      "#Epoch 288 with total epochs 300 at step 12 loss: 2.990370035171509 running average of batch loss 2.9991649297567515, time 0.48864316940307617\n",
      "#Epoch 288 with total epochs 300 at step 13 loss: 3.1230287551879883 running average of batch loss 3.0080123458589827, time 0.5008792877197266\n",
      "#Epoch 288 with total epochs 300 at step 14 loss: 2.8256421089172363 running average of batch loss 2.9958543300628664, time 0.4923214912414551\n",
      "#Epoch 288 with total epochs 300 at step 15 loss: 3.0968692302703857 running average of batch loss 3.002167761325836, time 0.48232150077819824\n",
      "#Epoch 288 with total epochs 300 at step 16 loss: 2.9242007732391357 running average of batch loss 2.9975814679089714, time 0.5033547878265381\n",
      "#Epoch 288 with total epochs 300 at step 17 loss: 3.7943575382232666 running average of batch loss 3.0418468051486545, time 0.4983515739440918\n",
      "#Epoch 288 with total epochs 300 at step 18 loss: 2.7859184741973877 running average of batch loss 3.028376892993325, time 0.49532604217529297\n",
      "#Epoch 288 with total epochs 300 at step 19 loss: 2.781968116760254 running average of batch loss 3.0160564541816712, time 0.5343787670135498\n",
      "#Epoch 288 with total epochs 300 at step 20 loss: 2.9512922763824463 running average of batch loss 3.0129724457150413, time 0.4983510971069336\n",
      "#Epoch 289 with total epochs 300 at step 0 loss: 3.1191811561584473 running average of batch loss 3.1191811561584473, time 0.5243744850158691\n",
      "#Epoch 289 with total epochs 300 at step 1 loss: 2.9308531284332275 running average of batch loss 3.0250171422958374, time 0.5093328952789307\n",
      "#Epoch 289 with total epochs 300 at step 2 loss: 3.1381051540374756 running average of batch loss 3.062713146209717, time 0.5283446311950684\n",
      "#Epoch 289 with total epochs 300 at step 3 loss: 3.0576930046081543 running average of batch loss 3.061458110809326, time 0.509343147277832\n",
      "#Epoch 289 with total epochs 300 at step 4 loss: 2.9964985847473145 running average of batch loss 3.048466205596924, time 0.5483627319335938\n",
      "#Epoch 289 with total epochs 300 at step 5 loss: 3.0130505561828613 running average of batch loss 3.0425635973612466, time 0.49332499504089355\n",
      "#Epoch 289 with total epochs 300 at step 6 loss: 3.0799989700317383 running average of batch loss 3.0479115077427457, time 0.5513918399810791\n",
      "#Epoch 289 with total epochs 300 at step 7 loss: 3.015549421310425 running average of batch loss 3.0438662469387054, time 0.5143353939056396\n",
      "#Epoch 289 with total epochs 300 at step 8 loss: 2.938899278640747 running average of batch loss 3.0322032504611545, time 0.502357006072998\n",
      "#Epoch 289 with total epochs 300 at step 9 loss: 3.0171241760253906 running average of batch loss 3.030695343017578, time 0.5173680782318115\n",
      "#Epoch 289 with total epochs 300 at step 10 loss: 3.024867534637451 running average of batch loss 3.0301655422557485, time 0.5383603572845459\n",
      "#Epoch 289 with total epochs 300 at step 11 loss: 3.001009702682495 running average of batch loss 3.0277358889579773, time 0.5243730545043945\n",
      "#Epoch 289 with total epochs 300 at step 12 loss: 2.9859941005706787 running average of batch loss 3.024524982158954, time 0.48734474182128906\n",
      "#Epoch 289 with total epochs 300 at step 13 loss: 3.2170333862304688 running average of batch loss 3.038275582449777, time 0.49035024642944336\n",
      "#Epoch 289 with total epochs 300 at step 14 loss: 3.1685595512390137 running average of batch loss 3.0469611803690593, time 0.49632906913757324\n",
      "#Epoch 289 with total epochs 300 at step 15 loss: 2.9403533935546875 running average of batch loss 3.040298193693161, time 0.5033562183380127\n",
      "#Epoch 289 with total epochs 300 at step 16 loss: 3.012894630432129 running average of batch loss 3.0386862193836883, time 0.4883232116699219\n",
      "#Epoch 289 with total epochs 300 at step 17 loss: 2.885697603225708 running average of batch loss 3.0301868518193564, time 0.5213701725006104\n",
      "#Epoch 289 with total epochs 300 at step 18 loss: 3.1631784439086914 running average of batch loss 3.0371864092977425, time 0.5033309459686279\n",
      "#Epoch 289 with total epochs 300 at step 19 loss: 3.2649035453796387 running average of batch loss 3.048572266101837, time 0.4913489818572998\n",
      "#Epoch 289 with total epochs 300 at step 20 loss: 2.718118667602539 running average of batch loss 3.0328363804590133, time 0.5043580532073975\n",
      "#Epoch 290 with total epochs 300 at step 0 loss: 3.07806396484375 running average of batch loss 3.07806396484375, time 0.5063610076904297\n",
      "#Epoch 290 with total epochs 300 at step 1 loss: 3.2081992626190186 running average of batch loss 3.1431316137313843, time 0.5073363780975342\n",
      "#Epoch 290 with total epochs 300 at step 2 loss: 3.209843635559082 running average of batch loss 3.1653689543406167, time 0.5213696956634521\n",
      "#Epoch 290 with total epochs 300 at step 3 loss: 3.125037431716919 running average of batch loss 3.1552860736846924, time 0.49532437324523926\n",
      "#Epoch 290 with total epochs 300 at step 4 loss: 3.2227940559387207 running average of batch loss 3.1687876701354982, time 0.4913492202758789\n",
      "#Epoch 290 with total epochs 300 at step 5 loss: 2.779090642929077 running average of batch loss 3.1038381656010947, time 0.5093398094177246\n",
      "#Epoch 290 with total epochs 300 at step 6 loss: 2.8751940727233887 running average of batch loss 3.0711747237614224, time 0.5043601989746094\n",
      "#Epoch 290 with total epochs 300 at step 7 loss: 2.612957000732422 running average of batch loss 3.0138975083827972, time 0.507357120513916\n",
      "#Epoch 290 with total epochs 300 at step 8 loss: 2.5475008487701416 running average of batch loss 2.9620756573147244, time 0.5083367824554443\n",
      "#Epoch 290 with total epochs 300 at step 9 loss: 3.0444324016571045 running average of batch loss 2.9703113317489622, time 0.5283746719360352\n",
      "#Epoch 290 with total epochs 300 at step 10 loss: 3.5098769664764404 running average of batch loss 3.019362753087824, time 0.5193667411804199\n",
      "#Epoch 290 with total epochs 300 at step 11 loss: 3.371131420135498 running average of batch loss 3.0486768086751304, time 0.5103366374969482\n",
      "#Epoch 290 with total epochs 300 at step 12 loss: 2.831496238708496 running average of batch loss 3.0319706109853892, time 0.4873476028442383\n",
      "#Epoch 290 with total epochs 300 at step 13 loss: 3.0768563747406006 running average of batch loss 3.0351767369679044, time 0.48932719230651855\n",
      "#Epoch 290 with total epochs 300 at step 14 loss: 3.2507779598236084 running average of batch loss 3.0495501518249513, time 0.4943220615386963\n",
      "#Epoch 290 with total epochs 300 at step 15 loss: 2.9794726371765137 running average of batch loss 3.045170307159424, time 0.5103633403778076\n",
      "#Epoch 290 with total epochs 300 at step 16 loss: 2.8283653259277344 running average of batch loss 3.0324170729693245, time 0.4963524341583252\n",
      "#Epoch 290 with total epochs 300 at step 17 loss: 4.174457550048828 running average of batch loss 3.095863766140408, time 0.4863464832305908\n",
      "#Epoch 290 with total epochs 300 at step 18 loss: 2.9202375411987305 running average of batch loss 3.086620280617162, time 0.5003502368927002\n",
      "#Epoch 290 with total epochs 300 at step 19 loss: 3.300133228302002 running average of batch loss 3.0972959280014036, time 0.49632954597473145\n",
      "#Epoch 290 with total epochs 300 at step 20 loss: 3.316708564758301 running average of batch loss 3.1077441487993513, time 0.49935126304626465\n",
      "#Epoch 291 with total epochs 300 at step 0 loss: 3.028038263320923 running average of batch loss 3.028038263320923, time 0.5123639106750488\n",
      "#Epoch 291 with total epochs 300 at step 1 loss: 3.26996111869812 running average of batch loss 3.1489996910095215, time 0.5003314018249512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 291 with total epochs 300 at step 2 loss: 3.0241057872772217 running average of batch loss 3.1073683897654214, time 0.5293481349945068\n",
      "#Epoch 291 with total epochs 300 at step 3 loss: 3.2560248374938965 running average of batch loss 3.1445325016975403, time 0.5083560943603516\n",
      "#Epoch 291 with total epochs 300 at step 4 loss: 3.63885235786438 running average of batch loss 3.2433964729309084, time 0.5183446407318115\n",
      "#Epoch 291 with total epochs 300 at step 5 loss: 3.438612222671509 running average of batch loss 3.2759324312210083, time 0.49035096168518066\n",
      "#Epoch 291 with total epochs 300 at step 6 loss: 2.7693912982940674 running average of batch loss 3.2035694122314453, time 0.5123345851898193\n",
      "#Epoch 291 with total epochs 300 at step 7 loss: 2.9085752964019775 running average of batch loss 3.166695147752762, time 0.5133669376373291\n",
      "#Epoch 291 with total epochs 300 at step 8 loss: 3.392831325531006 running average of batch loss 3.1918213897281222, time 0.552391767501831\n",
      "#Epoch 291 with total epochs 300 at step 9 loss: 3.076422691345215 running average of batch loss 3.1802815198898315, time 0.4953272342681885\n",
      "#Epoch 291 with total epochs 300 at step 10 loss: 3.004664897918701 running average of batch loss 3.1643163724379106, time 0.5353548526763916\n",
      "#Epoch 291 with total epochs 300 at step 11 loss: 2.9389185905456543 running average of batch loss 3.1455332239468894, time 0.48832225799560547\n",
      "#Epoch 291 with total epochs 300 at step 12 loss: 3.093003988265991 running average of batch loss 3.141492513509897, time 0.49935364723205566\n",
      "#Epoch 291 with total epochs 300 at step 13 loss: 3.1895172595977783 running average of batch loss 3.1449228525161743, time 0.5243728160858154\n",
      "#Epoch 291 with total epochs 300 at step 14 loss: 3.244480609893799 running average of batch loss 3.1515600363413494, time 0.5023317337036133\n",
      "#Epoch 291 with total epochs 300 at step 15 loss: 3.3494510650634766 running average of batch loss 3.1639282256364822, time 0.5013315677642822\n",
      "#Epoch 291 with total epochs 300 at step 16 loss: 2.9723713397979736 running average of batch loss 3.152660173528335, time 0.5063595771789551\n",
      "#Epoch 291 with total epochs 300 at step 17 loss: 2.778452157974243 running average of batch loss 3.131870839330885, time 0.5053331851959229\n",
      "#Epoch 291 with total epochs 300 at step 18 loss: 3.0645856857299805 running average of batch loss 3.1283295154571533, time 0.5053572654724121\n",
      "#Epoch 291 with total epochs 300 at step 19 loss: 2.9782516956329346 running average of batch loss 3.1208256244659425, time 0.49134087562561035\n",
      "#Epoch 291 with total epochs 300 at step 20 loss: 3.06595778465271 running average of batch loss 3.118212870189122, time 0.530376672744751\n",
      "#Epoch 292 with total epochs 300 at step 0 loss: 3.0541253089904785 running average of batch loss 3.0541253089904785, time 0.49632763862609863\n",
      "#Epoch 292 with total epochs 300 at step 1 loss: 3.0584278106689453 running average of batch loss 3.056276559829712, time 0.49935126304626465\n",
      "#Epoch 292 with total epochs 300 at step 2 loss: 3.4438488483428955 running average of batch loss 3.18546732266744, time 0.5033347606658936\n",
      "#Epoch 292 with total epochs 300 at step 3 loss: 2.752042293548584 running average of batch loss 3.077111065387726, time 0.5043609142303467\n",
      "#Epoch 292 with total epochs 300 at step 4 loss: 2.8841681480407715 running average of batch loss 3.038522481918335, time 0.4913506507873535\n",
      "#Epoch 292 with total epochs 300 at step 5 loss: 2.885136604309082 running average of batch loss 3.0129581689834595, time 0.5233714580535889\n",
      "#Epoch 292 with total epochs 300 at step 6 loss: 2.8735318183898926 running average of batch loss 2.9930401188986644, time 0.49632787704467773\n",
      "#Epoch 292 with total epochs 300 at step 7 loss: 2.8422672748565674 running average of batch loss 2.974193513393402, time 0.5293748378753662\n",
      "#Epoch 292 with total epochs 300 at step 8 loss: 2.885596990585327 running average of batch loss 2.964349455303616, time 0.5053579807281494\n",
      "#Epoch 292 with total epochs 300 at step 9 loss: 2.673436164855957 running average of batch loss 2.93525812625885, time 0.4943242073059082\n",
      "#Epoch 292 with total epochs 300 at step 10 loss: 3.0272998809814453 running average of batch loss 2.943625558506359, time 0.5303483009338379\n",
      "#Epoch 292 with total epochs 300 at step 11 loss: 3.0962958335876465 running average of batch loss 2.9563480814297995, time 0.49735522270202637\n",
      "#Epoch 292 with total epochs 300 at step 12 loss: 2.5503056049346924 running average of batch loss 2.9251140447763295, time 0.5043308734893799\n",
      "#Epoch 292 with total epochs 300 at step 13 loss: 3.146522283554077 running average of batch loss 2.9409289189747403, time 0.5043327808380127\n",
      "#Epoch 292 with total epochs 300 at step 14 loss: 3.0730366706848145 running average of batch loss 2.9497361024220785, time 0.5223433971405029\n",
      "#Epoch 292 with total epochs 300 at step 15 loss: 2.854004383087158 running average of batch loss 2.943752869963646, time 0.507357120513916\n",
      "#Epoch 292 with total epochs 300 at step 16 loss: 3.0322036743164062 running average of batch loss 2.9489558584549846, time 0.49535489082336426\n",
      "#Epoch 292 with total epochs 300 at step 17 loss: 3.163935422897339 running average of batch loss 2.960899167590671, time 0.5053322315216064\n",
      "#Epoch 292 with total epochs 300 at step 18 loss: 3.0069236755371094 running average of batch loss 2.963321510114168, time 0.5373528003692627\n",
      "#Epoch 292 with total epochs 300 at step 19 loss: 2.855912446975708 running average of batch loss 2.9579510569572447, time 0.5003304481506348\n",
      "#Epoch 292 with total epochs 300 at step 20 loss: 3.2482547760009766 running average of batch loss 2.9717750435783747, time 0.5533561706542969\n",
      "#Epoch 293 with total epochs 300 at step 0 loss: 3.291079521179199 running average of batch loss 3.291079521179199, time 0.5113646984100342\n",
      "#Epoch 293 with total epochs 300 at step 1 loss: 3.203451633453369 running average of batch loss 3.247265577316284, time 0.582383394241333\n",
      "#Epoch 293 with total epochs 300 at step 2 loss: 2.93615984916687 running average of batch loss 3.143563667933146, time 0.5123670101165771\n",
      "#Epoch 293 with total epochs 300 at step 3 loss: 3.352466344833374 running average of batch loss 3.195789337158203, time 0.5053298473358154\n",
      "#Epoch 293 with total epochs 300 at step 4 loss: 3.04239559173584 running average of batch loss 3.1651105880737305, time 0.499356746673584\n",
      "#Epoch 293 with total epochs 300 at step 5 loss: 2.797818899154663 running average of batch loss 3.1038953065872192, time 0.5083365440368652\n",
      "#Epoch 293 with total epochs 300 at step 6 loss: 3.1052589416503906 running average of batch loss 3.1040901115962436, time 0.48834919929504395\n",
      "#Epoch 293 with total epochs 300 at step 7 loss: 3.050583600997925 running average of batch loss 3.097401797771454, time 0.5033562183380127\n",
      "#Epoch 293 with total epochs 300 at step 8 loss: 3.169869899749756 running average of batch loss 3.1054538091023765, time 0.5353531837463379\n",
      "#Epoch 293 with total epochs 300 at step 9 loss: 2.9761040210723877 running average of batch loss 3.0925188302993774, time 0.48834872245788574\n",
      "#Epoch 293 with total epochs 300 at step 10 loss: 3.242854118347168 running average of batch loss 3.1061856746673584, time 0.5083358287811279\n",
      "#Epoch 293 with total epochs 300 at step 11 loss: 2.846193313598633 running average of batch loss 3.084519644578298, time 0.5063331127166748\n",
      "#Epoch 293 with total epochs 300 at step 12 loss: 2.829974412918091 running average of batch loss 3.0649392421428976, time 0.5053329467773438\n",
      "#Epoch 293 with total epochs 300 at step 13 loss: 3.16617488861084 running average of batch loss 3.0721703597477505, time 0.5023345947265625\n",
      "#Epoch 293 with total epochs 300 at step 14 loss: 2.834169626235962 running average of batch loss 3.0563036441802978, time 0.4963560104370117\n",
      "#Epoch 293 with total epochs 300 at step 15 loss: 2.8034021854400635 running average of batch loss 3.040497303009033, time 0.5153632164001465\n",
      "#Epoch 293 with total epochs 300 at step 16 loss: 3.1267237663269043 running average of batch loss 3.0455694479100845, time 0.5493638515472412\n",
      "#Epoch 293 with total epochs 300 at step 17 loss: 2.955899715423584 running average of batch loss 3.040587796105279, time 0.514366865158081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 293 with total epochs 300 at step 18 loss: 3.104048490524292 running average of batch loss 3.043927832653648, time 0.5093593597412109\n",
      "#Epoch 293 with total epochs 300 at step 19 loss: 3.297903537750244 running average of batch loss 3.056626617908478, time 0.501356840133667\n",
      "#Epoch 293 with total epochs 300 at step 20 loss: 3.075313091278076 running average of batch loss 3.0575164499736966, time 0.4883286952972412\n",
      "#Epoch 294 with total epochs 300 at step 0 loss: 2.8986172676086426 running average of batch loss 2.8986172676086426, time 0.500330924987793\n",
      "#Epoch 294 with total epochs 300 at step 1 loss: 3.083861827850342 running average of batch loss 2.991239547729492, time 0.5053579807281494\n",
      "#Epoch 294 with total epochs 300 at step 2 loss: 3.1558127403259277 running average of batch loss 3.0460972785949707, time 0.49732518196105957\n",
      "#Epoch 294 with total epochs 300 at step 3 loss: 2.9360268115997314 running average of batch loss 3.018579661846161, time 0.4893479347229004\n",
      "#Epoch 294 with total epochs 300 at step 4 loss: 3.20719838142395 running average of batch loss 3.0563034057617187, time 0.5093369483947754\n",
      "#Epoch 294 with total epochs 300 at step 5 loss: 2.75589919090271 running average of batch loss 3.0062360366185508, time 0.4903452396392822\n",
      "#Epoch 294 with total epochs 300 at step 6 loss: 2.8958728313446045 running average of batch loss 2.9904698644365584, time 0.5163695812225342\n",
      "#Epoch 294 with total epochs 300 at step 7 loss: 2.741616725921631 running average of batch loss 2.9593632221221924, time 0.5053305625915527\n",
      "#Epoch 294 with total epochs 300 at step 8 loss: 3.037539482116699 running average of batch loss 2.968049473232693, time 0.486339807510376\n",
      "#Epoch 294 with total epochs 300 at step 9 loss: 2.9655332565307617 running average of batch loss 2.9677978515625, time 0.4863452911376953\n",
      "#Epoch 294 with total epochs 300 at step 10 loss: 2.9812796115875244 running average of batch loss 2.9690234661102295, time 0.4933505058288574\n",
      "#Epoch 294 with total epochs 300 at step 11 loss: 2.904048442840576 running average of batch loss 2.9636088808377585, time 0.4843440055847168\n",
      "#Epoch 294 with total epochs 300 at step 12 loss: 3.1111457347869873 running average of batch loss 2.9749578696030836, time 0.5133655071258545\n",
      "#Epoch 294 with total epochs 300 at step 13 loss: 3.0193676948547363 running average of batch loss 2.9781299999782016, time 0.5003361701965332\n",
      "#Epoch 294 with total epochs 300 at step 14 loss: 3.029128313064575 running average of batch loss 2.981529887517293, time 0.553391695022583\n",
      "#Epoch 294 with total epochs 300 at step 15 loss: 3.3146920204162598 running average of batch loss 3.0023525208234787, time 0.5003292560577393\n",
      "#Epoch 294 with total epochs 300 at step 16 loss: 3.1499266624450684 running average of batch loss 3.0110333526835724, time 0.5003271102905273\n",
      "#Epoch 294 with total epochs 300 at step 17 loss: 2.8349204063415527 running average of batch loss 3.0012493001090155, time 0.551363468170166\n",
      "#Epoch 294 with total epochs 300 at step 18 loss: 3.2652082443237305 running average of batch loss 3.015141876120316, time 0.49034953117370605\n",
      "#Epoch 294 with total epochs 300 at step 19 loss: 2.7943432331085205 running average of batch loss 3.0041019439697267, time 0.5003523826599121\n",
      "#Epoch 294 with total epochs 300 at step 20 loss: 3.021305561065674 running average of batch loss 3.004921163831438, time 0.4803175926208496\n",
      "#Epoch 295 with total epochs 300 at step 0 loss: 3.0284228324890137 running average of batch loss 3.0284228324890137, time 0.48334479331970215\n",
      "#Epoch 295 with total epochs 300 at step 1 loss: 3.007272481918335 running average of batch loss 3.0178476572036743, time 0.48734593391418457\n",
      "#Epoch 295 with total epochs 300 at step 2 loss: 3.275775909423828 running average of batch loss 3.103823741277059, time 0.5413832664489746\n",
      "#Epoch 295 with total epochs 300 at step 3 loss: 3.0912554264068604 running average of batch loss 3.1006816625595093, time 0.5014190673828125\n",
      "#Epoch 295 with total epochs 300 at step 4 loss: 3.015359878540039 running average of batch loss 3.0836173057556153, time 0.5011656284332275\n",
      "#Epoch 295 with total epochs 300 at step 5 loss: 3.1659157276153564 running average of batch loss 3.0973337093989053, time 0.5023300647735596\n",
      "#Epoch 295 with total epochs 300 at step 6 loss: 2.828842878341675 running average of batch loss 3.05897787639073, time 0.4883229732513428\n",
      "#Epoch 295 with total epochs 300 at step 7 loss: 3.0891427993774414 running average of batch loss 3.0627484917640686, time 0.5083615779876709\n",
      "#Epoch 295 with total epochs 300 at step 8 loss: 3.17815899848938 running average of batch loss 3.075571881400214, time 0.500328779220581\n",
      "#Epoch 295 with total epochs 300 at step 9 loss: 3.0990755558013916 running average of batch loss 3.077922248840332, time 0.4883444309234619\n",
      "#Epoch 295 with total epochs 300 at step 10 loss: 2.8798158168792725 running average of batch loss 3.0599125732075083, time 0.48932623863220215\n",
      "#Epoch 295 with total epochs 300 at step 11 loss: 3.1532063484191895 running average of batch loss 3.0676870544751487, time 0.4883239269256592\n",
      "#Epoch 295 with total epochs 300 at step 12 loss: 2.6032302379608154 running average of batch loss 3.031959607050969, time 0.5033347606658936\n",
      "#Epoch 295 with total epochs 300 at step 13 loss: 2.927945613861084 running average of batch loss 3.0245300361088345, time 0.48731327056884766\n",
      "#Epoch 295 with total epochs 300 at step 14 loss: 2.9503142833709717 running average of batch loss 3.0195823192596434, time 0.5023536682128906\n",
      "#Epoch 295 with total epochs 300 at step 15 loss: 3.22489070892334 running average of batch loss 3.0324140936136246, time 0.5244550704956055\n",
      "#Epoch 295 with total epochs 300 at step 16 loss: 3.279423952102661 running average of batch loss 3.04694408528945, time 0.5068600177764893\n",
      "#Epoch 295 with total epochs 300 at step 17 loss: 3.060342788696289 running average of batch loss 3.047688457700941, time 0.5053331851959229\n",
      "#Epoch 295 with total epochs 300 at step 18 loss: 3.0649209022521973 running average of batch loss 3.048595428466797, time 0.50836181640625\n",
      "#Epoch 295 with total epochs 300 at step 19 loss: 3.299945116043091 running average of batch loss 3.0611629128456115, time 0.5373573303222656\n",
      "#Epoch 295 with total epochs 300 at step 20 loss: 2.9329404830932617 running average of batch loss 3.0550570828574046, time 0.5283751487731934\n",
      "#Epoch 296 with total epochs 300 at step 0 loss: 3.220378875732422 running average of batch loss 3.220378875732422, time 0.5133378505706787\n",
      "#Epoch 296 with total epochs 300 at step 1 loss: 3.2016849517822266 running average of batch loss 3.211031913757324, time 0.4883244037628174\n",
      "#Epoch 296 with total epochs 300 at step 2 loss: 3.418466806411743 running average of batch loss 3.280176877975464, time 0.49632787704467773\n",
      "#Epoch 296 with total epochs 300 at step 3 loss: 2.869457483291626 running average of batch loss 3.1774970293045044, time 0.4983551502227783\n",
      "#Epoch 296 with total epochs 300 at step 4 loss: 3.0622875690460205 running average of batch loss 3.154455137252808, time 0.5013275146484375\n",
      "#Epoch 296 with total epochs 300 at step 5 loss: 2.838235378265381 running average of batch loss 3.1017518440882363, time 0.51837158203125\n",
      "#Epoch 296 with total epochs 300 at step 6 loss: 2.9260547161102295 running average of batch loss 3.0766522543770924, time 0.5323772430419922\n",
      "#Epoch 296 with total epochs 300 at step 7 loss: 2.8048863410949707 running average of batch loss 3.0426815152168274, time 0.5023558139801025\n",
      "#Epoch 296 with total epochs 300 at step 8 loss: 3.0140199661254883 running average of batch loss 3.039496898651123, time 0.5433657169342041\n",
      "#Epoch 296 with total epochs 300 at step 9 loss: 3.0327072143554688 running average of batch loss 3.0388179302215574, time 0.5283751487731934\n",
      "#Epoch 296 with total epochs 300 at step 10 loss: 3.2424983978271484 running average of batch loss 3.0573343363675205, time 0.5283472537994385\n",
      "#Epoch 296 with total epochs 300 at step 11 loss: 2.6343021392822266 running average of batch loss 3.022081653277079, time 0.5093591213226318\n",
      "#Epoch 296 with total epochs 300 at step 12 loss: 3.120995044708252 running average of batch loss 3.029690375694862, time 0.5223486423492432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 296 with total epochs 300 at step 13 loss: 2.971745729446411 running average of batch loss 3.025551472391401, time 0.49134254455566406\n",
      "#Epoch 296 with total epochs 300 at step 14 loss: 2.917851686477661 running average of batch loss 3.0183714866638183, time 0.49035000801086426\n",
      "#Epoch 296 with total epochs 300 at step 15 loss: 3.1767802238464355 running average of batch loss 3.028272032737732, time 0.5433597564697266\n",
      "#Epoch 296 with total epochs 300 at step 16 loss: 3.3358006477355957 running average of batch loss 3.046361951267018, time 0.5353829860687256\n",
      "#Epoch 296 with total epochs 300 at step 17 loss: 3.026358127593994 running average of batch loss 3.0452506277296276, time 0.5183391571044922\n",
      "#Epoch 296 with total epochs 300 at step 18 loss: 3.321506977081299 running average of batch loss 3.059790435590242, time 0.5233736038208008\n",
      "#Epoch 296 with total epochs 300 at step 19 loss: 2.7928237915039062 running average of batch loss 3.0464421033859255, time 0.5013270378112793\n",
      "#Epoch 296 with total epochs 300 at step 20 loss: 3.203011989593506 running average of batch loss 3.053897812252953, time 0.5223703384399414\n",
      "#Epoch 297 with total epochs 300 at step 0 loss: 2.870500326156616 running average of batch loss 2.870500326156616, time 0.5063588619232178\n",
      "#Epoch 297 with total epochs 300 at step 1 loss: 3.2420363426208496 running average of batch loss 3.056268334388733, time 0.5023305416107178\n",
      "#Epoch 297 with total epochs 300 at step 2 loss: 3.1630373001098633 running average of batch loss 3.09185798962911, time 0.5724031925201416\n",
      "#Epoch 297 with total epochs 300 at step 3 loss: 2.993962526321411 running average of batch loss 3.067384123802185, time 0.5303475856781006\n",
      "#Epoch 297 with total epochs 300 at step 4 loss: 2.891334056854248 running average of batch loss 3.0321741104125977, time 0.5803859233856201\n",
      "#Epoch 297 with total epochs 300 at step 5 loss: 2.957016706466675 running average of batch loss 3.0196478764216104, time 0.5063397884368896\n",
      "#Epoch 297 with total epochs 300 at step 6 loss: 2.7893998622894287 running average of batch loss 2.986755302974156, time 0.5273597240447998\n",
      "#Epoch 297 with total epochs 300 at step 7 loss: 3.2194929122924805 running average of batch loss 3.0158475041389465, time 0.5173428058624268\n",
      "#Epoch 297 with total epochs 300 at step 8 loss: 3.111396074295044 running average of batch loss 3.0264640119340687, time 0.4963505268096924\n",
      "#Epoch 297 with total epochs 300 at step 9 loss: 2.8964314460754395 running average of batch loss 3.0134607553482056, time 0.490325927734375\n",
      "#Epoch 297 with total epochs 300 at step 10 loss: 2.7924141883850098 running average of batch loss 2.993365612897006, time 0.5123395919799805\n",
      "#Epoch 297 with total epochs 300 at step 11 loss: 3.2046396732330322 running average of batch loss 3.010971784591675, time 0.5163421630859375\n",
      "#Epoch 297 with total epochs 300 at step 12 loss: 3.1229543685913086 running average of batch loss 3.0195858295147238, time 0.4983532428741455\n",
      "#Epoch 297 with total epochs 300 at step 13 loss: 3.139953374862671 running average of batch loss 3.0281835113252913, time 0.5043342113494873\n",
      "#Epoch 297 with total epochs 300 at step 14 loss: 3.0470032691955566 running average of batch loss 3.0294381618499755, time 0.5053548812866211\n",
      "#Epoch 297 with total epochs 300 at step 15 loss: 3.0877208709716797 running average of batch loss 3.033080831170082, time 0.5023574829101562\n",
      "#Epoch 297 with total epochs 300 at step 16 loss: 3.308375835418701 running average of batch loss 3.0492746549494125, time 0.5403542518615723\n",
      "#Epoch 297 with total epochs 300 at step 17 loss: 2.882951021194458 running average of batch loss 3.040034453074137, time 0.48834943771362305\n",
      "#Epoch 297 with total epochs 300 at step 18 loss: 3.2310869693756104 running average of batch loss 3.050089848668952, time 0.527350902557373\n",
      "#Epoch 297 with total epochs 300 at step 19 loss: 2.8787097930908203 running average of batch loss 3.0415208458900453, time 0.5073614120483398\n",
      "#Epoch 297 with total epochs 300 at step 20 loss: 2.8389503955841064 running average of batch loss 3.0318746339707148, time 0.5093591213226318\n",
      "#Epoch 298 with total epochs 300 at step 0 loss: 2.793513298034668 running average of batch loss 2.793513298034668, time 0.5123674869537354\n",
      "#Epoch 298 with total epochs 300 at step 1 loss: 3.2500383853912354 running average of batch loss 3.0217758417129517, time 0.5063610076904297\n",
      "#Epoch 298 with total epochs 300 at step 2 loss: 3.621061325073242 running average of batch loss 3.2215376694997153, time 0.5063323974609375\n",
      "#Epoch 298 with total epochs 300 at step 3 loss: 3.0371270179748535 running average of batch loss 3.1754350066184998, time 0.5213699340820312\n",
      "#Epoch 298 with total epochs 300 at step 4 loss: 2.977405548095703 running average of batch loss 3.1358291149139403, time 0.50433349609375\n",
      "#Epoch 298 with total epochs 300 at step 5 loss: 2.924224376678467 running average of batch loss 3.1005616585413613, time 0.4973297119140625\n",
      "#Epoch 298 with total epochs 300 at step 6 loss: 3.178346633911133 running average of batch loss 3.1116737978799, time 0.5313496589660645\n",
      "#Epoch 298 with total epochs 300 at step 7 loss: 2.983600616455078 running average of batch loss 3.0956646502017975, time 0.49035143852233887\n",
      "#Epoch 298 with total epochs 300 at step 8 loss: 3.0870022773742676 running average of batch loss 3.094702164332072, time 0.4893198013305664\n",
      "#Epoch 298 with total epochs 300 at step 9 loss: 3.0696401596069336 running average of batch loss 3.092195963859558, time 0.506359338760376\n",
      "#Epoch 298 with total epochs 300 at step 10 loss: 3.0208091735839844 running average of batch loss 3.085706255652688, time 0.501328706741333\n",
      "#Epoch 298 with total epochs 300 at step 11 loss: 3.033203601837158 running average of batch loss 3.081331034501394, time 0.5023314952850342\n",
      "#Epoch 298 with total epochs 300 at step 12 loss: 3.0115840435028076 running average of batch loss 3.0759658813476562, time 0.58638596534729\n",
      "#Epoch 298 with total epochs 300 at step 13 loss: 2.9544010162353516 running average of batch loss 3.0672826766967773, time 0.5213711261749268\n",
      "#Epoch 298 with total epochs 300 at step 14 loss: 2.9254024028778076 running average of batch loss 3.057823991775513, time 0.5503873825073242\n",
      "#Epoch 298 with total epochs 300 at step 15 loss: 2.9902920722961426 running average of batch loss 3.053603246808052, time 0.4983558654785156\n",
      "#Epoch 298 with total epochs 300 at step 16 loss: 3.0571281909942627 running average of batch loss 3.0538105964660645, time 0.5113625526428223\n",
      "#Epoch 298 with total epochs 300 at step 17 loss: 3.0517585277557373 running average of batch loss 3.053696592648824, time 0.5263760089874268\n",
      "#Epoch 298 with total epochs 300 at step 18 loss: 2.8661105632781982 running average of batch loss 3.0438236437345805, time 0.49935269355773926\n",
      "#Epoch 298 with total epochs 300 at step 19 loss: 3.2707719802856445 running average of batch loss 3.0551710605621336, time 0.48732638359069824\n",
      "#Epoch 298 with total epochs 300 at step 20 loss: 2.8255269527435303 running average of batch loss 3.044235626856486, time 0.4943230152130127\n",
      "#Epoch 299 with total epochs 300 at step 0 loss: 2.9308018684387207 running average of batch loss 2.9308018684387207, time 0.5343794822692871\n",
      "#Epoch 299 with total epochs 300 at step 1 loss: 3.038665294647217 running average of batch loss 2.9847335815429688, time 0.5023536682128906\n",
      "#Epoch 299 with total epochs 300 at step 2 loss: 2.794882297515869 running average of batch loss 2.921449820200602, time 0.49532580375671387\n",
      "#Epoch 299 with total epochs 300 at step 3 loss: 3.04338002204895 running average of batch loss 2.951932370662689, time 0.4983506202697754\n",
      "#Epoch 299 with total epochs 300 at step 4 loss: 2.936579704284668 running average of batch loss 2.948861837387085, time 0.5023312568664551\n",
      "#Epoch 299 with total epochs 300 at step 5 loss: 3.0713155269622803 running average of batch loss 2.9692707856496177, time 0.5053284168243408\n",
      "#Epoch 299 with total epochs 300 at step 6 loss: 2.772603750228882 running average of batch loss 2.941175494875227, time 0.5263736248016357\n",
      "#Epoch 299 with total epochs 300 at step 7 loss: 3.312459945678711 running average of batch loss 2.9875860512256622, time 0.5043585300445557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 299 with total epochs 300 at step 8 loss: 3.3255085945129395 running average of batch loss 3.025133000479804, time 0.509361982345581\n",
      "#Epoch 299 with total epochs 300 at step 9 loss: 3.1684203147888184 running average of batch loss 3.0394617319107056, time 0.5353529453277588\n",
      "#Epoch 299 with total epochs 300 at step 10 loss: 2.9183151721954346 running average of batch loss 3.0284484083002265, time 0.5123610496520996\n",
      "#Epoch 299 with total epochs 300 at step 11 loss: 3.3531105518341064 running average of batch loss 3.0555035869280496, time 0.5033321380615234\n",
      "#Epoch 299 with total epochs 300 at step 12 loss: 3.1253252029418945 running average of batch loss 3.060874480467576, time 0.5033309459686279\n",
      "#Epoch 299 with total epochs 300 at step 13 loss: 3.043393135070801 running average of batch loss 3.059625812939235, time 0.5043303966522217\n",
      "#Epoch 299 with total epochs 300 at step 14 loss: 3.4736461639404297 running average of batch loss 3.0872271696726483, time 0.4873473644256592\n",
      "#Epoch 299 with total epochs 300 at step 15 loss: 3.22306489944458 running average of batch loss 3.095717027783394, time 0.4953489303588867\n",
      "#Epoch 299 with total epochs 300 at step 16 loss: 2.917013645172119 running average of batch loss 3.0852050641003776, time 0.5593736171722412\n",
      "#Epoch 299 with total epochs 300 at step 17 loss: 3.1908295154571533 running average of batch loss 3.091073089175754, time 0.4983522891998291\n",
      "#Epoch 299 with total epochs 300 at step 18 loss: 3.1524741649627686 running average of batch loss 3.0943047247434916, time 0.5543680191040039\n",
      "#Epoch 299 with total epochs 300 at step 19 loss: 2.9909987449645996 running average of batch loss 3.089139425754547, time 0.49532461166381836\n",
      "#Epoch 299 with total epochs 300 at step 20 loss: 2.9430837631225586 running average of batch loss 3.082184394200643, time 0.48731350898742676\n",
      "avg difference between predicted and ground truth batch wise 5.049549862759455\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(next_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=30\n",
    "\n",
    "print(y[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "for i in range(32):\n",
    "    print(y[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "for i in range(32):\n",
    "    print(np.around(y[i],decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.load('20gt_asp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.load('20predic_asp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=np.reshape(x,(-1,1984))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=np.reshape(y,(-1,1984))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xx,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloworld\n"
     ]
    }
   ],
   "source": [
    "name='world'\n",
    "\n",
    "print('hello'+str(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
